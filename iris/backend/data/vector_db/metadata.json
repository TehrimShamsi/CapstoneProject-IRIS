{
  "id_map": [
    {
      "paper_id": "test",
      "doc_id": 0,
      "text": "This is a test sentence for embedding"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 0,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 1,
      "text": "Artificial Intelligence and Economic Theories  \nTshilidzi Marwala and Evan Hurwitz  \nUniversity of Johannesburg  \n \nAbstract  \nThe advent of artificial intelligence has changed many disciplines such as engineering, social \nscience and economics. Artificial intelligence is a computational technique which is inspired by \nnatural intelligence such as the swarming of birds, the working of the brain and the pathfinding of \nthe ants. These techniques have  impact on economic theories . This book studies the impact of \nartificial intelligence on economic theories, a subject that has not been extensively studied. The \ntheorie s that are considered are : demand and supply,  asymmetrical information, pricing, rational \nchoice, rational expectation, game theory, efficient market hypotheses, mechanism design, \nprospect, bounded rationality, portfolio  theory , rational counterfactual and causality. The benefit \nof this book is that it evaluates existing theories of economics and update them based on the \ndevelopments in artificial intel ligence field.  \n1.1 Introduction  \n\u201cWorkers of the world unite, you have nothing to lose but chains\u201d so said Karl Marx  (Marx, 1849) . \nDespite what many Marxists claim, he never foretold the advent of artificial intelligence, otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 1,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 2,
      "text": "otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man. Man is \nthe invisible hand that drives the economy as observed by Adam Smith  (Smith, 2015) . The \neconomy was by man and about man but the theories that explained the economy did not quite \nmatch the behaviour of a man. For this reason the rational man is indeed irrational and his \nirrationality permeates every aspect of life including the very concept  we call the economy.   \n \nHomo -Sapiens have been around for hundred thousand years and throughout their existence and \neven from their forbearers have inherited certain traits and behaviours that influence them even \ntoday  (Harari, 2014) . Some of these traits and behaviours include greed, fear, bias and social \nstructure. All these traits are still with us today because of one and only one reason and that it \nbecause they all have given us an evolutionary advantage. Of course, this might ch ange in the \nfuture depending on the change of environment and therefore these traits might depart from human \nbeings. All these traits influence our decision making and the rationality thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 2,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 3,
      "text": "ty thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality. Our rationality is bound \nto all these constraints but what will happen when machine replaces humans. Is the rationality of \nmachines b ound? (Simon, 1991) Are the bounds of rationality bigger in humans than machines? \nThese are some of the questions that this book seeks to answer.  \n \nMachines are now part of everyday decision making.  They are becoming more intelligent due to \na technology ca lled artificial intelligence (AI). Alan Turing surmised that machines are intelligent \nif and only if when we interact with them we cannot tell whether we are interacting with a man or \na machine  (Traiger, 2000) . This is what is called a Turing test. No mach ine has passed this Turing \ntest over an extended levels of man -machine interaction. But this does not limit artificial \nintelligence and make machines incapable of solving complex problems.  \n \nThis paper  describes man -machine interaction and its impact on som e of the big ideas in \neconomics. Every economic epoch had its own theories or thinking. Some of these theories stood \nthe test of time but some have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 3,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 4,
      "text": "me have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England. What is not clear is why it did not happen in Asia especially India or China as \nprobabilistically these two regions had higher population densities. What was the catalyst tha t \ncaused the first industrial revolution? In the 17 century lived a man in England called Isaac Newton \nwho was educated at  Trinity College Cambridge  (Newton, 1726) . Legend claims that unlike many \npeople who had lived before him and had witnessed an apple f alling, he asked: \u201cWhy did the apple \nfall?\u201d And from this he discovered gravity an intriguing concept which was only given  an \nexplanation by a German/Swiss/American scientist Albert Einstein some hundreds of years later. \nNewton, furthermore, came with what  is now called the laws of motion which stated that objects \nwill continue at rest or keep on moving until they are moved or stopped respectively. Furthermore, \nhe observed the relationship between force, mass of an object and its acceleration. This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 4,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 5,
      "text": ". This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production. From this \nera economic principles such as Marxism, Adam Smith\u2019s invisible  hand as well as David Ricardo\u2019s \nlabor theory of value and the principle of comparative advantage were conceived  (de Vivo, 1987) .   \n \nThen in the 19th century came a British man called Michael Faraday who performed crucial \nexperiments which were later inter preted by James Clerk Maxwell through his beautiful \nmathematical equations  (Maxwell, 1873; Agassi, 1971) . Michael Faraday observed that if you \nhave a magnet and you put next to it a wire that conducts electricity and you move the wire, then \nelectricity flo ws in that conductor. This is wizardry beyond miracles of biblical proportions. Even \ntoday we generate electricity, perhaps with the exception of solar energy and few others, using this \ntechnique. Conversely, Faraday observed that again with a magnet and a  conducting wire and you \nforce electricity through the wire, then the wire moves and this was the birth of the electric motor \nthat still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 5,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 6,
      "text": "at still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced.   \n \nThen in the second half of the 20th century John Bardeen, Walter Brattain, and William Shockley \ndiscovered the transistor  (Amos and James, 1987) . It is based on semiconductors which are objects \nthat conduct electricity under certain conditions. The transistor is the catalyst for the electronic age \nthat gave us computers, cell phones, information technology and automation in our factories. It is \nthe DNA of the third industrial revoluti on. It was in the era that powerful economic concepts such \nas market efficiency where introduced prospect theory.  \n \nThe era we are living is the fourth industrial revolution. This is an era of intelligent machine  \n(Marwala, 2007; 2009; 2010; 2012; 2013; 2014 ; 2015; Marwala and Lagazio, 2012; Marwala et \nal, 2016) . The DNA of the fourth industrial revolution is AI. It will touch all aspects of our lives. \nWe will have robotic cops to protect us, robotic doctors to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 6,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 7,
      "text": "rs to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced.  What will happen to economics? Already \nwe know that the stock market no longer has crowds of people shouting a price of stocks because \nartificial intelligent software are doing the work. This paper  explores how economic theories that \nhave guided decision makers in the past will have to change or adapted in the light of artificial \nintelligent capabilities.     \n1.2 E conomics and Economic Theory  \nEconomics began when man started battering for exchanging goods. This was mainly based on the \nreality that man could not produce all he wanted. For example, suppose we have a man called Peter \nwho produces maize and another call ed John who produces peanuts. Then Peter will give half of \nhis maize for half of John\u2019s peanuts. If we include a third person Aiden who produces wheat, then \nPeter takes a third of his maize and gives it to John in exchange of a third of his peanuts, gives \nanother third to Aiden in exchange of his third of wheat. It is evident that this becomes a \ncomplicated problem quickly as more and more people exchange goods.  \n \nTo facilitate this process an additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 7,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 8,
      "text": "n additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless. It becomes useful when it has a property called trust. Trust is what \nmakes money useful. You take away the trust as Robert M ugabe did in Zimbabwe you collapse \nmoney as it happened in when Zimbabwean dollar was replaced by an American dollar as a legal \ncurrency. In this example there are factors of production that makes this transaction happen and \nthese are labour to plough, cap ital and here we are talking about seeds and land to plough these \nseeds on. The study of all these activities is called economics. The generalization of this activities \nsuch as the philosophy on how to price these goods is called economic theory. Generaliz ation is \nof course a big concept. For example if most of the time if it is cloudy and humid it rains then one \ncan generalize and say there is a natural law that states that whenever it is cloudy and humid then \nit will probably rain.   \n \nIf money is now the object to be used to exchange goods how do we put a price to peanuts, maize \nand wheat? Well it depends on your ideology. In the strictly planned economy the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 8,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 9,
      "text": "my the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed. One thing for \nsure, the producers of goods and services are only willing to sell their goods at a price which is \nhigher than the cost of producing these goods. This  paper  will explore how artificial intelligence \nchange pricing and the theory of pricing.  \n \nOn the theory of pricing one looks at the supply and demand and in our case we will use peanuts. \nWhen the supply and demand are equal this is called equilibrium. Equ ilibrium is a balance of all \neconomic forces and in our case these forces are the supply and demand of goods and services. At \nthe point of equilibrium there is no incentive to change because changing does not advantage any \nagent. With the advent of artific ial intelligence, we can now employ multi -agent system to simulate \nan economic process and observe the point of equilibrium thereby assisting in matters such as \npricing.     \n \nThe production of peanuts, wheat and maize can be industrialized using tractors. In this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 9,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 10,
      "text": "this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage. From a \nsituation like this in the major industrial town s of Britain, Karl Marx looked at this and crafted an \nideology where the workers become the owners of capital through a revolution. He went further \nand stated that \u201cTo each according to their needs and from each according to their abilities\u201d. This \nof cours e was against human nature and could not be enforced without the violence of Lenin and \nStalin.   \n \nAdam Smith looked at organization of the economy and observed that as individuals pursue goals \nof maximizing their returns the greater good of increasing prod uction and income are achieved. \nHe called the driver of this greater good the invisible hand. The concept of maximizing the greater \ngood is what is called utilitarianism and was proposed by John Stuart Mill  (Mill, 2001) . When \nthese owners of capital and wo rkers pursuing their individual wants the emergence outcome if the \ngreater good for society. Of course with the advent of multinationals that are big, and the influence \nof finance and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 10,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 11,
      "text": "ce and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) . \nAs Nobel Laureate Joseph Stiglitz in his book The Price of Inequality observes that inequality \nstifles economic growth  (Stiglitz, 2012) . The  idea of the invisible hand is phenomenon that is \nobserved even in biological systems. For example, the swarming of pigeons which is illus trated in \nFigure 1 is an example of the invisible hand because there is no leader. Each bird looks at what its \nneighbo urs as well as the group are doing and follows and what emerges is a coordinated \nmovement of the swarm towards the food source. This phenomeno n has been translated into an \nartificial intelligence  algorithm called particle swarm optimization.  \n \n \nFigure 1 Th e swarming of pigeons  \nThe other important factor is the concept of value. In our example, between peanuts, wheat and \nmaize which one is more valuable? Should we break them into their chemical components and \nprice each compound? The answer is very similar t o what William Shakespeare said about beauty: \n\u201cIt is on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 11,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 12,
      "text": "s on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues. Even w ithin a single product there is a difference in the perception of value for example \nfor Peter only 1/3 of maize is more valuable than wheat and peanuts and because of this fact Peter \nis only willing to trade the 2/3 of his maize. The concept of asymmetry o f value and its principal \nimportance in trade will be discussed in detail later in this paper  and it will be established that AI \nreduced information asymmetry.  \n \nIn an example we have given, Peter may go and create a company Peter Incorporated. The \ncompany  will have limited liability and the theory behind this is that in order to encourage people \nto form companies a legal framework is established to limit personal liability in situation when the \ncompany runs into difficulties. The company is therefore estab lished as a legal entity independent \n\nof its owners and therefore has rights and obligations. Peter may then decide to list the company \nin the local stock exchange to raise funds for the company and by so doing distributes shareholding \nto members of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 12,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 13,
      "text": "mbers of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses. Technical analysis \nis a mathematical exercise where one looks at the data of the performance of the stock and make \ndecisions on whether to buy such a stock or not. The problem with this is that people buy stock for \nno reason except that it is going up irrespective of how solid is the company with that particular \nshare price. The  dotcom bubble that busted in the early 2000 was largely based on this where a \ncompany with a shaky business model was listed in the stock market and its share price \nskyrocketed and then crashed to the ground  (Hamilton, 1922; Siegel, 2008 ). The other way of \npredicting the share price is by looking at the underlying business activities of companies and then \ndecide whether to buy the share price or not. Both these approaches have merit and today with the \nadvent of big data and AI technical an alysis is augmented with data from the internet whether \ntwitter or searching through the internet to find out what the market sentiments, including \nquantification of the fundamentals, on the particular stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 13,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 14,
      "text": "stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis. This theory basically states that it is impossible to beat the market because the share \nprice reflects all elements that are relevant. This theory states that even though there might be \ninstances where a share price might not already incorporate all relevant information it then self \ncorrects to reach an equilibrium point when the markets are efficient. Much of the infor mation in \nthe stock are based on human decisions which are unpredictable and in most cases irrational. For \na share price to incorporate all these decisions and their future intentions, is almost importable. \nIrrational people make decisions in the market th ese result with irrational markets. But now we \nknow that much of the decisions in the market are made by artificially intelligent machines and \nthe volume of these will expand into the future. Therefore, as these happen then the markets \nbecome more efficien t and this is discussed in detail in this paper . \n \nPeter, John and Aiden when they make their decisions on when to plan, how to plant, what \nfertilizers to use, how to trade, at what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 14,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 15,
      "text": "what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing. The second attribute is sufficient mental capability to make \nsense and process the information which is often less than perfect. This is t he concept that \nEconomics Nobel Prize Laurate and AI expert Herbert Simon called bounded rationality. He \nfurther observed that in such a situation, Peter, John and Aiden, will have to satisfice meaning \nobtaining satisfactory and sufficient solution. Now if  we add AI into this decision making process \nwhat happens to missing data and processing of information?  \n \nAll the players in the market have to make decisions, whether how much peanuts, maize and wheat \nto be planted. They make these decisions individually and/or collectively. The question that has \nbeen asked for many generations is: How do people make their choices? The theoretical answer is \nthat they make their choices based on their desires to maximize their utilities. There is a difference \nbetween a desi re to maximize utility and actually been able to make a rational decision. Studies \nhave shown that the theory of rational choice is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 )."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 15,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 16,
      "text": "ce is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 ).  \n \nNow with the advent of artificial intelligence, is it not possible to design machines that are able to \nmake decision based on rational choice theory? Doesn\u2019t artificial intelligence in decis ion making \nimplies that decisions are more and more going to be based on the theory of rational choice rather \nthan aversion to loss? Another closely aligned matter is the issue of rational expectation theory \nwhich states that people make decisions based on  future outlook, information available and past \nexperience. AI machines look at available information and past information to make a decision \nand excludes individual perception of the future. Therefore, the degree of uncertainty in AI made \ndecisions is low er than that made by human beings. For example, if one asks human beings to \nmake decisions at different times they will change their minds depending on all sorts of irrelevant \nfactors.  \n \nAs people make their decisions on what to do, there is a framework th at has been developed to aid \nwith that and this is called game theory. Game theory is a mathematical framework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 16,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 17,
      "text": "ework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g. zero sum \ngames where the gain for one player is the loss by another player. In game theory there are a \nnumber of assumptions that are made and these include the fact that players are rational, and there \nare se ts of rules and the games are played till Nash equilibrium is reached  (Nash, 1950) . Nash \nequilibrium is a position where each player cannot improve his utility by playing further. With the \nadvent of artificial intelligence and in particular multi -agent sys tems the whole theory of games \ncan be better implemented and for much complicated games for the benefit of better decision \nmaking.  \n \nAnother framework that has been developed is the framework of mechanism design which in our \nexample can be used to design a market for  the peanuts industry. Mechanism  design won Leonid \nHurwicz, Eric Maskin, and Roger Myerson a Nobel Prize in Economics  (Hurwicz  et al, 1975)) . \nMechanism design is in essence reverse game theory where instead of players, rules and then \nidentifying equilibrium, here you have the desired equilibrium and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 17,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 18,
      "text": "um and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome. For an ex ample, when an aircraft is \nflying over a highly turbulent environment then the autopilot system identifies the appropriate \nspeed, angle of attach and altitude to achieve maximum comfort for the passengers.  \n \nSuppose a trader has $1 million is faced with mak ing a choice on buying stocks from a list of 100 \nstocks. The trader, has two options either use $1 million to buy one stock or can buy a basket of \nstocks. The process of choosing the optimal basket of stocks is called portfolio optimization. The \noptimal ba sket today is not the optimal basket tomorrow and how then does he optimize this? \nPerhaps he can use a time window, say 2 months, to find the average optimal basket. All these \nvariables, e.g. time window, selection that forms a basket, how large should the  basket be, are all \nunknown variables. Nobel Prize Laureate, Harry Markowitz, proposed what is called portfolio \noptimization theory to select this basket of stocks. However, his theory is based on a number of \nassumptions including the fact that the charact er of the basket of stocks does not change, something \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 18,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 19,
      "text": "mething \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization. For example, \nhow do we solve portfolio optimization problem using the theory of ant colony intelligence which \nis based on depositing pheromones as they move and following the path with the strongest \npheromones, and then converging on an equilibrium path which happens to  be the shortest distance \nbetween the food source and ants nest?  \n \nThe theories of factual and counterfactuals are at the heart of economic theory. For example, if the \nfarmer Aiden plants wheat and instead planted maize, will he have obtained a better retur n on \ninvestments? These two scenarios, planting wheat, factual (planting wheat beca use it happened) \ncompared to the  counterfactual (planting maize because it did not happen). The economists have \na beautiful word for this and they call this opportunity cost s (Henderson, 2008) . The question that \nneeds to be answered in this thesis is whether we can use AI, with its predictive, adaptive and \nlearning capabilities, to estimate the counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 19,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 20,
      "text": "he counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments.  \n \nAnother issue that is closely related to the issues of factual and counterfactual is the concept of \ncausality  (Gujarati and Porter, 2009 ). Nob el Laureate Clive Granger thought he had pinned down \nthis matter when he proposed Granger causality which even though is useful particularly in \neconomics is not causality at all but some measure of correlation  (Dawn, 2009) . We know that \ndetecting causality  on static data is difficult and that only experimentation is the most reliable way \nof detecting causality. A causes B if and only if there is a flow of information from A to B. How \ndo we then detect such flow of information? Alternatively, we can frame ca usality in terms of \nfactual and counterfactual by posing the following problem instead: A causes B (factual) if when \nA doesn\u2019t happen then B does not happen. This paper  illustrates the centrality of causality in \nunderstanding economic problems and proposes  several ways in which to understand economics. \nWe explore the theories of rational choice and rational expectations within the dimensions of \ncausality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 20,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 21,
      "text": "causality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is. AI is made out of two words, artificial and intelligence and thus it is \nintelligence that is artificially made. Intelligence is the ability to make sense of information beyon d \nthe obvious  (Marwala et al, 2006; Marwala, 2007) . There are two types of intelligence in nature \nand these are individual intelligence and group intelligence. Individual intelligence is intelligence \nlocated in a single agent for example the farmer Aiden is individually intell igent, whereas group \nintelligence is when it is located in a group of agents such as the swarm ing of pigeons shown in \nFigure 1 or the school of fish.  \n \nWithin the field of AI intelligence manifests itself in two ways, specialised intelligence and \ngeneralise d intelligence. For example, a robot designed at the Korean Advanced Institute of \nScience an d Technology, shown in Figure 2, which drives a car, opens doors, walks and drills \nholes is demonstrating generalized intelligence. This is because it is able to do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 21,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 22,
      "text": "do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2. The KAIST humanoid robot amongst human  \n\n \nIn artificial intelligence, there are various capabilities that have been invented and these are how \nto make machine learn, optimize, predict, adapt and interact. On learning, the source of knowledge \nis how a human brain functions and from this a neural ne twork was invented which is able to take \ninformation from the world and interpret it. For example, a neural network is able to take an x -ray \npicture of the individual\u2019s lung and then establish whether the individual has pulmonary embolism \nor not. Neural ne twork is also able to take an EEG signal from an individual and establishes \nwhether the individual will be experiencing epileptic activities or not in the near future.  \n \nFigure 3 An example of a neural network  \n \nIn Figure 3, we have input and output layers . The input layer has the variables that are to be used \nas a basis for prediction whereas the output layer is what is to be predicted. An example, is a study \non using the income of parents to predict the educational outcome of the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 22,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 23,
      "text": "the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer. The hidden layers constitute \nthe mechanism or the engine which facilitates the translat ion of input data into the output. This \nengine consists of neurons (inspired by natural neurons) and the identity of these neurons which \n\nare represented by numbers is obtained from the observed historical data. The identification of \nthese neuron is obtaine d through the process called optimization. The interesting aspect of this \nsetup is that the prediction is essentially derived from the historical observation and thus confirms \nthe quote that: \"Predicting the future is nothing more than the rearrangement of  information that \ncurrently exists\"     \n \nThis are tasks that normally done by trained doctors. In fact, doctors here use what is called in \neconomic theory of rational expectation by taking current and previous histories and their \npredictions of the future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 23,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 24,
      "text": "future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty.  There are other AI techniques that have been designed for learnin g and these are \nfuzzy logic which brings precision to the spoken words and use these to make decisions through a \ncomputer and support vector machines which are based on increasing the dimension of the space \nto better differentiate attributes in objects.  \n \nThe second aspect of AI is optimization. Optimization is a process of identifying the lowest or a \nhighest point in a problem. For example, the process of identifying who is the shortest man in the \nworld is an optimization problem. Using this example, the op timization algorithm is a computer \nor mathematically based procedure of identifying who the shortest person in the world is. Another \nexample if you are designing an aircraft you might intend to make all your choices e.g. material to \nuse and shape of the pl ane to result in the lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 24,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 25,
      "text": "lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution. This controversial theory, especiall y amongst the \nreligious right, is a process in which species adapt to their environment and they achieve this \nthrough four drivers and these are mutation, random alteration of genes, crossover, mixing of \ngenes, as well as reproduction of those individuals that are most adaptive to their environment. \nThis natural optimization process has been codified to produce a computer based process called \ngenetic algorithm.  \n \nThe other aspect of AI is adaptation which is an optimization problem. For example, if one was t o \ncreate a predictive system that predicts whether it is going to rain or not. The first level of \noptimization is to set up parameters that will make a predictive system predicts whether it will rain \nor not. The second optimization level ensures that such a predictive system adapts to the evolving \nenvironment due to global warming. There have many techniques that have been developed to \nmake adaptation possible and these include fish school algorithm which is inspired by the school \nof fish behaviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 25,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 26,
      "text": "haviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities. It consists of the \ndemand characteristics of the customer which describes the relationship between price and \nquantity of goods. For example, if the price of a good is low the custo mer will buy more goods \nand services than if the price is high. The relationship between price and the willingness of the \ncustomers to buy goods and services is called the demand curve. The other aspect of the demand \nand supply law is the supply curve whic h relates the relationship between the price and the quantity \nof goods suppliers are willing to produce. For example, the higher the price the more the goods \nand services the suppliers are willing to produce. Conversely, the lower the price the lesser the \ngoods and services the suppliers are willing to produce. The point at which the suppliers are willing \nto supply a specified quantity of goods and services which are the same as those that the customers \nare willing to buy is called equilibrium. Artificial i ntelligence allows companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 26,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 27,
      "text": "companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends. In this regard individuals \nare not sub jected to prices derived fr om aggregate demand and supply (Marwala and Hurwitz, \n2017) . \n \nRational choice  \nRationality has played a pivotal role in economic theory. Some of the theories that have been used  \nassume perfect rationality. This  paper  studies the theories of rational choice , preference and utility \nmaximisation . Rational choice theory prescribes that when agents make decisions they do that \nbased on the desire to maximize utility. However, in perfect rationality each move these agents \nmake on building towards the ultimate decisi on is not necessarily optimal, however, the aggregate \nof all the moves they make can be rational. A type of artificial intelligence called r einforcement \nlearning can be used as a mechanism for mode lling rationality. T he concept of local and global \noptimiza tion can be explored within the context of evolutionary design to study the subject o f \nrationality. P roblems where acting rationally locally is vital for the overall global rational solution \nfor example making a stupid move in a game in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 27,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 28,
      "text": "in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) . \n \nRational expectations  \nThe theory of rational expectations prescribes that people predict the future based on past  and \navailable information and their predictions are not systematically wrong. In this way, predicting \nthe future is nothing more than the arrangements of the information that already exists. The theory \nof adaptive expectations predict the future based sol ely on the previous data and this has been \nfound to offer biased conclusions. With the advent of artificial intelligence , data fusion  and big \ndata the information that can be used in models to predict the future include mined text data and \npictures and this render the predictions of rational expectati ons more accurate and thus lowers the \ndegree of uncertainties  in decision making  (Marwala and Hurwitz, 2017) . \n \nBounded rationality  \nThe theory of flexibly -bounded rationality is an extension to the theory of bounded rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 28,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 29,
      "text": "rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine. Rational \ndecision making involves using information which is almost always imperfect and incomplete \ntogether with some intelligent machine which if it is a human being is inconsistent to make \ndecisions. In the theory of bounded rationa lity, this decision is made irrespective of the fact that \nthe information to be used is incomplete and imperfect and that the human brain is inconsistent \nand thus this decision that is to be made is taken within the bounds of these limitations. In the \ntheory of flexibly -bounded rationality, signal processing is used to filter noise and outliers in the \ndata and the correlation machine is applied to complete missing information and artificial \nintelligence is used to make more consistent decisions.  This results with the bounds prescribed  by \nthe theory of  bounded rationality expanding and thus increasing  the degree of rationality such \ndecisions are made  (Marwala and Hurwitz, 2017) .  \n \nAsymmetri c information  \nWhen agents come together to make decisions it is often the case that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 29,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 30,
      "text": "se that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information. Alternatively one agent can \nscreen for information to reduce the impact on asymmetric information. With the advent of big \ndata and artificial intelligence signalling and screening has been made easier. The impact of \nartificial intelligen ce on the theory of asymmetric information particularly given the fact that \nscreening is made easier due to artificial intelligence and data mining  is that it reduces the degree \nof information asymmetry in the markets and thereby reduces  the resultant distortion of the \nmarkets b y making them more efficient as well as  reduces the volume of trades in the market . \nTherefore , the more artificial intelligent there is in the market the less is the volume of trades in \nthe market, and the overall efficiency of the market is likely to improve over time as the market \nbecomes more saturated with intelligent trading and analysis agents  (Marwala and Hurwitz, 2017) . \n \nPricing  \nPricing theory is a well -established mechanism that illustrates the constant push -and-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 30,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 31,
      "text": "d-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller. This problem \nbecomes exponentially more difficult as more and more buyers and sellers are introduced into a \nmarket mode l, especially if they have strategies to stay ahead of not only their target, but also their \ncompeti tors. M ulti-agent intelligent systems are used to model complex behaviour in each agent, \nlaying the groundwork for creating complex price -finding models bas ed on the introduction or \nremoval of given agents from a large, complex system. These models can be robust and detailed \nenough to not only capture the steady -state final pricing, but also the dynamics of the price \nfluctuations that will be of great interes t to anyone wishing to model the price movements of goods \nwithin the marketplace.  The theory of pricing closely linked to the theory of value because the \nprice customers are willing to pay for goods and services is linked to how they value these goods \nand services. Contrary to what David Ricardo postulated when he proposed the labour theory of \nvalue where the value of goods and services is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 31,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 32,
      "text": "is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values.  Given the fact that the emergence  of \nartificial intelligence and big data in the market place implies i ndividualized supply and demand  \ncurve s, this implies that pricing is now individualized instead of being derived from aggregate \ndemand and supply curves  (Marwala and Hurwitz, 2017) .  \n \nGame theory  \nGame theory has been used quite extensively in economic problems. In game theory agents with \nrules interact to obtain pay -off at some equilibrium point often called Na sh equilibrium. The advent \nof artificial intelligence makes the multi -agents game theory possible. The impact of this \ndevelopment is that the implementation of this on issues such as equilibrium and optimal decisions  \nis far reaching . Furthermore, statistical physics is introduced and multi -agent games can now be \nused introduced to study games  (Marwala and Hurwitz, 2017) . \n \nMechanism design  \nIn game theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 32,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 33,
      "text": "me theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium. Mechanism design is the inverse of that, we know what the end -state should look like \nand our task is to identify the rules and pay -off function which will ensure that the desired end -\nstate is achieved. This is done by assuming that the agents in this setting acts rationally.  Deep \nlearning, big data and mechanism offer exciting avenues for economics  (Marwala and Hurwitz, \n2017) .   \n \nProspect theory  \nProspect theory offers both a fascinating alternative to modelling agent behaviour in a virtual \nmarket place, as well as an opportunity for further expanding prospect theory by utilising multiple \nagents in a larger simulated marketplace utilising multi -agent modelling. The basic premise of \nprospect theory is that the probabilities of profit / loss have a disproportionately large effect on the \nbehaviour of human agents in an economic system when compared to the actual expected outcome, \na premise that is born e out by the results of research in the field of behavioural  economics, and \none that contradicts the expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 33,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 34,
      "text": "expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling. A larger model consisting of intelligent agents that utilise a prospect -\ntheory -based means of determining risk would therefore offer greater accuracy in modelling the \nactual marketplace than the usual, truly ration al agents in more common use. This study surmise \nthat the applicability of prospect theory is determined by the level of artificial intelligence decision \nmakers that are deployed in a given problem  (Marwala and Hurwitz, 2017) .  \n \nEfficient market hypothesis  \nThe efficient market hypoth esis (in its varying forms) has allowed for the creation of financial \nmodels based on share price movements ever since its inception  (Fama, 1970) . In this paper  the \nbase assumptions drawn from root economic principles are brought into question. Their viabi lity \nfor application to the actual marketplace is dissected, elaborating on their successes as well as their \nshortcomings. The powerful techniques available within the fields of machine learning  and multi -\nagent modelling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 34,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 35,
      "text": "delling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace. In particular the application of multi -agent modelling to the market -modelling \nproblem provides a powe rful tool for simulating heterogeneous  agents with differing views and \nobjectives in order to create a more realistic market upon which to base our hypotheses. It is \nsurmised that the use of artificial intelligence in the market makes the market more effic ient \n(Marwala and Hurwitz, 2017) . \n \nPortfolio theory  \nThe basis of portfolio theory is rooted in statistical models based on Brownian motion. These \nmodels are surprisingly na\u00efve in their assumptions and resultant application within the trading \ncommunity. The application of artificial i ntelligence and machine learning to portfolio theory and \nconsequently to the applications of portfolio theory, portfolio management in particular, have \nbroad and far -reaching consequences. Artificial intelligence techniques allow us to model price \nmovement s with much greater accuracy than the random -walk nature of the original Markowitz  \nmodel, while the job of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 35,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 36,
      "text": "of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory. A particular method of price movement modelling is shown that \nmodels price movements with only simplistic inputs and still produces useful predictive results. A \nportfolio rebalancing method is also described, il lustrating the use of evolutionary computing for \nthe portfolio rebalancing problem in order to achieve the results demanded by investors within the \nframework of portfolio theory  (Marwala and Hurwitz, 2017) . \n \nRationality in facts and c ounter -facts \nThis section  introduces the concept of rational counterfactuals which is an idea of identifying a \ncounterfactual from the factual (whether perceived or real), and knowledge of the laws that govern \nthe relationships between the antecedent and the consequent, that maximizes the attainment of the \ndesired consequent  (Byrne, 2005) . In counterfactual thinking factual statements like: \u2018Greece was \nnot financially prudent and consequen tly its finances are in tatters  and with its counterfactual \nbeing: \u2018If Greece was financially prudent and consequently its finan ces are in good shape\u2018. In  order \nto build rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 36,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 37,
      "text": "ild rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) . The r ational counterfactual theory can be  applied to various problems in economics.  \n \nQuantitative finance  \nQuantitative finance has grown with the advents  of computing and this growth has accelerated in \nthe last decade with the growth of artificial intelligence . Techniques on how to price risk and \nforecast the stock price have been enhanced by the use of artificial intelligence. Subjects such as \nevolution, deep learning and big data are changing the effectiveness of quantitative finance.  \n \nEconomic Causality  \nCausality is a powerful concept which is at the heart of markets. Often one wants to establish \nwhether a particular attribute causes another. Often as human beings we have perceived causality \nthrough correlation. Because of this fact, causality has often been  confused for correlation. T he \nevolution of causality including the influential w ork of David Hume and its relevance to economics \nand finance  is an important area of study (Marwala and Hurwitz, 2017) . Various concepts and \nmodels of causality such as transmission, Granger and Pearl models of causality  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 37,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 38,
      "text": "y  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect. Bayesian inference as a \nmechanism of modelling causality  can be used to study the link between cigarette sm oking and \nlung cancer . \n1.5 Conclusion  \nThis paper  went through some of the big ideas that have been developed in the study of economics. \nThese include concepts such as Marxism, the theory of invisible hand, rational expectations, \nrational choice, mechanism design and game theory. Furthermore, this paper  discussed how some \nof these will change as man is replaced by an artificial intelligent machine as a principal agen t of \neconom ic decision making . \nReference:  \n1. Agassi, J . (1971). Faraday as a Natural Philosopher. Chicago: University of Chicago Press.  \n2. Amos , S.W. and  James , M.R. (1999). Principles of Transistor Circuits. Butterworth -\nHeinemann  \n3. Anand , P. (1993).\"Foundations of Rational Choice Under Risk\", Oxford: Oxford University \nPress.  \n4. Byrne, R.M.J. (2005). The rational imagination: how people create alternatives to reality. \nCambridge, M.A.: MIT Press.  \n5. de Vivo , G.  (1987). \"Ricardo, David,\" The New Palgrave: A Dictionary of Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 38,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 39,
      "text": "Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009). \"Causality in Economics: The Granger Causa lity Test\". \nBasic Econometrics (Fifth international ed.). New York: McGraw -Hill. \n8. Harari, Y.N. ; (2014). Sapiens: A Brief History of Humankind. Vintage , ISBN 9780099590088.  \n9. Hamilton, W. P. (1922). The Stock Market Baraometer. New York: John Wiley & Sons Inc \n(1998 reprint).  \n10. Henderson, D.R. (2008). \"Opportunity Cost\". Concise Encyclopedia of Economics (2nd ed.). \nIndianapolis: Library of Economics and Liberty.  \n11. Hurwicz, L., Radner , R. and Reiter , S. (1975) A Stochastic Decentralized Resource Allocation \nProcess:  Part I, Econometrica, Vol. 43, No. 2 (1975), pp. 187 -221 \n12. Kahneman , D. (2011). Thinking, Fast and Slow. Macmillan.  \n13. Markowitz, H.M. (March 1952). \"Portfolio Selection\". The Journal of Finance. 7 (1): 77 \u201391.  \n14. Marwala, T., Boulkaibet, I, and Adhikari S. (2017) Probabilistic Finite Element Model \nUpdating Using Bayesian Statistics: Applications to Aeronautical and Mechanical \nEngineering. John Wiley a nd Sons . \n15. Marwala, T. (2015). Causality, Correlation, and Artificial Intelligence for Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 39,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 40,
      "text": "or Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013). Economic Modeling Using Artificial Intelligence Methods. Heidelberg: \nSpringer.  \n18. Marwala, T. (2012). Condition Monitoring Using Computational Intelligence Methods. \nHeidelberg: Springer.  \n19. Marwala, T. and Lagazio, M. (2011). Militarized Conflict Modeling Using Computational \nIntelligence. Heidelb erg: Springer . \n20. Marwala, T. (2010). Finite E lement Model Updating Using Computational Intelligence \nTechniques: Applications to Structural Dynamics. Heidelberg: Springer.  \n21. Marwala, T. (2009). Computational Intelligence for Missing Data Imputation, Estimation, and \nManagement: Knowledge Optimization Te chniques. Pennsylvania: IGI Global.  \n22. Marwala, T. (2007). Computational Intelligence for Modelling Complex Systems. Delhi: \nResearch India Publ ications.  \n23. Marwala, T. and Hurwitz, E.  (2017)  Artificial Intelligence and Economic Theory: Skynet in \nthe Market. Springer.  (Accepted).  \n24. Marwala, T., Mahola, U and Nelwamondo , F.V.  (2006) Hidden Markov models and Gaussian \nmixture models for bearing fault detection using fractals. International Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 40,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 41,
      "text": "rnational Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C.  (1873), A treatise on electricity and magnetism Vol I, Oxford : Clarendon Press  \n27. Mill, J.S. (2001)  Utilitarianism and the 1868 Speech on Capital Punishment. (Sher, ed. Hackett \nPublishing Co, 2001)  \n28. Myerson, R .B. (1991). Game Theory: Analysis of Confli ct, Harvard University Press  \n29. Nash, J . (1950) \"Equilibrium points in n -person games\" Proceedings of the National Academy \nof Sciences 36(1):48 -49. \n30. Newton, I. (1726)  \"Mathematical Principles of Natural Philosophy\", 1729 English translation \nbased on 3rd Latin edition (1726), volume 2, containing Books 2 & 3.  \n31. Picketty , T. (2014)  Capital in the Twenty -First Century (Cambridge, MA: Belknap Press, \n2014)  \n32. Siegel, J. J. (2008) . \"Stock Market\". In David R. Henderson (ed.). Concise Encyclopedia of \nEconomics (2nd ed.). Indianapolis: Library of Economics and Liberty.  \n33. Simon, H . (1991). \"Bounded Rationality and Organizational Learning\". Organization Science. \n2 (1): 125 \u2013134. \n34. Smith , S. (2015) \". The Concise Encyclopedia of Economics. Liberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 41,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 42,
      "text": "iberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 42,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 43,
      "text": "How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 0,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 44,
      "text": "Artificial Intelligence and Economic Theories  \nTshilidzi Marwala and Evan Hurwitz  \nUniversity of Johannesburg  \n \nAbstract  \nThe advent of artificial intelligence has changed many disciplines such as engineering, social \nscience and economics. Artificial intelligence is a computational technique which is inspired by \nnatural intelligence such as the swarming of birds, the working of the brain and the pathfinding of \nthe ants. These techniques have  impact on economic theories . This book studies the impact of \nartificial intelligence on economic theories, a subject that has not been extensively studied. The \ntheorie s that are considered are : demand and supply,  asymmetrical information, pricing, rational \nchoice, rational expectation, game theory, efficient market hypotheses, mechanism design, \nprospect, bounded rationality, portfolio  theory , rational counterfactual and causality. The benefit \nof this book is that it evaluates existing theories of economics and update them based on the \ndevelopments in artificial intel ligence field.  \n1.1 Introduction  \n\u201cWorkers of the world unite, you have nothing to lose but chains\u201d so said Karl Marx  (Marx, 1849) . \nDespite what many Marxists claim, he never foretold the advent of artificial intelligence, otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 1,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 45,
      "text": "otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man. Man is \nthe invisible hand that drives the economy as observed by Adam Smith  (Smith, 2015) . The \neconomy was by man and about man but the theories that explained the economy did not quite \nmatch the behaviour of a man. For this reason the rational man is indeed irrational and his \nirrationality permeates every aspect of life including the very concept  we call the economy.   \n \nHomo -Sapiens have been around for hundred thousand years and throughout their existence and \neven from their forbearers have inherited certain traits and behaviours that influence them even \ntoday  (Harari, 2014) . Some of these traits and behaviours include greed, fear, bias and social \nstructure. All these traits are still with us today because of one and only one reason and that it \nbecause they all have given us an evolutionary advantage. Of course, this might ch ange in the \nfuture depending on the change of environment and therefore these traits might depart from human \nbeings. All these traits influence our decision making and the rationality thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 2,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 46,
      "text": "ty thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality. Our rationality is bound \nto all these constraints but what will happen when machine replaces humans. Is the rationality of \nmachines b ound? (Simon, 1991) Are the bounds of rationality bigger in humans than machines? \nThese are some of the questions that this book seeks to answer.  \n \nMachines are now part of everyday decision making.  They are becoming more intelligent due to \na technology ca lled artificial intelligence (AI). Alan Turing surmised that machines are intelligent \nif and only if when we interact with them we cannot tell whether we are interacting with a man or \na machine  (Traiger, 2000) . This is what is called a Turing test. No mach ine has passed this Turing \ntest over an extended levels of man -machine interaction. But this does not limit artificial \nintelligence and make machines incapable of solving complex problems.  \n \nThis paper  describes man -machine interaction and its impact on som e of the big ideas in \neconomics. Every economic epoch had its own theories or thinking. Some of these theories stood \nthe test of time but some have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 3,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 47,
      "text": "me have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England. What is not clear is why it did not happen in Asia especially India or China as \nprobabilistically these two regions had higher population densities. What was the catalyst tha t \ncaused the first industrial revolution? In the 17 century lived a man in England called Isaac Newton \nwho was educated at  Trinity College Cambridge  (Newton, 1726) . Legend claims that unlike many \npeople who had lived before him and had witnessed an apple f alling, he asked: \u201cWhy did the apple \nfall?\u201d And from this he discovered gravity an intriguing concept which was only given  an \nexplanation by a German/Swiss/American scientist Albert Einstein some hundreds of years later. \nNewton, furthermore, came with what  is now called the laws of motion which stated that objects \nwill continue at rest or keep on moving until they are moved or stopped respectively. Furthermore, \nhe observed the relationship between force, mass of an object and its acceleration. This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 4,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 48,
      "text": ". This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production. From this \nera economic principles such as Marxism, Adam Smith\u2019s invisible  hand as well as David Ricardo\u2019s \nlabor theory of value and the principle of comparative advantage were conceived  (de Vivo, 1987) .   \n \nThen in the 19th century came a British man called Michael Faraday who performed crucial \nexperiments which were later inter preted by James Clerk Maxwell through his beautiful \nmathematical equations  (Maxwell, 1873; Agassi, 1971) . Michael Faraday observed that if you \nhave a magnet and you put next to it a wire that conducts electricity and you move the wire, then \nelectricity flo ws in that conductor. This is wizardry beyond miracles of biblical proportions. Even \ntoday we generate electricity, perhaps with the exception of solar energy and few others, using this \ntechnique. Conversely, Faraday observed that again with a magnet and a  conducting wire and you \nforce electricity through the wire, then the wire moves and this was the birth of the electric motor \nthat still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 5,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 49,
      "text": "at still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced.   \n \nThen in the second half of the 20th century John Bardeen, Walter Brattain, and William Shockley \ndiscovered the transistor  (Amos and James, 1987) . It is based on semiconductors which are objects \nthat conduct electricity under certain conditions. The transistor is the catalyst for the electronic age \nthat gave us computers, cell phones, information technology and automation in our factories. It is \nthe DNA of the third industrial revoluti on. It was in the era that powerful economic concepts such \nas market efficiency where introduced prospect theory.  \n \nThe era we are living is the fourth industrial revolution. This is an era of intelligent machine  \n(Marwala, 2007; 2009; 2010; 2012; 2013; 2014 ; 2015; Marwala and Lagazio, 2012; Marwala et \nal, 2016) . The DNA of the fourth industrial revolution is AI. It will touch all aspects of our lives. \nWe will have robotic cops to protect us, robotic doctors to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 6,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 50,
      "text": "rs to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced.  What will happen to economics? Already \nwe know that the stock market no longer has crowds of people shouting a price of stocks because \nartificial intelligent software are doing the work. This paper  explores how economic theories that \nhave guided decision makers in the past will have to change or adapted in the light of artificial \nintelligent capabilities.     \n1.2 E conomics and Economic Theory  \nEconomics began when man started battering for exchanging goods. This was mainly based on the \nreality that man could not produce all he wanted. For example, suppose we have a man called Peter \nwho produces maize and another call ed John who produces peanuts. Then Peter will give half of \nhis maize for half of John\u2019s peanuts. If we include a third person Aiden who produces wheat, then \nPeter takes a third of his maize and gives it to John in exchange of a third of his peanuts, gives \nanother third to Aiden in exchange of his third of wheat. It is evident that this becomes a \ncomplicated problem quickly as more and more people exchange goods.  \n \nTo facilitate this process an additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 7,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 51,
      "text": "n additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless. It becomes useful when it has a property called trust. Trust is what \nmakes money useful. You take away the trust as Robert M ugabe did in Zimbabwe you collapse \nmoney as it happened in when Zimbabwean dollar was replaced by an American dollar as a legal \ncurrency. In this example there are factors of production that makes this transaction happen and \nthese are labour to plough, cap ital and here we are talking about seeds and land to plough these \nseeds on. The study of all these activities is called economics. The generalization of this activities \nsuch as the philosophy on how to price these goods is called economic theory. Generaliz ation is \nof course a big concept. For example if most of the time if it is cloudy and humid it rains then one \ncan generalize and say there is a natural law that states that whenever it is cloudy and humid then \nit will probably rain.   \n \nIf money is now the object to be used to exchange goods how do we put a price to peanuts, maize \nand wheat? Well it depends on your ideology. In the strictly planned economy the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 8,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 52,
      "text": "my the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed. One thing for \nsure, the producers of goods and services are only willing to sell their goods at a price which is \nhigher than the cost of producing these goods. This  paper  will explore how artificial intelligence \nchange pricing and the theory of pricing.  \n \nOn the theory of pricing one looks at the supply and demand and in our case we will use peanuts. \nWhen the supply and demand are equal this is called equilibrium. Equ ilibrium is a balance of all \neconomic forces and in our case these forces are the supply and demand of goods and services. At \nthe point of equilibrium there is no incentive to change because changing does not advantage any \nagent. With the advent of artific ial intelligence, we can now employ multi -agent system to simulate \nan economic process and observe the point of equilibrium thereby assisting in matters such as \npricing.     \n \nThe production of peanuts, wheat and maize can be industrialized using tractors. In this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 9,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 53,
      "text": "this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage. From a \nsituation like this in the major industrial town s of Britain, Karl Marx looked at this and crafted an \nideology where the workers become the owners of capital through a revolution. He went further \nand stated that \u201cTo each according to their needs and from each according to their abilities\u201d. This \nof cours e was against human nature and could not be enforced without the violence of Lenin and \nStalin.   \n \nAdam Smith looked at organization of the economy and observed that as individuals pursue goals \nof maximizing their returns the greater good of increasing prod uction and income are achieved. \nHe called the driver of this greater good the invisible hand. The concept of maximizing the greater \ngood is what is called utilitarianism and was proposed by John Stuart Mill  (Mill, 2001) . When \nthese owners of capital and wo rkers pursuing their individual wants the emergence outcome if the \ngreater good for society. Of course with the advent of multinationals that are big, and the influence \nof finance and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 10,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 54,
      "text": "ce and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) . \nAs Nobel Laureate Joseph Stiglitz in his book The Price of Inequality observes that inequality \nstifles economic growth  (Stiglitz, 2012) . The  idea of the invisible hand is phenomenon that is \nobserved even in biological systems. For example, the swarming of pigeons which is illus trated in \nFigure 1 is an example of the invisible hand because there is no leader. Each bird looks at what its \nneighbo urs as well as the group are doing and follows and what emerges is a coordinated \nmovement of the swarm towards the food source. This phenomeno n has been translated into an \nartificial intelligence  algorithm called particle swarm optimization.  \n \n \nFigure 1 Th e swarming of pigeons  \nThe other important factor is the concept of value. In our example, between peanuts, wheat and \nmaize which one is more valuable? Should we break them into their chemical components and \nprice each compound? The answer is very similar t o what William Shakespeare said about beauty: \n\u201cIt is on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 11,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 55,
      "text": "s on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues. Even w ithin a single product there is a difference in the perception of value for example \nfor Peter only 1/3 of maize is more valuable than wheat and peanuts and because of this fact Peter \nis only willing to trade the 2/3 of his maize. The concept of asymmetry o f value and its principal \nimportance in trade will be discussed in detail later in this paper  and it will be established that AI \nreduced information asymmetry.  \n \nIn an example we have given, Peter may go and create a company Peter Incorporated. The \ncompany  will have limited liability and the theory behind this is that in order to encourage people \nto form companies a legal framework is established to limit personal liability in situation when the \ncompany runs into difficulties. The company is therefore estab lished as a legal entity independent \n\nof its owners and therefore has rights and obligations. Peter may then decide to list the company \nin the local stock exchange to raise funds for the company and by so doing distributes shareholding \nto members of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 12,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 56,
      "text": "mbers of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses. Technical analysis \nis a mathematical exercise where one looks at the data of the performance of the stock and make \ndecisions on whether to buy such a stock or not. The problem with this is that people buy stock for \nno reason except that it is going up irrespective of how solid is the company with that particular \nshare price. The  dotcom bubble that busted in the early 2000 was largely based on this where a \ncompany with a shaky business model was listed in the stock market and its share price \nskyrocketed and then crashed to the ground  (Hamilton, 1922; Siegel, 2008 ). The other way of \npredicting the share price is by looking at the underlying business activities of companies and then \ndecide whether to buy the share price or not. Both these approaches have merit and today with the \nadvent of big data and AI technical an alysis is augmented with data from the internet whether \ntwitter or searching through the internet to find out what the market sentiments, including \nquantification of the fundamentals, on the particular stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 13,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 57,
      "text": "stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis. This theory basically states that it is impossible to beat the market because the share \nprice reflects all elements that are relevant. This theory states that even though there might be \ninstances where a share price might not already incorporate all relevant information it then self \ncorrects to reach an equilibrium point when the markets are efficient. Much of the infor mation in \nthe stock are based on human decisions which are unpredictable and in most cases irrational. For \na share price to incorporate all these decisions and their future intentions, is almost importable. \nIrrational people make decisions in the market th ese result with irrational markets. But now we \nknow that much of the decisions in the market are made by artificially intelligent machines and \nthe volume of these will expand into the future. Therefore, as these happen then the markets \nbecome more efficien t and this is discussed in detail in this paper . \n \nPeter, John and Aiden when they make their decisions on when to plan, how to plant, what \nfertilizers to use, how to trade, at what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 14,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 58,
      "text": "what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing. The second attribute is sufficient mental capability to make \nsense and process the information which is often less than perfect. This is t he concept that \nEconomics Nobel Prize Laurate and AI expert Herbert Simon called bounded rationality. He \nfurther observed that in such a situation, Peter, John and Aiden, will have to satisfice meaning \nobtaining satisfactory and sufficient solution. Now if  we add AI into this decision making process \nwhat happens to missing data and processing of information?  \n \nAll the players in the market have to make decisions, whether how much peanuts, maize and wheat \nto be planted. They make these decisions individually and/or collectively. The question that has \nbeen asked for many generations is: How do people make their choices? The theoretical answer is \nthat they make their choices based on their desires to maximize their utilities. There is a difference \nbetween a desi re to maximize utility and actually been able to make a rational decision. Studies \nhave shown that the theory of rational choice is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 )."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 15,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 59,
      "text": "ce is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 ).  \n \nNow with the advent of artificial intelligence, is it not possible to design machines that are able to \nmake decision based on rational choice theory? Doesn\u2019t artificial intelligence in decis ion making \nimplies that decisions are more and more going to be based on the theory of rational choice rather \nthan aversion to loss? Another closely aligned matter is the issue of rational expectation theory \nwhich states that people make decisions based on  future outlook, information available and past \nexperience. AI machines look at available information and past information to make a decision \nand excludes individual perception of the future. Therefore, the degree of uncertainty in AI made \ndecisions is low er than that made by human beings. For example, if one asks human beings to \nmake decisions at different times they will change their minds depending on all sorts of irrelevant \nfactors.  \n \nAs people make their decisions on what to do, there is a framework th at has been developed to aid \nwith that and this is called game theory. Game theory is a mathematical framework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 16,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 60,
      "text": "ework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g. zero sum \ngames where the gain for one player is the loss by another player. In game theory there are a \nnumber of assumptions that are made and these include the fact that players are rational, and there \nare se ts of rules and the games are played till Nash equilibrium is reached  (Nash, 1950) . Nash \nequilibrium is a position where each player cannot improve his utility by playing further. With the \nadvent of artificial intelligence and in particular multi -agent sys tems the whole theory of games \ncan be better implemented and for much complicated games for the benefit of better decision \nmaking.  \n \nAnother framework that has been developed is the framework of mechanism design which in our \nexample can be used to design a market for  the peanuts industry. Mechanism  design won Leonid \nHurwicz, Eric Maskin, and Roger Myerson a Nobel Prize in Economics  (Hurwicz  et al, 1975)) . \nMechanism design is in essence reverse game theory where instead of players, rules and then \nidentifying equilibrium, here you have the desired equilibrium and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 17,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 61,
      "text": "um and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome. For an ex ample, when an aircraft is \nflying over a highly turbulent environment then the autopilot system identifies the appropriate \nspeed, angle of attach and altitude to achieve maximum comfort for the passengers.  \n \nSuppose a trader has $1 million is faced with mak ing a choice on buying stocks from a list of 100 \nstocks. The trader, has two options either use $1 million to buy one stock or can buy a basket of \nstocks. The process of choosing the optimal basket of stocks is called portfolio optimization. The \noptimal ba sket today is not the optimal basket tomorrow and how then does he optimize this? \nPerhaps he can use a time window, say 2 months, to find the average optimal basket. All these \nvariables, e.g. time window, selection that forms a basket, how large should the  basket be, are all \nunknown variables. Nobel Prize Laureate, Harry Markowitz, proposed what is called portfolio \noptimization theory to select this basket of stocks. However, his theory is based on a number of \nassumptions including the fact that the charact er of the basket of stocks does not change, something \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 18,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 62,
      "text": "mething \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization. For example, \nhow do we solve portfolio optimization problem using the theory of ant colony intelligence which \nis based on depositing pheromones as they move and following the path with the strongest \npheromones, and then converging on an equilibrium path which happens to  be the shortest distance \nbetween the food source and ants nest?  \n \nThe theories of factual and counterfactuals are at the heart of economic theory. For example, if the \nfarmer Aiden plants wheat and instead planted maize, will he have obtained a better retur n on \ninvestments? These two scenarios, planting wheat, factual (planting wheat beca use it happened) \ncompared to the  counterfactual (planting maize because it did not happen). The economists have \na beautiful word for this and they call this opportunity cost s (Henderson, 2008) . The question that \nneeds to be answered in this thesis is whether we can use AI, with its predictive, adaptive and \nlearning capabilities, to estimate the counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 19,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 63,
      "text": "he counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments.  \n \nAnother issue that is closely related to the issues of factual and counterfactual is the concept of \ncausality  (Gujarati and Porter, 2009 ). Nob el Laureate Clive Granger thought he had pinned down \nthis matter when he proposed Granger causality which even though is useful particularly in \neconomics is not causality at all but some measure of correlation  (Dawn, 2009) . We know that \ndetecting causality  on static data is difficult and that only experimentation is the most reliable way \nof detecting causality. A causes B if and only if there is a flow of information from A to B. How \ndo we then detect such flow of information? Alternatively, we can frame ca usality in terms of \nfactual and counterfactual by posing the following problem instead: A causes B (factual) if when \nA doesn\u2019t happen then B does not happen. This paper  illustrates the centrality of causality in \nunderstanding economic problems and proposes  several ways in which to understand economics. \nWe explore the theories of rational choice and rational expectations within the dimensions of \ncausality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 20,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 64,
      "text": "causality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is. AI is made out of two words, artificial and intelligence and thus it is \nintelligence that is artificially made. Intelligence is the ability to make sense of information beyon d \nthe obvious  (Marwala et al, 2006; Marwala, 2007) . There are two types of intelligence in nature \nand these are individual intelligence and group intelligence. Individual intelligence is intelligence \nlocated in a single agent for example the farmer Aiden is individually intell igent, whereas group \nintelligence is when it is located in a group of agents such as the swarm ing of pigeons shown in \nFigure 1 or the school of fish.  \n \nWithin the field of AI intelligence manifests itself in two ways, specialised intelligence and \ngeneralise d intelligence. For example, a robot designed at the Korean Advanced Institute of \nScience an d Technology, shown in Figure 2, which drives a car, opens doors, walks and drills \nholes is demonstrating generalized intelligence. This is because it is able to do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 21,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 65,
      "text": "do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2. The KAIST humanoid robot amongst human  \n\n \nIn artificial intelligence, there are various capabilities that have been invented and these are how \nto make machine learn, optimize, predict, adapt and interact. On learning, the source of knowledge \nis how a human brain functions and from this a neural ne twork was invented which is able to take \ninformation from the world and interpret it. For example, a neural network is able to take an x -ray \npicture of the individual\u2019s lung and then establish whether the individual has pulmonary embolism \nor not. Neural ne twork is also able to take an EEG signal from an individual and establishes \nwhether the individual will be experiencing epileptic activities or not in the near future.  \n \nFigure 3 An example of a neural network  \n \nIn Figure 3, we have input and output layers . The input layer has the variables that are to be used \nas a basis for prediction whereas the output layer is what is to be predicted. An example, is a study \non using the income of parents to predict the educational outcome of the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 22,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 66,
      "text": "the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer. The hidden layers constitute \nthe mechanism or the engine which facilitates the translat ion of input data into the output. This \nengine consists of neurons (inspired by natural neurons) and the identity of these neurons which \n\nare represented by numbers is obtained from the observed historical data. The identification of \nthese neuron is obtaine d through the process called optimization. The interesting aspect of this \nsetup is that the prediction is essentially derived from the historical observation and thus confirms \nthe quote that: \"Predicting the future is nothing more than the rearrangement of  information that \ncurrently exists\"     \n \nThis are tasks that normally done by trained doctors. In fact, doctors here use what is called in \neconomic theory of rational expectation by taking current and previous histories and their \npredictions of the future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 23,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 67,
      "text": "future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty.  There are other AI techniques that have been designed for learnin g and these are \nfuzzy logic which brings precision to the spoken words and use these to make decisions through a \ncomputer and support vector machines which are based on increasing the dimension of the space \nto better differentiate attributes in objects.  \n \nThe second aspect of AI is optimization. Optimization is a process of identifying the lowest or a \nhighest point in a problem. For example, the process of identifying who is the shortest man in the \nworld is an optimization problem. Using this example, the op timization algorithm is a computer \nor mathematically based procedure of identifying who the shortest person in the world is. Another \nexample if you are designing an aircraft you might intend to make all your choices e.g. material to \nuse and shape of the pl ane to result in the lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 24,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 68,
      "text": "lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution. This controversial theory, especiall y amongst the \nreligious right, is a process in which species adapt to their environment and they achieve this \nthrough four drivers and these are mutation, random alteration of genes, crossover, mixing of \ngenes, as well as reproduction of those individuals that are most adaptive to their environment. \nThis natural optimization process has been codified to produce a computer based process called \ngenetic algorithm.  \n \nThe other aspect of AI is adaptation which is an optimization problem. For example, if one was t o \ncreate a predictive system that predicts whether it is going to rain or not. The first level of \noptimization is to set up parameters that will make a predictive system predicts whether it will rain \nor not. The second optimization level ensures that such a predictive system adapts to the evolving \nenvironment due to global warming. There have many techniques that have been developed to \nmake adaptation possible and these include fish school algorithm which is inspired by the school \nof fish behaviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 25,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 69,
      "text": "haviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities. It consists of the \ndemand characteristics of the customer which describes the relationship between price and \nquantity of goods. For example, if the price of a good is low the custo mer will buy more goods \nand services than if the price is high. The relationship between price and the willingness of the \ncustomers to buy goods and services is called the demand curve. The other aspect of the demand \nand supply law is the supply curve whic h relates the relationship between the price and the quantity \nof goods suppliers are willing to produce. For example, the higher the price the more the goods \nand services the suppliers are willing to produce. Conversely, the lower the price the lesser the \ngoods and services the suppliers are willing to produce. The point at which the suppliers are willing \nto supply a specified quantity of goods and services which are the same as those that the customers \nare willing to buy is called equilibrium. Artificial i ntelligence allows companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 26,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 70,
      "text": "companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends. In this regard individuals \nare not sub jected to prices derived fr om aggregate demand and supply (Marwala and Hurwitz, \n2017) . \n \nRational choice  \nRationality has played a pivotal role in economic theory. Some of the theories that have been used  \nassume perfect rationality. This  paper  studies the theories of rational choice , preference and utility \nmaximisation . Rational choice theory prescribes that when agents make decisions they do that \nbased on the desire to maximize utility. However, in perfect rationality each move these agents \nmake on building towards the ultimate decisi on is not necessarily optimal, however, the aggregate \nof all the moves they make can be rational. A type of artificial intelligence called r einforcement \nlearning can be used as a mechanism for mode lling rationality. T he concept of local and global \noptimiza tion can be explored within the context of evolutionary design to study the subject o f \nrationality. P roblems where acting rationally locally is vital for the overall global rational solution \nfor example making a stupid move in a game in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 27,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 71,
      "text": "in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) . \n \nRational expectations  \nThe theory of rational expectations prescribes that people predict the future based on past  and \navailable information and their predictions are not systematically wrong. In this way, predicting \nthe future is nothing more than the arrangements of the information that already exists. The theory \nof adaptive expectations predict the future based sol ely on the previous data and this has been \nfound to offer biased conclusions. With the advent of artificial intelligence , data fusion  and big \ndata the information that can be used in models to predict the future include mined text data and \npictures and this render the predictions of rational expectati ons more accurate and thus lowers the \ndegree of uncertainties  in decision making  (Marwala and Hurwitz, 2017) . \n \nBounded rationality  \nThe theory of flexibly -bounded rationality is an extension to the theory of bounded rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 28,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 72,
      "text": "rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine. Rational \ndecision making involves using information which is almost always imperfect and incomplete \ntogether with some intelligent machine which if it is a human being is inconsistent to make \ndecisions. In the theory of bounded rationa lity, this decision is made irrespective of the fact that \nthe information to be used is incomplete and imperfect and that the human brain is inconsistent \nand thus this decision that is to be made is taken within the bounds of these limitations. In the \ntheory of flexibly -bounded rationality, signal processing is used to filter noise and outliers in the \ndata and the correlation machine is applied to complete missing information and artificial \nintelligence is used to make more consistent decisions.  This results with the bounds prescribed  by \nthe theory of  bounded rationality expanding and thus increasing  the degree of rationality such \ndecisions are made  (Marwala and Hurwitz, 2017) .  \n \nAsymmetri c information  \nWhen agents come together to make decisions it is often the case that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 29,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 73,
      "text": "se that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information. Alternatively one agent can \nscreen for information to reduce the impact on asymmetric information. With the advent of big \ndata and artificial intelligence signalling and screening has been made easier. The impact of \nartificial intelligen ce on the theory of asymmetric information particularly given the fact that \nscreening is made easier due to artificial intelligence and data mining  is that it reduces the degree \nof information asymmetry in the markets and thereby reduces  the resultant distortion of the \nmarkets b y making them more efficient as well as  reduces the volume of trades in the market . \nTherefore , the more artificial intelligent there is in the market the less is the volume of trades in \nthe market, and the overall efficiency of the market is likely to improve over time as the market \nbecomes more saturated with intelligent trading and analysis agents  (Marwala and Hurwitz, 2017) . \n \nPricing  \nPricing theory is a well -established mechanism that illustrates the constant push -and-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 30,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 74,
      "text": "d-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller. This problem \nbecomes exponentially more difficult as more and more buyers and sellers are introduced into a \nmarket mode l, especially if they have strategies to stay ahead of not only their target, but also their \ncompeti tors. M ulti-agent intelligent systems are used to model complex behaviour in each agent, \nlaying the groundwork for creating complex price -finding models bas ed on the introduction or \nremoval of given agents from a large, complex system. These models can be robust and detailed \nenough to not only capture the steady -state final pricing, but also the dynamics of the price \nfluctuations that will be of great interes t to anyone wishing to model the price movements of goods \nwithin the marketplace.  The theory of pricing closely linked to the theory of value because the \nprice customers are willing to pay for goods and services is linked to how they value these goods \nand services. Contrary to what David Ricardo postulated when he proposed the labour theory of \nvalue where the value of goods and services is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 31,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 75,
      "text": "is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values.  Given the fact that the emergence  of \nartificial intelligence and big data in the market place implies i ndividualized supply and demand  \ncurve s, this implies that pricing is now individualized instead of being derived from aggregate \ndemand and supply curves  (Marwala and Hurwitz, 2017) .  \n \nGame theory  \nGame theory has been used quite extensively in economic problems. In game theory agents with \nrules interact to obtain pay -off at some equilibrium point often called Na sh equilibrium. The advent \nof artificial intelligence makes the multi -agents game theory possible. The impact of this \ndevelopment is that the implementation of this on issues such as equilibrium and optimal decisions  \nis far reaching . Furthermore, statistical physics is introduced and multi -agent games can now be \nused introduced to study games  (Marwala and Hurwitz, 2017) . \n \nMechanism design  \nIn game theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 32,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 76,
      "text": "me theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium. Mechanism design is the inverse of that, we know what the end -state should look like \nand our task is to identify the rules and pay -off function which will ensure that the desired end -\nstate is achieved. This is done by assuming that the agents in this setting acts rationally.  Deep \nlearning, big data and mechanism offer exciting avenues for economics  (Marwala and Hurwitz, \n2017) .   \n \nProspect theory  \nProspect theory offers both a fascinating alternative to modelling agent behaviour in a virtual \nmarket place, as well as an opportunity for further expanding prospect theory by utilising multiple \nagents in a larger simulated marketplace utilising multi -agent modelling. The basic premise of \nprospect theory is that the probabilities of profit / loss have a disproportionately large effect on the \nbehaviour of human agents in an economic system when compared to the actual expected outcome, \na premise that is born e out by the results of research in the field of behavioural  economics, and \none that contradicts the expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 33,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 77,
      "text": "expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling. A larger model consisting of intelligent agents that utilise a prospect -\ntheory -based means of determining risk would therefore offer greater accuracy in modelling the \nactual marketplace than the usual, truly ration al agents in more common use. This study surmise \nthat the applicability of prospect theory is determined by the level of artificial intelligence decision \nmakers that are deployed in a given problem  (Marwala and Hurwitz, 2017) .  \n \nEfficient market hypothesis  \nThe efficient market hypoth esis (in its varying forms) has allowed for the creation of financial \nmodels based on share price movements ever since its inception  (Fama, 1970) . In this paper  the \nbase assumptions drawn from root economic principles are brought into question. Their viabi lity \nfor application to the actual marketplace is dissected, elaborating on their successes as well as their \nshortcomings. The powerful techniques available within the fields of machine learning  and multi -\nagent modelling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 34,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 78,
      "text": "delling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace. In particular the application of multi -agent modelling to the market -modelling \nproblem provides a powe rful tool for simulating heterogeneous  agents with differing views and \nobjectives in order to create a more realistic market upon which to base our hypotheses. It is \nsurmised that the use of artificial intelligence in the market makes the market more effic ient \n(Marwala and Hurwitz, 2017) . \n \nPortfolio theory  \nThe basis of portfolio theory is rooted in statistical models based on Brownian motion. These \nmodels are surprisingly na\u00efve in their assumptions and resultant application within the trading \ncommunity. The application of artificial i ntelligence and machine learning to portfolio theory and \nconsequently to the applications of portfolio theory, portfolio management in particular, have \nbroad and far -reaching consequences. Artificial intelligence techniques allow us to model price \nmovement s with much greater accuracy than the random -walk nature of the original Markowitz  \nmodel, while the job of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 35,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 79,
      "text": "of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory. A particular method of price movement modelling is shown that \nmodels price movements with only simplistic inputs and still produces useful predictive results. A \nportfolio rebalancing method is also described, il lustrating the use of evolutionary computing for \nthe portfolio rebalancing problem in order to achieve the results demanded by investors within the \nframework of portfolio theory  (Marwala and Hurwitz, 2017) . \n \nRationality in facts and c ounter -facts \nThis section  introduces the concept of rational counterfactuals which is an idea of identifying a \ncounterfactual from the factual (whether perceived or real), and knowledge of the laws that govern \nthe relationships between the antecedent and the consequent, that maximizes the attainment of the \ndesired consequent  (Byrne, 2005) . In counterfactual thinking factual statements like: \u2018Greece was \nnot financially prudent and consequen tly its finances are in tatters  and with its counterfactual \nbeing: \u2018If Greece was financially prudent and consequently its finan ces are in good shape\u2018. In  order \nto build rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 36,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 80,
      "text": "ild rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) . The r ational counterfactual theory can be  applied to various problems in economics.  \n \nQuantitative finance  \nQuantitative finance has grown with the advents  of computing and this growth has accelerated in \nthe last decade with the growth of artificial intelligence . Techniques on how to price risk and \nforecast the stock price have been enhanced by the use of artificial intelligence. Subjects such as \nevolution, deep learning and big data are changing the effectiveness of quantitative finance.  \n \nEconomic Causality  \nCausality is a powerful concept which is at the heart of markets. Often one wants to establish \nwhether a particular attribute causes another. Often as human beings we have perceived causality \nthrough correlation. Because of this fact, causality has often been  confused for correlation. T he \nevolution of causality including the influential w ork of David Hume and its relevance to economics \nand finance  is an important area of study (Marwala and Hurwitz, 2017) . Various concepts and \nmodels of causality such as transmission, Granger and Pearl models of causality  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 37,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 81,
      "text": "y  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect. Bayesian inference as a \nmechanism of modelling causality  can be used to study the link between cigarette sm oking and \nlung cancer . \n1.5 Conclusion  \nThis paper  went through some of the big ideas that have been developed in the study of economics. \nThese include concepts such as Marxism, the theory of invisible hand, rational expectations, \nrational choice, mechanism design and game theory. Furthermore, this paper  discussed how some \nof these will change as man is replaced by an artificial intelligent machine as a principal agen t of \neconom ic decision making . \nReference:  \n1. Agassi, J . (1971). Faraday as a Natural Philosopher. Chicago: University of Chicago Press.  \n2. Amos , S.W. and  James , M.R. (1999). Principles of Transistor Circuits. Butterworth -\nHeinemann  \n3. Anand , P. (1993).\"Foundations of Rational Choice Under Risk\", Oxford: Oxford University \nPress.  \n4. Byrne, R.M.J. (2005). The rational imagination: how people create alternatives to reality. \nCambridge, M.A.: MIT Press.  \n5. de Vivo , G.  (1987). \"Ricardo, David,\" The New Palgrave: A Dictionary of Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 38,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 82,
      "text": "Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009). \"Causality in Economics: The Granger Causa lity Test\". \nBasic Econometrics (Fifth international ed.). New York: McGraw -Hill. \n8. Harari, Y.N. ; (2014). Sapiens: A Brief History of Humankind. Vintage , ISBN 9780099590088.  \n9. Hamilton, W. P. (1922). The Stock Market Baraometer. New York: John Wiley & Sons Inc \n(1998 reprint).  \n10. Henderson, D.R. (2008). \"Opportunity Cost\". Concise Encyclopedia of Economics (2nd ed.). \nIndianapolis: Library of Economics and Liberty.  \n11. Hurwicz, L., Radner , R. and Reiter , S. (1975) A Stochastic Decentralized Resource Allocation \nProcess:  Part I, Econometrica, Vol. 43, No. 2 (1975), pp. 187 -221 \n12. Kahneman , D. (2011). Thinking, Fast and Slow. Macmillan.  \n13. Markowitz, H.M. (March 1952). \"Portfolio Selection\". The Journal of Finance. 7 (1): 77 \u201391.  \n14. Marwala, T., Boulkaibet, I, and Adhikari S. (2017) Probabilistic Finite Element Model \nUpdating Using Bayesian Statistics: Applications to Aeronautical and Mechanical \nEngineering. John Wiley a nd Sons . \n15. Marwala, T. (2015). Causality, Correlation, and Artificial Intelligence for Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 39,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 83,
      "text": "or Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013). Economic Modeling Using Artificial Intelligence Methods. Heidelberg: \nSpringer.  \n18. Marwala, T. (2012). Condition Monitoring Using Computational Intelligence Methods. \nHeidelberg: Springer.  \n19. Marwala, T. and Lagazio, M. (2011). Militarized Conflict Modeling Using Computational \nIntelligence. Heidelb erg: Springer . \n20. Marwala, T. (2010). Finite E lement Model Updating Using Computational Intelligence \nTechniques: Applications to Structural Dynamics. Heidelberg: Springer.  \n21. Marwala, T. (2009). Computational Intelligence for Missing Data Imputation, Estimation, and \nManagement: Knowledge Optimization Te chniques. Pennsylvania: IGI Global.  \n22. Marwala, T. (2007). Computational Intelligence for Modelling Complex Systems. Delhi: \nResearch India Publ ications.  \n23. Marwala, T. and Hurwitz, E.  (2017)  Artificial Intelligence and Economic Theory: Skynet in \nthe Market. Springer.  (Accepted).  \n24. Marwala, T., Mahola, U and Nelwamondo , F.V.  (2006) Hidden Markov models and Gaussian \nmixture models for bearing fault detection using fractals. International Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 40,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 84,
      "text": "rnational Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C.  (1873), A treatise on electricity and magnetism Vol I, Oxford : Clarendon Press  \n27. Mill, J.S. (2001)  Utilitarianism and the 1868 Speech on Capital Punishment. (Sher, ed. Hackett \nPublishing Co, 2001)  \n28. Myerson, R .B. (1991). Game Theory: Analysis of Confli ct, Harvard University Press  \n29. Nash, J . (1950) \"Equilibrium points in n -person games\" Proceedings of the National Academy \nof Sciences 36(1):48 -49. \n30. Newton, I. (1726)  \"Mathematical Principles of Natural Philosophy\", 1729 English translation \nbased on 3rd Latin edition (1726), volume 2, containing Books 2 & 3.  \n31. Picketty , T. (2014)  Capital in the Twenty -First Century (Cambridge, MA: Belknap Press, \n2014)  \n32. Siegel, J. J. (2008) . \"Stock Market\". In David R. Henderson (ed.). Concise Encyclopedia of \nEconomics (2nd ed.). Indianapolis: Library of Economics and Liberty.  \n33. Simon, H . (1991). \"Bounded Rationality and Organizational Learning\". Organization Science. \n2 (1): 125 \u2013134. \n34. Smith , S. (2015) \". The Concise Encyclopedia of Economics. Liberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 41,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 85,
      "text": "iberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 42,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 86,
      "text": "How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 0,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 87,
      "text": "Artificial Intelligence and Economic Theories  \nTshilidzi Marwala and Evan Hurwitz  \nUniversity of Johannesburg  \n \nAbstract  \nThe advent of artificial intelligence has changed many disciplines such as engineering, social \nscience and economics. Artificial intelligence is a computational technique which is inspired by \nnatural intelligence such as the swarming of birds, the working of the brain and the pathfinding of \nthe ants. These techniques have  impact on economic theories . This book studies the impact of \nartificial intelligence on economic theories, a subject that has not been extensively studied. The \ntheorie s that are considered are : demand and supply,  asymmetrical information, pricing, rational \nchoice, rational expectation, game theory, efficient market hypotheses, mechanism design, \nprospect, bounded rationality, portfolio  theory , rational counterfactual and causality. The benefit \nof this book is that it evaluates existing theories of economics and update them based on the \ndevelopments in artificial intel ligence field.  \n1.1 Introduction  \n\u201cWorkers of the world unite, you have nothing to lose but chains\u201d so said Karl Marx  (Marx, 1849) . \nDespite what many Marxists claim, he never foretold the advent of artificial intelligence, otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 1,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 88,
      "text": "otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man. Man is \nthe invisible hand that drives the economy as observed by Adam Smith  (Smith, 2015) . The \neconomy was by man and about man but the theories that explained the economy did not quite \nmatch the behaviour of a man. For this reason the rational man is indeed irrational and his \nirrationality permeates every aspect of life including the very concept  we call the economy.   \n \nHomo -Sapiens have been around for hundred thousand years and throughout their existence and \neven from their forbearers have inherited certain traits and behaviours that influence them even \ntoday  (Harari, 2014) . Some of these traits and behaviours include greed, fear, bias and social \nstructure. All these traits are still with us today because of one and only one reason and that it \nbecause they all have given us an evolutionary advantage. Of course, this might ch ange in the \nfuture depending on the change of environment and therefore these traits might depart from human \nbeings. All these traits influence our decision making and the rationality thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 2,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 89,
      "text": "ty thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality. Our rationality is bound \nto all these constraints but what will happen when machine replaces humans. Is the rationality of \nmachines b ound? (Simon, 1991) Are the bounds of rationality bigger in humans than machines? \nThese are some of the questions that this book seeks to answer.  \n \nMachines are now part of everyday decision making.  They are becoming more intelligent due to \na technology ca lled artificial intelligence (AI). Alan Turing surmised that machines are intelligent \nif and only if when we interact with them we cannot tell whether we are interacting with a man or \na machine  (Traiger, 2000) . This is what is called a Turing test. No mach ine has passed this Turing \ntest over an extended levels of man -machine interaction. But this does not limit artificial \nintelligence and make machines incapable of solving complex problems.  \n \nThis paper  describes man -machine interaction and its impact on som e of the big ideas in \neconomics. Every economic epoch had its own theories or thinking. Some of these theories stood \nthe test of time but some have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 3,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 90,
      "text": "me have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England. What is not clear is why it did not happen in Asia especially India or China as \nprobabilistically these two regions had higher population densities. What was the catalyst tha t \ncaused the first industrial revolution? In the 17 century lived a man in England called Isaac Newton \nwho was educated at  Trinity College Cambridge  (Newton, 1726) . Legend claims that unlike many \npeople who had lived before him and had witnessed an apple f alling, he asked: \u201cWhy did the apple \nfall?\u201d And from this he discovered gravity an intriguing concept which was only given  an \nexplanation by a German/Swiss/American scientist Albert Einstein some hundreds of years later. \nNewton, furthermore, came with what  is now called the laws of motion which stated that objects \nwill continue at rest or keep on moving until they are moved or stopped respectively. Furthermore, \nhe observed the relationship between force, mass of an object and its acceleration. This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 4,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 91,
      "text": ". This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production. From this \nera economic principles such as Marxism, Adam Smith\u2019s invisible  hand as well as David Ricardo\u2019s \nlabor theory of value and the principle of comparative advantage were conceived  (de Vivo, 1987) .   \n \nThen in the 19th century came a British man called Michael Faraday who performed crucial \nexperiments which were later inter preted by James Clerk Maxwell through his beautiful \nmathematical equations  (Maxwell, 1873; Agassi, 1971) . Michael Faraday observed that if you \nhave a magnet and you put next to it a wire that conducts electricity and you move the wire, then \nelectricity flo ws in that conductor. This is wizardry beyond miracles of biblical proportions. Even \ntoday we generate electricity, perhaps with the exception of solar energy and few others, using this \ntechnique. Conversely, Faraday observed that again with a magnet and a  conducting wire and you \nforce electricity through the wire, then the wire moves and this was the birth of the electric motor \nthat still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 5,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 92,
      "text": "at still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced.   \n \nThen in the second half of the 20th century John Bardeen, Walter Brattain, and William Shockley \ndiscovered the transistor  (Amos and James, 1987) . It is based on semiconductors which are objects \nthat conduct electricity under certain conditions. The transistor is the catalyst for the electronic age \nthat gave us computers, cell phones, information technology and automation in our factories. It is \nthe DNA of the third industrial revoluti on. It was in the era that powerful economic concepts such \nas market efficiency where introduced prospect theory.  \n \nThe era we are living is the fourth industrial revolution. This is an era of intelligent machine  \n(Marwala, 2007; 2009; 2010; 2012; 2013; 2014 ; 2015; Marwala and Lagazio, 2012; Marwala et \nal, 2016) . The DNA of the fourth industrial revolution is AI. It will touch all aspects of our lives. \nWe will have robotic cops to protect us, robotic doctors to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 6,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 93,
      "text": "rs to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced.  What will happen to economics? Already \nwe know that the stock market no longer has crowds of people shouting a price of stocks because \nartificial intelligent software are doing the work. This paper  explores how economic theories that \nhave guided decision makers in the past will have to change or adapted in the light of artificial \nintelligent capabilities.     \n1.2 E conomics and Economic Theory  \nEconomics began when man started battering for exchanging goods. This was mainly based on the \nreality that man could not produce all he wanted. For example, suppose we have a man called Peter \nwho produces maize and another call ed John who produces peanuts. Then Peter will give half of \nhis maize for half of John\u2019s peanuts. If we include a third person Aiden who produces wheat, then \nPeter takes a third of his maize and gives it to John in exchange of a third of his peanuts, gives \nanother third to Aiden in exchange of his third of wheat. It is evident that this becomes a \ncomplicated problem quickly as more and more people exchange goods.  \n \nTo facilitate this process an additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 7,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 94,
      "text": "n additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless. It becomes useful when it has a property called trust. Trust is what \nmakes money useful. You take away the trust as Robert M ugabe did in Zimbabwe you collapse \nmoney as it happened in when Zimbabwean dollar was replaced by an American dollar as a legal \ncurrency. In this example there are factors of production that makes this transaction happen and \nthese are labour to plough, cap ital and here we are talking about seeds and land to plough these \nseeds on. The study of all these activities is called economics. The generalization of this activities \nsuch as the philosophy on how to price these goods is called economic theory. Generaliz ation is \nof course a big concept. For example if most of the time if it is cloudy and humid it rains then one \ncan generalize and say there is a natural law that states that whenever it is cloudy and humid then \nit will probably rain.   \n \nIf money is now the object to be used to exchange goods how do we put a price to peanuts, maize \nand wheat? Well it depends on your ideology. In the strictly planned economy the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 8,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 95,
      "text": "my the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed. One thing for \nsure, the producers of goods and services are only willing to sell their goods at a price which is \nhigher than the cost of producing these goods. This  paper  will explore how artificial intelligence \nchange pricing and the theory of pricing.  \n \nOn the theory of pricing one looks at the supply and demand and in our case we will use peanuts. \nWhen the supply and demand are equal this is called equilibrium. Equ ilibrium is a balance of all \neconomic forces and in our case these forces are the supply and demand of goods and services. At \nthe point of equilibrium there is no incentive to change because changing does not advantage any \nagent. With the advent of artific ial intelligence, we can now employ multi -agent system to simulate \nan economic process and observe the point of equilibrium thereby assisting in matters such as \npricing.     \n \nThe production of peanuts, wheat and maize can be industrialized using tractors. In this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 9,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 96,
      "text": "this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage. From a \nsituation like this in the major industrial town s of Britain, Karl Marx looked at this and crafted an \nideology where the workers become the owners of capital through a revolution. He went further \nand stated that \u201cTo each according to their needs and from each according to their abilities\u201d. This \nof cours e was against human nature and could not be enforced without the violence of Lenin and \nStalin.   \n \nAdam Smith looked at organization of the economy and observed that as individuals pursue goals \nof maximizing their returns the greater good of increasing prod uction and income are achieved. \nHe called the driver of this greater good the invisible hand. The concept of maximizing the greater \ngood is what is called utilitarianism and was proposed by John Stuart Mill  (Mill, 2001) . When \nthese owners of capital and wo rkers pursuing their individual wants the emergence outcome if the \ngreater good for society. Of course with the advent of multinationals that are big, and the influence \nof finance and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 10,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 97,
      "text": "ce and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) . \nAs Nobel Laureate Joseph Stiglitz in his book The Price of Inequality observes that inequality \nstifles economic growth  (Stiglitz, 2012) . The  idea of the invisible hand is phenomenon that is \nobserved even in biological systems. For example, the swarming of pigeons which is illus trated in \nFigure 1 is an example of the invisible hand because there is no leader. Each bird looks at what its \nneighbo urs as well as the group are doing and follows and what emerges is a coordinated \nmovement of the swarm towards the food source. This phenomeno n has been translated into an \nartificial intelligence  algorithm called particle swarm optimization.  \n \n \nFigure 1 Th e swarming of pigeons  \nThe other important factor is the concept of value. In our example, between peanuts, wheat and \nmaize which one is more valuable? Should we break them into their chemical components and \nprice each compound? The answer is very similar t o what William Shakespeare said about beauty: \n\u201cIt is on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 11,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 98,
      "text": "s on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues. Even w ithin a single product there is a difference in the perception of value for example \nfor Peter only 1/3 of maize is more valuable than wheat and peanuts and because of this fact Peter \nis only willing to trade the 2/3 of his maize. The concept of asymmetry o f value and its principal \nimportance in trade will be discussed in detail later in this paper  and it will be established that AI \nreduced information asymmetry.  \n \nIn an example we have given, Peter may go and create a company Peter Incorporated. The \ncompany  will have limited liability and the theory behind this is that in order to encourage people \nto form companies a legal framework is established to limit personal liability in situation when the \ncompany runs into difficulties. The company is therefore estab lished as a legal entity independent \n\nof its owners and therefore has rights and obligations. Peter may then decide to list the company \nin the local stock exchange to raise funds for the company and by so doing distributes shareholding \nto members of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 12,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 99,
      "text": "mbers of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses. Technical analysis \nis a mathematical exercise where one looks at the data of the performance of the stock and make \ndecisions on whether to buy such a stock or not. The problem with this is that people buy stock for \nno reason except that it is going up irrespective of how solid is the company with that particular \nshare price. The  dotcom bubble that busted in the early 2000 was largely based on this where a \ncompany with a shaky business model was listed in the stock market and its share price \nskyrocketed and then crashed to the ground  (Hamilton, 1922; Siegel, 2008 ). The other way of \npredicting the share price is by looking at the underlying business activities of companies and then \ndecide whether to buy the share price or not. Both these approaches have merit and today with the \nadvent of big data and AI technical an alysis is augmented with data from the internet whether \ntwitter or searching through the internet to find out what the market sentiments, including \nquantification of the fundamentals, on the particular stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 13,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 100,
      "text": "stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis. This theory basically states that it is impossible to beat the market because the share \nprice reflects all elements that are relevant. This theory states that even though there might be \ninstances where a share price might not already incorporate all relevant information it then self \ncorrects to reach an equilibrium point when the markets are efficient. Much of the infor mation in \nthe stock are based on human decisions which are unpredictable and in most cases irrational. For \na share price to incorporate all these decisions and their future intentions, is almost importable. \nIrrational people make decisions in the market th ese result with irrational markets. But now we \nknow that much of the decisions in the market are made by artificially intelligent machines and \nthe volume of these will expand into the future. Therefore, as these happen then the markets \nbecome more efficien t and this is discussed in detail in this paper . \n \nPeter, John and Aiden when they make their decisions on when to plan, how to plant, what \nfertilizers to use, how to trade, at what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 14,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 101,
      "text": "what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing. The second attribute is sufficient mental capability to make \nsense and process the information which is often less than perfect. This is t he concept that \nEconomics Nobel Prize Laurate and AI expert Herbert Simon called bounded rationality. He \nfurther observed that in such a situation, Peter, John and Aiden, will have to satisfice meaning \nobtaining satisfactory and sufficient solution. Now if  we add AI into this decision making process \nwhat happens to missing data and processing of information?  \n \nAll the players in the market have to make decisions, whether how much peanuts, maize and wheat \nto be planted. They make these decisions individually and/or collectively. The question that has \nbeen asked for many generations is: How do people make their choices? The theoretical answer is \nthat they make their choices based on their desires to maximize their utilities. There is a difference \nbetween a desi re to maximize utility and actually been able to make a rational decision. Studies \nhave shown that the theory of rational choice is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 )."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 15,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 102,
      "text": "ce is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 ).  \n \nNow with the advent of artificial intelligence, is it not possible to design machines that are able to \nmake decision based on rational choice theory? Doesn\u2019t artificial intelligence in decis ion making \nimplies that decisions are more and more going to be based on the theory of rational choice rather \nthan aversion to loss? Another closely aligned matter is the issue of rational expectation theory \nwhich states that people make decisions based on  future outlook, information available and past \nexperience. AI machines look at available information and past information to make a decision \nand excludes individual perception of the future. Therefore, the degree of uncertainty in AI made \ndecisions is low er than that made by human beings. For example, if one asks human beings to \nmake decisions at different times they will change their minds depending on all sorts of irrelevant \nfactors.  \n \nAs people make their decisions on what to do, there is a framework th at has been developed to aid \nwith that and this is called game theory. Game theory is a mathematical framework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 16,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 103,
      "text": "ework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g. zero sum \ngames where the gain for one player is the loss by another player. In game theory there are a \nnumber of assumptions that are made and these include the fact that players are rational, and there \nare se ts of rules and the games are played till Nash equilibrium is reached  (Nash, 1950) . Nash \nequilibrium is a position where each player cannot improve his utility by playing further. With the \nadvent of artificial intelligence and in particular multi -agent sys tems the whole theory of games \ncan be better implemented and for much complicated games for the benefit of better decision \nmaking.  \n \nAnother framework that has been developed is the framework of mechanism design which in our \nexample can be used to design a market for  the peanuts industry. Mechanism  design won Leonid \nHurwicz, Eric Maskin, and Roger Myerson a Nobel Prize in Economics  (Hurwicz  et al, 1975)) . \nMechanism design is in essence reverse game theory where instead of players, rules and then \nidentifying equilibrium, here you have the desired equilibrium and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 17,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 104,
      "text": "um and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome. For an ex ample, when an aircraft is \nflying over a highly turbulent environment then the autopilot system identifies the appropriate \nspeed, angle of attach and altitude to achieve maximum comfort for the passengers.  \n \nSuppose a trader has $1 million is faced with mak ing a choice on buying stocks from a list of 100 \nstocks. The trader, has two options either use $1 million to buy one stock or can buy a basket of \nstocks. The process of choosing the optimal basket of stocks is called portfolio optimization. The \noptimal ba sket today is not the optimal basket tomorrow and how then does he optimize this? \nPerhaps he can use a time window, say 2 months, to find the average optimal basket. All these \nvariables, e.g. time window, selection that forms a basket, how large should the  basket be, are all \nunknown variables. Nobel Prize Laureate, Harry Markowitz, proposed what is called portfolio \noptimization theory to select this basket of stocks. However, his theory is based on a number of \nassumptions including the fact that the charact er of the basket of stocks does not change, something \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 18,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 105,
      "text": "mething \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization. For example, \nhow do we solve portfolio optimization problem using the theory of ant colony intelligence which \nis based on depositing pheromones as they move and following the path with the strongest \npheromones, and then converging on an equilibrium path which happens to  be the shortest distance \nbetween the food source and ants nest?  \n \nThe theories of factual and counterfactuals are at the heart of economic theory. For example, if the \nfarmer Aiden plants wheat and instead planted maize, will he have obtained a better retur n on \ninvestments? These two scenarios, planting wheat, factual (planting wheat beca use it happened) \ncompared to the  counterfactual (planting maize because it did not happen). The economists have \na beautiful word for this and they call this opportunity cost s (Henderson, 2008) . The question that \nneeds to be answered in this thesis is whether we can use AI, with its predictive, adaptive and \nlearning capabilities, to estimate the counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 19,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 106,
      "text": "he counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments.  \n \nAnother issue that is closely related to the issues of factual and counterfactual is the concept of \ncausality  (Gujarati and Porter, 2009 ). Nob el Laureate Clive Granger thought he had pinned down \nthis matter when he proposed Granger causality which even though is useful particularly in \neconomics is not causality at all but some measure of correlation  (Dawn, 2009) . We know that \ndetecting causality  on static data is difficult and that only experimentation is the most reliable way \nof detecting causality. A causes B if and only if there is a flow of information from A to B. How \ndo we then detect such flow of information? Alternatively, we can frame ca usality in terms of \nfactual and counterfactual by posing the following problem instead: A causes B (factual) if when \nA doesn\u2019t happen then B does not happen. This paper  illustrates the centrality of causality in \nunderstanding economic problems and proposes  several ways in which to understand economics. \nWe explore the theories of rational choice and rational expectations within the dimensions of \ncausality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 20,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 107,
      "text": "causality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is. AI is made out of two words, artificial and intelligence and thus it is \nintelligence that is artificially made. Intelligence is the ability to make sense of information beyon d \nthe obvious  (Marwala et al, 2006; Marwala, 2007) . There are two types of intelligence in nature \nand these are individual intelligence and group intelligence. Individual intelligence is intelligence \nlocated in a single agent for example the farmer Aiden is individually intell igent, whereas group \nintelligence is when it is located in a group of agents such as the swarm ing of pigeons shown in \nFigure 1 or the school of fish.  \n \nWithin the field of AI intelligence manifests itself in two ways, specialised intelligence and \ngeneralise d intelligence. For example, a robot designed at the Korean Advanced Institute of \nScience an d Technology, shown in Figure 2, which drives a car, opens doors, walks and drills \nholes is demonstrating generalized intelligence. This is because it is able to do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 21,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 108,
      "text": "do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2. The KAIST humanoid robot amongst human  \n\n \nIn artificial intelligence, there are various capabilities that have been invented and these are how \nto make machine learn, optimize, predict, adapt and interact. On learning, the source of knowledge \nis how a human brain functions and from this a neural ne twork was invented which is able to take \ninformation from the world and interpret it. For example, a neural network is able to take an x -ray \npicture of the individual\u2019s lung and then establish whether the individual has pulmonary embolism \nor not. Neural ne twork is also able to take an EEG signal from an individual and establishes \nwhether the individual will be experiencing epileptic activities or not in the near future.  \n \nFigure 3 An example of a neural network  \n \nIn Figure 3, we have input and output layers . The input layer has the variables that are to be used \nas a basis for prediction whereas the output layer is what is to be predicted. An example, is a study \non using the income of parents to predict the educational outcome of the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 22,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 109,
      "text": "the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer. The hidden layers constitute \nthe mechanism or the engine which facilitates the translat ion of input data into the output. This \nengine consists of neurons (inspired by natural neurons) and the identity of these neurons which \n\nare represented by numbers is obtained from the observed historical data. The identification of \nthese neuron is obtaine d through the process called optimization. The interesting aspect of this \nsetup is that the prediction is essentially derived from the historical observation and thus confirms \nthe quote that: \"Predicting the future is nothing more than the rearrangement of  information that \ncurrently exists\"     \n \nThis are tasks that normally done by trained doctors. In fact, doctors here use what is called in \neconomic theory of rational expectation by taking current and previous histories and their \npredictions of the future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 23,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 110,
      "text": "future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty.  There are other AI techniques that have been designed for learnin g and these are \nfuzzy logic which brings precision to the spoken words and use these to make decisions through a \ncomputer and support vector machines which are based on increasing the dimension of the space \nto better differentiate attributes in objects.  \n \nThe second aspect of AI is optimization. Optimization is a process of identifying the lowest or a \nhighest point in a problem. For example, the process of identifying who is the shortest man in the \nworld is an optimization problem. Using this example, the op timization algorithm is a computer \nor mathematically based procedure of identifying who the shortest person in the world is. Another \nexample if you are designing an aircraft you might intend to make all your choices e.g. material to \nuse and shape of the pl ane to result in the lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 24,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 111,
      "text": "lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution. This controversial theory, especiall y amongst the \nreligious right, is a process in which species adapt to their environment and they achieve this \nthrough four drivers and these are mutation, random alteration of genes, crossover, mixing of \ngenes, as well as reproduction of those individuals that are most adaptive to their environment. \nThis natural optimization process has been codified to produce a computer based process called \ngenetic algorithm.  \n \nThe other aspect of AI is adaptation which is an optimization problem. For example, if one was t o \ncreate a predictive system that predicts whether it is going to rain or not. The first level of \noptimization is to set up parameters that will make a predictive system predicts whether it will rain \nor not. The second optimization level ensures that such a predictive system adapts to the evolving \nenvironment due to global warming. There have many techniques that have been developed to \nmake adaptation possible and these include fish school algorithm which is inspired by the school \nof fish behaviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 25,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 112,
      "text": "haviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities. It consists of the \ndemand characteristics of the customer which describes the relationship between price and \nquantity of goods. For example, if the price of a good is low the custo mer will buy more goods \nand services than if the price is high. The relationship between price and the willingness of the \ncustomers to buy goods and services is called the demand curve. The other aspect of the demand \nand supply law is the supply curve whic h relates the relationship between the price and the quantity \nof goods suppliers are willing to produce. For example, the higher the price the more the goods \nand services the suppliers are willing to produce. Conversely, the lower the price the lesser the \ngoods and services the suppliers are willing to produce. The point at which the suppliers are willing \nto supply a specified quantity of goods and services which are the same as those that the customers \nare willing to buy is called equilibrium. Artificial i ntelligence allows companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 26,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 113,
      "text": "companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends. In this regard individuals \nare not sub jected to prices derived fr om aggregate demand and supply (Marwala and Hurwitz, \n2017) . \n \nRational choice  \nRationality has played a pivotal role in economic theory. Some of the theories that have been used  \nassume perfect rationality. This  paper  studies the theories of rational choice , preference and utility \nmaximisation . Rational choice theory prescribes that when agents make decisions they do that \nbased on the desire to maximize utility. However, in perfect rationality each move these agents \nmake on building towards the ultimate decisi on is not necessarily optimal, however, the aggregate \nof all the moves they make can be rational. A type of artificial intelligence called r einforcement \nlearning can be used as a mechanism for mode lling rationality. T he concept of local and global \noptimiza tion can be explored within the context of evolutionary design to study the subject o f \nrationality. P roblems where acting rationally locally is vital for the overall global rational solution \nfor example making a stupid move in a game in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 27,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 114,
      "text": "in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) . \n \nRational expectations  \nThe theory of rational expectations prescribes that people predict the future based on past  and \navailable information and their predictions are not systematically wrong. In this way, predicting \nthe future is nothing more than the arrangements of the information that already exists. The theory \nof adaptive expectations predict the future based sol ely on the previous data and this has been \nfound to offer biased conclusions. With the advent of artificial intelligence , data fusion  and big \ndata the information that can be used in models to predict the future include mined text data and \npictures and this render the predictions of rational expectati ons more accurate and thus lowers the \ndegree of uncertainties  in decision making  (Marwala and Hurwitz, 2017) . \n \nBounded rationality  \nThe theory of flexibly -bounded rationality is an extension to the theory of bounded rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 28,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 115,
      "text": "rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine. Rational \ndecision making involves using information which is almost always imperfect and incomplete \ntogether with some intelligent machine which if it is a human being is inconsistent to make \ndecisions. In the theory of bounded rationa lity, this decision is made irrespective of the fact that \nthe information to be used is incomplete and imperfect and that the human brain is inconsistent \nand thus this decision that is to be made is taken within the bounds of these limitations. In the \ntheory of flexibly -bounded rationality, signal processing is used to filter noise and outliers in the \ndata and the correlation machine is applied to complete missing information and artificial \nintelligence is used to make more consistent decisions.  This results with the bounds prescribed  by \nthe theory of  bounded rationality expanding and thus increasing  the degree of rationality such \ndecisions are made  (Marwala and Hurwitz, 2017) .  \n \nAsymmetri c information  \nWhen agents come together to make decisions it is often the case that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 29,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 116,
      "text": "se that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information. Alternatively one agent can \nscreen for information to reduce the impact on asymmetric information. With the advent of big \ndata and artificial intelligence signalling and screening has been made easier. The impact of \nartificial intelligen ce on the theory of asymmetric information particularly given the fact that \nscreening is made easier due to artificial intelligence and data mining  is that it reduces the degree \nof information asymmetry in the markets and thereby reduces  the resultant distortion of the \nmarkets b y making them more efficient as well as  reduces the volume of trades in the market . \nTherefore , the more artificial intelligent there is in the market the less is the volume of trades in \nthe market, and the overall efficiency of the market is likely to improve over time as the market \nbecomes more saturated with intelligent trading and analysis agents  (Marwala and Hurwitz, 2017) . \n \nPricing  \nPricing theory is a well -established mechanism that illustrates the constant push -and-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 30,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 117,
      "text": "d-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller. This problem \nbecomes exponentially more difficult as more and more buyers and sellers are introduced into a \nmarket mode l, especially if they have strategies to stay ahead of not only their target, but also their \ncompeti tors. M ulti-agent intelligent systems are used to model complex behaviour in each agent, \nlaying the groundwork for creating complex price -finding models bas ed on the introduction or \nremoval of given agents from a large, complex system. These models can be robust and detailed \nenough to not only capture the steady -state final pricing, but also the dynamics of the price \nfluctuations that will be of great interes t to anyone wishing to model the price movements of goods \nwithin the marketplace.  The theory of pricing closely linked to the theory of value because the \nprice customers are willing to pay for goods and services is linked to how they value these goods \nand services. Contrary to what David Ricardo postulated when he proposed the labour theory of \nvalue where the value of goods and services is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 31,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 118,
      "text": "is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values.  Given the fact that the emergence  of \nartificial intelligence and big data in the market place implies i ndividualized supply and demand  \ncurve s, this implies that pricing is now individualized instead of being derived from aggregate \ndemand and supply curves  (Marwala and Hurwitz, 2017) .  \n \nGame theory  \nGame theory has been used quite extensively in economic problems. In game theory agents with \nrules interact to obtain pay -off at some equilibrium point often called Na sh equilibrium. The advent \nof artificial intelligence makes the multi -agents game theory possible. The impact of this \ndevelopment is that the implementation of this on issues such as equilibrium and optimal decisions  \nis far reaching . Furthermore, statistical physics is introduced and multi -agent games can now be \nused introduced to study games  (Marwala and Hurwitz, 2017) . \n \nMechanism design  \nIn game theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 32,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 119,
      "text": "me theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium. Mechanism design is the inverse of that, we know what the end -state should look like \nand our task is to identify the rules and pay -off function which will ensure that the desired end -\nstate is achieved. This is done by assuming that the agents in this setting acts rationally.  Deep \nlearning, big data and mechanism offer exciting avenues for economics  (Marwala and Hurwitz, \n2017) .   \n \nProspect theory  \nProspect theory offers both a fascinating alternative to modelling agent behaviour in a virtual \nmarket place, as well as an opportunity for further expanding prospect theory by utilising multiple \nagents in a larger simulated marketplace utilising multi -agent modelling. The basic premise of \nprospect theory is that the probabilities of profit / loss have a disproportionately large effect on the \nbehaviour of human agents in an economic system when compared to the actual expected outcome, \na premise that is born e out by the results of research in the field of behavioural  economics, and \none that contradicts the expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 33,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 120,
      "text": "expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling. A larger model consisting of intelligent agents that utilise a prospect -\ntheory -based means of determining risk would therefore offer greater accuracy in modelling the \nactual marketplace than the usual, truly ration al agents in more common use. This study surmise \nthat the applicability of prospect theory is determined by the level of artificial intelligence decision \nmakers that are deployed in a given problem  (Marwala and Hurwitz, 2017) .  \n \nEfficient market hypothesis  \nThe efficient market hypoth esis (in its varying forms) has allowed for the creation of financial \nmodels based on share price movements ever since its inception  (Fama, 1970) . In this paper  the \nbase assumptions drawn from root economic principles are brought into question. Their viabi lity \nfor application to the actual marketplace is dissected, elaborating on their successes as well as their \nshortcomings. The powerful techniques available within the fields of machine learning  and multi -\nagent modelling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 34,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 121,
      "text": "delling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace. In particular the application of multi -agent modelling to the market -modelling \nproblem provides a powe rful tool for simulating heterogeneous  agents with differing views and \nobjectives in order to create a more realistic market upon which to base our hypotheses. It is \nsurmised that the use of artificial intelligence in the market makes the market more effic ient \n(Marwala and Hurwitz, 2017) . \n \nPortfolio theory  \nThe basis of portfolio theory is rooted in statistical models based on Brownian motion. These \nmodels are surprisingly na\u00efve in their assumptions and resultant application within the trading \ncommunity. The application of artificial i ntelligence and machine learning to portfolio theory and \nconsequently to the applications of portfolio theory, portfolio management in particular, have \nbroad and far -reaching consequences. Artificial intelligence techniques allow us to model price \nmovement s with much greater accuracy than the random -walk nature of the original Markowitz  \nmodel, while the job of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 35,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 122,
      "text": "of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory. A particular method of price movement modelling is shown that \nmodels price movements with only simplistic inputs and still produces useful predictive results. A \nportfolio rebalancing method is also described, il lustrating the use of evolutionary computing for \nthe portfolio rebalancing problem in order to achieve the results demanded by investors within the \nframework of portfolio theory  (Marwala and Hurwitz, 2017) . \n \nRationality in facts and c ounter -facts \nThis section  introduces the concept of rational counterfactuals which is an idea of identifying a \ncounterfactual from the factual (whether perceived or real), and knowledge of the laws that govern \nthe relationships between the antecedent and the consequent, that maximizes the attainment of the \ndesired consequent  (Byrne, 2005) . In counterfactual thinking factual statements like: \u2018Greece was \nnot financially prudent and consequen tly its finances are in tatters  and with its counterfactual \nbeing: \u2018If Greece was financially prudent and consequently its finan ces are in good shape\u2018. In  order \nto build rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 36,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 123,
      "text": "ild rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) . The r ational counterfactual theory can be  applied to various problems in economics.  \n \nQuantitative finance  \nQuantitative finance has grown with the advents  of computing and this growth has accelerated in \nthe last decade with the growth of artificial intelligence . Techniques on how to price risk and \nforecast the stock price have been enhanced by the use of artificial intelligence. Subjects such as \nevolution, deep learning and big data are changing the effectiveness of quantitative finance.  \n \nEconomic Causality  \nCausality is a powerful concept which is at the heart of markets. Often one wants to establish \nwhether a particular attribute causes another. Often as human beings we have perceived causality \nthrough correlation. Because of this fact, causality has often been  confused for correlation. T he \nevolution of causality including the influential w ork of David Hume and its relevance to economics \nand finance  is an important area of study (Marwala and Hurwitz, 2017) . Various concepts and \nmodels of causality such as transmission, Granger and Pearl models of causality  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 37,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 124,
      "text": "y  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect. Bayesian inference as a \nmechanism of modelling causality  can be used to study the link between cigarette sm oking and \nlung cancer . \n1.5 Conclusion  \nThis paper  went through some of the big ideas that have been developed in the study of economics. \nThese include concepts such as Marxism, the theory of invisible hand, rational expectations, \nrational choice, mechanism design and game theory. Furthermore, this paper  discussed how some \nof these will change as man is replaced by an artificial intelligent machine as a principal agen t of \neconom ic decision making . \nReference:  \n1. Agassi, J . (1971). Faraday as a Natural Philosopher. Chicago: University of Chicago Press.  \n2. Amos , S.W. and  James , M.R. (1999). Principles of Transistor Circuits. Butterworth -\nHeinemann  \n3. Anand , P. (1993).\"Foundations of Rational Choice Under Risk\", Oxford: Oxford University \nPress.  \n4. Byrne, R.M.J. (2005). The rational imagination: how people create alternatives to reality. \nCambridge, M.A.: MIT Press.  \n5. de Vivo , G.  (1987). \"Ricardo, David,\" The New Palgrave: A Dictionary of Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 38,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 125,
      "text": "Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009). \"Causality in Economics: The Granger Causa lity Test\". \nBasic Econometrics (Fifth international ed.). New York: McGraw -Hill. \n8. Harari, Y.N. ; (2014). Sapiens: A Brief History of Humankind. Vintage , ISBN 9780099590088.  \n9. Hamilton, W. P. (1922). The Stock Market Baraometer. New York: John Wiley & Sons Inc \n(1998 reprint).  \n10. Henderson, D.R. (2008). \"Opportunity Cost\". Concise Encyclopedia of Economics (2nd ed.). \nIndianapolis: Library of Economics and Liberty.  \n11. Hurwicz, L., Radner , R. and Reiter , S. (1975) A Stochastic Decentralized Resource Allocation \nProcess:  Part I, Econometrica, Vol. 43, No. 2 (1975), pp. 187 -221 \n12. Kahneman , D. (2011). Thinking, Fast and Slow. Macmillan.  \n13. Markowitz, H.M. (March 1952). \"Portfolio Selection\". The Journal of Finance. 7 (1): 77 \u201391.  \n14. Marwala, T., Boulkaibet, I, and Adhikari S. (2017) Probabilistic Finite Element Model \nUpdating Using Bayesian Statistics: Applications to Aeronautical and Mechanical \nEngineering. John Wiley a nd Sons . \n15. Marwala, T. (2015). Causality, Correlation, and Artificial Intelligence for Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 39,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 126,
      "text": "or Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013). Economic Modeling Using Artificial Intelligence Methods. Heidelberg: \nSpringer.  \n18. Marwala, T. (2012). Condition Monitoring Using Computational Intelligence Methods. \nHeidelberg: Springer.  \n19. Marwala, T. and Lagazio, M. (2011). Militarized Conflict Modeling Using Computational \nIntelligence. Heidelb erg: Springer . \n20. Marwala, T. (2010). Finite E lement Model Updating Using Computational Intelligence \nTechniques: Applications to Structural Dynamics. Heidelberg: Springer.  \n21. Marwala, T. (2009). Computational Intelligence for Missing Data Imputation, Estimation, and \nManagement: Knowledge Optimization Te chniques. Pennsylvania: IGI Global.  \n22. Marwala, T. (2007). Computational Intelligence for Modelling Complex Systems. Delhi: \nResearch India Publ ications.  \n23. Marwala, T. and Hurwitz, E.  (2017)  Artificial Intelligence and Economic Theory: Skynet in \nthe Market. Springer.  (Accepted).  \n24. Marwala, T., Mahola, U and Nelwamondo , F.V.  (2006) Hidden Markov models and Gaussian \nmixture models for bearing fault detection using fractals. International Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 40,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 127,
      "text": "rnational Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C.  (1873), A treatise on electricity and magnetism Vol I, Oxford : Clarendon Press  \n27. Mill, J.S. (2001)  Utilitarianism and the 1868 Speech on Capital Punishment. (Sher, ed. Hackett \nPublishing Co, 2001)  \n28. Myerson, R .B. (1991). Game Theory: Analysis of Confli ct, Harvard University Press  \n29. Nash, J . (1950) \"Equilibrium points in n -person games\" Proceedings of the National Academy \nof Sciences 36(1):48 -49. \n30. Newton, I. (1726)  \"Mathematical Principles of Natural Philosophy\", 1729 English translation \nbased on 3rd Latin edition (1726), volume 2, containing Books 2 & 3.  \n31. Picketty , T. (2014)  Capital in the Twenty -First Century (Cambridge, MA: Belknap Press, \n2014)  \n32. Siegel, J. J. (2008) . \"Stock Market\". In David R. Henderson (ed.). Concise Encyclopedia of \nEconomics (2nd ed.). Indianapolis: Library of Economics and Liberty.  \n33. Simon, H . (1991). \"Bounded Rationality and Organizational Learning\". Organization Science. \n2 (1): 125 \u2013134. \n34. Smith , S. (2015) \". The Concise Encyclopedia of Economics. Liberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 41,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 128,
      "text": "iberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 42,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 129,
      "text": "How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 0,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 130,
      "text": "Artificial Intelligence and Economic Theories  \nTshilidzi Marwala and Evan Hurwitz  \nUniversity of Johannesburg  \n \nAbstract  \nThe advent of artificial intelligence has changed many disciplines such as engineering, social \nscience and economics. Artificial intelligence is a computational technique which is inspired by \nnatural intelligence such as the swarming of birds, the working of the brain and the pathfinding of \nthe ants. These techniques have  impact on economic theories . This book studies the impact of \nartificial intelligence on economic theories, a subject that has not been extensively studied. The \ntheorie s that are considered are : demand and supply,  asymmetrical information, pricing, rational \nchoice, rational expectation, game theory, efficient market hypotheses, mechanism design, \nprospect, bounded rationality, portfolio  theory , rational counterfactual and causality. The benefit \nof this book is that it evaluates existing theories of economics and update them based on the \ndevelopments in artificial intel ligence field.  \n1.1 Introduction  \n\u201cWorkers of the world unite, you have nothing to lose but chains\u201d so said Karl Marx  (Marx, 1849) . \nDespite what many Marxists claim, he never foretold the advent of artificial intelligence, otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 1,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 131,
      "text": "otherwise \nhe would probably have s aid \u201cArtificial intelligent machines of the world unite, you have nothing \nto lose but chains\u201d. But what Marx realized was that the principal agent of work is man. Man is \nthe invisible hand that drives the economy as observed by Adam Smith  (Smith, 2015) . The \neconomy was by man and about man but the theories that explained the economy did not quite \nmatch the behaviour of a man. For this reason the rational man is indeed irrational and his \nirrationality permeates every aspect of life including the very concept  we call the economy.   \n \nHomo -Sapiens have been around for hundred thousand years and throughout their existence and \neven from their forbearers have inherited certain traits and behaviours that influence them even \ntoday  (Harari, 2014) . Some of these traits and behaviours include greed, fear, bias and social \nstructure. All these traits are still with us today because of one and only one reason and that it \nbecause they all have given us an evolutionary advantage. Of course, this might ch ange in the \nfuture depending on the change of environment and therefore these traits might depart from human \nbeings. All these traits influence our decision making and the rationality thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 2,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 132,
      "text": "ty thereof.  Herbert Simon \ncalls the idea of making decisions making with a ll these constraints e.g. processing power of our \nbrains, incomplete information and human behaviour, bounded rationality. Our rationality is bound \nto all these constraints but what will happen when machine replaces humans. Is the rationality of \nmachines b ound? (Simon, 1991) Are the bounds of rationality bigger in humans than machines? \nThese are some of the questions that this book seeks to answer.  \n \nMachines are now part of everyday decision making.  They are becoming more intelligent due to \na technology ca lled artificial intelligence (AI). Alan Turing surmised that machines are intelligent \nif and only if when we interact with them we cannot tell whether we are interacting with a man or \na machine  (Traiger, 2000) . This is what is called a Turing test. No mach ine has passed this Turing \ntest over an extended levels of man -machine interaction. But this does not limit artificial \nintelligence and make machines incapable of solving complex problems.  \n \nThis paper  describes man -machine interaction and its impact on som e of the big ideas in \neconomics. Every economic epoch had its own theories or thinking. Some of these theories stood \nthe test of time but some have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 3,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 133,
      "text": "me have fallen by the wayside. The biggest event in history of economics is \nthe history of industrialisation and all  its various stages. The first industrial revolution happened \nin 1874 in England. What is not clear is why it did not happen in Asia especially India or China as \nprobabilistically these two regions had higher population densities. What was the catalyst tha t \ncaused the first industrial revolution? In the 17 century lived a man in England called Isaac Newton \nwho was educated at  Trinity College Cambridge  (Newton, 1726) . Legend claims that unlike many \npeople who had lived before him and had witnessed an apple f alling, he asked: \u201cWhy did the apple \nfall?\u201d And from this he discovered gravity an intriguing concept which was only given  an \nexplanation by a German/Swiss/American scientist Albert Einstein some hundreds of years later. \nNewton, furthermore, came with what  is now called the laws of motion which stated that objects \nwill continue at rest or keep on moving until they are moved or stopped respectively. Furthermore, \nhe observed the relationship between force, mass of an object and its acceleration. This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 4,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 134,
      "text": ". This thinking  \nof Newton, made us understand movement and became the catalyst or DNA for the first industrial \nrevolution. This gave us steam engines, trains and mechanical machines for production. From this \nera economic principles such as Marxism, Adam Smith\u2019s invisible  hand as well as David Ricardo\u2019s \nlabor theory of value and the principle of comparative advantage were conceived  (de Vivo, 1987) .   \n \nThen in the 19th century came a British man called Michael Faraday who performed crucial \nexperiments which were later inter preted by James Clerk Maxwell through his beautiful \nmathematical equations  (Maxwell, 1873; Agassi, 1971) . Michael Faraday observed that if you \nhave a magnet and you put next to it a wire that conducts electricity and you move the wire, then \nelectricity flo ws in that conductor. This is wizardry beyond miracles of biblical proportions. Even \ntoday we generate electricity, perhaps with the exception of solar energy and few others, using this \ntechnique. Conversely, Faraday observed that again with a magnet and a  conducting wire and you \nforce electricity through the wire, then the wire moves and this was the birth of the electric motor \nthat still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 5,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 135,
      "text": "at still moves our assembly lines. These events were the DNA for the second industrial \nrevolution. From this era economic princi ples such as mass production and Keynesian economics \nwere introduced.   \n \nThen in the second half of the 20th century John Bardeen, Walter Brattain, and William Shockley \ndiscovered the transistor  (Amos and James, 1987) . It is based on semiconductors which are objects \nthat conduct electricity under certain conditions. The transistor is the catalyst for the electronic age \nthat gave us computers, cell phones, information technology and automation in our factories. It is \nthe DNA of the third industrial revoluti on. It was in the era that powerful economic concepts such \nas market efficiency where introduced prospect theory.  \n \nThe era we are living is the fourth industrial revolution. This is an era of intelligent machine  \n(Marwala, 2007; 2009; 2010; 2012; 2013; 2014 ; 2015; Marwala and Lagazio, 2012; Marwala et \nal, 2016) . The DNA of the fourth industrial revolution is AI. It will touch all aspects of our lives. \nWe will have robotic cops to protect us, robotic doctors to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 6,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 136,
      "text": "rs to assist us with medical issues, all our \nvital org ans will be monitored real time to extend human lives, driverless cars and aircraft as well \nas human empty factories as human will be replaced.  What will happen to economics? Already \nwe know that the stock market no longer has crowds of people shouting a price of stocks because \nartificial intelligent software are doing the work. This paper  explores how economic theories that \nhave guided decision makers in the past will have to change or adapted in the light of artificial \nintelligent capabilities.     \n1.2 E conomics and Economic Theory  \nEconomics began when man started battering for exchanging goods. This was mainly based on the \nreality that man could not produce all he wanted. For example, suppose we have a man called Peter \nwho produces maize and another call ed John who produces peanuts. Then Peter will give half of \nhis maize for half of John\u2019s peanuts. If we include a third person Aiden who produces wheat, then \nPeter takes a third of his maize and gives it to John in exchange of a third of his peanuts, gives \nanother third to Aiden in exchange of his third of wheat. It is evident that this becomes a \ncomplicated problem quickly as more and more people exchange goods.  \n \nTo facilitate this process an additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 7,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 137,
      "text": "n additional entity called money comes into the picture for one an d one \nreason only and that is to simplify the exchange of goods and services. Well not quite because \nmoney on its own is worthless. It becomes useful when it has a property called trust. Trust is what \nmakes money useful. You take away the trust as Robert M ugabe did in Zimbabwe you collapse \nmoney as it happened in when Zimbabwean dollar was replaced by an American dollar as a legal \ncurrency. In this example there are factors of production that makes this transaction happen and \nthese are labour to plough, cap ital and here we are talking about seeds and land to plough these \nseeds on. The study of all these activities is called economics. The generalization of this activities \nsuch as the philosophy on how to price these goods is called economic theory. Generaliz ation is \nof course a big concept. For example if most of the time if it is cloudy and humid it rains then one \ncan generalize and say there is a natural law that states that whenever it is cloudy and humid then \nit will probably rain.   \n \nIf money is now the object to be used to exchange goods how do we put a price to peanuts, maize \nand wheat? Well it depends on your ideology. In the strictly planned economy the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 8,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 138,
      "text": "my the authority \ndetermines the price whereas in the market economy it is determined by the demand and sup ply \ncharacteristics whereas in a market in Delhi you negotiate a price and it is not fixed. One thing for \nsure, the producers of goods and services are only willing to sell their goods at a price which is \nhigher than the cost of producing these goods. This  paper  will explore how artificial intelligence \nchange pricing and the theory of pricing.  \n \nOn the theory of pricing one looks at the supply and demand and in our case we will use peanuts. \nWhen the supply and demand are equal this is called equilibrium. Equ ilibrium is a balance of all \neconomic forces and in our case these forces are the supply and demand of goods and services. At \nthe point of equilibrium there is no incentive to change because changing does not advantage any \nagent. With the advent of artific ial intelligence, we can now employ multi -agent system to simulate \nan economic process and observe the point of equilibrium thereby assisting in matters such as \npricing.     \n \nThe production of peanuts, wheat and maize can be industrialized using tractors. In this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 9,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 139,
      "text": "this situation \nthe owners of capital do not necessarily have to work, the workers have to work. In the worst case \nscenario, these workers can be so exploited that they are paid a bare minimum wage. From a \nsituation like this in the major industrial town s of Britain, Karl Marx looked at this and crafted an \nideology where the workers become the owners of capital through a revolution. He went further \nand stated that \u201cTo each according to their needs and from each according to their abilities\u201d. This \nof cours e was against human nature and could not be enforced without the violence of Lenin and \nStalin.   \n \nAdam Smith looked at organization of the economy and observed that as individuals pursue goals \nof maximizing their returns the greater good of increasing prod uction and income are achieved. \nHe called the driver of this greater good the invisible hand. The concept of maximizing the greater \ngood is what is called utilitarianism and was proposed by John Stuart Mill  (Mill, 2001) . When \nthese owners of capital and wo rkers pursuing their individual wants the emergence outcome if the \ngreater good for society. Of course with the advent of multinationals that are big, and the influence \nof finance and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 10,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 140,
      "text": "ce and advertising this is not necessarily th e case. In fact as Thomas Picke tty observes in \nhis seminal book Capital in the 21st Century  that inequality is still a major problem  (Piketty, 2014) . \nAs Nobel Laureate Joseph Stiglitz in his book The Price of Inequality observes that inequality \nstifles economic growth  (Stiglitz, 2012) . The  idea of the invisible hand is phenomenon that is \nobserved even in biological systems. For example, the swarming of pigeons which is illus trated in \nFigure 1 is an example of the invisible hand because there is no leader. Each bird looks at what its \nneighbo urs as well as the group are doing and follows and what emerges is a coordinated \nmovement of the swarm towards the food source. This phenomeno n has been translated into an \nartificial intelligence  algorithm called particle swarm optimization.  \n \n \nFigure 1 Th e swarming of pigeons  \nThe other important factor is the concept of value. In our example, between peanuts, wheat and \nmaize which one is more valuable? Should we break them into their chemical components and \nprice each compound? The answer is very similar t o what William Shakespeare said about beauty: \n\u201cIt is on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 11,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 141,
      "text": "s on the eyes of the beholder\u201d. It depends on an individual\u2019s frame of reference and the reason \nwhy these three farmers will exchange goods is because of the differences in the perception of \nvalues. Even w ithin a single product there is a difference in the perception of value for example \nfor Peter only 1/3 of maize is more valuable than wheat and peanuts and because of this fact Peter \nis only willing to trade the 2/3 of his maize. The concept of asymmetry o f value and its principal \nimportance in trade will be discussed in detail later in this paper  and it will be established that AI \nreduced information asymmetry.  \n \nIn an example we have given, Peter may go and create a company Peter Incorporated. The \ncompany  will have limited liability and the theory behind this is that in order to encourage people \nto form companies a legal framework is established to limit personal liability in situation when the \ncompany runs into difficulties. The company is therefore estab lished as a legal entity independent \n\nof its owners and therefore has rights and obligations. Peter may then decide to list the company \nin the local stock exchange to raise funds for the company and by so doing distributes shareholding \nto members of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 12,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 142,
      "text": "mbers of the pub lic.  \n \nThere is whole discipline on how to predict the future price of stocks and there are two general \nways of doing this and these are through fundamental and technical analyses. Technical analysis \nis a mathematical exercise where one looks at the data of the performance of the stock and make \ndecisions on whether to buy such a stock or not. The problem with this is that people buy stock for \nno reason except that it is going up irrespective of how solid is the company with that particular \nshare price. The  dotcom bubble that busted in the early 2000 was largely based on this where a \ncompany with a shaky business model was listed in the stock market and its share price \nskyrocketed and then crashed to the ground  (Hamilton, 1922; Siegel, 2008 ). The other way of \npredicting the share price is by looking at the underlying business activities of companies and then \ndecide whether to buy the share price or not. Both these approaches have merit and today with the \nadvent of big data and AI technical an alysis is augmented with data from the internet whether \ntwitter or searching through the internet to find out what the market sentiments, including \nquantification of the fundamentals, on the particular stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 13,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 143,
      "text": "stock are. These will be discussed in this paper  \nin a section  on quantitative analysis.  \n \nAnother theory that has emerged from the stock market is the theory of the efficient market \nhypothesis. This theory basically states that it is impossible to beat the market because the share \nprice reflects all elements that are relevant. This theory states that even though there might be \ninstances where a share price might not already incorporate all relevant information it then self \ncorrects to reach an equilibrium point when the markets are efficient. Much of the infor mation in \nthe stock are based on human decisions which are unpredictable and in most cases irrational. For \na share price to incorporate all these decisions and their future intentions, is almost importable. \nIrrational people make decisions in the market th ese result with irrational markets. But now we \nknow that much of the decisions in the market are made by artificially intelligent machines and \nthe volume of these will expand into the future. Therefore, as these happen then the markets \nbecome more efficien t and this is discussed in detail in this paper . \n \nPeter, John and Aiden when they make their decisions on when to plan, how to plant, what \nfertilizers to use, how to trade, at what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 14,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 144,
      "text": "what price and who to seek advice from, they require certain \nattributes to make these decisions. The first attribute is information and this is often limited, not \nwholly accurate and often missing. The second attribute is sufficient mental capability to make \nsense and process the information which is often less than perfect. This is t he concept that \nEconomics Nobel Prize Laurate and AI expert Herbert Simon called bounded rationality. He \nfurther observed that in such a situation, Peter, John and Aiden, will have to satisfice meaning \nobtaining satisfactory and sufficient solution. Now if  we add AI into this decision making process \nwhat happens to missing data and processing of information?  \n \nAll the players in the market have to make decisions, whether how much peanuts, maize and wheat \nto be planted. They make these decisions individually and/or collectively. The question that has \nbeen asked for many generations is: How do people make their choices? The theoretical answer is \nthat they make their choices based on their desires to maximize their utilities. There is a difference \nbetween a desi re to maximize utility and actually been able to make a rational decision. Studies \nhave shown that the theory of rational choice is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 )."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 15,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 145,
      "text": "ce is not what drives decision making. In fact Kahneman \nin his book Thinking fast and slow demonstrated that people make decisions  based on their \naversion to loss  (Kahneman , 2011 ; Anand, 1993 ).  \n \nNow with the advent of artificial intelligence, is it not possible to design machines that are able to \nmake decision based on rational choice theory? Doesn\u2019t artificial intelligence in decis ion making \nimplies that decisions are more and more going to be based on the theory of rational choice rather \nthan aversion to loss? Another closely aligned matter is the issue of rational expectation theory \nwhich states that people make decisions based on  future outlook, information available and past \nexperience. AI machines look at available information and past information to make a decision \nand excludes individual perception of the future. Therefore, the degree of uncertainty in AI made \ndecisions is low er than that made by human beings. For example, if one asks human beings to \nmake decisions at different times they will change their minds depending on all sorts of irrelevant \nfactors.  \n \nAs people make their decisions on what to do, there is a framework th at has been developed to aid \nwith that and this is called game theory. Game theory is a mathematical framework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 16,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 146,
      "text": "ework which assists \nus in making optimal decisions given the fact that we do not know what other people\u2019s choices \nwill be but their choices influence t he outcome. There are many types of games e.g. zero sum \ngames where the gain for one player is the loss by another player. In game theory there are a \nnumber of assumptions that are made and these include the fact that players are rational, and there \nare se ts of rules and the games are played till Nash equilibrium is reached  (Nash, 1950) . Nash \nequilibrium is a position where each player cannot improve his utility by playing further. With the \nadvent of artificial intelligence and in particular multi -agent sys tems the whole theory of games \ncan be better implemented and for much complicated games for the benefit of better decision \nmaking.  \n \nAnother framework that has been developed is the framework of mechanism design which in our \nexample can be used to design a market for  the peanuts industry. Mechanism  design won Leonid \nHurwicz, Eric Maskin, and Roger Myerson a Nobel Prize in Economics  (Hurwicz  et al, 1975)) . \nMechanism design is in essence reverse game theory where instead of players, rules and then \nidentifying equilibrium, here you have the desired equilibrium and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 17,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 147,
      "text": "um and players and you want to design \nthe rules so that the desired equilibrium can be reached. This is in effect a control problem where \nthe system is designed to achieve a certain desired outcome. For an ex ample, when an aircraft is \nflying over a highly turbulent environment then the autopilot system identifies the appropriate \nspeed, angle of attach and altitude to achieve maximum comfort for the passengers.  \n \nSuppose a trader has $1 million is faced with mak ing a choice on buying stocks from a list of 100 \nstocks. The trader, has two options either use $1 million to buy one stock or can buy a basket of \nstocks. The process of choosing the optimal basket of stocks is called portfolio optimization. The \noptimal ba sket today is not the optimal basket tomorrow and how then does he optimize this? \nPerhaps he can use a time window, say 2 months, to find the average optimal basket. All these \nvariables, e.g. time window, selection that forms a basket, how large should the  basket be, are all \nunknown variables. Nobel Prize Laureate, Harry Markowitz, proposed what is called portfolio \noptimization theory to select this basket of stocks. However, his theory is based on a number of \nassumptions including the fact that the charact er of the basket of stocks does not change, something \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 18,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 148,
      "text": "mething \nthat is called stationarity in mathematical nomenclature  (Markowitz  et al., 1952) . With the advent \nof AI, one is now able to apply this technology to the theory of portfolio optimization. For example, \nhow do we solve portfolio optimization problem using the theory of ant colony intelligence which \nis based on depositing pheromones as they move and following the path with the strongest \npheromones, and then converging on an equilibrium path which happens to  be the shortest distance \nbetween the food source and ants nest?  \n \nThe theories of factual and counterfactuals are at the heart of economic theory. For example, if the \nfarmer Aiden plants wheat and instead planted maize, will he have obtained a better retur n on \ninvestments? These two scenarios, planting wheat, factual (planting wheat beca use it happened) \ncompared to the  counterfactual (planting maize because it did not happen). The economists have \na beautiful word for this and they call this opportunity cost s (Henderson, 2008) . The question that \nneeds to be answered in this thesis is whether we can use AI, with its predictive, adaptive and \nlearning capabilities, to estimate the counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 19,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 149,
      "text": "he counterfactuals and thus economic costs. If we are able to \nquantify the opportunit y cost it means this can be integrated into decision making to make choices \nthat maximize return on investments.  \n \nAnother issue that is closely related to the issues of factual and counterfactual is the concept of \ncausality  (Gujarati and Porter, 2009 ). Nob el Laureate Clive Granger thought he had pinned down \nthis matter when he proposed Granger causality which even though is useful particularly in \neconomics is not causality at all but some measure of correlation  (Dawn, 2009) . We know that \ndetecting causality  on static data is difficult and that only experimentation is the most reliable way \nof detecting causality. A causes B if and only if there is a flow of information from A to B. How \ndo we then detect such flow of information? Alternatively, we can frame ca usality in terms of \nfactual and counterfactual by posing the following problem instead: A causes B (factual) if when \nA doesn\u2019t happen then B does not happen. This paper  illustrates the centrality of causality in \nunderstanding economic problems and proposes  several ways in which to understand economics. \nWe explore the theories of rational choice and rational expectations within the dimensions of \ncausality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 20,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 150,
      "text": "causality.                  \n1.3 Artificial Intelligence  \nIn order to rewrite economic theory in the light of artif icial intelligence it is important to understand \nwhat artificial intelligence is. AI is made out of two words, artificial and intelligence and thus it is \nintelligence that is artificially made. Intelligence is the ability to make sense of information beyon d \nthe obvious  (Marwala et al, 2006; Marwala, 2007) . There are two types of intelligence in nature \nand these are individual intelligence and group intelligence. Individual intelligence is intelligence \nlocated in a single agent for example the farmer Aiden is individually intell igent, whereas group \nintelligence is when it is located in a group of agents such as the swarm ing of pigeons shown in \nFigure 1 or the school of fish.  \n \nWithin the field of AI intelligence manifests itself in two ways, specialised intelligence and \ngeneralise d intelligence. For example, a robot designed at the Korean Advanced Institute of \nScience an d Technology, shown in Figure 2, which drives a car, opens doors, walks and drills \nholes is demonstrating generalized intelligence. This is because it is able to do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 21,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 151,
      "text": "do  multiple \nindependent tasks. A voice recognition software which is able to hear and interpret a person is a \nspecialised robot because it is trained and is able to do one task only.  \n \nFigure 2. The KAIST humanoid robot amongst human  \n\n \nIn artificial intelligence, there are various capabilities that have been invented and these are how \nto make machine learn, optimize, predict, adapt and interact. On learning, the source of knowledge \nis how a human brain functions and from this a neural ne twork was invented which is able to take \ninformation from the world and interpret it. For example, a neural network is able to take an x -ray \npicture of the individual\u2019s lung and then establish whether the individual has pulmonary embolism \nor not. Neural ne twork is also able to take an EEG signal from an individual and establishes \nwhether the individual will be experiencing epileptic activities or not in the near future.  \n \nFigure 3 An example of a neural network  \n \nIn Figure 3, we have input and output layers . The input layer has the variables that are to be used \nas a basis for prediction whereas the output layer is what is to be predicted. An example, is a study \non using the income of parents to predict the educational outcome of the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 22,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 152,
      "text": "the children as measured by \nwhether they go to college or not. Here the income of the parents will be in the input layer whereas \nthe educational outcome of the children will be in the output layer. The hidden layers constitute \nthe mechanism or the engine which facilitates the translat ion of input data into the output. This \nengine consists of neurons (inspired by natural neurons) and the identity of these neurons which \n\nare represented by numbers is obtained from the observed historical data. The identification of \nthese neuron is obtaine d through the process called optimization. The interesting aspect of this \nsetup is that the prediction is essentially derived from the historical observation and thus confirms \nthe quote that: \"Predicting the future is nothing more than the rearrangement of  information that \ncurrently exists\"     \n \nThis are tasks that normally done by trained doctors. In fact, doctors here use what is called in \neconomic theory of rational expectation by taking current and previous histories and their \npredictions of the future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 23,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 153,
      "text": "future t o make decisions. What AI does is not necessarily to change the predicted \ndiagnosis but to bring more consistency which in statistically terms called reduction of the degree \nof uncertainty.  There are other AI techniques that have been designed for learnin g and these are \nfuzzy logic which brings precision to the spoken words and use these to make decisions through a \ncomputer and support vector machines which are based on increasing the dimension of the space \nto better differentiate attributes in objects.  \n \nThe second aspect of AI is optimization. Optimization is a process of identifying the lowest or a \nhighest point in a problem. For example, the process of identifying who is the shortest man in the \nworld is an optimization problem. Using this example, the op timization algorithm is a computer \nor mathematically based procedure of identifying who the shortest person in the world is. Another \nexample if you are designing an aircraft you might intend to make all your choices e.g. material to \nuse and shape of the pl ane to result in the lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 24,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 154,
      "text": "lowest amount of aeroplane weight. The parameters that \nyou will play around are called design variables. Nature is full of optimization processes and one \nexample is the process of natural evolution. This controversial theory, especiall y amongst the \nreligious right, is a process in which species adapt to their environment and they achieve this \nthrough four drivers and these are mutation, random alteration of genes, crossover, mixing of \ngenes, as well as reproduction of those individuals that are most adaptive to their environment. \nThis natural optimization process has been codified to produce a computer based process called \ngenetic algorithm.  \n \nThe other aspect of AI is adaptation which is an optimization problem. For example, if one was t o \ncreate a predictive system that predicts whether it is going to rain or not. The first level of \noptimization is to set up parameters that will make a predictive system predicts whether it will rain \nor not. The second optimization level ensures that such a predictive system adapts to the evolving \nenvironment due to global warming. There have many techniques that have been developed to \nmake adaptation possible and these include fish school algorithm which is inspired by the school \nof fish behaviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 25,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 155,
      "text": "haviour and ant colony optimization which is inspired by the colony of ants.  \n \n1.4 Economic Theories  \nSupply and Demand  \nThe law of demand and supply is the fundamental law of economic activities. It consists of the \ndemand characteristics of the customer which describes the relationship between price and \nquantity of goods. For example, if the price of a good is low the custo mer will buy more goods \nand services than if the price is high. The relationship between price and the willingness of the \ncustomers to buy goods and services is called the demand curve. The other aspect of the demand \nand supply law is the supply curve whic h relates the relationship between the price and the quantity \nof goods suppliers are willing to produce. For example, the higher the price the more the goods \nand services the suppliers are willing to produce. Conversely, the lower the price the lesser the \ngoods and services the suppliers are willing to produce. The point at which the suppliers are willing \nto supply a specified quantity of goods and services which are the same as those that the customers \nare willing to buy is called equilibrium. Artificial i ntelligence allows companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 26,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 156,
      "text": "companies, such as Amazon, \nto gather information on the customers such that they are able to create an individual demand and \nsupply curve and therefore price individually based on historical trends. In this regard individuals \nare not sub jected to prices derived fr om aggregate demand and supply (Marwala and Hurwitz, \n2017) . \n \nRational choice  \nRationality has played a pivotal role in economic theory. Some of the theories that have been used  \nassume perfect rationality. This  paper  studies the theories of rational choice , preference and utility \nmaximisation . Rational choice theory prescribes that when agents make decisions they do that \nbased on the desire to maximize utility. However, in perfect rationality each move these agents \nmake on building towards the ultimate decisi on is not necessarily optimal, however, the aggregate \nof all the moves they make can be rational. A type of artificial intelligence called r einforcement \nlearning can be used as a mechanism for mode lling rationality. T he concept of local and global \noptimiza tion can be explored within the context of evolutionary design to study the subject o f \nrationality. P roblems where acting rationally locally is vital for the overall global rational solution \nfor example making a stupid move in a game in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 27,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 157,
      "text": "in order to deceive yo ur opponent  are studied and  \nthe condition in which an irrational technique becomes necessary for achieving global rationality  \ncan be derived  (Marwala and Hurwitz, 2017) . \n \nRational expectations  \nThe theory of rational expectations prescribes that people predict the future based on past  and \navailable information and their predictions are not systematically wrong. In this way, predicting \nthe future is nothing more than the arrangements of the information that already exists. The theory \nof adaptive expectations predict the future based sol ely on the previous data and this has been \nfound to offer biased conclusions. With the advent of artificial intelligence , data fusion  and big \ndata the information that can be used in models to predict the future include mined text data and \npictures and this render the predictions of rational expectati ons more accurate and thus lowers the \ndegree of uncertainties  in decision making  (Marwala and Hurwitz, 2017) . \n \nBounded rationality  \nThe theory of flexibly -bounded rationality is an extension to the theory of bounded rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 28,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 158,
      "text": "rationalit y. In \nparticular, it is noted  that a decision making process involves three components and these are, \ninformation gathering and analysis, the correlation machine and  the causal machine. Rational \ndecision making involves using information which is almost always imperfect and incomplete \ntogether with some intelligent machine which if it is a human being is inconsistent to make \ndecisions. In the theory of bounded rationa lity, this decision is made irrespective of the fact that \nthe information to be used is incomplete and imperfect and that the human brain is inconsistent \nand thus this decision that is to be made is taken within the bounds of these limitations. In the \ntheory of flexibly -bounded rationality, signal processing is used to filter noise and outliers in the \ndata and the correlation machine is applied to complete missing information and artificial \nintelligence is used to make more consistent decisions.  This results with the bounds prescribed  by \nthe theory of  bounded rationality expanding and thus increasing  the degree of rationality such \ndecisions are made  (Marwala and Hurwitz, 2017) .  \n \nAsymmetri c information  \nWhen agents come together to make decisions it is often the case that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 29,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 159,
      "text": "se that one agent has more \ninformation than the other and this distorts the market. Often if one agent intends to manipulate a \ndecision in its favour the agent can signal wrong or right information. Alternatively one agent can \nscreen for information to reduce the impact on asymmetric information. With the advent of big \ndata and artificial intelligence signalling and screening has been made easier. The impact of \nartificial intelligen ce on the theory of asymmetric information particularly given the fact that \nscreening is made easier due to artificial intelligence and data mining  is that it reduces the degree \nof information asymmetry in the markets and thereby reduces  the resultant distortion of the \nmarkets b y making them more efficient as well as  reduces the volume of trades in the market . \nTherefore , the more artificial intelligent there is in the market the less is the volume of trades in \nthe market, and the overall efficiency of the market is likely to improve over time as the market \nbecomes more saturated with intelligent trading and analysis agents  (Marwala and Hurwitz, 2017) . \n \nPricing  \nPricing theory is a well -established mechanism that illustrates the constant push -and-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 30,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 160,
      "text": "d-pull of buyers \nversus consumers and the final semi -stable  price that is found for a given good. The theory \naccounts very well for the two -person situation of a single buyer and a single seller. This problem \nbecomes exponentially more difficult as more and more buyers and sellers are introduced into a \nmarket mode l, especially if they have strategies to stay ahead of not only their target, but also their \ncompeti tors. M ulti-agent intelligent systems are used to model complex behaviour in each agent, \nlaying the groundwork for creating complex price -finding models bas ed on the introduction or \nremoval of given agents from a large, complex system. These models can be robust and detailed \nenough to not only capture the steady -state final pricing, but also the dynamics of the price \nfluctuations that will be of great interes t to anyone wishing to model the price movements of goods \nwithin the marketplace.  The theory of pricing closely linked to the theory of value because the \nprice customers are willing to pay for goods and services is linked to how they value these goods \nand services. Contrary to what David Ricardo postulated when he proposed the labour theory of \nvalue where the value of goods and services is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 31,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 161,
      "text": "is measured by how much labor went into the \nmanufacturing of those goods and services, value is dynamic and artificial int elligence offers a \nunique opportunity to dynamically estimate those values.  Given the fact that the emergence  of \nartificial intelligence and big data in the market place implies i ndividualized supply and demand  \ncurve s, this implies that pricing is now individualized instead of being derived from aggregate \ndemand and supply curves  (Marwala and Hurwitz, 2017) .  \n \nGame theory  \nGame theory has been used quite extensively in economic problems. In game theory agents with \nrules interact to obtain pay -off at some equilibrium point often called Na sh equilibrium. The advent \nof artificial intelligence makes the multi -agents game theory possible. The impact of this \ndevelopment is that the implementation of this on issues such as equilibrium and optimal decisions  \nis far reaching . Furthermore, statistical physics is introduced and multi -agent games can now be \nused introduced to study games  (Marwala and Hurwitz, 2017) . \n \nMechanism design  \nIn game theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 32,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 162,
      "text": "me theory players have rules and pay -off and they interact until some point of equilibrium is \nachieved. This way we are able to see how a game with sets of rules and a pay -off reaches \nequilibrium. Mechanism design is the inverse of that, we know what the end -state should look like \nand our task is to identify the rules and pay -off function which will ensure that the desired end -\nstate is achieved. This is done by assuming that the agents in this setting acts rationally.  Deep \nlearning, big data and mechanism offer exciting avenues for economics  (Marwala and Hurwitz, \n2017) .   \n \nProspect theory  \nProspect theory offers both a fascinating alternative to modelling agent behaviour in a virtual \nmarket place, as well as an opportunity for further expanding prospect theory by utilising multiple \nagents in a larger simulated marketplace utilising multi -agent modelling. The basic premise of \nprospect theory is that the probabilities of profit / loss have a disproportionately large effect on the \nbehaviour of human agents in an economic system when compared to the actual expected outcome, \na premise that is born e out by the results of research in the field of behavioural  economics, and \none that contradicts the expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 33,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 163,
      "text": "expectation of rationality that is used as a basis of so much economic \nmodelling and theory, especially in relation the assumption of rationality that form s the bedrock \nof microeconomic modelling. A larger model consisting of intelligent agents that utilise a prospect -\ntheory -based means of determining risk would therefore offer greater accuracy in modelling the \nactual marketplace than the usual, truly ration al agents in more common use. This study surmise \nthat the applicability of prospect theory is determined by the level of artificial intelligence decision \nmakers that are deployed in a given problem  (Marwala and Hurwitz, 2017) .  \n \nEfficient market hypothesis  \nThe efficient market hypoth esis (in its varying forms) has allowed for the creation of financial \nmodels based on share price movements ever since its inception  (Fama, 1970) . In this paper  the \nbase assumptions drawn from root economic principles are brought into question. Their viabi lity \nfor application to the actual marketplace is dissected, elaborating on their successes as well as their \nshortcomings. The powerful techniques available within the fields of machine learning  and multi -\nagent modelling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 34,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 164,
      "text": "delling  are explored, illustrating their po tential to forge a new paradigm in which more \naccurate models can be created upon a basis that presents a truer reflection of the underlying \nmarketplace. In particular the application of multi -agent modelling to the market -modelling \nproblem provides a powe rful tool for simulating heterogeneous  agents with differing views and \nobjectives in order to create a more realistic market upon which to base our hypotheses. It is \nsurmised that the use of artificial intelligence in the market makes the market more effic ient \n(Marwala and Hurwitz, 2017) . \n \nPortfolio theory  \nThe basis of portfolio theory is rooted in statistical models based on Brownian motion. These \nmodels are surprisingly na\u00efve in their assumptions and resultant application within the trading \ncommunity. The application of artificial i ntelligence and machine learning to portfolio theory and \nconsequently to the applications of portfolio theory, portfolio management in particular, have \nbroad and far -reaching consequences. Artificial intelligence techniques allow us to model price \nmovement s with much greater accuracy than the random -walk nature of the original Markowitz  \nmodel, while the job of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 35,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 165,
      "text": "of optimising a portfolio can be performed with greater optimality and \nefficiency using evolutionary computation while still staying true to the origina l goals and \nconceptions of portfolio theory. A particular method of price movement modelling is shown that \nmodels price movements with only simplistic inputs and still produces useful predictive results. A \nportfolio rebalancing method is also described, il lustrating the use of evolutionary computing for \nthe portfolio rebalancing problem in order to achieve the results demanded by investors within the \nframework of portfolio theory  (Marwala and Hurwitz, 2017) . \n \nRationality in facts and c ounter -facts \nThis section  introduces the concept of rational counterfactuals which is an idea of identifying a \ncounterfactual from the factual (whether perceived or real), and knowledge of the laws that govern \nthe relationships between the antecedent and the consequent, that maximizes the attainment of the \ndesired consequent  (Byrne, 2005) . In counterfactual thinking factual statements like: \u2018Greece was \nnot financially prudent and consequen tly its finances are in tatters  and with its counterfactual \nbeing: \u2018If Greece was financially prudent and consequently its finan ces are in good shape\u2018. In  order \nto build rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 36,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 166,
      "text": "ild rational counterfactuals artifi cial intelligence techniques can be  applied  to identify the \nantecedent that gives the desired consequent which is deemed rational  (Marwala and Hurwitz, \n2017) . The r ational counterfactual theory can be  applied to various problems in economics.  \n \nQuantitative finance  \nQuantitative finance has grown with the advents  of computing and this growth has accelerated in \nthe last decade with the growth of artificial intelligence . Techniques on how to price risk and \nforecast the stock price have been enhanced by the use of artificial intelligence. Subjects such as \nevolution, deep learning and big data are changing the effectiveness of quantitative finance.  \n \nEconomic Causality  \nCausality is a powerful concept which is at the heart of markets. Often one wants to establish \nwhether a particular attribute causes another. Often as human beings we have perceived causality \nthrough correlation. Because of this fact, causality has often been  confused for correlation. T he \nevolution of causality including the influential w ork of David Hume and its relevance to economics \nand finance  is an important area of study (Marwala and Hurwitz, 2017) . Various concepts and \nmodels of causality such as transmission, Granger and Pearl models of causality  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 37,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 167,
      "text": "y  can be improved \nby the use of artificial intelligence . The transmission model of causality states that for causality to \nexist there shou ld be a flow of information from the cause to the effect. Bayesian inference as a \nmechanism of modelling causality  can be used to study the link between cigarette sm oking and \nlung cancer . \n1.5 Conclusion  \nThis paper  went through some of the big ideas that have been developed in the study of economics. \nThese include concepts such as Marxism, the theory of invisible hand, rational expectations, \nrational choice, mechanism design and game theory. Furthermore, this paper  discussed how some \nof these will change as man is replaced by an artificial intelligent machine as a principal agen t of \neconom ic decision making . \nReference:  \n1. Agassi, J . (1971). Faraday as a Natural Philosopher. Chicago: University of Chicago Press.  \n2. Amos , S.W. and  James , M.R. (1999). Principles of Transistor Circuits. Butterworth -\nHeinemann  \n3. Anand , P. (1993).\"Foundations of Rational Choice Under Risk\", Oxford: Oxford University \nPress.  \n4. Byrne, R.M.J. (2005). The rational imagination: how people create alternatives to reality. \nCambridge, M.A.: MIT Press.  \n5. de Vivo , G.  (1987). \"Ricardo, David,\" The New Palgrave: A Dictionary of Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 38,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 168,
      "text": "Economics, v. 4, \npp. 183 \u201398 \n6. Fama, E.  (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work\". \nJournal of Finance. 25 (2): 383 \u2013417.  \n7. Gujarati, D.N.; Porter, D.C. (2009). \"Causality in Economics: The Granger Causa lity Test\". \nBasic Econometrics (Fifth international ed.). New York: McGraw -Hill. \n8. Harari, Y.N. ; (2014). Sapiens: A Brief History of Humankind. Vintage , ISBN 9780099590088.  \n9. Hamilton, W. P. (1922). The Stock Market Baraometer. New York: John Wiley & Sons Inc \n(1998 reprint).  \n10. Henderson, D.R. (2008). \"Opportunity Cost\". Concise Encyclopedia of Economics (2nd ed.). \nIndianapolis: Library of Economics and Liberty.  \n11. Hurwicz, L., Radner , R. and Reiter , S. (1975) A Stochastic Decentralized Resource Allocation \nProcess:  Part I, Econometrica, Vol. 43, No. 2 (1975), pp. 187 -221 \n12. Kahneman , D. (2011). Thinking, Fast and Slow. Macmillan.  \n13. Markowitz, H.M. (March 1952). \"Portfolio Selection\". The Journal of Finance. 7 (1): 77 \u201391.  \n14. Marwala, T., Boulkaibet, I, and Adhikari S. (2017) Probabilistic Finite Element Model \nUpdating Using Bayesian Statistics: Applications to Aeronautical and Mechanical \nEngineering. John Wiley a nd Sons . \n15. Marwala, T. (2015). Causality, Correlation, and Artificial Intelligence for Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013)."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 39,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 169,
      "text": "or Rational Decision \nMaking . Singapore: World Scientific.  \n16. Marwala, T. (2014). Artificial Intelligence Techniques for Rational Decision Making. \nHeidelberg: Springer.  \n17. Marwala, T.  (2013). Economic Modeling Using Artificial Intelligence Methods. Heidelberg: \nSpringer.  \n18. Marwala, T. (2012). Condition Monitoring Using Computational Intelligence Methods. \nHeidelberg: Springer.  \n19. Marwala, T. and Lagazio, M. (2011). Militarized Conflict Modeling Using Computational \nIntelligence. Heidelb erg: Springer . \n20. Marwala, T. (2010). Finite E lement Model Updating Using Computational Intelligence \nTechniques: Applications to Structural Dynamics. Heidelberg: Springer.  \n21. Marwala, T. (2009). Computational Intelligence for Missing Data Imputation, Estimation, and \nManagement: Knowledge Optimization Te chniques. Pennsylvania: IGI Global.  \n22. Marwala, T. (2007). Computational Intelligence for Modelling Complex Systems. Delhi: \nResearch India Publ ications.  \n23. Marwala, T. and Hurwitz, E.  (2017)  Artificial Intelligence and Economic Theory: Skynet in \nthe Market. Springer.  (Accepted).  \n24. Marwala, T., Mahola, U and Nelwamondo , F.V.  (2006) Hidden Markov models and Gaussian \nmixture models for bearing fault detection using fractals. International Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 40,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 170,
      "text": "rnational Joint Conference on \nNeural Networks, (IJCNN'06) pp. 3237 -3242  \n25. Marx, K . (1849). Wage Labour and Capital. Germany: Neue Rheinische Zeitung. Retrieved \n2016 -10-26. \n26. Maxwell , J.C.  (1873), A treatise on electricity and magnetism Vol I, Oxford : Clarendon Press  \n27. Mill, J.S. (2001)  Utilitarianism and the 1868 Speech on Capital Punishment. (Sher, ed. Hackett \nPublishing Co, 2001)  \n28. Myerson, R .B. (1991). Game Theory: Analysis of Confli ct, Harvard University Press  \n29. Nash, J . (1950) \"Equilibrium points in n -person games\" Proceedings of the National Academy \nof Sciences 36(1):48 -49. \n30. Newton, I. (1726)  \"Mathematical Principles of Natural Philosophy\", 1729 English translation \nbased on 3rd Latin edition (1726), volume 2, containing Books 2 & 3.  \n31. Picketty , T. (2014)  Capital in the Twenty -First Century (Cambridge, MA: Belknap Press, \n2014)  \n32. Siegel, J. J. (2008) . \"Stock Market\". In David R. Henderson (ed.). Concise Encyclopedia of \nEconomics (2nd ed.). Indianapolis: Library of Economics and Liberty.  \n33. Simon, H . (1991). \"Bounded Rationality and Organizational Learning\". Organization Science. \n2 (1): 125 \u2013134. \n34. Smith , S. (2015) \". The Concise Encyclopedia of Economics. Liberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S ."
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 41,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 171,
      "text": "iberty Fund, Inc. Retrieved 29 \nJuly 2015.  \n35. Stiglitz, J .E. (2012). The Price of Inequality: How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "1703.06597v1",
      "chunk_id": 42,
      "pdf_path": "papers\\1703.06597v1.pdf",
      "doc_id": 172,
      "text": "How Today's Divided Society Endangers Our \nFuture. New York: W.W. Norton & Company.  \n36. Traiger, S . (2000), \"Making the Right Identification in the Turing Test\", Minds and Machines, \n10 (4): 561"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 173,
      "text": "Exploring the Frontiers of LLMs in Psychological Applications: A \nComprehensive Review  \n \nLuoma Ke1, Song Tong1,2*, Peng Cheng3, Kaiping Peng1,* \n1. Department of Psychological and Cognitive Sciences , Tsinghua University  \n2. Department of Psychology, Beijing Normal University  \n3. School of Social Science, Tsinghua University  \n* Corresponding authors: tong.song.53w@kyoto -u.jp; pengkp@tsinghua,edu.cn  \n \nAbstract  \nThis review explores the frontiers of large language models (LLMs) in psychological applications. \nPsychology has undergone several theoretical changes, and the current use of artificial intelligence (AI) and \nmachine learning, particularly LLMs, promises to  open up new research directions. We aim to provide a \ndetailed exploration of how LLMs are transforming psychological research. We discuss the impact of LLMs \nacross various branches of psychology \u2014including cognitive and behavioral, clinical and counseling,  \neducational and developmental, and social and cultural psychology \u2014highlighting their ability to model \npatterns, cognition, and behavior similar to those observed in humans. Furthermore, we explore the ability \nof such models to generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 174,
      "text": "generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology. We emphasize the importance of addressing technical and ethical challenges, including data \nprivacy, the ethics of using LLMs in psychological research, and the need for a deeper understanding of \nthese models\u2019 limitations. Researchers should use LLMs responsibly in psychological studies, adhering to \nethical standards and considering the pote ntial consequences of deploying these technologies in sensitive \nareas. Overall, this review provides a comprehensive overview of the current state of LLMs in psychology, \nexploring the potential benefits and challenges. We hope it can serve as a call to act ion for researchers to \nresponsibly leverage LLMs\u2019 advantages while addressing the associated risks.  \nKeywords large language models (LLMs); machine learning; artificial intelligence (AI); psychology; \nresearch methods  \n \n1. Introduction  \nArtificial intelligence (AI) has a history spanning nearly seven decades, beginning with the 1956 \nDartmouth Conference. The field has recently been revolutionized with the advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 175,
      "text": "he advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g., solving difficult tasks in math, coding, vision, \nmedicine, law, and psychology) (Bubeck et al., 2023) , exemplifying the concept of \u201cAI for science\u201d  (Wang \net al., 2023) . LLMs mark a critical juncture in the evolution of machine learning and AI, propelled by their \nexpansive size and sophisticated neural architectures that incorporate attention mechanisms  (V aswani et al., \n2017) . These models incorporate cognitive principles  (Binz & Schulz, 2023a)  and exhibit emergent \nproperties comparable to those seen in complex physical systems  (Wei et al., 2022) . This has enhanced their \nability to process and represent concepts and high -level semantics (J. Li et al., 2022)  while also deepening \nour insights into human cognitive processes  (Sejnowski, 2022) . In psychological applications, these \ndevelopments are reshaping interactions among data, language, and the environment  (De Bot et al., 2007; \nDemszky et al., 2023) , contributing significantly to various fields, including clinical  (Thirunavukarasu et al., \n2023) , developmental (Frank, 2023; Hagendorff, 2023) , and social psychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 176,
      "text": "sychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis.  \n1.1.  The LLM concept: From machine learning to capability emergence  \nGenerative AI evolved from advances in pattern  recognition capability. While convolutional neural \nnetworks (CNNs) excelled at recognizing objects and concepts, the next challenge was to use this recognition \ncapability for a generation. For example, if a CNN can identify \u201cage\u201d in portraits, we can use that \nunderstanding to modify \u201cage\u201d in any portrait. This generative approach first succeeded in computer vision \nthrough models such as generative adversarial networks (Goodfellow et al., 2020)  and deconvolution (Zeiler, \n2014) , which could create realistic images based on learned patterns. The same generative principles were \nthen applied to language, leading to LLMs that could generate contextually relevant text. LLMs represent a \nparticularly significant leap in the capabilitie s of generative AI. These models are designed to process natural \nlanguage text and generate contextually relevant text.  LLMs like GPT -4, LLaMA,  Claude, and  Gemini \nleverage the transformer architecture (V aswani et al., 2017), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 177,
      "text": "17), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks. For instance, LLaMA focuses on efficient training processes \n(Touvron et al., 2023) , Claude emphasizes safety and alignment (Li et al., 2024) , and Gemini integrates \nadvanced reasoning capabilities (Rane et al., 2024) . LLaMA \u2019s open -source nature allows local deployment \nand efficient training, making it suitable for psychological studies needing rapid iteration or customization, \nsuch as behavioral modeling ( Binz and Schulz (2023a) . Claude, designed for safety and alignment, is less \ncommonly used in psychology research and more oriented toward knowledge -based tasks (Li et al., 2024). \nGPT-4, with its large -scale parameters and broad training data, supports a wide range of tasks, including \ncognitive simulations and clinical assessments.  These differences guide model selection based on research \nneeds like accessibility, task specificity, or data scale.  \nWhile these models highlight the versatility of LLMs, it is essential to distinguish between specific \nproducts designed for particular interactions, such as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 178,
      "text": "as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction. This range of applications demonstrates that LLMs\u2019 capabilities are \nemergent, manifesting new abilities as the model size increases. Performance improvements on  log-log \nscales sometimes experience \u201cbreaks\u201d where unexpected capabilities emerge from complex interactions \nwithin the models (Wei et al., 2022) . \nAt the heart of LLMs is the transformer architecture, a deep neural network with an attention mechanism \nthat efficiently processes sequential data in parallel (V aswani et al., 2017) ; this works in a manner somewhat \nsimilar to human brain functions. This architecture has revolutionized the field of natural language \nprocessing. The self -attention mechanism of the transformer architecture captures contextual relationships \nin textual dat a, allowing for more sophisticated language understanding. Notably, the \u201clarge\u201d in LLM refers \nto the many parameters and massive amounts of training data used to fine -tune these models, typically \nbillions of parameters and terabytes of text (Binz & Schulz, 2023b) , in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 179,
      "text": "in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages. (1) Pretraining: LLMs are pretrained on large amounts of textual data to \nlearn intricate linguistic, syntactic, and textua l structures, where the model learns to predict the next token \nthrough unsupervised learning, resulting in a base model that captures the statistical patterns of language (P . \nLiu et al., 2023) . (2) Alignment: Supervised learning is used to create a foundation model that can better \ninteract with users in the intended ways, which typically involves instruction tuning and reinforcement \nlearning based on human feedback. After the foundation model i s available, domain -specific fine -tuning can \nadapt the model for particular applications (Liu et al., 2022) . This fine -tuning process ensures the model can \ngenerate contextually relevant responses and engage in meaningful conversations or tasks. Through these \nstages of development, LLMs demonstrate increasingly sophisticated text -generation capabilities, includi ng \nresponse generation, content summarization, translation, and compositional text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 180,
      "text": "nal text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models. Finally, LLMs exhibit \u201cobserved capability emergence\u201d \nwhen integrated into various applications and systems, in addition to performing tasks that require a deep \nunderstanding of language and context, thus often achieving human -like or superhuman performance in \nspecific experimental tasks, such as analogical reasoning (Webb et al., 2023) , creativity (Stevenson et al., \n2022) , and emotion recognition (Patel & Fan, 2023) . \nTherefore, LLMs can provide valuable insights into how such technologies can simulate or augment \nprocesses traditionally associated with human cognition. Specifically, LLMs maintain a balance between \nlogical processing and the use of cognitive shortcuts (heuristics), and they adapt their reas oning strategies to \noptimize between accuracy and effort. This aligns with the principles of resource -rational human cognition, \nas discussed in dual -process theory (Mukherjee & Chang, 2024). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 181,
      "text": "24). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) . These parallels allow for the exploration of AI applications in \nareas such as cognitive psychology (Sartori & Orr\u00f9, 2023) , language acquisition (Jungherr, 2023) , and even \nmental health (Lamichhane, 2023) . Moreover, the study of LLMs contributes to our understanding of the \nhuman mind, offering a computational perspective on language processing, decision -making (Sha et al., \n2023) , and learning mechanisms (Hendel et al., 2023) . The fusion of such disciplines could drive \nadvancements in AI and provide a computational framework for investigating processes related to human \ncognition.  \n1.2.  Psychology and AI  \nPsychology, as a science that explores the human mind and behavior, has undergone significant \ntheoretical changes since the late nineteenth century, with psychoanalysis and behaviorism extending to \ncognitive psychology (Hothersall & Lovett, 2022) . This history marks a shift in the focus of psychology \nresearch, reflecting the academic trend of moving from observing behavioral manifestations to exploring in -\ndepth psychological connotations. Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 182,
      "text": ". Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology. In clinical and \ncounseling psychology, research on cognitive psychology supports diagnosing and treating psychological \ndisorders. It deepens our understanding of the psycho logical mechanisms underlying emotions, stress, and \nhuman behavior. Psychotherapies such as cognitive -behavioral therapy (Hofmann et al., 2012)  and \npsychodynamic therapy have become essential tools for promoting mental health and emotional regulation. \nIn educational and developmental psychology, the development of cognitive psychology has fostered a \ndeeper understanding of the roles of perceptual  and affective factors in learning processes (Glaser, 1984) , \nwhich has led to innovations in teaching methods and learning strategies. In social and cultural psychology, \ncognitive psychology research helps explain individuals\u2019 behaviors and mental processes in different social \nand cultural contexts, exploring how cultural differences affect cognitive patterns, values, and behavioral \nnorms, especially in the context of globalization, interaction, and integration. In social psychology, \nmeanwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 183,
      "text": "nwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) . \nAI is becoming an increasingly influential tool in psycho -cognitive research. Simon (1979)  was among \nthe first to recognize the potential of computational models to simulate aspects of human cognitive processes. \nCurrently, LLMs can process and generate human -like texts and perform certain tasks in a manner similar to \nhuman cognition (Bubeck et al., 2023) . LLMs also offer a unique computational perspective for the study of \nhuman cognition. For example, GPT -3 can solve vignette -based tasks similar to or better than human subjects \nand can perform rational decision -making based on descriptions, outperforming humans in the multiarmed \nbandit task (Binz & Schulz, 2023b) . Furthermore, after extensive testing, GPT -3 is able to solve complex \nanalogical problems at levels comparable to human performance, and analogical reasoning is an essential \nhallmark of human intelligence (Webb et al., 2023) . Moreover, fine -tuning across multiple tasks can allow \nLLMs to predict human behavior in previously unseen tasks \u2014that is, LLMs can be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 184,
      "text": "n be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general.  \nNewell (1990)  offered a structured framework for analyzing human behavior, categorizing cognitive and \nbehavioral processes into four distinct layers based on their time scales (Fig. 1a). At the biological level, the \nfocus is on physiological and neural processes occurr ing at rapid time scales, ranging from milliseconds to \none second. This level can include neural responses and sensory processing, which form the foundation of \nhuman cognition. The cognitive level pertains to mechanisms such as attention, perception, and s hort-term \nmemory, which operate at intermediate time scales, typically between one second and one minute. These \nprocesses enable fundamental cognitive functions. At the rational level, the framework considers more \ncomplex cognitive activities such as probl em-solving, planning, and decision -making. Such activities occur \nover longer time scales, spanning several minutes to a few hours, and involve sustained cognitive \nengagement. Finally, the social level considers behaviors shaped by social interaction and cultural influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 185,
      "text": "influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition. It underscores the multifaceted \nnature of human behavior, highlighting the relationship between rapid physiological p rocesses and the more \nprolonged, socially influenced aspects of human cognition.  Figure 1 integrates this framework by mapping \npsychological domains (e.g., cognitive, social) onto these timescales, demonstrating LLMs \u2019 ability to \nsimulate behaviors \u2014from short -term processes like memory retrieval to long -term phenomena like cultural \ntrends. Emergent properties (e.g., cognitive simulation) connect these domains to practical research tools \n(e.g., stimuli generation), with bidirectional influence refinin g both a pplications and properties.  \nTherefore, by analyzing LLM application across these four levels (Fig. 1a), it is possible to further \nexplore their potential for modeling and studying human cognition and behavior (Fig. 1b), as well as their \nunique role in psycho -cognitive processes. Rece nt research has revealed significant advancements in LLMs\u2019 \nability to perform complex human -like cognitive and social tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 186,
      "text": "cial tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al. (2023)  demonstrated LLMs\u2019 proficiency in simulating human social \ninteractions and perceptual processing, respectively. Orru et al. (2023)  and (Webb et al., 2023)  highlighted \nLLMs\u2019 capabilities in complex problem -solving and reasoning while Hagendorff et al. (2023)  focused on \ndecision -making processes. Stevenson et al. (2022)  documented LLMs\u2019 potential for creativity, and Patel \nand Fan (2023)  demonstrated their emotion -recognition abilities. Taken together, such findings highlight the \nexpanding role of LLMs in representing and augmenting human cognitive and social functions, marking \nsignificant progress in AI research.   \nAs general -purpose cognitive models (Binz & Schulz, 2023a) , LLMs offer new perspectives and \napproaches for research in the fields of cognitive and behavioral psychology, clinical and counseling \npsychology, educational and developmental psychology, and social and cultural psychology, at different time \nscales of hu man behavior (Fig. 1a).  LLMs can also be used as research aids (Fig. 1c) to help psychologists \nwith everything from literature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 187,
      "text": "ature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al., 2023)  to promote scholarly communication: academic writing (Dergaa et al., 2023; Stokel -\nWalker, 2022)  or peer review (Chiang & Lee, 2023; Van Dis et al., 2023) . Thus, LLMs can potentially \nbecome research assistants for psychologists, helping them improve their research efficiency.  \n \nFig. 1 LLMs in Psychological Research Across Timescales. (a) Domains (e.g., Cognitive & Behavioral, \nSocial & Cultural) mapped to timescales of behavior; (b) Emergent properties (e.g., cognitive simulation) \nenabling domain -specific modeling; (c) LLMs as research tools (e.g., stimuli generation). Double -sided \narrows indicate that emergent properties bridge domains and tools, supporting applications (e.g., memory  \nretrieval) and refining properties through usage . \n \n1.3.  Objectives and significance of the present review  \nThis review aims to provide a comprehensive analysis of the applications and effects of LLMs in \npsychological research. To ensure a systematic and rigorous review, we established specific inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 188,
      "text": "ic inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science. Our initial keyword selection \u2014\n\u201cGPT-3\u201d, \u201cChatGPT \u201d, \u201cGPT-4\u201d, \u201clarge language models \u201d, and \u201cpsychology \u201d\u2014was determined during the \nliterature collection in October 2023, when GPT -based models were predominant in psychological research \n(e.g., Binz & Schulz, 2023b; Bubeck et al., 2023). At the time, open -source models like LLaMA (Touvron \net al., 2023) and propr ietary models like Claude had limited psychology -specific applications. To maintain \na focused scope, we did not retrospectively expand search terms but included diverse LLMs via manual \nscreening. To reflect recent developments, an updated search incorporat ed studies from 2024.  \nTo bolster the integrity of our data extraction process, two interdisciplinary researchers (male, 33 and \n41 years) specializing in information science and psychology conducted the encoding and screening. Our \n\ninclusion criteria required the selected studies to (1) explore the application or analysis of LLMs in \npsychological contexts; (2) be peer -reviewed journal articles or high -impact conference proceedings; and (3) \npresent empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 189,
      "text": "present empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature. Articles without a \npsychological focus or those addressing non -LLM -based AI systems were excluded.  The study selection \ninvolved screening 191 identified studies, analyzing 100 full -text articles, and ultimately including 4 7 studies \ncategorized into various psychological subfields. Each of these studies met stringent inclusion criteria, \nensuring they contributed meaningfully to our understanding of LLMs in psychological research.  \nIn this review, we systematically examine the use of LLMs in various psychological domains by \nanalyzing their application at different behavioral time scales. The rest of the paper is structured as follows. \nIn section 2, we explore LLMs in cognitive and be havioral psychology. In section 3, the roles of LLMs in \nclinical and counseling psychology are discussed. Subsequently, educational and developmental psychology \nare addressed in section 4, followed by social and cultural psychology in section 5, outlining LLMs\u2019 \ncontributions to each area. While psychological techniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 190,
      "text": "hniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research. The primary focus of this review is how LLMs facilitate and advance \npsychological research across these domains. For a deeper understanding of the effect of LLMs on \npsychological research, an overview of LLMs\u2019 potential as tools for scientific research is given in section 6. \nIn section 7, the challenges and future research directions with regard to applying LLMs to psychological \ncontexts are provided. Finally, conclusions are presented in section 8, with a summary of LLMs\u2019 applications \nin psychology and rec ommendations for future work. Importantly, we propose strategies for integrating \nLLMs into psychological research and provide insights into interpreting such models from a psychological \nstandpoint, contributing to their safety and interpretability.  \n \n2. LLMs in cognitive and behavioral psychology  \nWithin the multilevel time scales of human behavior (Newell, 1990) , cognitive and behavioral \npsychology has primarily focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 191,
      "text": "focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning. Cognitive  and behavioral psychology typically uses experimental methods to study \nthese cognitive processes, controlling and observing behaviors and responses under specific conditions. The \nrecent emergence of LLMs has reinvigorated the discussion on whether such models might exhibit patterns \nresembling human cognitive processes; if so,  it may be possible to study the \u201ccognitive processes\u201d of LLMs, \nwhich could provide valuable insights into human cognitive phenomena and serve as a valuable addition to \nexisting research methods in cognitive psychology. The foundational technology underlyi ng large language \nmodels (LLMs) is the generative pre -trained transformer (GPT) architecture, which employs deep neural \nnetworks to process and generate human -like text. GPT models function through mechanisms, such as \nattention mechanisms and token predict ion, enabling them to capture complex linguistic patterns and \ngenerate contextually coherent outputs. These foundational technologies have transformed natural language \nprocessing (NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 192,
      "text": "(NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) . The \nincorporation of such architectures into psychological research has initiated discussions regarding their \npotential to simulate cognitive phenomena.  \nBinz and Schulz (2023a)  found that fine -tuning multiple tasks enabled an LLM to predict human \nbehavior in previously unseen tasks, suggesting that LLMs can be adapted to become generalist cognitive \nmodels. In another study, the same authors tested GPT -3 using tools from cognitiv e psychology and showed \nthat it made better decisions than humans and outperformed them in the multiarmed bandit task (Binz & \nSchulz, 2023b) . Other studies have shown that LLMs can display perceptual judgment (Marjieh et al., 2023) , \nreasoning (Webb et al., 2023) , and decision -making abilities (Hagendorff et al., 2023) , as well as creativity \n(Stevenson et al., 2022)  and problem -solving (Orru et al., 2023) . One study found that an LLM had the \nmental ability of a seven -year-old child based on a false -belief task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 193,
      "text": "ef task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al. (2023)  designed a series of semantic illusion and cognitive \nreflection tests designed to elicit intuitive but erroneous responses (these are conventionally used to study \nhuman reasoning and decision -making) and then ran the tests for LLMs. They conducted an anal ysis of \nmodel performance on a Cognitive Reflection Test (CRT) task and a semantic illusion task to elucidate their \ncognitive processes, drawing upon System 1 and System 2 thinking, as conceptualized by Daniel Kahneman \nin his seminal work Thinking, Fast, a nd Slow (Kahneman, 2011) , which represent fundamental constructs \nfor understanding human cognitive processes. System 1 refers to intuitive and automatic thinking, whereas \nSystem 2 involves rational, deliberate decision -making processes. This framework provides a theoretical \nbasis for interpreting how LLMs simulate human -like cognitive behaviors during these tasks. They observe \nhow these models show correct responses in these tasks and avoid pitfalls. The performance of the models \nin the CRT task were further evaluated by prev enting them from chain -thinking to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 194,
      "text": "ing to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors. Table 1 provides a summary of the applications of \nLLMs to cognitive and behavioral psychology.  \nTable 1  Applications of large language models (LLMs) in cognitive and behavioral psychology study.  \nReference  Research Question  Research method  Key finding  \n \nHuman -like Cognitive Abilities  \nBinz and \nSchulz \n(2023b)  How does GPT -3 perform on \ncognitive psychology tasks, \nincluding decision -making, \ninformation search, and causal \nreasoning?  GPT-3 was tested using canonical \ncognitive psychology experiments \nand compared to human \nperformance.  GPT-3 excels in decision -making and \nreinforcement learning but struggles with \ntask perturbations, directed exploration, \nand causal reasoning.  \nStevenson et \nal. (2022)  Can GPT -3 generate creative \nsolutions comparable to humans in \nGuilford\u2019s Alternative Uses Test \n(AUT)?  GPT-3\u2019s responses to AUT were \nevaluated for originality, usefulness, \nsurprise, and flexibility, using expert \nratings and semantic distance \nanalysis, and compared with human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 195,
      "text": "th human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal. (2023)  Can LLMs recover perceptual \ninformation from language, and \nhow do they reflect cross -linguistic \nvariations?  GPT-3, GPT -3.5, GPT -4 were tested \non six psychophysical datasets and a \nmultilingual color -naming task to \ncompare their outputs with human \nperceptual data.  LLMs like GPT -4 align closely with \nhuman perceptual data, recover \nrepresentations such as the color wheel, \nand reflect cross -linguistic perceptual \nvariations, demonstrating their ability to \nextract perceptual information from \nlanguage.  \nLoconte et \nal. (2023)  How do various LLMs perform on \nneuropsychological tests assessing \nprefrontal functions compared to \nhuman cognitive abilities?  GPT-3.5, GPT -4,were evaluated on \ntasks related to planning, semantic \nunderstanding, and Theory of Mind.  Findings indicate that GPT -4 generally \nmeets normative human standards, \nwhereas  Claude2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 196,
      "text": "2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal. (2023)  How does GPT -4 perform on \ncognitive psychology tasks \ncompared to prior state -of-the-art \nmodels?  GPT-4 was evaluated on cognitive \npsychology datasets \n(CommonsenseQA, SuperGLUE, \nMATH, HANS) to analyze its \nintegration of cognitive processes \nwith contextual information.  GPT-4 demonstrates high accuracy on \ncognitive psychology tasks, surpassing \nprior models, and showcases significant \npotential to bridge human and machine \nreasoning.  \nHagendorff \n(2024)  Can modern LLMs understand and \napply deception strategies?  Experiments tested LLMs on \ninducing false beliefs, using chain -\nof-thought reasoning, and displaying \nMachiavellian behavior in simple \nand complex deception scenarios.  GPT-4 demonstrates advanced deceptive \nbehavior, succeeding in 99.16% of simple \nand 71.46% of complex scenarios, \nhighlighting the emergence of \nsophisticated deception abilities absent in \nearlier models.  \n \nExperimental Methodologies for Cognitive Research Using LLMs  \nBinz and \nSchulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 197,
      "text": "Schulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors.  Fine-tuned LLaMA outperforms \ntraditional cognitive models, accurately \nmodel individual behavior, and predict \nunseen human responses.  \nDubey et al. \n(2024)  How can generative AI tools be \nutilized to streamline the creation of \nexperimental stimuli in \npsychological research and \ninfluence public attitudes toward \nsustainable policies?  DALL -E 2 was employed to generate \nrealistic visual stimuli of car -free \nurban environments, which were \nthen presented to participants to \nmeasure attitudes toward sustainable \npolicies.  By using DALL -E 2, the study \ndemonstrated that generative AI tools can \nenhance the design process of \nexperimental stimuli, offering greater \ncontrol, diversity, and scalability, thereby \neffectively influencing participants' \nattitudes.  \nNote: The AUT is a psychological test that measures creativity by asking participants to think of as many \nuses as possible for a common object; DALL -E 2 is developed by OpenAI that generates detailed and \nrealistic images from textual descriptions to explore AI's potential in creative fields.  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 198,
      "text": ".  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al. (2024) , for \ninstance, used DALL -E 21 to create realistic visual stimuli depicting car -free urban environments, which \ninfluenced participants\u2019 attitudes toward sustainable policies. Such tools streamline the stimulus design \nprocess by providing control, diversity, and scalability. Similarly, LLMs have been employed in hardware \ntesting to generate tailored stimuli, outperforming traditional methods in specific scenarios (Z. Zhang et al., \n2023) . Charness et al. (2023)  further demonstrated the use of LLMs for enhancing experimental workflows \nby refining task instructions, ensuring consistency, and monitoring participant engagement. By leveraging \ntheir flexibility and scalability, LLMs can provide novel methods for advan cing experimental psychology. \nThese applications facilitate the exploration of complex cognitive phenomena and the development of \ninnovative research designs while also complementing traditional psychological research frameworks \n(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 199,
      "text": "(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3. LLMs in clinical and counseling psychology  \nClinical and counseling psychology focuses on assessing, diagnosing, treating, and preventing mental \nhealth problems. These processes often involve medium - to long -term periods. In the multilevel time scales \nof human behavior (Newell, 1990) , clinical and counseling psychology involves assessing everyday \nbehavioral acts (about a few hours to a day), habitual thinking (about a day to a few months), and \npsychological disorders (a few months to many years), among others (Fig. 1). The application  of LLMs in \nclinical and counseling psychology can be broadly divided into two categories: psychological assessment \nand psychological intervention. Psychological assessment focuses on improving the ecological validity, \nscalability, and accuracy of measurin g mental health states while psychological interventions consider how \nLLMs can be used for scalable and personalized mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 200,
      "text": "d mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) . LLMs are expected to be used in clinical psychology and counseling \n \n1 Note: Although DALL -E 2 is not an LLM, we included this study due to its reliance on Transformer -\nbased semantic understanding, a cornerstone of LLM research, and its demonstrated utility in generating \ncontrolled visual stimuli for psychological experiments.  \n \nbecause they can parse human language and generate human -like responses, categorize text, and flexibly \nadapt conversational styles representing different theoretical orientations (Stade et al., 2023) . This leads to \nthe following question: How do LLMs work in psychotherapy, and can they replace human psychotherapists?  \nAn LLM is a basic generalized model with the ability to learn from small samples (Brown et al., 2020) , \nwhich allows it to quickly become an \u201cexpert\u201d in the clinical and counseling domain with only a small \namount of data to learn from. For example, LLMs trained on clinical content can identify more specific \nfactors of change that can help psychologists und erstand the process of clinical intervention, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 201,
      "text": "on, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al., 2023)  and respond \nappropriately. They can also perform complex mental health evaluations (Patel & Fan, 2023; Schaaff et al., \n2023) , such as suicide risk assessment and schizophrenia prognosis. For example, Elyoseph and Levkovich \n(2024)  found that GPT -4, Google Bard, and Claude produced evaluations consistent with professional \nbenchmarks in treated schizophrenia cases, though GPT -3.5 exhibited overly pessimistic predictions. Other \nresearch has shown that GPT -3.5 excels in clinical psychi atric cases, achieving top grades in diagnosis and \nmanagement across 61% of cases, with only minor discrepancies in more complex scenarios (D\u2019Souza et al., \n2023) . \nIn psychological interventions, LLMs have shown significant potential for delivering scalable and \npersonalized mental health support (Blyler & Seligman, 2023a, 2023b) . For example, Blyler and Seligman \n(2023a) demonstrated that GPT -4 can generate personalized therapeutic strategies by analyzing narrative \nidentities. These strategies were found to be valid and reasonable, highlighting GPT -4\u2019s utility as a supportive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 202,
      "text": "portive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19.6% and significantly \nboosted self -efficacy among users struggling to pro vide support. Furthermore, J. M. Liu et al. (2023)  \nevaluated ChatCounselor, a model trained on a domain -specific dataset of psychologist \u2013client conversations, \nand found it outperformed open -source models, thereby demonstrating the importance of domain -specific \ntraining for improving counseling capabilitie s. Table 2 summarizes the applications of LLMs to clinical and \ncounseling psychology.  \nThe above research cases, which demonstrate LLMs\u2019 ability to provide clinicians with adequate mental \nhealth support (Schueller & Morris, 2023) , hold promise for addressing insufficient capacity in the mental \nhealth care system and offering more individualized treatment services, even potentially fully automating \npsychotherapy in the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 203,
      "text": "the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies . \nReferences  Research question  Research method  Key finding  \n \nPsychological Assessment Using LLMs  \nElyoseph and \nLevkovich \n(2023)  How effective and accurate \nare ChatGPT in assessing \nsuicide risk?  The study evaluated ChatGPT's \nanalysis of a text vignette depicting a \nhypothetical patient with varied \npsychological states, comparing its \nassessments to those of mental health \nprofessionals.  The study found that ChatGPT consistently \nunderestimated suicide risk and mental \nresilience compared to mental health \nprofessionals, suggesting that reliance on \nChatGPT for suicide risk assessment could \nlead to inaccurately low evaluations.  \nElyoseph and \nLevkovich \n(2024)  How do LLMs compare to \nmental health professionals \nin assessing schizophrenia \nprognosis and treatment \noutcomes?  Vignettes were used to compare the \nassessments of four LLMs (GPT -3.5, \nGPT-4, Bard, Claude) against \nprofessional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 204,
      "text": "ional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3.5)  in addressing clinical \npsychiatric cases and \nsupporting mental health \ncare?  ChatGPT was tested on 100 clinical \npsychiatric vignettes, and expert \npsychiatrists graded its responses \nacross 10 categories.  ChatGPT  excelled in management and \ndiagnosis, earning top grades in 61% of cases, \nwith no major errors but minor discrepancies \nin complex cases.  \nSufyan et al. \n(2024)  How do the social \nintelligence (SI) levels of \nLLMs compare to human \npsychologists?  Social intelligence scores of ChatGPT \n(4), Bard, and Bing were compared \nwith 180 counseling psychology \nstudents (bachelor\u2019s and PhD levels) . ChatGPT surpassed all psychologists in \nsocial intelligence, Bing outperformed most \nbachelor\u2019s and some PhDs, while Bard \naligned with bachelor\u2019s students but fell \nbehind PhDs.  \n \nPsychological Interventions with LLMs  \nBlyler and \nSeligman \n(2023a)  Can GPT-4 generate \npersonalized therapeutic \nstrategies based on narrative \nidentity?  GPT-4 analyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 205,
      "text": "nalyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching.  \nBlyler and \nSeligman \n(2023b)  Can GPT-4 generate \naccurate and insightful \npersonal narratives to \nsupport self -discovery in \ntherapy and coaching?  GPT-4 processed 50 stream -of-\nconsciousness thoughts from 26 \nparticipants to create personalized \nnarratives, which participants evaluated \nfor accuracy, surprise, and self -insight.  96% of participants rated the narratives as \naccurate, and 73% reported gaining new self -\ninsights, suggesting GPT-4\u2019s potential for \nenhancing self -discovery in therapeutic \ncontexts.  \nSharma et al. \n(2023)  Can AI enhance empathy in \npeer-to-peer mental health \nsupport?  Tested HAILEY  which based on GPT -\n2, which  offering real -time empathic \nfeedback, in a trial with 300 peer \nsupporters on TalkLife.  HAILEY improved empathy by 19.6% \noverall and 38.9% for those struggling with \nsupport, boosting self -efficacy without \ncreating reliance.  \nJ. M. Liu et al. \n(2023)  How to improve  LLM  in \nproviding mental health \nsupport compared to other \nmodels?  ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 206,
      "text": "ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics.  ChatCounselor outperforms LLaMA, \nChatGLM  and approaches GPT-4\u2019s \nperformance, highlighting the impact of \ndomain -specific training on counseling \ncapabilities.  \n4. LLMs in educational and developmental psychology  \n Educational and developmental psychology is concerned with learning processes, knowledge \naccumulation, skill development, and changes in individual psychology in educational environments. \nEducational and developmental psychology is mainly positioned at th e relatively medium - to long -term level \n(Newell, 1990), reflecting the ongoing learning and development that characterize the educational process. \nA national survey found that only 3 months after the public release of GPT, 40% of US teachers used it \nweekly for lesson planning, highlighting the growing impact of LLMs in education.  \nTable 3 summarizes the applications of LLMs in educational and developmental psychology, which can \nbe broadly divided into two categories: developmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 207,
      "text": "evelopmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g., theory of mind and emotional reasoning) and how such capabilities \nmight advance our understanding of human cognitive and emotional development. Kosinski (2024) , for \ninstance, tested different LLMs in 40 false -belief tasks and found that GPT -4 achieved 75% accuracy, \ncomparable to the performance of a six -year-old child, while older models performed significantly worse. \nVzorinab et al. (2024)  used the Mayer \u2013Salovey \u2013Caruso Emotional Intelligence Test (MSCEIT) to evaluate \nGPT-4\u2019s emotional intelligence. While GPT -4 excelled at understanding and managing emotions, its \nreflective analysis resembled the early developmental stages of human emotional  reasoning.  \nThe study of using LLMs for education and learning applications focuses on leveraging LLMs to address \nchallenges in education, such as providing personalized learning and improving learning motivation. LLMs \nlearn from massive amounts of data taken from boo ks and the Internet (Binz & Schulz, 2023b ) and can be \nused as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 208,
      "text": "ed as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al. (2024) , for \ninstance, found that an AI tutor powered by GPT -3 improved academic performance by up to 15 percentile \npoints through personalized learning strategies. Stojanov (2023)  used the following approach to explore \nGPT\u2019s potential as a learning tool: First, he set learning objectives and had \u201cconversations\u201d with GPT about \nits functionality for 4 hours. For the next 3 hours, he continued the discussion with GPT and watched some \nrelevant videos on YouTube. He experienced positive feedback from his interactions with GPT and found it \nto be a motivating and relevant learning experience.  \n \nTable 3  Applications of LLMs in educational and developmental psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nDevelopmental Research with LLMs  \nKosinski \n(2024)  Can LLMs demonstrate theory \nof mind (ToM) abilities?  Eleven  different  LLMs were tested on 40 \nfalse -belief tasks, requiring success in \neight related scenarios per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 209,
      "text": "os per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal. (2024)  How does GPT -4\u2019s emotional \nintelligence align with \ndevelopmental patterns in \nhuman emotional reasoning?  GPT-4 was evaluated using the Mayer -\nSalovey -Caruso Emotional Intelligence \nTest (MSCEIT) through text -based \nprompts.  GPT-4 excels in understanding and \nmanaging emotions but shows limited \nreflective analysis, resembling early \ndevelopmental stages in human \nemotional reasoning.  \nTrott et al. \n(2023)  How does exposure to language \ninfluence the development of \ntheory of mind in humans and \nAI? A linguistic False Belief Task was \npresented to humans and GPT -3 to assess \nbelief attribution abilities.  GPT-3\u2019s partial success suggests that \nwhile language exposure contributes to \nbelief reasoning, other developmental \nmechanisms unique to humans are \ncrucial for fully developing theory of \nmind.  \n \nLLMs for Education and Learning Applications  \nStojanov \n(2023)  How effective is GPT as a \nlearning aid in scaffolding \nunderstanding of a specific \ntopic? An autoethnographic study exploring the \nauthor\u2019s personal experience using \nChat GPT (3.5)  to learn about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 210,
      "text": "about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge.  \nJyothy et al. \n(2024)  What factors influence the \nadoption of LLMs like \nChat GPT in learning, teaching, \nand research?  The Fogg Behavior Model (FBM) was \napplied to analyze the motivations, \nabilities, and perceptions of students, \nteachers, and researchers toward LLM \nuse. User motivation and ability drive LLM \nadoption, but limitations like teacher \nhesitance and technical challenges hinder \nbroader integration.  \nLogacheva et \nal. (2024)  Can GPT-4 generate \npersonalized programming \nexercises to enhance student \nengagement and learning?  GPT-4-generated exercises were \nevaluated in an introductory \nprogramming course by students and \ninstructors for quality and engagement.  GPT-4 effectively produced high -quality, \nengaging exercises, offering \npersonalized and scalable practice \nmaterials for programming education.  \nMachin et al. \n(2024)  Can GPT demonstrate \npsychological literacy \ncomparable to subject matter \nexperts (SMEs) in psychology \nresearch methods?  GPT rated 13 research scenarios, and its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 211,
      "text": "nd its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy.  \nGhafouri \n(2024)  Can a ChatGPT-based rapport -\nbuilding protocol (CGRBP) \nenhance L2 (Second Language) \ngrit in English learners?  A 16 -week experimental study compared \n30 EFL learners (15 experimental, 15 \ncontrol) using pre -test post -test ANCOV A \nanalysis.  CGRBP significantly improved L2 grit, \ndemonstrating its potential to foster \nemotional support and learning \nmotivation.  \nGhafouri et \nal. (2024)  Can ChatGPT match expert \npsychological literacy in \nevaluating research methods?  The study compared responses from \nChatGPT to 13 psychological research \nmethod scenarios against ratings by \nsubject matter experts.  ChatGPT \u2019s responses correlated strongly \nwith expert evaluations, suggesting its \npotential as an educational tool in \npsychology, though its usage should be \napproached with caution.  \nBaillifard et \nal. (2024)  Can AI tutors improve \nacademic performance through \npersonalized learning \nstrategies?  A semester -long study with 51 \npsychology students using a GPT -3-\npowered AI tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 212,
      "text": "tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results.  \nNote\uff1a Theory of mind (ToM) is the cognitive ability to attribute mental states to oneself and others \uff1b the \nFogg Behavior Model (FBM) explains behavior as a product of motivation, ability, and prompts.  \n \n \n \n \n5. LLMs in social and cultural psychology  \nSocial and cultural psychology explores how individuals interact with and are influenced by their social \nand cultural environments. It focused on interpersonal dynamics, group behavior, social cognition, and the \nlong-term formation and transformation of at titudes and norms (Tajfel, 1982 ). Such phenomena occur at \nvarious time scales, from immediate social interactions to cultural changes evolving over several years \n(Newell, 1990 ). LLMs provide valuable tools for advancing social and cultural psychology. By analyzing \ntextual datasets, simulating social interactions, and modeling human -like behaviors, LLMs can provide \ninsights into the dynamics of social cognition, group processes, and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 213,
      "text": ", and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts.  \nResearch on LLMs in social and cultural psychology can be categorized into three main areas: cultural \nand cognitive understanding, social interactions and behavioral simulations, and practical applications. First, \nLLMs have many similarities with humans re garding social cognition. For example, research has found that \nLLMs reflect a variety of typical human cognitive biases in judgment and decision -making, such as the \nanchoring effect, the representativeness heuristic, and base -rate neglect (Talboy & Fuller, 2023 ). In addition, \ncultural psychology research has identified significant differences in the cognitive processes of Easterners \nand Westerners when processing information and making judgments (Nisbett et al., 2001 ); in this regard, \nLLM consistently favors holistic Eastern ways of thinking (Jin et al., 2023 ). Second, LLMs have been shown \nto characterize human groups in social interaction settings. It has been shown that LLMs can replicate the \nresults of Milgram\u2019s electroshock experiments (Aher et al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 214,
      "text": "al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 ). \nThird, LLMs are increasingly used as proxies for human participants in psychological research. One \nstudy, for example, explored the potential of LLMs to serve as valid proxies for specific human subgroups \nin social science research; it found that LLMs cont ained information that went far beyond superficial \nsimilarity, reflecting the complex interplay between ideas, attitudes, and sociocultural contexts that \ncharacterizes human attitudes (Argyle et al., 2022 ). In addition, LLM has been tested for personality and \nvalues, obtaining results comparable to those for human samples, indicating their potential as psychological \nresearch tools (Miotto et al., 2022 ). Within this broader perspective, industrial and organizational psychology \nhas increasingly employed LLMs, particularly in employee selection and workplace optimization, \ndemonstrating their broader utility for understanding human behavior in structured en vironments. For \nexample, LLMs have been shown to improve the accuracy and efficiency of recruitment systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 215,
      "text": "t systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates. LLMs have also been integrated into \nsystems such as PALR (personalization -aware LLMs for recommendation) to dynamically align individual \ncapabilities with o rganizational needs. Such systems significantly reduce inefficiencies in hiring processes \nand enhance predictions about job performance by identifying nuanced compatibility factors in resumes and \ncover letters (Yang et al., 2023 ). Beyond individual applications, LLMs have contributed to understanding \nbroader organizational cultures and transformational dynamics by providing insights into how group \ninteractions and leadership styles influence workplace outcomes (Noy & Zhang, 2023 ). In the context of \nemployee productivity, experiments using LLMs have revealed substantial benefits. For instance, \nprofessionals using ChatGPT in workplace writing tasks improved productivity by reducing task completion \ntime by 40% and enhancing output qu ality by 18%, indicating its potential to effectively augment mid -level \nprofessional tasks (Noy & Zhang, 2023 ). Similarly, research on creativity has demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 216,
      "text": "as demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology.  \nLLMs have many applications in social and cultural psychology, allowing us to test theories and \nhypotheses about human behavior in social and cultural interaction settings. Zhao et al. (2024) , for instance, \nexamined whether AI chatbots can adjust their financial decisions and prosocial behaviors based on \nemotional cues, similar to humans. It was hypothesized that bots would take fewer risks when exposed to \nfear cues and more risks with joy cue s. Emotional primes (fear, joy, or neutral) were applied, and investment \ndecisions were analyzed. Additionally, prosocial responses, such as donating to a sick friend, were measured \nto assess how LLMs adapt behaviorally under emotional influences.  These findings highlight LLMs \u2019 ability \nto model complex social dynamics and cultural influences. The next section broadens this perspective, \nexploring LLMs \u2019 potential as versatile research tools for psychologists.  \n \n \n \nTable 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 217,
      "text": "Table 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al. \n(2023)  Do LLMs exhibit biases \ntoward WEIRD (Western, \nEducated, Industrialized, \nRich, Democratic) societies in \npsychological tasks?  LLMs\u2019 responses on psychological measures \nwere compared to cross -cultural human data.  LLMs closely align with WEIRD \ncognitive patterns but show declining \naccuracy with non -WEIRD \npopulations (r = -0.70), revealing a \nWEIRD bias.  \nJin et al. \n(2023)  Does GPT exhibit cultural \ncognitive traits aligned with \nEastern or Western thinking?  GPT was evaluated using cognitive and value \njudgment  scales.  GPT leans towards Eastern holistic \nthinking in cognitive tasks but shows \nno cultural bias in value judgments, \nlikely influenced by its training data \nand methods.  \nSchaaff et al. \n(2023)  How empathetic is GPT \ncompared to humans?  GPT\u2019s empathy was evaluated through \nemotion recognition tasks, conversational \nanalysis, and five empathy -related \nquestionnaires.  GPT accurately identified emotions in \n91.7% of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 218,
      "text": "of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3.5, and GPT -4 match human \nempathy and emotion \nidentification?  Empathy and emotional understanding were \nassessed using TAS -20 (Toronto Alexithymia \nScale -20) and EQ -60 (Emotional Quotient \nInventory -60), comparing LLM responses to \nhuman benchmarks.  GPT-4 approached human -level \nemotional intelligence, outperforming \nBard and GPT -3.5, which showed \nalexithymic tendencies.  \nX. Wang et \nal. (2023)  How do LLMs compare to \nhumans in emotional \nintelligence?  A psychometric assessment focusing on \nEmotion Understanding  was developed and \napplied to mainstream LLMs, benchmarking \nthem against over 500 human participants.  GPT-4 scored higher than 89% of \nhumans in emotional intelligence, with \nLLMs showing above -average \nemotional intelligence  but using non -\nhuman mechanisms influenced by \nmodel design.  \nX. Li et al. \n(2022)  Are LLMs psychologically \nsafe, and how can fine -tuning \nimprove their safety?  LLMs were assessed using the Short Dark \nTriad (SD -3), Big Five Inventory (BFI), and \nwell-being tests to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 219,
      "text": "to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al. \n(2022)  What are GPT -3\u2019s personality \ntraits and values as assessed \nby validated psychological \ntools? Administered validated personality and values \nmeasurement tools to GPT -3, including a \nmodel response memory to assess value \nalignment.  GPT-3 exhibits personality traits and \nvalues similar to human samples, \nproviding initial evidence of \npsychological assessment in LLMs.   \n \nSocial Interactions and Behavioral Simulations  \nZhao et al. \n(2024)  Can LLMs like GPT adapt \nresponses to emotional primes \nin decision -making?  Tested GPT -4 and 3.5 with scenarios eliciting \npositive, negative, or neutral emotions.  GPT-4 showed distinct emotional \nresponse patterns, exceeding GPT -3.5, \nindicating advanced modulation but no \ntrue emotions.  \nAher et al. \n(2023)  Can LLMs accurately \nsimulate human behaviors, \nand what biases emerge in \ntheir simulations?  Introduced Turing Experiments to evaluate \nLLMs against findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 220,
      "text": "st findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal. (2023)  Do LLMs exhibit biases \ntoward math and STEM, and \nhow do these biases compare \nacross models and with \nhumans?  Using Behavioral Forma Mentis Networks, \nbiases in GPT -3, GPT -3.5, GPT -4, and high \nschool students were analyzed through a \nlanguage generation task.  Newer LLMs (GPT -4) show reduced \nnegative bias and richer semantic \nassociations toward math and STEM \ncompared to older models and \nhumans, suggesting advancements in \nreducing stereotypes.  \nAlmeida et \nal. (2024)  How do state -of-the-art LLMs \nreason about moral and legal \nissues, and how do their \nresponses align with human \njudgments?  Eight experimental psychology studies were \nreplicated using Google\u2019s Gemini Pro, \nAnthropic\u2019s Claude 2.1, GPT -4, and Meta\u2019s \nLlama 2 Chat 70b. Model responses were \ncompared to human responses to assess \nalignment and systematic differences.  GPT -4 showed the best human \nalignment among LLMs but \nexaggerated effects and reduced \nvariance, highlighting biases that limit \ntheir suitability as substitutes for \nhuman participants in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 221,
      "text": "in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks.  ChatGPT improved productivity (40% \nfaster task completion, 18% better \nquality).  \nLee and \nChung \n(2024)  How does ChatGPT influence \ncreativity?  Measured creativity using associative and \ndivergent thinking tasks.  ChatGPT supports incremental \ncreativity but is less effective for \nradical innovation.  \nYang et al. \n(2023)  Can LLMs personalize job \nrecommendations?  PALR(personalization -aware LLMs for \nrecommendation) integrated interaction data \nwith LLMs for dynamic recommendations.  PALR enhanced predictions of job \nperformance and improved role \nmatching.  \nDu et al. \n(2024)  How can LLMs improve job \nrecommendations?  Used GANs with LLMs to refine low -quality \nresumes.  GAN -based systems predicted better \njob fit and reduced hiring \ninefficiencies.  \nAkata et al. \n(2023)  How do LLMs perform in \nsocial interaction tasks \ninvolving cooperation and \ncoordination?  LLMs played repeated two -player games (e.g., \nPrisoner\u2019s Dilemma, Battle of the Sexes) with \nother LLMs and human -like strategies to \nanalyze their behavior.  LLMs perform well in self -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 222,
      "text": "lf -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al. \n(2024)  Does GPT exhibit heuristics \nand context -sensitive \nresponses similar to those \nobserved in human decision -\nmaking?  Four studies tested GPT\u2019s responses to \nprompts designed to assess cognitive biases \n(anchoring, representativeness, availability \nheuristic, framing effect, endowment effect) \nand compared them to human participant \nresponses.  GPT demonstrated biases consistent \nwith human heuristics across all \nstudies, suggesting that language \npatterns alone may contribute to these \neffects, independent of human \ncognitive and affective processes.  \nPark et al. \n(2022)  How can designers predict \nand refine social behaviors in \nlarge -scale social computing \nsystems before deployment?  Developed \u201csocial simulacra,\u201d an LLM -driven \nsimulation that generates realistic community \ninteractions based on design inputs (goals, \nrules, personas), allowing scenario testing and \niterative design refinement.  Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 223,
      "text": "Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al. \n(2022)  Can LLMs demonstrate social \nintelligence and Theory of \nMind (ToM)?  LLMs were evaluated using SocialIQa (social \nintents and reactions) and ToMi (mental states \nand realities), with results contextualized \nthrough pragmatics theories.  LLMs, including GPT -4, perform \nbelow human levels (55% on \nSocialIQa, 60% on ToMi), indicating \nthat scaling alone does not yield ToM, \nhighlighting the need for person -\ncentric NLP approaches.  \nArgyle et al. \n(2022)  Can GPT -3 reliably emulate \nhuman subpopulations for \nsocial science research?  GPT-3 was conditioned on sociodemographic \nbackstories from U.S. surveys, creating \n\u201csilicon samples,\u201d which were compared to \nhuman survey data.  GPT-3 exhibits nuanced, \ndemographically aligned biases, \nindicating its potential as a tool for \nstudying human behavior and societal \ndynamics.  \nP. S. Park et \nal. (2024)  Can GPT -3.5 simulate human \nparticipants and replicate \nsocial science study results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 224,
      "text": "udy results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37.5% of study \nresults but exhibited uniform \nresponses (\u201ccorrect answer\u201d effect) \nand skewed conservative in moral \nfoundation surveys, questioning its \nreliability and diversity as a human \nparticipant substitute.  \nNote:  WEIRD (Western, Educated, Industrialized, Rich, Democratic) refers to societies that represent a \nminority of the global population but are often overrepresented in psychological research.  \n \n6. LLMs as research tools in psychology  \nSections 2 -5 illustrate LLMs \u2019 applications across cognitive, clinical, educational, and social psychology, \nrevealing their potential to transform research practices. Together, these advancements speed up \npsychological research with new tools, encourage collaboration with fields like c omputer science and \nlinguistics, and improve theoretical models through behavioral simulation \u2014key ways LLMs advance \npsychology. Building on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 225,
      "text": "on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5). By reducing subjective bias and minimizing human variability in tasks like stimulus generation \n(Section 2), standardized assessments (Section 3), and data inter pretation (Section 4), LLMs enhance \nobjectivity and efficiency across these applications.  \nFor instance, LLMs can automate systematic reviews and meta -analyses, revolutionizing evidence \nsynthesis and provide actionable insights for psychologists, as grounded in cognitive and behavioral \nprinciples  (e.g., in Sections 2 and 3).  This capacity extends to enhancing psychologists \u2019 workflows, \nbuilding on productivity improvements noted in Section 5, through tools like literature review, hypothesis \ngeneration, experimental design, experimental subjects, and data analysis (Table 5).  \nTable 5. LLMs as research tools in psychology study.  \nTopic  Related study  \nLiterature review  LLMs can summarize the researched literature (Dis, Bollen, Zuidema, Rooij, & Bockting, 2023) , complete literature \nreview tasks (Qureshi et al., 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 226,
      "text": ", 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al., 2022) \u3002 \nHypothesis \ngeneration  LLMs can generate hypotheses from scientific literature, make inferences based on scientific data, and then clarify \ntheir conclusions through interpretation (Zheng et al., 2023) , and can quickly and automatically test these research \nhypotheses and learn from mistakes . \nExperimental \ndesign  \n LLMs provide text -based material for experimental design, thereby optimizing the research process and reducing \nexperimental complexity. By employing these models, researchers can easily create experimental stimuli, develop \ntest items, and even simulate interactive sessions in con trolled environments  (Aher, Arriaga, & Kalai, 2022; Akata \net al., 2023) , providing a high degree of control and precision to the experimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 227,
      "text": "erimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al., 2023) , their use in place of human participation in experiments \nsaves time and costs and can be applied to some experiments where human participation is not appropriate (Hutson, \n2023 ), they can be combined with factors such as the specific research topic, the task, and the sample, and the use \nof LLM as an alternative to research participants where appropriate (Dillion et al., 2023 ). \nData analysis  LLMs can efficiently analyze massive amounts of textual data to gain insights into human behavior and emotions \nat an unprecedented scale  (Patel & Fan, 2023) , can analyze textual data in multiple languages, and accurately detect \nmental structures within it (Rathje et al., 2023) , can draw mental profiles from social media data (Peters & Matz, \n2023)\u3002 \nScholarly \nCommunication  LLMs can also help humans in writing (Dergaa et al., 2023 ; Stokel -Walker, 2022 ; Van Dis et al., 2023 ). LLMs were \nused in two natural language processing tasks and a human expert to assess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 228,
      "text": "ess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D. students struggling to finish their dissertations, to peer reviewers submitting \nanalyses under time pressure (Van Dis et al., 2023 ). \n \n6.1.  Automated literature review and meta -analysis  \nConducting a literature review meta -analysis is a complex, arduous process that requires significant \ntime and expertise (Michelson & Reuter, 2019 ). Nature reported that researchers have used GPT as a research \nassistant to summarize literature (Dis et al.  2023) . In one study, researchers used GPT to complete certain \nsystematic literature review tasks (Qureshi et al., 2023) . In another study, a literature review article was \ncreated using GPT with the application of digital twins in the health field; the results showed that knowledge \ncompilation and representation were accelerated with the help of LLMs. However, their academi c validity \nneeds to be further verified (Ayd\u0131n & Karaarslan, 2022) . Researchers have also specifically trained LLMs to \nsupport the practical needs of scientific research (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 229,
      "text": "ch (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal. (2024)  demonstrated that LLMs can screen literature, extract data, and generate statistical codes for meta -\nanalyses, significantly reducing workload while maintaining recall rates comparable to manual curation. \nSimilarly, Tong et al. (2024)  used LLMs to extract causal pairs from 43,312 psychology articles, achieving \nan 86.98% success rate in pair extraction through adaptive prompting. As discussed in section 3, LLMs have \nshown strong capabilities in extracting causal relationships from large  textual datasets, underscoring their \npotential to streamline evidence synthesis for systematic reviews and meta -analyses. Nevertheless, while \nLLMs excel in organizing qualitative data and identifying conceptual patterns, they face challenges in \nextracting  the precise numerical data necessary for meta -analyses. For example, although LLM -based tools \ncan retrieve and summarize outcome measures, manual validation remains essential to ensure accuracy, \nespecially when processing complex figures or tables.  \nIn summary, LLMs can speed up the process of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 230,
      "text": "ess of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2.  Hypothesis generation and experimental design  \nHypothesis -driven research is at the core of scientific activity. LLMs can generate hypotheses from \nscientific literature, make inferences based on data, and then clarify conclusions through interpretation \n(Banker et al., 2024 ; Zheng et al., 2023 ). Although LLMs are capable of becoming \u201chypothesis machines,\u201d \ntheir logical and mathematical derivation capabilities still need improvement to eliminate factual errors, \nquickly test hypotheses, and learn from mistakes (Y . J. Park et al., 2024 ) . As innovative tools, LLMs have \ngreat potential for use in psychological experiments, given their ability to provide text -based material for \nexperimental designs, thus optimizing the research process and reducing experimental complexity. Using \nsuch model s researchers can easily create experimental stimuli, develop test items, and even simulate \ninteractive sessions in controlled environments (Aher, Arriaga, & Kalai, 2022; Akata et al., 2023) , providing \na high degree of control and precision in the experimental process.  \nIn conclusion, LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 231,
      "text": "LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3.  LLMs as subjects in psychological experiments  \nAlthough LLMs can simulate some human behaviors and responses \u2014which provides an opportunity \nto test theories and hypotheses about human behavior (Grossmann et al., 2023) \u2014there is still some \ncontroversy on whether LLMs can be used as a substitute for human subjects in psychological research. \nWhile recognizing that certain problems persist (e.g., biases and insufficiently trained data), some \nresearchers have suggested that LLMs can be used as substitutes for human participants to save time and \ncost and can be applied to experiments that are not suitable for human participation (Hutson,2023) . Others \nhave proposed using LLMs as an alternative method of studying participants when appropriate, based on \ntheir performance in conjunction with factors such as specific research topics, tasks, and samples (Dillion et \nal., 2023 ). However, it is also believed that although LLMs can significantly affect scientific research, they \nare unlikely to replace human participants in any meaningful way (Harding et al., 2023 ). At the same time, \nsome studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 232,
      "text": "some studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects.  \nIn conclusion, although LLMs can simulate human judgment, their simulation of human thinking \nremains limited, and their output should be validated and interpreted with caution when used as \npsychological subjects.  \n6.4.  Tools for data analysis  \nVarious forms of AI have long been used to analyze psychological data, such as flight data for pilot \nscreening (Ke et al., 2023 ). Machine learning algorithms facilitate the processing of large datasets, \nidentifying patterns and correlations that might otherwise be overlooked. However, LLMs take this \ncapability to a new level; they can efficiently analyze massive amounts of textual data on an unprecedented \nscale to derive insights into human behavior and emotions (Patel & Fan, 2023) . For psychological research, \nthis means faster and more comprehensive data analysis, leading to more reliable, nuanced findings. LLMs \ncan analyze textual data in multiple languages, accurately detect psychological structures within them \n(Rathje et al., 20 23), and generate psychological profiles from social media data (Peters & Matz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 233,
      "text": "atz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation. Yet, LLMs cannot \noutperform experienced neuroradiologists, suggestin g the need for continued improvement in the medical \ncontext (Nazario -Johnson et al., 2023 ). These findings demonstrate the great potential of LLMs for \nevaluating and analyzing data.  \n6.5.  Promoting scholarly communication  \nScholarly communication is a cornerstone of academic research, encompassing the processes of \ncreating, evaluating, and disseminating knowledge. It includes writing research papers, conducting peer \nreviews, and ensuring that findings are communicated transp arently and ethically. In psychology, this process \nis particularly complex owing to the field\u2019s diverse theoretical frameworks and methodological approaches, \nranging from experimental to qualitative research. The discipline\u2019s focus on human behavior and it s \nintersection with technology demands precise and ethical communication practices.  \nIt has been argued that LLMs currently cannot completely replace human writing and instead can only \nanswer questions and generate naturally fluent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 234,
      "text": "uent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing. The experimental group that used GPT was found to be similar to the control group \nin terms of writing quality, speed, and authenticity; the authors suggested that this could be because \nexperienced researchers can better guide GPT to produce high -quality information. By contrast, students \u2014\nwho have less writing experience than researchers \u2014found that GPT did not perform as effectively (Ba\u0161i\u0107 et \nal., 2023 ). Another article discussed the prospects and potential threats of GPT in academic writing, \nemphasizing that using GPT in academic research should prioritize peer -reviewed scholarly sources. Yet, \nGPT\u2019s potential advantages for academic research, including the handling of large amounts of textual data \nand the automatic generation of abstracts and research questions (Dergaa et al., 2023 ), were highlighted. \nFurthermore, LLMs can potentially be used for peer review (Van Dis et al., 2023 ). The decisions/judgments \nof LLMs in a text -evaluation task were found to be consistent with those of human experts (Chiang & Lee, \n2023) . \nIn conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 235,
      "text": "n conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually. They \ncan be used to scan academic papers and extract es sential details, generate objective and unbiased abstracts, \nand create research questions in social psychology (Banker et al., 2023 ; Tong et al., 2024 ). However, \nresearchers must exercise caution when using them as they can also introduce false or biased information \ninto papers, leading to unintentional plagiarism and the misattribution of concepts (Van Dis et al., 2023 ). \n \n \n7. Challenges and future directions  \n7.1.  Challenges and limitations  \nLLMs have enormous potential to simulate complex cognitive processes, providing researchers with \nnew tools to explore the mechanisms of human cognition and behavior for wide -ranging application in \nvarious fields, including clinical and counseling psycholog y, educational and developmental psychology, \nand social and cultural psychology. However, LLM output should not be mistaken for the presence of thought \nbut instead viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 236,
      "text": "d viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding. \nThe interpretation of LLMs\u2019 capabilities must be based on an understanding of their limitations and the \nnature of their operations, which might differ fu ndamentally from human cognition. It is essential, then, to \nfocus on the potential of LLMs in psychological research while also acknowledging the technical and ethical \nchallenges that might arise.  \nFirst, despite the emergence of LLM competence (Wei et al., 2022 ), its internal working mechanism \nremains a black box from a cognitive and behavioral psychology perspective. For example, LLMs perform \nimpressively on tasks requiring formal linguistic competence (including knowledge of the rules and patterns \nof a particul ar language) but fail many tests requiring functional competence (the set of cognitive abilities \nneeded to understand and use language in the real world) (Mahowald et al., 2023 ). They excel in analogical \nand moral reasoning tasks but perform poorly on spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 237,
      "text": "spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 ). For example, gatekeepers, patients, and even mental \nhealth professionals who use GPT to assess suicide risk or improve decision -making might receive \ninaccurate assessments that underestimate risk (Elyoseph & Levkovich, 2023 ) or bias clinician decision -\nmaking, which can lead to healthcare inequities (Pal et al., 2023 ). In addition, LLMs in psychiatry research \nand practice have been associated with potential bias and privacy violations (Zhong et al., 2023 ). \nThird, LLMs face application challenges in fields such as educational, developmental, and social and \ncultural psychology. It is evident that when applied in education, LLMs have the potential for output bias \nand misuse (Kasneci et al., 2023 ). One study found that texts generated by GPT were not always consistent \nor logical and sometimes even contradictory (Stojanov, 2023 ). In the field of social and cultural psychology, \nLLMs exhibit cognitive biases (Talboy & Fuller, 2023 ) and cultural biases (Atari et al., 2023 ) similar to those \nof humans, in addition to implicitly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 238,
      "text": "citly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings.  \nFinally, LLMs have some limitations as aids to scientific research. With regard to writing, for example, \nLLMs currently cannot fully replace humans. Instead, they answer questions and generate naturally flowing, \ninformative content lacking real intelligenc e (Stokel -Walker, 2022) . Although macrolanguage models can \nsimulate human judgment when used as experimental subjects, there are still limits to their \u201cunderstanding\u201d \nof human thought (Dillion et al., 2023 ). Van Dis et al. (2023)  noted that LLMs might accelerate innovation, \nshorten publication times, and increase scientific diversity and equality. However, they might also reduce \nthe quality and transparency of research and fundamentally alter scientists\u2019 autonomy as human research ers. \nIn summary, while LLMs offer extraordinary capabilities for psychological research, they also present \nchallenges related to bias, ethical issues, data security, transparency, and technical expertise. Researchers \nshould be fully aware of these challenges wh en using LLMs and adopt the following steps for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 239,
      "text": "s for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation. Third, use diverse training data to \nreduce cultural or gender biases. Fourth , in sensitive areas like mental health, limit use to assist \u2014not \nreplace\u2014judgment and train users to interpret outputs critically. These steps, supported by recent studies \n(Abdurahman et al., 2024; Guo et al., 2024; Porsdam Mann et al., 2024), address ethi cal concerns in \npsychological research.  Table 6 summarizes the challenges and limitations of LLMs in psychological \napplications.  \nTable 6  Challenges and limitations of LLMs in psychological applications.  \nChallenges  Author  Details  \nCogniti ve and Behavior al Psychology  \nLack of Real -World \nUnderstanding  Mitchell \n(2023)  LLMs lack real -world understanding, abstract reasoning, and intent comprehension.  \nLack of Meta -\nknowledge  Stella et al. \n(2023)  LLMs fabricate information (hallucination) and lack curiosity/meta -knowledge.  \nCausal Reasoning and \nCreativity  Sartori and \nOrr\u00f9 (2023)  Poor causal reasoning, dependence on biased training data, lack of creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 240,
      "text": "creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al. \n(2023)  Forgetting knowledge in new tasks, poor common -sense reasoning, inconsistent problem -\nsolving.  \nModel Behavior \nChallenges  Holtzman et \nal. (2023)  Lack of interpretability and formal behavioral descriptions makes systematic analysis difficult.  \nPsycholinguistic \nFeatures  Seals and \nShalin \n(2023)  GPT and human -generated analogies differed in these stylistic dimensions, these lexical \nfeatures, their choice of words for these features and these devices that help readers understand \ntext. GPT may lack human cognitive and psycholinguistic features when generating analogies.  \nClinic and Counseling  Psychology  \nTechnical Limitations& \nPatient Connection \nIssues  Stade et al. \n(2023)  Difficulty assessing suicide risk, substance abuse, safety issues, and interpreting nonverbal \ncues& Problems forming therapeutic relationships, interpreting nonverbal behaviors.  \n \nEducation and Development  Psychology  \nIntegrity and Ethics \nIssues  Li et al. \n(2023)  Academic integrity concerns, misinformation, data privacy, and impact on critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 241,
      "text": "n critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity.& \nLimited support for diverse languages and equitable access.  \nSocial and Culture  Psychology  \nLiability and Privacy \nIssues  Fecher et al. \n(2023)  Liability issues: challenging traditional mechanisms of authorship and liability. Bias issues: \naffecting the objectivity and impartiality of science. Privacy and data protection issues: may be \nprivacy issues with the training data of LLMs. Intellectual pro perty issues: potential legal \ndisputes. Environmental issues: generating large amounts of carbon emissions, which can have \na negative impact on the environment.  \nGlobal Diversity \nIgnorance  Atari et al. \n(2023)  Ignoring global psychological diversity (e.g., tend to favor the psychological characteristics of \nWEIRD societies) and which can lead to prejudice and discrimination against people of other \ncultures and backgrounds. Differences in values and moral judgment s and which can lead to \nproblems of communication and understanding in multicultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 242,
      "text": "icultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal. (202 4) Reduced innovation and development, bias and discrimination, culture clash and conflict, \ndifferences in values and morals and entrenchment of the status quo.  \nSocial Context \nLimitations  Salah et al. \n(2023)  Limited understanding of social context: Although GPT  performs well in syntax and general \nsemantics, it still has limitations in capturing the nuances of social language.  Ethical challenges: \nAI-generated fake content can lead to ethical issues including digital personhood, informed \nconsent, potential manipulation, and the implications of using AI to simulate human \ninteractions.  \nBias and Misleading Hayes Potential biases: if the training data contain biases, LLMs may learn and replicate them. Data \nOutputs  (2023)  privacy and consent issues: Text generated using LLMs may involve data privacy and consent \nissues.  Output may be non -humanly understandable: although LLMs generate text that closely \nresembles human language, they do not truly understand the content and may generate absurd \nor misleading responses.  \nTraining Data Bias  Miotto et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 243,
      "text": "to et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements.  \nResponsibility and control: Due to the complexity of language models, it is difficult to determine \nwho is responsible for the model's output, which can lead to attribution of problems and lack of \ncontrols.  \nPropagation of Harm  Bender et \nal. (2021)  Potential Harm: LLMs may lead to the propagation of harmful ideas such as stereotyping, \ndiscrimination, and extremism, and may lead to misinformation and bullying when generating \ntext. Data bias and unfairness: leading to potential harm to marginalized communities. \nAutomating bias: exacerbating existing biases and discrimination.  Enhancement of authoritative \nviewpoints: LLMs may reinforce dominant viewpoints in the training data, further undermining \nmarginalized people.  \nAlignment Challenges  Tamkin et \nal. (2021)  Alignment: In order to better align models with human values, algorithmic improvements are \nneeded to increase factual accuracy and robustness against adversarial samples. In addition, \nappropriate values need to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 244,
      "text": "to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al. \n(2020)  Misuse of language modeling: GPT -3 may be used to generate fake news, spread extremist \nideas, conduct cyber -attacks and other malicious uses.  Fairness, bias, and representation: GPT -\n3 may carry bias against gender, race, and religion, among others, sparking related \ncontroversies.  News generation: News generated by GPT -3 may be difficult to distinguish from \nreal news, leading to confusing and misleading information.  \nResearch Tools  \nPlagiarism and \nCopyright Issues  Sallam \n(2023)  Plagiarism: content generated by GPT may be considered plagiarized, violating academic \nnorms.  Copyright issues:  Is the generated content owned by GPT or by the user?  Transparency \nissues: The workings of GPT may not be transparent, making it difficult for users to understand \nthe source of generated content. Liability issues: who is responsible for GPT when generating \nincorrect content?  \nTransparency \nLimitations  Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 245,
      "text": "Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content.  Legal \nand Ethical Issues: Generative AI models may involve intellectual property, privacy, and ethical \nissues, requiring attention to compliance with relevant laws and regulations during use.  \nAcademic Integrity \nConcerns  Dergaa et \nal. (2023)  Integration of erroneous or biased information. Problems with citing original sources and \nauthors. Impact on academic integrity and quality. Increased inequity and inequality: Difficulty \nin recognizing AI -generated content. Academic evaluation and recognit ion issues. Direct \nreplacement for academic researchers: GPT is not a complete replacement for academic \nresearchers as it has limitations in certain types of academic research.  \nPrivacy and Bias Risks  Peters and \nMatz \n(2023)  User privacy: LLMs can infer psychological traits from a user's social media data, which may \nviolate the user's privacy. Potential bias: LLMs may create potential bias in the inference \nprocess, which may lead to unfair treatment of specific groups (e.g., gender, age, etc.). Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 246,
      "text": ". Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al. \n(2023)  Academic misconduct: GPT may be used for academic cheating, such as generating false papers \nor assignments.  Challenges in the medical field: GPT  has limitations in medical image analysis, \nwhich may lead to wrong diagnosis and jeopardize patients' health.  \n \n7.2.  Future directions and emergent trends  \nCurrently, LLMs are used in different areas of psychology, including cognitive and behavioral, clinical \nand counseling, educational and developmental, and social and cultural psychology. As the capabilities of \nLLMs are further enhanced, their potential applications in psychology will continue to develop.  \nFirst, in the field of cognitive and behavioral psychology, with the emergence of multimodal LLMs \n(OpenAI, 2023 ), it is possible to combine visual and auditory information with textual data to better \nunderstand and model emotions, behaviors, and mental states for cognition. However, neuroimaging data \ncan be used to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 247,
      "text": "to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought.  \nSecond, in the field of clinical and counseling psychology, on the one hand, personal data, such as social \nmedia posts, medical records, or wearable device data, can be used to create tailored, personalized LLMs \nthat provide more accurate and relevant insi ghts into an individual\u2019s state of mind. At the same time, the \nstrengths of human clinical and counseling expertise can be combined with the scalability and computational \npower of LLMs to create new diagnostic treatment and intervention tools. In addition,  in educational and \ndevelopmental psychology and social and cultural psychology, it is essential to build ethical LLMs and \nensure they are designed and deployed in a way that respects privacy and uses data fairly and responsibly.  \nUltimately, LLMs represent a systematic project whose future development cannot be achieved without \nthe interdisciplinary collaboration of researchers in diverse fields such as psychology, computer science, and \nlinguistics. For psychology researchers, acce ssible open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 248,
      "text": "ble open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application.  \nTable 7  Future directions and emergent trends of LLMs in psychological applications . \nAuthor  Future directions and emergent trends  \nCognition and Behavior  \nD'Oria (2023)  Delving into Human -Computer Interaction (HCI) to understand AI's ability to mimic human behavior.  Exploring how \nAI language modeling can be applied in the human sciences to improve research efficiency and quality  \nCrockett and \nMesseri (2023)  Focus on the costs of adopting alternative human narratives in cognitive science research, such as masking the human \nlabor behind them and the impact on human well -being.  Concern about the impact of technological developments on \nscientific work and human understanding to ensure that cognitive scientists remain proactive in technological advances.  \nBinz and \nSchulz \n(2023b)  Explore ways to make LLMs more stable and robust in the face of descriptive tasks.  \nInvestigate whether LLMs can learn to explore purposefully and how to better utilize causal knowledge in tasks.  Analyze \nthe performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 249,
      "text": "the performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans.  \nHuang and \nChang (2022)  Improve the reasoning ability of LLMs to encourage reasoning by optimizing training data, model architecture, and \noptimization goals.  Develop more appropriate evaluation methods and benchmarks to measure the reasoning ability of \nLLMs to better reflect the true reasoning ability of the models.  Investigate the potential of LLMs in different applications \n(e.g., problem solving, decision making and planning tasks).  Explore other forms of reasoning (e.g., inductive and \nretrospective reasoning).  \nClinic and Counseling  \nAbd-Alrazaq \net al. (2019)  Develop more chatbots for people with mental illness, especially for those with disorders such as schizophrenia, \nobsessive -compulsive disorder and bipolar disorder.  \nImplement more chatbots in developing countries to address the shortage of mental health professionals.  Conduct more \nrandomized controlled trials to evaluate the effectiveness of chatbots in mental health.  \nStade et al. \n(2023)  Developing new therapeutic techniques and evidence -based practices (EBPs). Focus on evidence -based practices first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 250,
      "text": "es first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success.  Involve interdisciplinary collaboration. \nFocuses on therapist and patient trust and usability. Criteria for designing effective clinical LLMs.  \nDemszky et al. \n(2023)  Development of high -quality cornerstone datasets: these datasets need to encompass populations and psychological \nconstructs of interest and be associated with psychologically important outcomes (e.g., actual behaviors, mindfulness, \nhealth, and mental well -being). Focus on future research directions in consumer neuroscience and clinical neuroscience: \nresearch in these areas may involve the neural systems of marketing -related behaviors, decision neuroscience, \nneuroeconomics, and more.  \nEducation and Development  \nHagendorff \n(2023)  Developmental psychology: examining how LLMs develop cognitively, socially, and emotionally over the lifespan and \nhow these models can be optimized for specific tasks and situations. Learning psychology: studying how LLMs acquire \nand retain knowledge and s kills, and how to optimize these models to improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 251,
      "text": "o improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities.  Investigate ways to combine static text with rich social intelligence and interaction data to improve \nsocial intelligence in LLMs. Investigate the theoretical -psychological abilities of LLMs in more naturalistic settings to \nreveal their performance in real -world scenarios.   \nArgyle et al. \n(2022)  Investigate the algorithmic fidelity of the GPT -3 model and how appropriate conditioning can allow the model to \naccurately simulate the response distributions of various human subgroups.  Created \"in silico samples\" by conditioning \non the socio -demographic backgrounds of real human participants in multiple large U.S. surveys.  \nSchaaff et al. \n(2023)  Developing more advanced models: to more accurately capture the emotional context of conversations and improve \nemotional understanding and expression.  Measuring the emotional capabilities of bots: to investigate how to assess the \nemotional capabilities of chatbots in order to better understand how they behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 252,
      "text": "ey behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al. \n(2023)  Cross -cultural CSS research: future research should separately consider the utility of LLMs for cross -cultural CSS in \norder to better serve social science research in different cultural contexts.  Future research could explore contrastive or \ncausal explanations in LLMs.  New paradigms for social science and AI collaboration.  \nResearch Tools  \nVan Dis et al. \n(2023)  Invest in truly open LLMs: develop and implement open -source AI technologies to increase transparency and democratic \ncontrol.  Embrace the advantages of AI: utilize AI to accelerate innovation and breakthroughs at all academic stages, \nwhile focusing on issues of ethics and human autonomy.  Broaden the discussion: organize international forums to \ndiscuss the development and responsible use of LLMs in research, including issues of diversity and inequality.  \nFecher et al. \n(2023)  Analyzing the risks and opportunities of LLMs for science systems. Examining how LLMs affect academic quality \nassurance mechanisms, academic misconduct, and scientific integrity. Exploring the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 253,
      "text": "the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8. Conclusion  \nWith the rapid development of AI technologies, especially the continuous advancement of LLMs, \nmachine learning has reached the point where it can recognize and generate human language. This \ndevelopment is not simply a technological breakthrough for the fie ld of psychology, but it opens the door to \na range of potential applications.  \nFirst, in the field of cognitive and behavioral psychology, LLMs are excelling in a variety of cognitive \ntasks. Although there are still limitations in causal cognition and planning, these models resurrect the \nprinciple of association, demonstrating the ab ility to associate at a distance and reason in complex ways. At \nthe same time, the ability to adapt LLMs to cognitive models is a significant strength of psychological \nresearch, allowing for new explorations of human cognitive and behavioral processing mec hanisms.  \nSecond, in clinical and counseling psychology, LLMs can be used as preliminary diagnostic tools for \nmental health. While traditional mental health diagnosis relies on the experience of professionals and direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 254,
      "text": "nd direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content. Importantly, while such \ndiagnoses cannot wholly replace professional psychological assessment, they can serve as a n effective \nadjunct to help psychologists understand a patient\u2019s condition more quickly, or play a role in primary mental \nhealth interventions. Meanwhile, personalized psychological intervention is another critical application \ndirection for LLMs. By combining informat ion about an individual\u2019s health data and lifestyle habits, these \nmodels can provide tailored psychological advice and intervention programs. Such personalized approaches \ncould be crucial for improving the effectiveness of psychological interventions.  \nThird, LLMs have the same potential for application in both educational and developmental psychology \nand social and cultural psychology. For example, LLMs provide interactive and personalized learning \nexperiences or generate research tasks based on real -life applications that increase motivation and enhance \nlearning. In addition, by analyzing large amounts of social media data, these models can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 255,
      "text": "s can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency. Researchers can \nuse these models to quickly organize and analyze large amounts of literature, thus saving time. These models \ncan also assist with experimental design, dat a analysis, and even promoting scholarly communication, \nmaking psychological research more efficient and precise.  \nIn light of the above, LLMs have promising applications for psychology, such as research support, \ncognitive modeling, individualized intervention, and personalized learning. LLMs also have the potential to \ndramatically improve our understanding of human co mmunication, thought processes, and behaviors, \nleading to the development of more comprehensive theories of mind and cognitive science. At the same time, \nit is important to be aware of the related risks and challenges and to ensure adherence to ethical sta ndards, \nespecially with regard to individual privacy and data security. It is also important to recognize that no matter \nhow technologically advanced they are, LLMs can only partially replace the judgment and experience of \nhuman professionals. Therefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 256,
      "text": "herefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019). An overview \nof the features of chatbots in mental health: A scoping review. International Journal of Medical \nInformatics , 132, 103978. https://doi.org/10.1016/j.ijmedinf.2019.103978   \nAbdurahman, S., Atari, M., Karimi -Malekabadi , F., Xue, M. J., Trager, J., Park, P. S., ... & Dehghani, M. (2024). \nPerils and opportunities in using large language models in psychological research. PNAS nexus , 3(7), \npgae245.  \nAbramski, K., Citraro, S., Lombardi, L., Rossetti, G., & Stella, M. (2023). Cognitive network science reveals bias \nin gpt -3, gpt -3.5 turbo, and gpt -4 mirroring math anxiety in high -school students. Big Data and Cognitive \nComputing , 7(3), 124.  \nAgrawal, S. (2023). Are LLMs the Master of All Trades? : Exploring Domain -Agnostic Reasoning Skills of LLMs. \narXiv preprint . https://doi.org/10.48550/arxiv.2303.12810   \nAher, G., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate multiple humans and \nreplicate human subject studies  Proceedings of the 40th International Conference on Machine Learning, \nHonolulu, Hawaii, USA.  \nAkata, E., Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 257,
      "text": "Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M., Shamsan, M. A. A., Hezam, T. A., & Mohammed, A. A. Q. (2023). Impact of ChatGPT on Learning \nMotivation. Journal of English Studies in Arabia Felix , 2(1), 41 -49. \nhttps://doi.org/10.56540/jesaf.v2i1.51   \nAlmeida, G. F., Nunes, J. L., Engelmann, N., Wiegmann, A., & de Ara\u00fajo, M. (2024). Exploring the psychology \nof LLMs\u2019 moral and legal reasoning. Artificial intelligence , 333, 104145.  \nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J., Rytting, C., & Wingate, D. (2022). Out of One, Many: Using \nLanguage Models to Simulate Human Samples. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2209.06899   \nAtari, M., Xue, M. J., Park, P. S., Blasi, D. E., & Henrich, J. (2023). Which Humans? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/5b26t   \nAyd\u0131n, \u00d6., & Karaarslan, E. (2022). OpenAI ChatGPT Generated Literature Review: Digital Twin in Healthcare. \nEmerging Computer Technologies (2), 22 -31. https://doi.org/10.2139/ssrn.4308687   \nBaillifard, A., Gabella, M., Lavenex, P. B., & Martarelli, C. S. (2024). Effective learning with a personal AI tutor: \nA case study. Education and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 258,
      "text": "and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10.31234/osf.io/kv6f7   \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2024). Machine -assisted social psychology hypothesis \ngeneration. American psychologist , 79(6), 789.  \nBa\u0161i\u0107, \u017d., Banovac, A., Kru\u017ei\u0107, I., & Jerkovi\u0107, I. (2023). ChatGPT -3.5 as writing assistance in students\u2019 essays. \nHumanities and Social Sciences Communications , 10(1). https://doi.org/10.1057/s41599 -023-02269 -7  \nBender, E. M., Gebru, T., McMillan -Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: \nCan Language Models Be Too Big?  Proceedings of the 2021 ACM Conference on Fairness, \nAccountability, and Transparency, Virtual Event, Canada. https://doi.org/10.1145/3442188.3445922  \nBinz, M., & Schulz, E. (2023a). Turning large language models into cognitive models. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2306.03917   \nBinz, M., & Schulz, E. (2023b). Using cognitive psychology to understand GPT -3. Proceedings of the National \nAcademy of Sciences of the United States of America , 120(6), e2218523120. \nhttps://doi.org/10.1073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 259,
      "text": "073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b). Personal narrative and stream of consciousness: an AI approach. The \nJournal of Positive Psychology , 1-7. https://doi.org/10.1080/17439760.2023.2257666   \nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \nAskell, A., Agarwal, S., Herbert -Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. \nM., Wu, J., Winter, C.,\u2026Amodei, D. (2 020). Language Models are Few -Shot Learners. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2005.14165   \nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E. K., Kamar, E., Lee, P., Lee, Y. T., Li, Y. -F., \nLundberg, S. M., Nori, H., Palangi, H., Ribeiro, M. T., & Zhang, Y. (2023). Sparks of Artificial General \nIntelligence: Early experiments with GPT -4. arXiv preprint . https://doi.org/10.48550/arXiv.2303.12712   \nCharness, G., Jabarian, B., & List, J. A. (2023). Generation next: Experimentation with ai .  \nChiang, C. -H., & Lee, H. -y. (2023). Can Large Language Models Be an Alternative to Human Evaluations? arXiv \npreprint . https://doi.org/10.48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 260,
      "text": ".48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023). Can AI Language Models Improve Human Sciences Research? A Phenomenological Analysis \nand Future Directions. Encyclopaideia , 27(66), 77 -92. https://doi.org/10.6092/issn.1825 -8670/16554   \nD\u2019Souza, R. F., Amanullah, S., Mathew, M., & Surapaneni, K. M. (2023). Appraising the performance of ChatGPT \nin psychiatry using 100 clinical case vignettes. Asian Journal of Psychiatry , 89, 103770.  \nDe Bot, K., Lowie, W., & Verspoor, M. (2007). A Dynamic Systems Theory approach to second language \nacquisition. Bilingualism: Language and Cognition , 10(1), 7 -21. \nhttps://doi.org/10.1017/S1366728906002732   \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., Eichstaedt, J. C., Hecht, C., \nJamieson, J., Johnson, M., Jones, M., Krettek -Cobb, D., Lai, L., JonesMitchell, N., Ong, D. C., Dweck, \nC. S., Gross, J. J., & Pennebaker, J. W. (20 23). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDergaa, I., Chamari, K., Zmijewski, P., & Ben Saad, H. (2023). From human writing to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 261,
      "text": "g to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023.125623   \nDhingra, S., Singh, M., Sb, V., Malviya, N., & Singh Gill, S. (2023). Mind meets machine: Unravelling GPT -4's \ncognitive psychology. arXiv preprint , arXiv:2303.11436. https://doi.org/10.48550/arXiv.2303.11436   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human participants? Trends \nin Cognitive Sciences , 27(7), 597 -600. https://doi.org/10.1016/j.tics.2023.04.008   \nDu, Y., Luo, D., Yan, R., Wang, X., Liu, H., Zhu, H., Song, Y., & Zhang, J. (2024). Enhancing job recommendation \nthrough llm -based generative adversarial networks. Proceedings of the AAAI Conference on Artificial \nIntelligence,  \nDubey, R., Hardy, M. D., Griffiths, T. L., & Bhui, R. (2024). AI -generated visuals of car -free US cities help \nimprove support for sustainable policies. Nature Sustainability , 7(4), 399 -403.  \nElyoseph, Z., & Levkovich, I. (2023). Beyond human expertise - the promise and limitationsof ChatGPT in suicide \nrisk assessment. Frontiers in Psychiatry , 14. https://doi.org/10.3389/fpsyt.2023.1213141   \nElyoseph, Z., & Levkovich, I. (2024). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 262,
      "text": "). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M., Laufer, M., Pohle, J., & Sofsky, F. (2023). Friend or foe? Exploring the implications of \nlarge language models on the science system. AI & Society . https://doi.org/10.1007/s00146 -023-01791 -\n1  \nFloridi, L., & Chiriatti, M. (2020). GPT -3: Its Nature, Scope, Limits, and Consequences. Minds and Machines , \n30(4), 681 -694. https://doi.org/10.1007/s11023 -020-09548 -1  \nFrank, M. C. (2023). Baby steps in evaluating the capacities of large language models. Nature Reviews Psychology , \n2(8), 451 -452. https://doi.org/10.1038/s44159 -023-00211 -x  \nGhafouri, M. (2024). ChatGPT: The catalyst for teacher -student rapport and grit development in L2 class. System , \n120, 103209.  \nGhafouri, M., Hassaskhah, J., & Mahdavi -Zafarghandi, A. (2024). From virtual assistant to writing mentor: \nExploring the impact of a ChatGPT -based writing instruction protocol on EFL teachers\u2019 self -efficacy and \nlearners\u2019 writing skill. Language Teaching Research , 13621688241239764.  \nGlaser, R. (1984). Education and thinking: The role of knowledge. American psychologist , 39(2), 93.  \nGoertzel, B. (2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 263,
      "text": "2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J., Mirza, M., Xu, B., Warde -Farley, D., Ozair, S., Courville, A., & Bengio, Y. \n(2020). Generative adversarial networks. Communications of the ACM , 63(11), 139 -144.  \nGraber -Stiehl, I. (2023). IS THE WORLD READY FOR AI -POWERED THERAPY? Nature , 617, 22-24. \nhttps://doi.org/10.1038/d41586 -023-01473 -4  \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, W. A. (2023). AI and \nthe transformation of social science research. Science , 380(6650), 1108 -1109. \nhttps://doi.org/10.1126/science.adi1778   \nGuo, Z., Lai, A., Thygesen, J. H., Farrington, J., Keen, T., & Li, K. (2024). Large language models for mental \nhealth applications: Systematic review. JMIR mental health , 11(1), e57400  \nGupta, M., Akiri, C., Aryal, K., Parker, E., & Praharaj, L. (2023). From ChatGPT to ThreatGPT: Impact of \nGenerative AI in Cybersecurity and Privacy. IEEE Access , 11, 80218 -80245. \nhttps://doi.org/10.1109/access.2023.3300381   \nHagendorff, T. (2023). Machine Psychology: Investigating Emergent Capabilities and Behavior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 264,
      "text": "avior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models. Proceedings of the National \nAcademy of Sciences , 121(24), e2317967121.  \nHagendorff, T., Fabi, S., & Kosinski, M. (2023). Human -like intuitive behavior and reasoning biases emerged in \nlarge language models but disappeared in ChatGPT. Nature Computational Science , 3(10), 833 -838. \nhttps://doi.org/10.1038/s43588 -023-00527 -x  \nHarding, J., D\u2019Alessandro, W., Laskowski, N. G., & Long, R. (2023). AI language models cannot replace human \nresearch participants. AI & Society . https://doi.org/10.1007/s00146 -023-01725 -x  \nHardy, M., Sucholutsky, I., Thompson, B., & Griffiths, T. (2023). Large language models meet cognitive science: \nLlms as tools, models, and participants. Proceedings of the annual meeting of the cognitive science \nsociety,  \nHayes, A. (2023). \u201cConversing\u201d with Qualitative Data: Enhancing Qualitative Research through Large Language \nModels (LLMs). PsyArXiv preprint . https://doi.org/10.31235/osf.io/yms8p   \nHendel, R., Geva, M., & Globerson, A. (2023). In -Context Learning Creates Task Vectors. arXiv preprint , \narXiv:2310.15916. https://doi.org/10.48550/arXiv.2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 265,
      "text": ".2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440. https://doi.org/10.1007/s10608 -\n012-9476 -1  \nHoltzman, A., West, P., & Zettlemoyer, L. (2023). Generative Models as a Complex Systems Science: How can \nwe make sense of large language model behavior? arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.00189   \nHothersall, D., & Lovett, B. J. (2022). History of psychology . Cambridge University Press.  \nHuang, J., & Chang, K. C. -C. (2022). Towards Reasoning in Large Language Models: A Survey. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10403   \nHutson, M. (2023). Doing research with human subjects is costly and cumbersome.Can AI chatbots replace them? \nScience , 381(6654), 121 -123. https://doi.org/10.1126/science.adj6791   \nJin, C., Zhang, S., Shu, T., & Cui, Z. (2023). The Cultural Psychology of Large Language Models: Is ChatGPT a \nHolistic or Analytic Thinker? arXiv preprint . https://doi.org/10.48550/arXiv.2308.14242   \nJungherr, A. (2023). Using ChatGPT and Other Large Language Model (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 266,
      "text": "odel (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024). Exploring large language models as an integrated tool \nfor learning, teaching, and research through the Fogg Behavior Model: a comprehensive mixed -methods \nanalysis. Cogent Engineering , 11(1), 2353494.  \nKahneman, D. (2011). Thinking, fast and slow. Farrar, Straus and Giroux .  \nKasneci, E., Sessler, K., K\u00fcchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., \nG\u00fcnnemann, S., H\u00fcllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, \nO., Sailer, M., Schmidt, A., Seidel, T.,\u2026Kasn eci, G. (2023). ChatGPT for good? On opportunities and \nchallenges of large language models for education. Learning and Individual Differences , 103. \nhttps://doi.org/10.1016/j.lindif.2023.102274   \nKe, L., Zhang, G., He, J., Li, Y., Li, Y., Liu, X., & Fang, P. (2023). Pilot Selection in the Era of Virtual Reality: \nAlgorithms for Accurate and Interpretable Machine Learning Models. Aerospace , 10(5). \nhttps://doi.org/10.3390/aerospace10050394   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings of the National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 267,
      "text": "National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10.48550/arXiv.2303.15727   \nLee, B. C., & Chung, J. (2024). An empirical investigation of the impact of ChatGPT on creativity. Nature Human \nBehaviour , 8(10), 1906 -1914.  \nLi, J., Tang, T., Zhao, W. X., Nie, J. -Y., & Wen, J. -R. (2022). Pretrained Language Models for Text Generation: A \nSurvey. arXiv preprint , arXiv:2201.05273. https://doi.org/10.48550/arXiv.2201.05273   \nLi, M., Enkhtur, A., Cheng, F., & Yamamoto, B. A. (2023). Ethical implications of ChatGPT in higher education: \nA scoping review. arXiv preprint . https://doi.org/10.48550/arXiv.2311.14378   \nLi, T., Lu, J., Chu, C., Zeng, T., Zheng, Y., Li, M., Huang, H., Wu, B., Liu, Z., & Ma, K. (2024). Scisafeeval: a \ncomprehensive benchmark for safety alignment of large language models in scientific tasks. arXiv \npreprint arXiv:2410.03769 .  \nLi, X., Li, Y., Liu, L., Bing, L., & Joty, S. (2022). Does GPT -3 Demonstrate Psychopathy? Evaluating Large \nLanguage Models from a Psychological Perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10529   \nLiu, J. M., Li, D., Cao, H., Ren, T., Liao, Z., & Wu, J. (2023). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 268,
      "text": "3). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre -train, Prompt, and Predict: A Systematic \nSurvey of Prompting Methods in Natural Language Processing. ACM Computing Surveys , 55(9), 1 -35. \nhttps://doi.org/10.1145/3560815   \nLiu, X., Ji, K., Fu, Y., Tam, W., Du, Z., Yang, Z., & Tang, J. (2022). P -Tuning: Prompt Tuning Can Be Comparable \nto Fine -tuning Across Scales and Tasks. Proceedings of the 60th Annual Meeting of the Association for \nComputational Linguistics (Volume 2: Short Papers), Dublin, Ireland.  \nLiu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., Wu, Z., Zhao, L., Zhu, D., Li, \nX., Qiang, N., Shen, D., Liu, T., & Ge, B. (2023). Summary of ChatGPT -Related research and perspective \ntowards the future of large language models. Meta -Radiology , 1(2). \nhttps://doi.org/10.1016/j.metrad.2023.100017   \nLoconte, R., Orr\u00f9, G., Tribastone, M., Pietrini, P., & Sartori, G. (2023). Challenging ChatGPT's \"intelligence\" \nwith human tools: A Neuropsychological Investigation on Prefrontal Functioning of a Large Language \nModel. SSRN preprint . https://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 269,
      "text": "ttps://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI. Proceedings of the 2024 ACM Conference on \nInternational Computing Education Research -Volume 1,  \nLuo, X., Chen, F., Zhu, D., Wang, L., Wang, Z., Liu, H., Lyu, M., Wang, Y., Wang, Q., & Chen, Y. (2024). Potential \nRoles of Large Language Models in the Production of Systematic Reviews and Meta -Analyses. Journal \nof Medical Internet Research , 26, e56780.  \nMachin, M. A., Machin, T. M., & Gasson, N. (2024). Comparing ChatGPT With Experts\u2019 Responses to Scenarios \nthat Assess Psychological Literacy. Psychology Learning & Teaching , 14757257241241592.  \nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., & Fedorenko, E. (2023). \nDissociating language and thought in large language models: a cognitive perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2301.06627   \nMarjieh, R., Sucholutsky, I., Rijn, P. v., Jacoby, N., & Griffiths, T. L. (2023). Large language models predict human \nsensory judgments across six modalities. arXiv preprint . https://doi.org/10.48550/arXiv.2302.01308   \nMichelson, M., & Reuter, K. (2019). The significant cost of systematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 270,
      "text": "ematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi.org/10.1016/j.conctc.2019.100443   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022). Who is GPT -3? An Exploration of Personality, Values and \nDemographics. arXiv preprint . https://doi.org/10.48550/arXiv.2209.14338   \nMitchell, M. (2023). AI's challenge of understanding the world. Science , 382(6671). \nhttps://doi.org/10.1126/science.adm8175   \nNazario -Johnson, L., Zaki, H. A., & Tung, G. A. (2023). Use of large language models to predict neuroimaging. \nJournal of the American College of Radiology , 20(10), 1004 -1009. \nhttps://doi.org/10.1016/j.jacr.2023.06.008   \nNewell, A. (1990). Unified theories of cognition . Harvard University Press.  \nNisbett, R. E., Peng, K., Choi, I., & Norenzayan, A. (2001). Culture and systems of thought: holistic versus \nanalytic cognition. Psychological review , 108(2), 291 -310. https://doi.org/10.1037//0033 -\n295X.108.2.291   \nNoy, S., & Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. \nScience , 381(6654), 187 -192.  \nOpenAI. (2023). GPT -4 Technical Report. arXiv preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 271,
      "text": "preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT. Frontiers in Artificial Intelligence , 6, 1199350. \nhttps://doi.org/10.3389/frai.2023.1199350   \nPal, R., Garg, H., Patel, S., & Sethi, T. (2023). Bias Amplification in Intersectional Subpopulations for Clinical \nPhenotyping by Large Language Models. medRxiv preprint . \nhttps://doi.org/10.1101/2023.03.22.23287585   \nPark, B., & Judd, C. M. (2005). Rethinking the Link Between Categorization and Prejudice Within the Social \nCognition Perspective. Personality and Social Psychology Review , 9(2), 108 -130. \nhttps://doi.org/10.1207/s15327957pspr0902_2   \nPark, J. S., Popowski, L., Cai, C., Morris, M. R., Liang, P., & Bernstein, M. S. (2022). Social simulacra: Creating \npopulated prototypes for social computing systems. Proceedings of the 35th Annual ACM Symposium \non User Interface Software and Technology,  \nPark, P. S., Schoenegger, P., & Zhu, C. (2024). Diminished diversity -of-thought in a standard large language model. \nBehavior Research Methods , 1-17.  \nPark, Y. J., Kaplan, D., Ren, Z., Hsu, C. -W., Li, C., Xu, H., Li, S., & Li, J. (2024). Can ChatGPT be used to \ngenerate scientific hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 272,
      "text": "ic hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi.org/10.1101/2023.07.17.549421   \nPeng, Y., Han, J., Zhang, Z., Fan, L., Liu, T., Qi, S., Feng, X., Ma, Y., Wang, Y., & Zhu, S. -C. (2023). The Tong \nTest: Evaluating Artificial General Intelligence Through Dynamic Embodied Physical and Social \nInteractions. Engineering . https://doi.org/10.1016/j.eng.2023.07.006   \nPeters, H., & Matz, S. (2023). Large Language Models Can Infer Psychological Dispositions of Social Media \nUsers. arXiv preprint . https://doi.org/10.48550/arXiv.2309.08631   \nPorsdam Mann, S., Vazirani, A. A., Aboy, M., Earp, B. D., Minssen, T., Cohen, I. G., & Savulescu, J. (2024). \nGuidelines for ethical use and acknowledgement of large language models in academic writing. Nature \nMachine Intelligence , 1-3. \nQureshi, R., Shaughnessy, D., Gill, K. A. R., Robinson, K. A., Li, T., & Agai, E. (2023). Are ChatGPT and large \nlanguage models \"the answer\" to bringing us closer to systematic review automation? Systematic Reviews , \n12(1), 72. https://doi.org/10.1186/s13643 -023-02243 -z  \nRane, N., Choudhary, S., & Rane, J. (2024). Gemini versus ChatGPT: applications, performance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 273,
      "text": "rformance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R., Robertson, C., & Bavel, J. J. V. (2023). GPT is an effective \ntool for multilingual psychological text analysis. PsyArXiv preprint . https://doi.org/10.31234/osf.io/sekf5   \nSalah, M., Al Halbusi, H., & Abdelfattah, F. (2023). May the force of text data analysis be with you: Unleashing \nthe power of generative AI for social psychology research. Computers in Human Behavior: Artificial \nHumans , 1(2). https://doi.org/10.1016/j.chbah.2023.100006   \nSallam, M. (2023). ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the \nPromising Perspectives and Valid Concerns. Healthcare (Basel) , 11(6). \nhttps://doi.org/10.3390/healthcare11060887   \nSap, M., LeBras, R., Fried, D., & Choi, Y. (2022). Neural Theory -of-Mind? On the Limits of Social Intelligence \nin Large LMs. arXiv preprint . https://doi.org/10.48550/arXiv.2210.13312   \nSartori, G., & Orr\u00f9, G. (2023). Language models and psychological sciences. Frontiers in Psychology , 14. \nhttps://doi.org/10.3389/fpsyg.2023.1279317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 274,
      "text": "9317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023). Clinical science and practice in the age of large language models and \ngenerative artificial intelligence. Journal of Consulting and Clinical Psychology , 91(10), 559 -561. \nhttps://doi.org/10.1037/ccp0000848   \nSeals, S. M., & Shalin, V. L. (2023). Long -form analogies generated by chatGPT lack human -like psycholinguistic \nproperties. arXiv preprint . https://doi.org/10.48550/arxiv.2306.04537   \nSejnowski, T. (2022). Large Language Models and the Reverse Turing Test. arXiv preprint . \nhttps://doi.org/10.48550/arxiv.2207.14382   \nSha, H., Mu, Y., Jiang, Y., Chen, L., Xu, C., Luo, P., Eben Li, S., Tomizuka, M., Zhan, W., & Ding, M. (2023). \nLanguageMPC : Large Language Models as Decision Makers for Autonomous Driving. arXiv preprint , \narXiv:2310.03026. https://doi.org/10.48550/arXiv.2310.03026   \nSharma, A., Lin, I. W., Miner, A. S., Atkins, D. C., & Althoff, T. (2023). Human \u2013AI collaboration enables more \nempathic conversations in text -based peer -to-peer mental health support. Nature Machine Intelligence , \n5(1), 46 -57. https://doi.org/10.1038/s42256 -022-00593 -2  \nSimon, H. A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 275,
      "text": "A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K. (2023). Leveraging Cognitive Science for Testing Large Language \nModels. 2023 IEEE International Conference On Artificial Intelligence Testing (AITest),  \nStade, E. C., Stirman, S. W., Ungar, L., Boland, C. L., Schwartz, H. A., Yaden, D. B., Sedoc, J., Derubeis, R. J., \nWiller, R., & Eichstaedt, J. C. (2023). Large Language Models Could Change the Future of Behavioral \nHealthcare: A Proposal for Responsible De velopment and Evaluation. PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/cuzvr   \nStella, M., Hills, T. T., & Kenett, Y. N. (2023). Using cognitive psychology to understand GPT -like models needs \nto extend beyond human biases. Proceedings of the National Academy of Sciences of the United States \nof America , 120(43), e2312911120. https://doi.org/10.1073/pnas.2312911120   \nStevenson, C., Smal, I., Baas, M., Grasman, R., & Maas, H. v. d. (2022). Putting GPT -3's Creativity to the \n(Alternative Uses) Test. arXiv preprint . https://doi.org/10.48550/arXiv.2206.08932   \nStojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 103,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 276,
      "text": "knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022). AI bot ChatGPT writes smart essays \u2014 should professors worry? Nature . \nhttps://doi.org/10.1038/d41586 -022-04397 -7  \nSufyan, N. S., Fadhel, F. H., Alkhathami, S. S., & Mukhadi, J. Y. (2024). Artificial intelligence and social \nintelligence: preliminary comparison study between AI models and psychologists. Frontiers in \nPsychology , 15, 1353022.  \nSuri, G., Slater, L. R., Ziaee, A., & Nguyen, M. (2024). Do large language models show decision heuristics similar \nto humans? A case study using GPT -3.5. Journal of Experimental Psychology: General .  \nTajfel, H. (1982). Social psychology of intergroup relations. Annual Review of Psychology , 33(1), 1 -39.  \nTalboy, A. N., & Fuller, E. (2023). Challenging the appearance of machine intelligence: Cognitive bias in LLMs. \narXiv preprint . https://doi.org/10.48550/arXiv.2304.01358   \nTamkin, A., Brundage, M., Clark, J., & Ganguli, D. (2021). Understanding the Capabilities, Limitations, and \nSocietal Impact of Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2102.02503   \nThirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 104,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 277,
      "text": "ovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K., Huang, Z., Zhao, Y., & Peng, K. (2024). Automating psychological hypothesis generation with \nAI: when large language models meet causal graph. Humanities and Social Sciences Communications , \n11(1), 896. https://doi.org/10.1057/s41599 -024-03407 -5  \nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., & \nBhosale, S. (2023). Llama 2: Open foundation and fine -tuned chat models. arXiv preprint \narXiv:2307.09288 .  \nTrott, S., Jones, C., Chang, T., Michaelov, J., & Bergen, B. (2023). Do large language models know what humans \nknow? Cognitive Science , 47(7), e13309.  \nVan Dis, E. A., Bollen, J., Zuidema, W., van Rooij, R., & Bockting, C. L. (2023). ChatGPT: five priorities for \nresearch. Nature , 614(7947), 224 -226. https://doi.org/10.1038/d41586 -023-00288 -7  \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin , I. (2017). \nAttention is all you need. Advances in neural information processing systems , 30.  \nVzorinab, G. D., Bukinichac, A. M., Sedykha, A. V., Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 105,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 278,
      "text": "Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., Chandak, P., Liu, S., Van Katwyk, P., Deac, A., Anandkumar, \nA., Bergen, K., Gomes, C. P., Ho, S., Kohli, P., Lasenby, J., Leskovec, J., Liu, T. Y., Manrai, A.,\u2026Zitnik, \nM. (2023). Scientific discovery i n the age of artificial intelligence. Nature , 620(7972), 47 -60. \nhttps://doi.org/10.1038/s41586 -023-06221 -2  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language models. Nature \nHuman Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -023-01659 -w  \nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, \nD., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J., & Fedus, W. (2022). Emergent Abilities \nof Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2206.07682   \nYang, F., Chen, Z., Jiang, Z., Cho, E., Huang, X., & Lu, Y. (2023). Palr: Personalization aware llms for \nrecommendation. arXiv preprint arXiv:2305.07622 .  \nYildirim, I., & Paul, L. A. (2023). From task structures to world models: What do LLMs know? arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 106,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 279,
      "text": "arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing. PsyArXiv preprint . https://doi.org/10.31234/osf.io/9ymfz   \nZeiler, M. (2014). Visualizing and Understanding Convolutional Networks. European conference on computer \nvision/arXiv,  \nZhang, J., Xu, X., & Deng, S. (2023). Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology \nView. arXiv preprint , arXiv:2310.02124. https://doi.org/10.48550/arXiv.2310.02124   \nZhang, Z., Chadwick, G., McNally, H., Zhao, Y., & Mullins, R. (2023). Llm4dv: Using large language models for \nhardware test stimuli generation. arXiv preprint arXiv:2310.04535 .  \nZhao, Y., Huang, Z., Seligman, M., & Peng, K. (2024). Risk and prosocial behavioural cues elicit human -like \nresponse patterns from AI chatbots. Scientific Reports , 14(1), 7095.  \nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I., & Pan, S. (2023). Large Language Models \nfor Scientific Synthesis, Inference and Explanation. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2310.07984   \nZhong, Y., Chen, Y. J., Zhou, Y., Lyu, Y. A., Yin, J. J., & Gao, Y. J. (2023). The Artificial intelligence large language \nmodels and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 107,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 280,
      "text": "els and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z., Zhao, G., Zhang, Z., Mao, Q., Wang, S., & Chen, E. \n(2023). Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective. arXiv \npreprint . https://doi.org/10.48550/arXiv.2306.10512   \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 108,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 281,
      "text": "s, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 282,
      "text": "Exploring the Frontiers of LLMs in Psychological Applications: A \nComprehensive Review  \n \nLuoma Ke1, Song Tong1,2*, Peng Cheng3, Kaiping Peng1,* \n1. Department of Psychological and Cognitive Sciences , Tsinghua University  \n2. Department of Psychology, Beijing Normal University  \n3. School of Social Science, Tsinghua University  \n* Corresponding authors: tong.song.53w@kyoto -u.jp; pengkp@tsinghua,edu.cn  \n \nAbstract  \nThis review explores the frontiers of large language models (LLMs) in psychological applications. \nPsychology has undergone several theoretical changes, and the current use of artificial intelligence (AI) and \nmachine learning, particularly LLMs, promises to  open up new research directions. We aim to provide a \ndetailed exploration of how LLMs are transforming psychological research. We discuss the impact of LLMs \nacross various branches of psychology \u2014including cognitive and behavioral, clinical and counseling,  \neducational and developmental, and social and cultural psychology \u2014highlighting their ability to model \npatterns, cognition, and behavior similar to those observed in humans. Furthermore, we explore the ability \nof such models to generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 283,
      "text": "generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology. We emphasize the importance of addressing technical and ethical challenges, including data \nprivacy, the ethics of using LLMs in psychological research, and the need for a deeper understanding of \nthese models\u2019 limitations. Researchers should use LLMs responsibly in psychological studies, adhering to \nethical standards and considering the pote ntial consequences of deploying these technologies in sensitive \nareas. Overall, this review provides a comprehensive overview of the current state of LLMs in psychology, \nexploring the potential benefits and challenges. We hope it can serve as a call to act ion for researchers to \nresponsibly leverage LLMs\u2019 advantages while addressing the associated risks.  \nKeywords large language models (LLMs); machine learning; artificial intelligence (AI); psychology; \nresearch methods  \n \n1. Introduction  \nArtificial intelligence (AI) has a history spanning nearly seven decades, beginning with the 1956 \nDartmouth Conference. The field has recently been revolutionized with the advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 284,
      "text": "he advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g., solving difficult tasks in math, coding, vision, \nmedicine, law, and psychology) (Bubeck et al., 2023) , exemplifying the concept of \u201cAI for science\u201d  (Wang \net al., 2023) . LLMs mark a critical juncture in the evolution of machine learning and AI, propelled by their \nexpansive size and sophisticated neural architectures that incorporate attention mechanisms  (V aswani et al., \n2017) . These models incorporate cognitive principles  (Binz & Schulz, 2023a)  and exhibit emergent \nproperties comparable to those seen in complex physical systems  (Wei et al., 2022) . This has enhanced their \nability to process and represent concepts and high -level semantics (J. Li et al., 2022)  while also deepening \nour insights into human cognitive processes  (Sejnowski, 2022) . In psychological applications, these \ndevelopments are reshaping interactions among data, language, and the environment  (De Bot et al., 2007; \nDemszky et al., 2023) , contributing significantly to various fields, including clinical  (Thirunavukarasu et al., \n2023) , developmental (Frank, 2023; Hagendorff, 2023) , and social psychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 285,
      "text": "sychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis.  \n1.1.  The LLM concept: From machine learning to capability emergence  \nGenerative AI evolved from advances in pattern  recognition capability. While convolutional neural \nnetworks (CNNs) excelled at recognizing objects and concepts, the next challenge was to use this recognition \ncapability for a generation. For example, if a CNN can identify \u201cage\u201d in portraits, we can use that \nunderstanding to modify \u201cage\u201d in any portrait. This generative approach first succeeded in computer vision \nthrough models such as generative adversarial networks (Goodfellow et al., 2020)  and deconvolution (Zeiler, \n2014) , which could create realistic images based on learned patterns. The same generative principles were \nthen applied to language, leading to LLMs that could generate contextually relevant text. LLMs represent a \nparticularly significant leap in the capabilitie s of generative AI. These models are designed to process natural \nlanguage text and generate contextually relevant text.  LLMs like GPT -4, LLaMA,  Claude, and  Gemini \nleverage the transformer architecture (V aswani et al., 2017), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 286,
      "text": "17), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks. For instance, LLaMA focuses on efficient training processes \n(Touvron et al., 2023) , Claude emphasizes safety and alignment (Li et al., 2024) , and Gemini integrates \nadvanced reasoning capabilities (Rane et al., 2024) . LLaMA \u2019s open -source nature allows local deployment \nand efficient training, making it suitable for psychological studies needing rapid iteration or customization, \nsuch as behavioral modeling ( Binz and Schulz (2023a) . Claude, designed for safety and alignment, is less \ncommonly used in psychology research and more oriented toward knowledge -based tasks (Li et al., 2024). \nGPT-4, with its large -scale parameters and broad training data, supports a wide range of tasks, including \ncognitive simulations and clinical assessments.  These differences guide model selection based on research \nneeds like accessibility, task specificity, or data scale.  \nWhile these models highlight the versatility of LLMs, it is essential to distinguish between specific \nproducts designed for particular interactions, such as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 287,
      "text": "as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction. This range of applications demonstrates that LLMs\u2019 capabilities are \nemergent, manifesting new abilities as the model size increases. Performance improvements on  log-log \nscales sometimes experience \u201cbreaks\u201d where unexpected capabilities emerge from complex interactions \nwithin the models (Wei et al., 2022) . \nAt the heart of LLMs is the transformer architecture, a deep neural network with an attention mechanism \nthat efficiently processes sequential data in parallel (V aswani et al., 2017) ; this works in a manner somewhat \nsimilar to human brain functions. This architecture has revolutionized the field of natural language \nprocessing. The self -attention mechanism of the transformer architecture captures contextual relationships \nin textual dat a, allowing for more sophisticated language understanding. Notably, the \u201clarge\u201d in LLM refers \nto the many parameters and massive amounts of training data used to fine -tune these models, typically \nbillions of parameters and terabytes of text (Binz & Schulz, 2023b) , in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 288,
      "text": "in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages. (1) Pretraining: LLMs are pretrained on large amounts of textual data to \nlearn intricate linguistic, syntactic, and textua l structures, where the model learns to predict the next token \nthrough unsupervised learning, resulting in a base model that captures the statistical patterns of language (P . \nLiu et al., 2023) . (2) Alignment: Supervised learning is used to create a foundation model that can better \ninteract with users in the intended ways, which typically involves instruction tuning and reinforcement \nlearning based on human feedback. After the foundation model i s available, domain -specific fine -tuning can \nadapt the model for particular applications (Liu et al., 2022) . This fine -tuning process ensures the model can \ngenerate contextually relevant responses and engage in meaningful conversations or tasks. Through these \nstages of development, LLMs demonstrate increasingly sophisticated text -generation capabilities, includi ng \nresponse generation, content summarization, translation, and compositional text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 289,
      "text": "nal text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models. Finally, LLMs exhibit \u201cobserved capability emergence\u201d \nwhen integrated into various applications and systems, in addition to performing tasks that require a deep \nunderstanding of language and context, thus often achieving human -like or superhuman performance in \nspecific experimental tasks, such as analogical reasoning (Webb et al., 2023) , creativity (Stevenson et al., \n2022) , and emotion recognition (Patel & Fan, 2023) . \nTherefore, LLMs can provide valuable insights into how such technologies can simulate or augment \nprocesses traditionally associated with human cognition. Specifically, LLMs maintain a balance between \nlogical processing and the use of cognitive shortcuts (heuristics), and they adapt their reas oning strategies to \noptimize between accuracy and effort. This aligns with the principles of resource -rational human cognition, \nas discussed in dual -process theory (Mukherjee & Chang, 2024). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 290,
      "text": "24). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) . These parallels allow for the exploration of AI applications in \nareas such as cognitive psychology (Sartori & Orr\u00f9, 2023) , language acquisition (Jungherr, 2023) , and even \nmental health (Lamichhane, 2023) . Moreover, the study of LLMs contributes to our understanding of the \nhuman mind, offering a computational perspective on language processing, decision -making (Sha et al., \n2023) , and learning mechanisms (Hendel et al., 2023) . The fusion of such disciplines could drive \nadvancements in AI and provide a computational framework for investigating processes related to human \ncognition.  \n1.2.  Psychology and AI  \nPsychology, as a science that explores the human mind and behavior, has undergone significant \ntheoretical changes since the late nineteenth century, with psychoanalysis and behaviorism extending to \ncognitive psychology (Hothersall & Lovett, 2022) . This history marks a shift in the focus of psychology \nresearch, reflecting the academic trend of moving from observing behavioral manifestations to exploring in -\ndepth psychological connotations. Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 291,
      "text": ". Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology. In clinical and \ncounseling psychology, research on cognitive psychology supports diagnosing and treating psychological \ndisorders. It deepens our understanding of the psycho logical mechanisms underlying emotions, stress, and \nhuman behavior. Psychotherapies such as cognitive -behavioral therapy (Hofmann et al., 2012)  and \npsychodynamic therapy have become essential tools for promoting mental health and emotional regulation. \nIn educational and developmental psychology, the development of cognitive psychology has fostered a \ndeeper understanding of the roles of perceptual  and affective factors in learning processes (Glaser, 1984) , \nwhich has led to innovations in teaching methods and learning strategies. In social and cultural psychology, \ncognitive psychology research helps explain individuals\u2019 behaviors and mental processes in different social \nand cultural contexts, exploring how cultural differences affect cognitive patterns, values, and behavioral \nnorms, especially in the context of globalization, interaction, and integration. In social psychology, \nmeanwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 292,
      "text": "nwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) . \nAI is becoming an increasingly influential tool in psycho -cognitive research. Simon (1979)  was among \nthe first to recognize the potential of computational models to simulate aspects of human cognitive processes. \nCurrently, LLMs can process and generate human -like texts and perform certain tasks in a manner similar to \nhuman cognition (Bubeck et al., 2023) . LLMs also offer a unique computational perspective for the study of \nhuman cognition. For example, GPT -3 can solve vignette -based tasks similar to or better than human subjects \nand can perform rational decision -making based on descriptions, outperforming humans in the multiarmed \nbandit task (Binz & Schulz, 2023b) . Furthermore, after extensive testing, GPT -3 is able to solve complex \nanalogical problems at levels comparable to human performance, and analogical reasoning is an essential \nhallmark of human intelligence (Webb et al., 2023) . Moreover, fine -tuning across multiple tasks can allow \nLLMs to predict human behavior in previously unseen tasks \u2014that is, LLMs can be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 293,
      "text": "n be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general.  \nNewell (1990)  offered a structured framework for analyzing human behavior, categorizing cognitive and \nbehavioral processes into four distinct layers based on their time scales (Fig. 1a). At the biological level, the \nfocus is on physiological and neural processes occurr ing at rapid time scales, ranging from milliseconds to \none second. This level can include neural responses and sensory processing, which form the foundation of \nhuman cognition. The cognitive level pertains to mechanisms such as attention, perception, and s hort-term \nmemory, which operate at intermediate time scales, typically between one second and one minute. These \nprocesses enable fundamental cognitive functions. At the rational level, the framework considers more \ncomplex cognitive activities such as probl em-solving, planning, and decision -making. Such activities occur \nover longer time scales, spanning several minutes to a few hours, and involve sustained cognitive \nengagement. Finally, the social level considers behaviors shaped by social interaction and cultural influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 294,
      "text": "influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition. It underscores the multifaceted \nnature of human behavior, highlighting the relationship between rapid physiological p rocesses and the more \nprolonged, socially influenced aspects of human cognition.  Figure 1 integrates this framework by mapping \npsychological domains (e.g., cognitive, social) onto these timescales, demonstrating LLMs \u2019 ability to \nsimulate behaviors \u2014from short -term processes like memory retrieval to long -term phenomena like cultural \ntrends. Emergent properties (e.g., cognitive simulation) connect these domains to practical research tools \n(e.g., stimuli generation), with bidirectional influence refinin g both a pplications and properties.  \nTherefore, by analyzing LLM application across these four levels (Fig. 1a), it is possible to further \nexplore their potential for modeling and studying human cognition and behavior (Fig. 1b), as well as their \nunique role in psycho -cognitive processes. Rece nt research has revealed significant advancements in LLMs\u2019 \nability to perform complex human -like cognitive and social tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 295,
      "text": "cial tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al. (2023)  demonstrated LLMs\u2019 proficiency in simulating human social \ninteractions and perceptual processing, respectively. Orru et al. (2023)  and (Webb et al., 2023)  highlighted \nLLMs\u2019 capabilities in complex problem -solving and reasoning while Hagendorff et al. (2023)  focused on \ndecision -making processes. Stevenson et al. (2022)  documented LLMs\u2019 potential for creativity, and Patel \nand Fan (2023)  demonstrated their emotion -recognition abilities. Taken together, such findings highlight the \nexpanding role of LLMs in representing and augmenting human cognitive and social functions, marking \nsignificant progress in AI research.   \nAs general -purpose cognitive models (Binz & Schulz, 2023a) , LLMs offer new perspectives and \napproaches for research in the fields of cognitive and behavioral psychology, clinical and counseling \npsychology, educational and developmental psychology, and social and cultural psychology, at different time \nscales of hu man behavior (Fig. 1a).  LLMs can also be used as research aids (Fig. 1c) to help psychologists \nwith everything from literature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 296,
      "text": "ature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al., 2023)  to promote scholarly communication: academic writing (Dergaa et al., 2023; Stokel -\nWalker, 2022)  or peer review (Chiang & Lee, 2023; Van Dis et al., 2023) . Thus, LLMs can potentially \nbecome research assistants for psychologists, helping them improve their research efficiency.  \n \nFig. 1 LLMs in Psychological Research Across Timescales. (a) Domains (e.g., Cognitive & Behavioral, \nSocial & Cultural) mapped to timescales of behavior; (b) Emergent properties (e.g., cognitive simulation) \nenabling domain -specific modeling; (c) LLMs as research tools (e.g., stimuli generation). Double -sided \narrows indicate that emergent properties bridge domains and tools, supporting applications (e.g., memory  \nretrieval) and refining properties through usage . \n \n1.3.  Objectives and significance of the present review  \nThis review aims to provide a comprehensive analysis of the applications and effects of LLMs in \npsychological research. To ensure a systematic and rigorous review, we established specific inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 297,
      "text": "ic inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science. Our initial keyword selection \u2014\n\u201cGPT-3\u201d, \u201cChatGPT \u201d, \u201cGPT-4\u201d, \u201clarge language models \u201d, and \u201cpsychology \u201d\u2014was determined during the \nliterature collection in October 2023, when GPT -based models were predominant in psychological research \n(e.g., Binz & Schulz, 2023b; Bubeck et al., 2023). At the time, open -source models like LLaMA (Touvron \net al., 2023) and propr ietary models like Claude had limited psychology -specific applications. To maintain \na focused scope, we did not retrospectively expand search terms but included diverse LLMs via manual \nscreening. To reflect recent developments, an updated search incorporat ed studies from 2024.  \nTo bolster the integrity of our data extraction process, two interdisciplinary researchers (male, 33 and \n41 years) specializing in information science and psychology conducted the encoding and screening. Our \n\ninclusion criteria required the selected studies to (1) explore the application or analysis of LLMs in \npsychological contexts; (2) be peer -reviewed journal articles or high -impact conference proceedings; and (3) \npresent empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 298,
      "text": "present empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature. Articles without a \npsychological focus or those addressing non -LLM -based AI systems were excluded.  The study selection \ninvolved screening 191 identified studies, analyzing 100 full -text articles, and ultimately including 4 7 studies \ncategorized into various psychological subfields. Each of these studies met stringent inclusion criteria, \nensuring they contributed meaningfully to our understanding of LLMs in psychological research.  \nIn this review, we systematically examine the use of LLMs in various psychological domains by \nanalyzing their application at different behavioral time scales. The rest of the paper is structured as follows. \nIn section 2, we explore LLMs in cognitive and be havioral psychology. In section 3, the roles of LLMs in \nclinical and counseling psychology are discussed. Subsequently, educational and developmental psychology \nare addressed in section 4, followed by social and cultural psychology in section 5, outlining LLMs\u2019 \ncontributions to each area. While psychological techniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 299,
      "text": "hniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research. The primary focus of this review is how LLMs facilitate and advance \npsychological research across these domains. For a deeper understanding of the effect of LLMs on \npsychological research, an overview of LLMs\u2019 potential as tools for scientific research is given in section 6. \nIn section 7, the challenges and future research directions with regard to applying LLMs to psychological \ncontexts are provided. Finally, conclusions are presented in section 8, with a summary of LLMs\u2019 applications \nin psychology and rec ommendations for future work. Importantly, we propose strategies for integrating \nLLMs into psychological research and provide insights into interpreting such models from a psychological \nstandpoint, contributing to their safety and interpretability.  \n \n2. LLMs in cognitive and behavioral psychology  \nWithin the multilevel time scales of human behavior (Newell, 1990) , cognitive and behavioral \npsychology has primarily focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 300,
      "text": "focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning. Cognitive  and behavioral psychology typically uses experimental methods to study \nthese cognitive processes, controlling and observing behaviors and responses under specific conditions. The \nrecent emergence of LLMs has reinvigorated the discussion on whether such models might exhibit patterns \nresembling human cognitive processes; if so,  it may be possible to study the \u201ccognitive processes\u201d of LLMs, \nwhich could provide valuable insights into human cognitive phenomena and serve as a valuable addition to \nexisting research methods in cognitive psychology. The foundational technology underlyi ng large language \nmodels (LLMs) is the generative pre -trained transformer (GPT) architecture, which employs deep neural \nnetworks to process and generate human -like text. GPT models function through mechanisms, such as \nattention mechanisms and token predict ion, enabling them to capture complex linguistic patterns and \ngenerate contextually coherent outputs. These foundational technologies have transformed natural language \nprocessing (NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 301,
      "text": "(NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) . The \nincorporation of such architectures into psychological research has initiated discussions regarding their \npotential to simulate cognitive phenomena.  \nBinz and Schulz (2023a)  found that fine -tuning multiple tasks enabled an LLM to predict human \nbehavior in previously unseen tasks, suggesting that LLMs can be adapted to become generalist cognitive \nmodels. In another study, the same authors tested GPT -3 using tools from cognitiv e psychology and showed \nthat it made better decisions than humans and outperformed them in the multiarmed bandit task (Binz & \nSchulz, 2023b) . Other studies have shown that LLMs can display perceptual judgment (Marjieh et al., 2023) , \nreasoning (Webb et al., 2023) , and decision -making abilities (Hagendorff et al., 2023) , as well as creativity \n(Stevenson et al., 2022)  and problem -solving (Orru et al., 2023) . One study found that an LLM had the \nmental ability of a seven -year-old child based on a false -belief task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 302,
      "text": "ef task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al. (2023)  designed a series of semantic illusion and cognitive \nreflection tests designed to elicit intuitive but erroneous responses (these are conventionally used to study \nhuman reasoning and decision -making) and then ran the tests for LLMs. They conducted an anal ysis of \nmodel performance on a Cognitive Reflection Test (CRT) task and a semantic illusion task to elucidate their \ncognitive processes, drawing upon System 1 and System 2 thinking, as conceptualized by Daniel Kahneman \nin his seminal work Thinking, Fast, a nd Slow (Kahneman, 2011) , which represent fundamental constructs \nfor understanding human cognitive processes. System 1 refers to intuitive and automatic thinking, whereas \nSystem 2 involves rational, deliberate decision -making processes. This framework provides a theoretical \nbasis for interpreting how LLMs simulate human -like cognitive behaviors during these tasks. They observe \nhow these models show correct responses in these tasks and avoid pitfalls. The performance of the models \nin the CRT task were further evaluated by prev enting them from chain -thinking to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 303,
      "text": "ing to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors. Table 1 provides a summary of the applications of \nLLMs to cognitive and behavioral psychology.  \nTable 1  Applications of large language models (LLMs) in cognitive and behavioral psychology study.  \nReference  Research Question  Research method  Key finding  \n \nHuman -like Cognitive Abilities  \nBinz and \nSchulz \n(2023b)  How does GPT -3 perform on \ncognitive psychology tasks, \nincluding decision -making, \ninformation search, and causal \nreasoning?  GPT-3 was tested using canonical \ncognitive psychology experiments \nand compared to human \nperformance.  GPT-3 excels in decision -making and \nreinforcement learning but struggles with \ntask perturbations, directed exploration, \nand causal reasoning.  \nStevenson et \nal. (2022)  Can GPT -3 generate creative \nsolutions comparable to humans in \nGuilford\u2019s Alternative Uses Test \n(AUT)?  GPT-3\u2019s responses to AUT were \nevaluated for originality, usefulness, \nsurprise, and flexibility, using expert \nratings and semantic distance \nanalysis, and compared with human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 304,
      "text": "th human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal. (2023)  Can LLMs recover perceptual \ninformation from language, and \nhow do they reflect cross -linguistic \nvariations?  GPT-3, GPT -3.5, GPT -4 were tested \non six psychophysical datasets and a \nmultilingual color -naming task to \ncompare their outputs with human \nperceptual data.  LLMs like GPT -4 align closely with \nhuman perceptual data, recover \nrepresentations such as the color wheel, \nand reflect cross -linguistic perceptual \nvariations, demonstrating their ability to \nextract perceptual information from \nlanguage.  \nLoconte et \nal. (2023)  How do various LLMs perform on \nneuropsychological tests assessing \nprefrontal functions compared to \nhuman cognitive abilities?  GPT-3.5, GPT -4,were evaluated on \ntasks related to planning, semantic \nunderstanding, and Theory of Mind.  Findings indicate that GPT -4 generally \nmeets normative human standards, \nwhereas  Claude2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 305,
      "text": "2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal. (2023)  How does GPT -4 perform on \ncognitive psychology tasks \ncompared to prior state -of-the-art \nmodels?  GPT-4 was evaluated on cognitive \npsychology datasets \n(CommonsenseQA, SuperGLUE, \nMATH, HANS) to analyze its \nintegration of cognitive processes \nwith contextual information.  GPT-4 demonstrates high accuracy on \ncognitive psychology tasks, surpassing \nprior models, and showcases significant \npotential to bridge human and machine \nreasoning.  \nHagendorff \n(2024)  Can modern LLMs understand and \napply deception strategies?  Experiments tested LLMs on \ninducing false beliefs, using chain -\nof-thought reasoning, and displaying \nMachiavellian behavior in simple \nand complex deception scenarios.  GPT-4 demonstrates advanced deceptive \nbehavior, succeeding in 99.16% of simple \nand 71.46% of complex scenarios, \nhighlighting the emergence of \nsophisticated deception abilities absent in \nearlier models.  \n \nExperimental Methodologies for Cognitive Research Using LLMs  \nBinz and \nSchulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 306,
      "text": "Schulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors.  Fine-tuned LLaMA outperforms \ntraditional cognitive models, accurately \nmodel individual behavior, and predict \nunseen human responses.  \nDubey et al. \n(2024)  How can generative AI tools be \nutilized to streamline the creation of \nexperimental stimuli in \npsychological research and \ninfluence public attitudes toward \nsustainable policies?  DALL -E 2 was employed to generate \nrealistic visual stimuli of car -free \nurban environments, which were \nthen presented to participants to \nmeasure attitudes toward sustainable \npolicies.  By using DALL -E 2, the study \ndemonstrated that generative AI tools can \nenhance the design process of \nexperimental stimuli, offering greater \ncontrol, diversity, and scalability, thereby \neffectively influencing participants' \nattitudes.  \nNote: The AUT is a psychological test that measures creativity by asking participants to think of as many \nuses as possible for a common object; DALL -E 2 is developed by OpenAI that generates detailed and \nrealistic images from textual descriptions to explore AI's potential in creative fields.  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 307,
      "text": ".  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al. (2024) , for \ninstance, used DALL -E 21 to create realistic visual stimuli depicting car -free urban environments, which \ninfluenced participants\u2019 attitudes toward sustainable policies. Such tools streamline the stimulus design \nprocess by providing control, diversity, and scalability. Similarly, LLMs have been employed in hardware \ntesting to generate tailored stimuli, outperforming traditional methods in specific scenarios (Z. Zhang et al., \n2023) . Charness et al. (2023)  further demonstrated the use of LLMs for enhancing experimental workflows \nby refining task instructions, ensuring consistency, and monitoring participant engagement. By leveraging \ntheir flexibility and scalability, LLMs can provide novel methods for advan cing experimental psychology. \nThese applications facilitate the exploration of complex cognitive phenomena and the development of \ninnovative research designs while also complementing traditional psychological research frameworks \n(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 308,
      "text": "(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3. LLMs in clinical and counseling psychology  \nClinical and counseling psychology focuses on assessing, diagnosing, treating, and preventing mental \nhealth problems. These processes often involve medium - to long -term periods. In the multilevel time scales \nof human behavior (Newell, 1990) , clinical and counseling psychology involves assessing everyday \nbehavioral acts (about a few hours to a day), habitual thinking (about a day to a few months), and \npsychological disorders (a few months to many years), among others (Fig. 1). The application  of LLMs in \nclinical and counseling psychology can be broadly divided into two categories: psychological assessment \nand psychological intervention. Psychological assessment focuses on improving the ecological validity, \nscalability, and accuracy of measurin g mental health states while psychological interventions consider how \nLLMs can be used for scalable and personalized mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 309,
      "text": "d mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) . LLMs are expected to be used in clinical psychology and counseling \n \n1 Note: Although DALL -E 2 is not an LLM, we included this study due to its reliance on Transformer -\nbased semantic understanding, a cornerstone of LLM research, and its demonstrated utility in generating \ncontrolled visual stimuli for psychological experiments.  \n \nbecause they can parse human language and generate human -like responses, categorize text, and flexibly \nadapt conversational styles representing different theoretical orientations (Stade et al., 2023) . This leads to \nthe following question: How do LLMs work in psychotherapy, and can they replace human psychotherapists?  \nAn LLM is a basic generalized model with the ability to learn from small samples (Brown et al., 2020) , \nwhich allows it to quickly become an \u201cexpert\u201d in the clinical and counseling domain with only a small \namount of data to learn from. For example, LLMs trained on clinical content can identify more specific \nfactors of change that can help psychologists und erstand the process of clinical intervention, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 310,
      "text": "on, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al., 2023)  and respond \nappropriately. They can also perform complex mental health evaluations (Patel & Fan, 2023; Schaaff et al., \n2023) , such as suicide risk assessment and schizophrenia prognosis. For example, Elyoseph and Levkovich \n(2024)  found that GPT -4, Google Bard, and Claude produced evaluations consistent with professional \nbenchmarks in treated schizophrenia cases, though GPT -3.5 exhibited overly pessimistic predictions. Other \nresearch has shown that GPT -3.5 excels in clinical psychi atric cases, achieving top grades in diagnosis and \nmanagement across 61% of cases, with only minor discrepancies in more complex scenarios (D\u2019Souza et al., \n2023) . \nIn psychological interventions, LLMs have shown significant potential for delivering scalable and \npersonalized mental health support (Blyler & Seligman, 2023a, 2023b) . For example, Blyler and Seligman \n(2023a) demonstrated that GPT -4 can generate personalized therapeutic strategies by analyzing narrative \nidentities. These strategies were found to be valid and reasonable, highlighting GPT -4\u2019s utility as a supportive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 311,
      "text": "portive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19.6% and significantly \nboosted self -efficacy among users struggling to pro vide support. Furthermore, J. M. Liu et al. (2023)  \nevaluated ChatCounselor, a model trained on a domain -specific dataset of psychologist \u2013client conversations, \nand found it outperformed open -source models, thereby demonstrating the importance of domain -specific \ntraining for improving counseling capabilitie s. Table 2 summarizes the applications of LLMs to clinical and \ncounseling psychology.  \nThe above research cases, which demonstrate LLMs\u2019 ability to provide clinicians with adequate mental \nhealth support (Schueller & Morris, 2023) , hold promise for addressing insufficient capacity in the mental \nhealth care system and offering more individualized treatment services, even potentially fully automating \npsychotherapy in the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 312,
      "text": "the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies . \nReferences  Research question  Research method  Key finding  \n \nPsychological Assessment Using LLMs  \nElyoseph and \nLevkovich \n(2023)  How effective and accurate \nare ChatGPT in assessing \nsuicide risk?  The study evaluated ChatGPT's \nanalysis of a text vignette depicting a \nhypothetical patient with varied \npsychological states, comparing its \nassessments to those of mental health \nprofessionals.  The study found that ChatGPT consistently \nunderestimated suicide risk and mental \nresilience compared to mental health \nprofessionals, suggesting that reliance on \nChatGPT for suicide risk assessment could \nlead to inaccurately low evaluations.  \nElyoseph and \nLevkovich \n(2024)  How do LLMs compare to \nmental health professionals \nin assessing schizophrenia \nprognosis and treatment \noutcomes?  Vignettes were used to compare the \nassessments of four LLMs (GPT -3.5, \nGPT-4, Bard, Claude) against \nprofessional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 313,
      "text": "ional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3.5)  in addressing clinical \npsychiatric cases and \nsupporting mental health \ncare?  ChatGPT was tested on 100 clinical \npsychiatric vignettes, and expert \npsychiatrists graded its responses \nacross 10 categories.  ChatGPT  excelled in management and \ndiagnosis, earning top grades in 61% of cases, \nwith no major errors but minor discrepancies \nin complex cases.  \nSufyan et al. \n(2024)  How do the social \nintelligence (SI) levels of \nLLMs compare to human \npsychologists?  Social intelligence scores of ChatGPT \n(4), Bard, and Bing were compared \nwith 180 counseling psychology \nstudents (bachelor\u2019s and PhD levels) . ChatGPT surpassed all psychologists in \nsocial intelligence, Bing outperformed most \nbachelor\u2019s and some PhDs, while Bard \naligned with bachelor\u2019s students but fell \nbehind PhDs.  \n \nPsychological Interventions with LLMs  \nBlyler and \nSeligman \n(2023a)  Can GPT-4 generate \npersonalized therapeutic \nstrategies based on narrative \nidentity?  GPT-4 analyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 314,
      "text": "nalyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching.  \nBlyler and \nSeligman \n(2023b)  Can GPT-4 generate \naccurate and insightful \npersonal narratives to \nsupport self -discovery in \ntherapy and coaching?  GPT-4 processed 50 stream -of-\nconsciousness thoughts from 26 \nparticipants to create personalized \nnarratives, which participants evaluated \nfor accuracy, surprise, and self -insight.  96% of participants rated the narratives as \naccurate, and 73% reported gaining new self -\ninsights, suggesting GPT-4\u2019s potential for \nenhancing self -discovery in therapeutic \ncontexts.  \nSharma et al. \n(2023)  Can AI enhance empathy in \npeer-to-peer mental health \nsupport?  Tested HAILEY  which based on GPT -\n2, which  offering real -time empathic \nfeedback, in a trial with 300 peer \nsupporters on TalkLife.  HAILEY improved empathy by 19.6% \noverall and 38.9% for those struggling with \nsupport, boosting self -efficacy without \ncreating reliance.  \nJ. M. Liu et al. \n(2023)  How to improve  LLM  in \nproviding mental health \nsupport compared to other \nmodels?  ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 315,
      "text": "ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics.  ChatCounselor outperforms LLaMA, \nChatGLM  and approaches GPT-4\u2019s \nperformance, highlighting the impact of \ndomain -specific training on counseling \ncapabilities.  \n4. LLMs in educational and developmental psychology  \n Educational and developmental psychology is concerned with learning processes, knowledge \naccumulation, skill development, and changes in individual psychology in educational environments. \nEducational and developmental psychology is mainly positioned at th e relatively medium - to long -term level \n(Newell, 1990), reflecting the ongoing learning and development that characterize the educational process. \nA national survey found that only 3 months after the public release of GPT, 40% of US teachers used it \nweekly for lesson planning, highlighting the growing impact of LLMs in education.  \nTable 3 summarizes the applications of LLMs in educational and developmental psychology, which can \nbe broadly divided into two categories: developmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 316,
      "text": "evelopmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g., theory of mind and emotional reasoning) and how such capabilities \nmight advance our understanding of human cognitive and emotional development. Kosinski (2024) , for \ninstance, tested different LLMs in 40 false -belief tasks and found that GPT -4 achieved 75% accuracy, \ncomparable to the performance of a six -year-old child, while older models performed significantly worse. \nVzorinab et al. (2024)  used the Mayer \u2013Salovey \u2013Caruso Emotional Intelligence Test (MSCEIT) to evaluate \nGPT-4\u2019s emotional intelligence. While GPT -4 excelled at understanding and managing emotions, its \nreflective analysis resembled the early developmental stages of human emotional  reasoning.  \nThe study of using LLMs for education and learning applications focuses on leveraging LLMs to address \nchallenges in education, such as providing personalized learning and improving learning motivation. LLMs \nlearn from massive amounts of data taken from boo ks and the Internet (Binz & Schulz, 2023b ) and can be \nused as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 317,
      "text": "ed as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al. (2024) , for \ninstance, found that an AI tutor powered by GPT -3 improved academic performance by up to 15 percentile \npoints through personalized learning strategies. Stojanov (2023)  used the following approach to explore \nGPT\u2019s potential as a learning tool: First, he set learning objectives and had \u201cconversations\u201d with GPT about \nits functionality for 4 hours. For the next 3 hours, he continued the discussion with GPT and watched some \nrelevant videos on YouTube. He experienced positive feedback from his interactions with GPT and found it \nto be a motivating and relevant learning experience.  \n \nTable 3  Applications of LLMs in educational and developmental psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nDevelopmental Research with LLMs  \nKosinski \n(2024)  Can LLMs demonstrate theory \nof mind (ToM) abilities?  Eleven  different  LLMs were tested on 40 \nfalse -belief tasks, requiring success in \neight related scenarios per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 318,
      "text": "os per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal. (2024)  How does GPT -4\u2019s emotional \nintelligence align with \ndevelopmental patterns in \nhuman emotional reasoning?  GPT-4 was evaluated using the Mayer -\nSalovey -Caruso Emotional Intelligence \nTest (MSCEIT) through text -based \nprompts.  GPT-4 excels in understanding and \nmanaging emotions but shows limited \nreflective analysis, resembling early \ndevelopmental stages in human \nemotional reasoning.  \nTrott et al. \n(2023)  How does exposure to language \ninfluence the development of \ntheory of mind in humans and \nAI? A linguistic False Belief Task was \npresented to humans and GPT -3 to assess \nbelief attribution abilities.  GPT-3\u2019s partial success suggests that \nwhile language exposure contributes to \nbelief reasoning, other developmental \nmechanisms unique to humans are \ncrucial for fully developing theory of \nmind.  \n \nLLMs for Education and Learning Applications  \nStojanov \n(2023)  How effective is GPT as a \nlearning aid in scaffolding \nunderstanding of a specific \ntopic? An autoethnographic study exploring the \nauthor\u2019s personal experience using \nChat GPT (3.5)  to learn about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 319,
      "text": "about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge.  \nJyothy et al. \n(2024)  What factors influence the \nadoption of LLMs like \nChat GPT in learning, teaching, \nand research?  The Fogg Behavior Model (FBM) was \napplied to analyze the motivations, \nabilities, and perceptions of students, \nteachers, and researchers toward LLM \nuse. User motivation and ability drive LLM \nadoption, but limitations like teacher \nhesitance and technical challenges hinder \nbroader integration.  \nLogacheva et \nal. (2024)  Can GPT-4 generate \npersonalized programming \nexercises to enhance student \nengagement and learning?  GPT-4-generated exercises were \nevaluated in an introductory \nprogramming course by students and \ninstructors for quality and engagement.  GPT-4 effectively produced high -quality, \nengaging exercises, offering \npersonalized and scalable practice \nmaterials for programming education.  \nMachin et al. \n(2024)  Can GPT demonstrate \npsychological literacy \ncomparable to subject matter \nexperts (SMEs) in psychology \nresearch methods?  GPT rated 13 research scenarios, and its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 320,
      "text": "nd its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy.  \nGhafouri \n(2024)  Can a ChatGPT-based rapport -\nbuilding protocol (CGRBP) \nenhance L2 (Second Language) \ngrit in English learners?  A 16 -week experimental study compared \n30 EFL learners (15 experimental, 15 \ncontrol) using pre -test post -test ANCOV A \nanalysis.  CGRBP significantly improved L2 grit, \ndemonstrating its potential to foster \nemotional support and learning \nmotivation.  \nGhafouri et \nal. (2024)  Can ChatGPT match expert \npsychological literacy in \nevaluating research methods?  The study compared responses from \nChatGPT to 13 psychological research \nmethod scenarios against ratings by \nsubject matter experts.  ChatGPT \u2019s responses correlated strongly \nwith expert evaluations, suggesting its \npotential as an educational tool in \npsychology, though its usage should be \napproached with caution.  \nBaillifard et \nal. (2024)  Can AI tutors improve \nacademic performance through \npersonalized learning \nstrategies?  A semester -long study with 51 \npsychology students using a GPT -3-\npowered AI tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 321,
      "text": "tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results.  \nNote\uff1a Theory of mind (ToM) is the cognitive ability to attribute mental states to oneself and others \uff1b the \nFogg Behavior Model (FBM) explains behavior as a product of motivation, ability, and prompts.  \n \n \n \n \n5. LLMs in social and cultural psychology  \nSocial and cultural psychology explores how individuals interact with and are influenced by their social \nand cultural environments. It focused on interpersonal dynamics, group behavior, social cognition, and the \nlong-term formation and transformation of at titudes and norms (Tajfel, 1982 ). Such phenomena occur at \nvarious time scales, from immediate social interactions to cultural changes evolving over several years \n(Newell, 1990 ). LLMs provide valuable tools for advancing social and cultural psychology. By analyzing \ntextual datasets, simulating social interactions, and modeling human -like behaviors, LLMs can provide \ninsights into the dynamics of social cognition, group processes, and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 322,
      "text": ", and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts.  \nResearch on LLMs in social and cultural psychology can be categorized into three main areas: cultural \nand cognitive understanding, social interactions and behavioral simulations, and practical applications. First, \nLLMs have many similarities with humans re garding social cognition. For example, research has found that \nLLMs reflect a variety of typical human cognitive biases in judgment and decision -making, such as the \nanchoring effect, the representativeness heuristic, and base -rate neglect (Talboy & Fuller, 2023 ). In addition, \ncultural psychology research has identified significant differences in the cognitive processes of Easterners \nand Westerners when processing information and making judgments (Nisbett et al., 2001 ); in this regard, \nLLM consistently favors holistic Eastern ways of thinking (Jin et al., 2023 ). Second, LLMs have been shown \nto characterize human groups in social interaction settings. It has been shown that LLMs can replicate the \nresults of Milgram\u2019s electroshock experiments (Aher et al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 323,
      "text": "al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 ). \nThird, LLMs are increasingly used as proxies for human participants in psychological research. One \nstudy, for example, explored the potential of LLMs to serve as valid proxies for specific human subgroups \nin social science research; it found that LLMs cont ained information that went far beyond superficial \nsimilarity, reflecting the complex interplay between ideas, attitudes, and sociocultural contexts that \ncharacterizes human attitudes (Argyle et al., 2022 ). In addition, LLM has been tested for personality and \nvalues, obtaining results comparable to those for human samples, indicating their potential as psychological \nresearch tools (Miotto et al., 2022 ). Within this broader perspective, industrial and organizational psychology \nhas increasingly employed LLMs, particularly in employee selection and workplace optimization, \ndemonstrating their broader utility for understanding human behavior in structured en vironments. For \nexample, LLMs have been shown to improve the accuracy and efficiency of recruitment systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 324,
      "text": "t systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates. LLMs have also been integrated into \nsystems such as PALR (personalization -aware LLMs for recommendation) to dynamically align individual \ncapabilities with o rganizational needs. Such systems significantly reduce inefficiencies in hiring processes \nand enhance predictions about job performance by identifying nuanced compatibility factors in resumes and \ncover letters (Yang et al., 2023 ). Beyond individual applications, LLMs have contributed to understanding \nbroader organizational cultures and transformational dynamics by providing insights into how group \ninteractions and leadership styles influence workplace outcomes (Noy & Zhang, 2023 ). In the context of \nemployee productivity, experiments using LLMs have revealed substantial benefits. For instance, \nprofessionals using ChatGPT in workplace writing tasks improved productivity by reducing task completion \ntime by 40% and enhancing output qu ality by 18%, indicating its potential to effectively augment mid -level \nprofessional tasks (Noy & Zhang, 2023 ). Similarly, research on creativity has demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 325,
      "text": "as demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology.  \nLLMs have many applications in social and cultural psychology, allowing us to test theories and \nhypotheses about human behavior in social and cultural interaction settings. Zhao et al. (2024) , for instance, \nexamined whether AI chatbots can adjust their financial decisions and prosocial behaviors based on \nemotional cues, similar to humans. It was hypothesized that bots would take fewer risks when exposed to \nfear cues and more risks with joy cue s. Emotional primes (fear, joy, or neutral) were applied, and investment \ndecisions were analyzed. Additionally, prosocial responses, such as donating to a sick friend, were measured \nto assess how LLMs adapt behaviorally under emotional influences.  These findings highlight LLMs \u2019 ability \nto model complex social dynamics and cultural influences. The next section broadens this perspective, \nexploring LLMs \u2019 potential as versatile research tools for psychologists.  \n \n \n \nTable 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 326,
      "text": "Table 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al. \n(2023)  Do LLMs exhibit biases \ntoward WEIRD (Western, \nEducated, Industrialized, \nRich, Democratic) societies in \npsychological tasks?  LLMs\u2019 responses on psychological measures \nwere compared to cross -cultural human data.  LLMs closely align with WEIRD \ncognitive patterns but show declining \naccuracy with non -WEIRD \npopulations (r = -0.70), revealing a \nWEIRD bias.  \nJin et al. \n(2023)  Does GPT exhibit cultural \ncognitive traits aligned with \nEastern or Western thinking?  GPT was evaluated using cognitive and value \njudgment  scales.  GPT leans towards Eastern holistic \nthinking in cognitive tasks but shows \nno cultural bias in value judgments, \nlikely influenced by its training data \nand methods.  \nSchaaff et al. \n(2023)  How empathetic is GPT \ncompared to humans?  GPT\u2019s empathy was evaluated through \nemotion recognition tasks, conversational \nanalysis, and five empathy -related \nquestionnaires.  GPT accurately identified emotions in \n91.7% of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 327,
      "text": "of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3.5, and GPT -4 match human \nempathy and emotion \nidentification?  Empathy and emotional understanding were \nassessed using TAS -20 (Toronto Alexithymia \nScale -20) and EQ -60 (Emotional Quotient \nInventory -60), comparing LLM responses to \nhuman benchmarks.  GPT-4 approached human -level \nemotional intelligence, outperforming \nBard and GPT -3.5, which showed \nalexithymic tendencies.  \nX. Wang et \nal. (2023)  How do LLMs compare to \nhumans in emotional \nintelligence?  A psychometric assessment focusing on \nEmotion Understanding  was developed and \napplied to mainstream LLMs, benchmarking \nthem against over 500 human participants.  GPT-4 scored higher than 89% of \nhumans in emotional intelligence, with \nLLMs showing above -average \nemotional intelligence  but using non -\nhuman mechanisms influenced by \nmodel design.  \nX. Li et al. \n(2022)  Are LLMs psychologically \nsafe, and how can fine -tuning \nimprove their safety?  LLMs were assessed using the Short Dark \nTriad (SD -3), Big Five Inventory (BFI), and \nwell-being tests to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 328,
      "text": "to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al. \n(2022)  What are GPT -3\u2019s personality \ntraits and values as assessed \nby validated psychological \ntools? Administered validated personality and values \nmeasurement tools to GPT -3, including a \nmodel response memory to assess value \nalignment.  GPT-3 exhibits personality traits and \nvalues similar to human samples, \nproviding initial evidence of \npsychological assessment in LLMs.   \n \nSocial Interactions and Behavioral Simulations  \nZhao et al. \n(2024)  Can LLMs like GPT adapt \nresponses to emotional primes \nin decision -making?  Tested GPT -4 and 3.5 with scenarios eliciting \npositive, negative, or neutral emotions.  GPT-4 showed distinct emotional \nresponse patterns, exceeding GPT -3.5, \nindicating advanced modulation but no \ntrue emotions.  \nAher et al. \n(2023)  Can LLMs accurately \nsimulate human behaviors, \nand what biases emerge in \ntheir simulations?  Introduced Turing Experiments to evaluate \nLLMs against findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 329,
      "text": "st findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal. (2023)  Do LLMs exhibit biases \ntoward math and STEM, and \nhow do these biases compare \nacross models and with \nhumans?  Using Behavioral Forma Mentis Networks, \nbiases in GPT -3, GPT -3.5, GPT -4, and high \nschool students were analyzed through a \nlanguage generation task.  Newer LLMs (GPT -4) show reduced \nnegative bias and richer semantic \nassociations toward math and STEM \ncompared to older models and \nhumans, suggesting advancements in \nreducing stereotypes.  \nAlmeida et \nal. (2024)  How do state -of-the-art LLMs \nreason about moral and legal \nissues, and how do their \nresponses align with human \njudgments?  Eight experimental psychology studies were \nreplicated using Google\u2019s Gemini Pro, \nAnthropic\u2019s Claude 2.1, GPT -4, and Meta\u2019s \nLlama 2 Chat 70b. Model responses were \ncompared to human responses to assess \nalignment and systematic differences.  GPT -4 showed the best human \nalignment among LLMs but \nexaggerated effects and reduced \nvariance, highlighting biases that limit \ntheir suitability as substitutes for \nhuman participants in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 330,
      "text": "in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks.  ChatGPT improved productivity (40% \nfaster task completion, 18% better \nquality).  \nLee and \nChung \n(2024)  How does ChatGPT influence \ncreativity?  Measured creativity using associative and \ndivergent thinking tasks.  ChatGPT supports incremental \ncreativity but is less effective for \nradical innovation.  \nYang et al. \n(2023)  Can LLMs personalize job \nrecommendations?  PALR(personalization -aware LLMs for \nrecommendation) integrated interaction data \nwith LLMs for dynamic recommendations.  PALR enhanced predictions of job \nperformance and improved role \nmatching.  \nDu et al. \n(2024)  How can LLMs improve job \nrecommendations?  Used GANs with LLMs to refine low -quality \nresumes.  GAN -based systems predicted better \njob fit and reduced hiring \ninefficiencies.  \nAkata et al. \n(2023)  How do LLMs perform in \nsocial interaction tasks \ninvolving cooperation and \ncoordination?  LLMs played repeated two -player games (e.g., \nPrisoner\u2019s Dilemma, Battle of the Sexes) with \nother LLMs and human -like strategies to \nanalyze their behavior.  LLMs perform well in self -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 331,
      "text": "lf -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al. \n(2024)  Does GPT exhibit heuristics \nand context -sensitive \nresponses similar to those \nobserved in human decision -\nmaking?  Four studies tested GPT\u2019s responses to \nprompts designed to assess cognitive biases \n(anchoring, representativeness, availability \nheuristic, framing effect, endowment effect) \nand compared them to human participant \nresponses.  GPT demonstrated biases consistent \nwith human heuristics across all \nstudies, suggesting that language \npatterns alone may contribute to these \neffects, independent of human \ncognitive and affective processes.  \nPark et al. \n(2022)  How can designers predict \nand refine social behaviors in \nlarge -scale social computing \nsystems before deployment?  Developed \u201csocial simulacra,\u201d an LLM -driven \nsimulation that generates realistic community \ninteractions based on design inputs (goals, \nrules, personas), allowing scenario testing and \niterative design refinement.  Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 332,
      "text": "Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al. \n(2022)  Can LLMs demonstrate social \nintelligence and Theory of \nMind (ToM)?  LLMs were evaluated using SocialIQa (social \nintents and reactions) and ToMi (mental states \nand realities), with results contextualized \nthrough pragmatics theories.  LLMs, including GPT -4, perform \nbelow human levels (55% on \nSocialIQa, 60% on ToMi), indicating \nthat scaling alone does not yield ToM, \nhighlighting the need for person -\ncentric NLP approaches.  \nArgyle et al. \n(2022)  Can GPT -3 reliably emulate \nhuman subpopulations for \nsocial science research?  GPT-3 was conditioned on sociodemographic \nbackstories from U.S. surveys, creating \n\u201csilicon samples,\u201d which were compared to \nhuman survey data.  GPT-3 exhibits nuanced, \ndemographically aligned biases, \nindicating its potential as a tool for \nstudying human behavior and societal \ndynamics.  \nP. S. Park et \nal. (2024)  Can GPT -3.5 simulate human \nparticipants and replicate \nsocial science study results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 333,
      "text": "udy results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37.5% of study \nresults but exhibited uniform \nresponses (\u201ccorrect answer\u201d effect) \nand skewed conservative in moral \nfoundation surveys, questioning its \nreliability and diversity as a human \nparticipant substitute.  \nNote:  WEIRD (Western, Educated, Industrialized, Rich, Democratic) refers to societies that represent a \nminority of the global population but are often overrepresented in psychological research.  \n \n6. LLMs as research tools in psychology  \nSections 2 -5 illustrate LLMs \u2019 applications across cognitive, clinical, educational, and social psychology, \nrevealing their potential to transform research practices. Together, these advancements speed up \npsychological research with new tools, encourage collaboration with fields like c omputer science and \nlinguistics, and improve theoretical models through behavioral simulation \u2014key ways LLMs advance \npsychology. Building on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 334,
      "text": "on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5). By reducing subjective bias and minimizing human variability in tasks like stimulus generation \n(Section 2), standardized assessments (Section 3), and data inter pretation (Section 4), LLMs enhance \nobjectivity and efficiency across these applications.  \nFor instance, LLMs can automate systematic reviews and meta -analyses, revolutionizing evidence \nsynthesis and provide actionable insights for psychologists, as grounded in cognitive and behavioral \nprinciples  (e.g., in Sections 2 and 3).  This capacity extends to enhancing psychologists \u2019 workflows, \nbuilding on productivity improvements noted in Section 5, through tools like literature review, hypothesis \ngeneration, experimental design, experimental subjects, and data analysis (Table 5).  \nTable 5. LLMs as research tools in psychology study.  \nTopic  Related study  \nLiterature review  LLMs can summarize the researched literature (Dis, Bollen, Zuidema, Rooij, & Bockting, 2023) , complete literature \nreview tasks (Qureshi et al., 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 335,
      "text": ", 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al., 2022) \u3002 \nHypothesis \ngeneration  LLMs can generate hypotheses from scientific literature, make inferences based on scientific data, and then clarify \ntheir conclusions through interpretation (Zheng et al., 2023) , and can quickly and automatically test these research \nhypotheses and learn from mistakes . \nExperimental \ndesign  \n LLMs provide text -based material for experimental design, thereby optimizing the research process and reducing \nexperimental complexity. By employing these models, researchers can easily create experimental stimuli, develop \ntest items, and even simulate interactive sessions in con trolled environments  (Aher, Arriaga, & Kalai, 2022; Akata \net al., 2023) , providing a high degree of control and precision to the experimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 336,
      "text": "erimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al., 2023) , their use in place of human participation in experiments \nsaves time and costs and can be applied to some experiments where human participation is not appropriate (Hutson, \n2023 ), they can be combined with factors such as the specific research topic, the task, and the sample, and the use \nof LLM as an alternative to research participants where appropriate (Dillion et al., 2023 ). \nData analysis  LLMs can efficiently analyze massive amounts of textual data to gain insights into human behavior and emotions \nat an unprecedented scale  (Patel & Fan, 2023) , can analyze textual data in multiple languages, and accurately detect \nmental structures within it (Rathje et al., 2023) , can draw mental profiles from social media data (Peters & Matz, \n2023)\u3002 \nScholarly \nCommunication  LLMs can also help humans in writing (Dergaa et al., 2023 ; Stokel -Walker, 2022 ; Van Dis et al., 2023 ). LLMs were \nused in two natural language processing tasks and a human expert to assess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 337,
      "text": "ess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D. students struggling to finish their dissertations, to peer reviewers submitting \nanalyses under time pressure (Van Dis et al., 2023 ). \n \n6.1.  Automated literature review and meta -analysis  \nConducting a literature review meta -analysis is a complex, arduous process that requires significant \ntime and expertise (Michelson & Reuter, 2019 ). Nature reported that researchers have used GPT as a research \nassistant to summarize literature (Dis et al.  2023) . In one study, researchers used GPT to complete certain \nsystematic literature review tasks (Qureshi et al., 2023) . In another study, a literature review article was \ncreated using GPT with the application of digital twins in the health field; the results showed that knowledge \ncompilation and representation were accelerated with the help of LLMs. However, their academi c validity \nneeds to be further verified (Ayd\u0131n & Karaarslan, 2022) . Researchers have also specifically trained LLMs to \nsupport the practical needs of scientific research (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 338,
      "text": "ch (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal. (2024)  demonstrated that LLMs can screen literature, extract data, and generate statistical codes for meta -\nanalyses, significantly reducing workload while maintaining recall rates comparable to manual curation. \nSimilarly, Tong et al. (2024)  used LLMs to extract causal pairs from 43,312 psychology articles, achieving \nan 86.98% success rate in pair extraction through adaptive prompting. As discussed in section 3, LLMs have \nshown strong capabilities in extracting causal relationships from large  textual datasets, underscoring their \npotential to streamline evidence synthesis for systematic reviews and meta -analyses. Nevertheless, while \nLLMs excel in organizing qualitative data and identifying conceptual patterns, they face challenges in \nextracting  the precise numerical data necessary for meta -analyses. For example, although LLM -based tools \ncan retrieve and summarize outcome measures, manual validation remains essential to ensure accuracy, \nespecially when processing complex figures or tables.  \nIn summary, LLMs can speed up the process of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 339,
      "text": "ess of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2.  Hypothesis generation and experimental design  \nHypothesis -driven research is at the core of scientific activity. LLMs can generate hypotheses from \nscientific literature, make inferences based on data, and then clarify conclusions through interpretation \n(Banker et al., 2024 ; Zheng et al., 2023 ). Although LLMs are capable of becoming \u201chypothesis machines,\u201d \ntheir logical and mathematical derivation capabilities still need improvement to eliminate factual errors, \nquickly test hypotheses, and learn from mistakes (Y . J. Park et al., 2024 ) . As innovative tools, LLMs have \ngreat potential for use in psychological experiments, given their ability to provide text -based material for \nexperimental designs, thus optimizing the research process and reducing experimental complexity. Using \nsuch model s researchers can easily create experimental stimuli, develop test items, and even simulate \ninteractive sessions in controlled environments (Aher, Arriaga, & Kalai, 2022; Akata et al., 2023) , providing \na high degree of control and precision in the experimental process.  \nIn conclusion, LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 340,
      "text": "LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3.  LLMs as subjects in psychological experiments  \nAlthough LLMs can simulate some human behaviors and responses \u2014which provides an opportunity \nto test theories and hypotheses about human behavior (Grossmann et al., 2023) \u2014there is still some \ncontroversy on whether LLMs can be used as a substitute for human subjects in psychological research. \nWhile recognizing that certain problems persist (e.g., biases and insufficiently trained data), some \nresearchers have suggested that LLMs can be used as substitutes for human participants to save time and \ncost and can be applied to experiments that are not suitable for human participation (Hutson,2023) . Others \nhave proposed using LLMs as an alternative method of studying participants when appropriate, based on \ntheir performance in conjunction with factors such as specific research topics, tasks, and samples (Dillion et \nal., 2023 ). However, it is also believed that although LLMs can significantly affect scientific research, they \nare unlikely to replace human participants in any meaningful way (Harding et al., 2023 ). At the same time, \nsome studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 341,
      "text": "some studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects.  \nIn conclusion, although LLMs can simulate human judgment, their simulation of human thinking \nremains limited, and their output should be validated and interpreted with caution when used as \npsychological subjects.  \n6.4.  Tools for data analysis  \nVarious forms of AI have long been used to analyze psychological data, such as flight data for pilot \nscreening (Ke et al., 2023 ). Machine learning algorithms facilitate the processing of large datasets, \nidentifying patterns and correlations that might otherwise be overlooked. However, LLMs take this \ncapability to a new level; they can efficiently analyze massive amounts of textual data on an unprecedented \nscale to derive insights into human behavior and emotions (Patel & Fan, 2023) . For psychological research, \nthis means faster and more comprehensive data analysis, leading to more reliable, nuanced findings. LLMs \ncan analyze textual data in multiple languages, accurately detect psychological structures within them \n(Rathje et al., 20 23), and generate psychological profiles from social media data (Peters & Matz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 342,
      "text": "atz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation. Yet, LLMs cannot \noutperform experienced neuroradiologists, suggestin g the need for continued improvement in the medical \ncontext (Nazario -Johnson et al., 2023 ). These findings demonstrate the great potential of LLMs for \nevaluating and analyzing data.  \n6.5.  Promoting scholarly communication  \nScholarly communication is a cornerstone of academic research, encompassing the processes of \ncreating, evaluating, and disseminating knowledge. It includes writing research papers, conducting peer \nreviews, and ensuring that findings are communicated transp arently and ethically. In psychology, this process \nis particularly complex owing to the field\u2019s diverse theoretical frameworks and methodological approaches, \nranging from experimental to qualitative research. The discipline\u2019s focus on human behavior and it s \nintersection with technology demands precise and ethical communication practices.  \nIt has been argued that LLMs currently cannot completely replace human writing and instead can only \nanswer questions and generate naturally fluent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 343,
      "text": "uent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing. The experimental group that used GPT was found to be similar to the control group \nin terms of writing quality, speed, and authenticity; the authors suggested that this could be because \nexperienced researchers can better guide GPT to produce high -quality information. By contrast, students \u2014\nwho have less writing experience than researchers \u2014found that GPT did not perform as effectively (Ba\u0161i\u0107 et \nal., 2023 ). Another article discussed the prospects and potential threats of GPT in academic writing, \nemphasizing that using GPT in academic research should prioritize peer -reviewed scholarly sources. Yet, \nGPT\u2019s potential advantages for academic research, including the handling of large amounts of textual data \nand the automatic generation of abstracts and research questions (Dergaa et al., 2023 ), were highlighted. \nFurthermore, LLMs can potentially be used for peer review (Van Dis et al., 2023 ). The decisions/judgments \nof LLMs in a text -evaluation task were found to be consistent with those of human experts (Chiang & Lee, \n2023) . \nIn conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 344,
      "text": "n conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually. They \ncan be used to scan academic papers and extract es sential details, generate objective and unbiased abstracts, \nand create research questions in social psychology (Banker et al., 2023 ; Tong et al., 2024 ). However, \nresearchers must exercise caution when using them as they can also introduce false or biased information \ninto papers, leading to unintentional plagiarism and the misattribution of concepts (Van Dis et al., 2023 ). \n \n \n7. Challenges and future directions  \n7.1.  Challenges and limitations  \nLLMs have enormous potential to simulate complex cognitive processes, providing researchers with \nnew tools to explore the mechanisms of human cognition and behavior for wide -ranging application in \nvarious fields, including clinical and counseling psycholog y, educational and developmental psychology, \nand social and cultural psychology. However, LLM output should not be mistaken for the presence of thought \nbut instead viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 345,
      "text": "d viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding. \nThe interpretation of LLMs\u2019 capabilities must be based on an understanding of their limitations and the \nnature of their operations, which might differ fu ndamentally from human cognition. It is essential, then, to \nfocus on the potential of LLMs in psychological research while also acknowledging the technical and ethical \nchallenges that might arise.  \nFirst, despite the emergence of LLM competence (Wei et al., 2022 ), its internal working mechanism \nremains a black box from a cognitive and behavioral psychology perspective. For example, LLMs perform \nimpressively on tasks requiring formal linguistic competence (including knowledge of the rules and patterns \nof a particul ar language) but fail many tests requiring functional competence (the set of cognitive abilities \nneeded to understand and use language in the real world) (Mahowald et al., 2023 ). They excel in analogical \nand moral reasoning tasks but perform poorly on spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 346,
      "text": "spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 ). For example, gatekeepers, patients, and even mental \nhealth professionals who use GPT to assess suicide risk or improve decision -making might receive \ninaccurate assessments that underestimate risk (Elyoseph & Levkovich, 2023 ) or bias clinician decision -\nmaking, which can lead to healthcare inequities (Pal et al., 2023 ). In addition, LLMs in psychiatry research \nand practice have been associated with potential bias and privacy violations (Zhong et al., 2023 ). \nThird, LLMs face application challenges in fields such as educational, developmental, and social and \ncultural psychology. It is evident that when applied in education, LLMs have the potential for output bias \nand misuse (Kasneci et al., 2023 ). One study found that texts generated by GPT were not always consistent \nor logical and sometimes even contradictory (Stojanov, 2023 ). In the field of social and cultural psychology, \nLLMs exhibit cognitive biases (Talboy & Fuller, 2023 ) and cultural biases (Atari et al., 2023 ) similar to those \nof humans, in addition to implicitly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 347,
      "text": "citly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings.  \nFinally, LLMs have some limitations as aids to scientific research. With regard to writing, for example, \nLLMs currently cannot fully replace humans. Instead, they answer questions and generate naturally flowing, \ninformative content lacking real intelligenc e (Stokel -Walker, 2022) . Although macrolanguage models can \nsimulate human judgment when used as experimental subjects, there are still limits to their \u201cunderstanding\u201d \nof human thought (Dillion et al., 2023 ). Van Dis et al. (2023)  noted that LLMs might accelerate innovation, \nshorten publication times, and increase scientific diversity and equality. However, they might also reduce \nthe quality and transparency of research and fundamentally alter scientists\u2019 autonomy as human research ers. \nIn summary, while LLMs offer extraordinary capabilities for psychological research, they also present \nchallenges related to bias, ethical issues, data security, transparency, and technical expertise. Researchers \nshould be fully aware of these challenges wh en using LLMs and adopt the following steps for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 348,
      "text": "s for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation. Third, use diverse training data to \nreduce cultural or gender biases. Fourth , in sensitive areas like mental health, limit use to assist \u2014not \nreplace\u2014judgment and train users to interpret outputs critically. These steps, supported by recent studies \n(Abdurahman et al., 2024; Guo et al., 2024; Porsdam Mann et al., 2024), address ethi cal concerns in \npsychological research.  Table 6 summarizes the challenges and limitations of LLMs in psychological \napplications.  \nTable 6  Challenges and limitations of LLMs in psychological applications.  \nChallenges  Author  Details  \nCogniti ve and Behavior al Psychology  \nLack of Real -World \nUnderstanding  Mitchell \n(2023)  LLMs lack real -world understanding, abstract reasoning, and intent comprehension.  \nLack of Meta -\nknowledge  Stella et al. \n(2023)  LLMs fabricate information (hallucination) and lack curiosity/meta -knowledge.  \nCausal Reasoning and \nCreativity  Sartori and \nOrr\u00f9 (2023)  Poor causal reasoning, dependence on biased training data, lack of creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 349,
      "text": "creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al. \n(2023)  Forgetting knowledge in new tasks, poor common -sense reasoning, inconsistent problem -\nsolving.  \nModel Behavior \nChallenges  Holtzman et \nal. (2023)  Lack of interpretability and formal behavioral descriptions makes systematic analysis difficult.  \nPsycholinguistic \nFeatures  Seals and \nShalin \n(2023)  GPT and human -generated analogies differed in these stylistic dimensions, these lexical \nfeatures, their choice of words for these features and these devices that help readers understand \ntext. GPT may lack human cognitive and psycholinguistic features when generating analogies.  \nClinic and Counseling  Psychology  \nTechnical Limitations& \nPatient Connection \nIssues  Stade et al. \n(2023)  Difficulty assessing suicide risk, substance abuse, safety issues, and interpreting nonverbal \ncues& Problems forming therapeutic relationships, interpreting nonverbal behaviors.  \n \nEducation and Development  Psychology  \nIntegrity and Ethics \nIssues  Li et al. \n(2023)  Academic integrity concerns, misinformation, data privacy, and impact on critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 350,
      "text": "n critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity.& \nLimited support for diverse languages and equitable access.  \nSocial and Culture  Psychology  \nLiability and Privacy \nIssues  Fecher et al. \n(2023)  Liability issues: challenging traditional mechanisms of authorship and liability. Bias issues: \naffecting the objectivity and impartiality of science. Privacy and data protection issues: may be \nprivacy issues with the training data of LLMs. Intellectual pro perty issues: potential legal \ndisputes. Environmental issues: generating large amounts of carbon emissions, which can have \na negative impact on the environment.  \nGlobal Diversity \nIgnorance  Atari et al. \n(2023)  Ignoring global psychological diversity (e.g., tend to favor the psychological characteristics of \nWEIRD societies) and which can lead to prejudice and discrimination against people of other \ncultures and backgrounds. Differences in values and moral judgment s and which can lead to \nproblems of communication and understanding in multicultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 351,
      "text": "icultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal. (202 4) Reduced innovation and development, bias and discrimination, culture clash and conflict, \ndifferences in values and morals and entrenchment of the status quo.  \nSocial Context \nLimitations  Salah et al. \n(2023)  Limited understanding of social context: Although GPT  performs well in syntax and general \nsemantics, it still has limitations in capturing the nuances of social language.  Ethical challenges: \nAI-generated fake content can lead to ethical issues including digital personhood, informed \nconsent, potential manipulation, and the implications of using AI to simulate human \ninteractions.  \nBias and Misleading Hayes Potential biases: if the training data contain biases, LLMs may learn and replicate them. Data \nOutputs  (2023)  privacy and consent issues: Text generated using LLMs may involve data privacy and consent \nissues.  Output may be non -humanly understandable: although LLMs generate text that closely \nresembles human language, they do not truly understand the content and may generate absurd \nor misleading responses.  \nTraining Data Bias  Miotto et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 352,
      "text": "to et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements.  \nResponsibility and control: Due to the complexity of language models, it is difficult to determine \nwho is responsible for the model's output, which can lead to attribution of problems and lack of \ncontrols.  \nPropagation of Harm  Bender et \nal. (2021)  Potential Harm: LLMs may lead to the propagation of harmful ideas such as stereotyping, \ndiscrimination, and extremism, and may lead to misinformation and bullying when generating \ntext. Data bias and unfairness: leading to potential harm to marginalized communities. \nAutomating bias: exacerbating existing biases and discrimination.  Enhancement of authoritative \nviewpoints: LLMs may reinforce dominant viewpoints in the training data, further undermining \nmarginalized people.  \nAlignment Challenges  Tamkin et \nal. (2021)  Alignment: In order to better align models with human values, algorithmic improvements are \nneeded to increase factual accuracy and robustness against adversarial samples. In addition, \nappropriate values need to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 353,
      "text": "to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al. \n(2020)  Misuse of language modeling: GPT -3 may be used to generate fake news, spread extremist \nideas, conduct cyber -attacks and other malicious uses.  Fairness, bias, and representation: GPT -\n3 may carry bias against gender, race, and religion, among others, sparking related \ncontroversies.  News generation: News generated by GPT -3 may be difficult to distinguish from \nreal news, leading to confusing and misleading information.  \nResearch Tools  \nPlagiarism and \nCopyright Issues  Sallam \n(2023)  Plagiarism: content generated by GPT may be considered plagiarized, violating academic \nnorms.  Copyright issues:  Is the generated content owned by GPT or by the user?  Transparency \nissues: The workings of GPT may not be transparent, making it difficult for users to understand \nthe source of generated content. Liability issues: who is responsible for GPT when generating \nincorrect content?  \nTransparency \nLimitations  Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 354,
      "text": "Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content.  Legal \nand Ethical Issues: Generative AI models may involve intellectual property, privacy, and ethical \nissues, requiring attention to compliance with relevant laws and regulations during use.  \nAcademic Integrity \nConcerns  Dergaa et \nal. (2023)  Integration of erroneous or biased information. Problems with citing original sources and \nauthors. Impact on academic integrity and quality. Increased inequity and inequality: Difficulty \nin recognizing AI -generated content. Academic evaluation and recognit ion issues. Direct \nreplacement for academic researchers: GPT is not a complete replacement for academic \nresearchers as it has limitations in certain types of academic research.  \nPrivacy and Bias Risks  Peters and \nMatz \n(2023)  User privacy: LLMs can infer psychological traits from a user's social media data, which may \nviolate the user's privacy. Potential bias: LLMs may create potential bias in the inference \nprocess, which may lead to unfair treatment of specific groups (e.g., gender, age, etc.). Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 355,
      "text": ". Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al. \n(2023)  Academic misconduct: GPT may be used for academic cheating, such as generating false papers \nor assignments.  Challenges in the medical field: GPT  has limitations in medical image analysis, \nwhich may lead to wrong diagnosis and jeopardize patients' health.  \n \n7.2.  Future directions and emergent trends  \nCurrently, LLMs are used in different areas of psychology, including cognitive and behavioral, clinical \nand counseling, educational and developmental, and social and cultural psychology. As the capabilities of \nLLMs are further enhanced, their potential applications in psychology will continue to develop.  \nFirst, in the field of cognitive and behavioral psychology, with the emergence of multimodal LLMs \n(OpenAI, 2023 ), it is possible to combine visual and auditory information with textual data to better \nunderstand and model emotions, behaviors, and mental states for cognition. However, neuroimaging data \ncan be used to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 356,
      "text": "to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought.  \nSecond, in the field of clinical and counseling psychology, on the one hand, personal data, such as social \nmedia posts, medical records, or wearable device data, can be used to create tailored, personalized LLMs \nthat provide more accurate and relevant insi ghts into an individual\u2019s state of mind. At the same time, the \nstrengths of human clinical and counseling expertise can be combined with the scalability and computational \npower of LLMs to create new diagnostic treatment and intervention tools. In addition,  in educational and \ndevelopmental psychology and social and cultural psychology, it is essential to build ethical LLMs and \nensure they are designed and deployed in a way that respects privacy and uses data fairly and responsibly.  \nUltimately, LLMs represent a systematic project whose future development cannot be achieved without \nthe interdisciplinary collaboration of researchers in diverse fields such as psychology, computer science, and \nlinguistics. For psychology researchers, acce ssible open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 357,
      "text": "ble open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application.  \nTable 7  Future directions and emergent trends of LLMs in psychological applications . \nAuthor  Future directions and emergent trends  \nCognition and Behavior  \nD'Oria (2023)  Delving into Human -Computer Interaction (HCI) to understand AI's ability to mimic human behavior.  Exploring how \nAI language modeling can be applied in the human sciences to improve research efficiency and quality  \nCrockett and \nMesseri (2023)  Focus on the costs of adopting alternative human narratives in cognitive science research, such as masking the human \nlabor behind them and the impact on human well -being.  Concern about the impact of technological developments on \nscientific work and human understanding to ensure that cognitive scientists remain proactive in technological advances.  \nBinz and \nSchulz \n(2023b)  Explore ways to make LLMs more stable and robust in the face of descriptive tasks.  \nInvestigate whether LLMs can learn to explore purposefully and how to better utilize causal knowledge in tasks.  Analyze \nthe performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 358,
      "text": "the performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans.  \nHuang and \nChang (2022)  Improve the reasoning ability of LLMs to encourage reasoning by optimizing training data, model architecture, and \noptimization goals.  Develop more appropriate evaluation methods and benchmarks to measure the reasoning ability of \nLLMs to better reflect the true reasoning ability of the models.  Investigate the potential of LLMs in different applications \n(e.g., problem solving, decision making and planning tasks).  Explore other forms of reasoning (e.g., inductive and \nretrospective reasoning).  \nClinic and Counseling  \nAbd-Alrazaq \net al. (2019)  Develop more chatbots for people with mental illness, especially for those with disorders such as schizophrenia, \nobsessive -compulsive disorder and bipolar disorder.  \nImplement more chatbots in developing countries to address the shortage of mental health professionals.  Conduct more \nrandomized controlled trials to evaluate the effectiveness of chatbots in mental health.  \nStade et al. \n(2023)  Developing new therapeutic techniques and evidence -based practices (EBPs). Focus on evidence -based practices first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 359,
      "text": "es first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success.  Involve interdisciplinary collaboration. \nFocuses on therapist and patient trust and usability. Criteria for designing effective clinical LLMs.  \nDemszky et al. \n(2023)  Development of high -quality cornerstone datasets: these datasets need to encompass populations and psychological \nconstructs of interest and be associated with psychologically important outcomes (e.g., actual behaviors, mindfulness, \nhealth, and mental well -being). Focus on future research directions in consumer neuroscience and clinical neuroscience: \nresearch in these areas may involve the neural systems of marketing -related behaviors, decision neuroscience, \nneuroeconomics, and more.  \nEducation and Development  \nHagendorff \n(2023)  Developmental psychology: examining how LLMs develop cognitively, socially, and emotionally over the lifespan and \nhow these models can be optimized for specific tasks and situations. Learning psychology: studying how LLMs acquire \nand retain knowledge and s kills, and how to optimize these models to improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 360,
      "text": "o improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities.  Investigate ways to combine static text with rich social intelligence and interaction data to improve \nsocial intelligence in LLMs. Investigate the theoretical -psychological abilities of LLMs in more naturalistic settings to \nreveal their performance in real -world scenarios.   \nArgyle et al. \n(2022)  Investigate the algorithmic fidelity of the GPT -3 model and how appropriate conditioning can allow the model to \naccurately simulate the response distributions of various human subgroups.  Created \"in silico samples\" by conditioning \non the socio -demographic backgrounds of real human participants in multiple large U.S. surveys.  \nSchaaff et al. \n(2023)  Developing more advanced models: to more accurately capture the emotional context of conversations and improve \nemotional understanding and expression.  Measuring the emotional capabilities of bots: to investigate how to assess the \nemotional capabilities of chatbots in order to better understand how they behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 361,
      "text": "ey behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al. \n(2023)  Cross -cultural CSS research: future research should separately consider the utility of LLMs for cross -cultural CSS in \norder to better serve social science research in different cultural contexts.  Future research could explore contrastive or \ncausal explanations in LLMs.  New paradigms for social science and AI collaboration.  \nResearch Tools  \nVan Dis et al. \n(2023)  Invest in truly open LLMs: develop and implement open -source AI technologies to increase transparency and democratic \ncontrol.  Embrace the advantages of AI: utilize AI to accelerate innovation and breakthroughs at all academic stages, \nwhile focusing on issues of ethics and human autonomy.  Broaden the discussion: organize international forums to \ndiscuss the development and responsible use of LLMs in research, including issues of diversity and inequality.  \nFecher et al. \n(2023)  Analyzing the risks and opportunities of LLMs for science systems. Examining how LLMs affect academic quality \nassurance mechanisms, academic misconduct, and scientific integrity. Exploring the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 362,
      "text": "the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8. Conclusion  \nWith the rapid development of AI technologies, especially the continuous advancement of LLMs, \nmachine learning has reached the point where it can recognize and generate human language. This \ndevelopment is not simply a technological breakthrough for the fie ld of psychology, but it opens the door to \na range of potential applications.  \nFirst, in the field of cognitive and behavioral psychology, LLMs are excelling in a variety of cognitive \ntasks. Although there are still limitations in causal cognition and planning, these models resurrect the \nprinciple of association, demonstrating the ab ility to associate at a distance and reason in complex ways. At \nthe same time, the ability to adapt LLMs to cognitive models is a significant strength of psychological \nresearch, allowing for new explorations of human cognitive and behavioral processing mec hanisms.  \nSecond, in clinical and counseling psychology, LLMs can be used as preliminary diagnostic tools for \nmental health. While traditional mental health diagnosis relies on the experience of professionals and direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 363,
      "text": "nd direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content. Importantly, while such \ndiagnoses cannot wholly replace professional psychological assessment, they can serve as a n effective \nadjunct to help psychologists understand a patient\u2019s condition more quickly, or play a role in primary mental \nhealth interventions. Meanwhile, personalized psychological intervention is another critical application \ndirection for LLMs. By combining informat ion about an individual\u2019s health data and lifestyle habits, these \nmodels can provide tailored psychological advice and intervention programs. Such personalized approaches \ncould be crucial for improving the effectiveness of psychological interventions.  \nThird, LLMs have the same potential for application in both educational and developmental psychology \nand social and cultural psychology. For example, LLMs provide interactive and personalized learning \nexperiences or generate research tasks based on real -life applications that increase motivation and enhance \nlearning. In addition, by analyzing large amounts of social media data, these models can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 364,
      "text": "s can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency. Researchers can \nuse these models to quickly organize and analyze large amounts of literature, thus saving time. These models \ncan also assist with experimental design, dat a analysis, and even promoting scholarly communication, \nmaking psychological research more efficient and precise.  \nIn light of the above, LLMs have promising applications for psychology, such as research support, \ncognitive modeling, individualized intervention, and personalized learning. LLMs also have the potential to \ndramatically improve our understanding of human co mmunication, thought processes, and behaviors, \nleading to the development of more comprehensive theories of mind and cognitive science. At the same time, \nit is important to be aware of the related risks and challenges and to ensure adherence to ethical sta ndards, \nespecially with regard to individual privacy and data security. It is also important to recognize that no matter \nhow technologically advanced they are, LLMs can only partially replace the judgment and experience of \nhuman professionals. Therefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 365,
      "text": "herefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019). An overview \nof the features of chatbots in mental health: A scoping review. International Journal of Medical \nInformatics , 132, 103978. https://doi.org/10.1016/j.ijmedinf.2019.103978   \nAbdurahman, S., Atari, M., Karimi -Malekabadi , F., Xue, M. J., Trager, J., Park, P. S., ... & Dehghani, M. (2024). \nPerils and opportunities in using large language models in psychological research. PNAS nexus , 3(7), \npgae245.  \nAbramski, K., Citraro, S., Lombardi, L., Rossetti, G., & Stella, M. (2023). Cognitive network science reveals bias \nin gpt -3, gpt -3.5 turbo, and gpt -4 mirroring math anxiety in high -school students. Big Data and Cognitive \nComputing , 7(3), 124.  \nAgrawal, S. (2023). Are LLMs the Master of All Trades? : Exploring Domain -Agnostic Reasoning Skills of LLMs. \narXiv preprint . https://doi.org/10.48550/arxiv.2303.12810   \nAher, G., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate multiple humans and \nreplicate human subject studies  Proceedings of the 40th International Conference on Machine Learning, \nHonolulu, Hawaii, USA.  \nAkata, E., Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 366,
      "text": "Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M., Shamsan, M. A. A., Hezam, T. A., & Mohammed, A. A. Q. (2023). Impact of ChatGPT on Learning \nMotivation. Journal of English Studies in Arabia Felix , 2(1), 41 -49. \nhttps://doi.org/10.56540/jesaf.v2i1.51   \nAlmeida, G. F., Nunes, J. L., Engelmann, N., Wiegmann, A., & de Ara\u00fajo, M. (2024). Exploring the psychology \nof LLMs\u2019 moral and legal reasoning. Artificial intelligence , 333, 104145.  \nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J., Rytting, C., & Wingate, D. (2022). Out of One, Many: Using \nLanguage Models to Simulate Human Samples. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2209.06899   \nAtari, M., Xue, M. J., Park, P. S., Blasi, D. E., & Henrich, J. (2023). Which Humans? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/5b26t   \nAyd\u0131n, \u00d6., & Karaarslan, E. (2022). OpenAI ChatGPT Generated Literature Review: Digital Twin in Healthcare. \nEmerging Computer Technologies (2), 22 -31. https://doi.org/10.2139/ssrn.4308687   \nBaillifard, A., Gabella, M., Lavenex, P. B., & Martarelli, C. S. (2024). Effective learning with a personal AI tutor: \nA case study. Education and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 367,
      "text": "and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10.31234/osf.io/kv6f7   \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2024). Machine -assisted social psychology hypothesis \ngeneration. American psychologist , 79(6), 789.  \nBa\u0161i\u0107, \u017d., Banovac, A., Kru\u017ei\u0107, I., & Jerkovi\u0107, I. (2023). ChatGPT -3.5 as writing assistance in students\u2019 essays. \nHumanities and Social Sciences Communications , 10(1). https://doi.org/10.1057/s41599 -023-02269 -7  \nBender, E. M., Gebru, T., McMillan -Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: \nCan Language Models Be Too Big?  Proceedings of the 2021 ACM Conference on Fairness, \nAccountability, and Transparency, Virtual Event, Canada. https://doi.org/10.1145/3442188.3445922  \nBinz, M., & Schulz, E. (2023a). Turning large language models into cognitive models. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2306.03917   \nBinz, M., & Schulz, E. (2023b). Using cognitive psychology to understand GPT -3. Proceedings of the National \nAcademy of Sciences of the United States of America , 120(6), e2218523120. \nhttps://doi.org/10.1073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 368,
      "text": "073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b). Personal narrative and stream of consciousness: an AI approach. The \nJournal of Positive Psychology , 1-7. https://doi.org/10.1080/17439760.2023.2257666   \nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \nAskell, A., Agarwal, S., Herbert -Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. \nM., Wu, J., Winter, C.,\u2026Amodei, D. (2 020). Language Models are Few -Shot Learners. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2005.14165   \nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E. K., Kamar, E., Lee, P., Lee, Y. T., Li, Y. -F., \nLundberg, S. M., Nori, H., Palangi, H., Ribeiro, M. T., & Zhang, Y. (2023). Sparks of Artificial General \nIntelligence: Early experiments with GPT -4. arXiv preprint . https://doi.org/10.48550/arXiv.2303.12712   \nCharness, G., Jabarian, B., & List, J. A. (2023). Generation next: Experimentation with ai .  \nChiang, C. -H., & Lee, H. -y. (2023). Can Large Language Models Be an Alternative to Human Evaluations? arXiv \npreprint . https://doi.org/10.48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 369,
      "text": ".48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023). Can AI Language Models Improve Human Sciences Research? A Phenomenological Analysis \nand Future Directions. Encyclopaideia , 27(66), 77 -92. https://doi.org/10.6092/issn.1825 -8670/16554   \nD\u2019Souza, R. F., Amanullah, S., Mathew, M., & Surapaneni, K. M. (2023). Appraising the performance of ChatGPT \nin psychiatry using 100 clinical case vignettes. Asian Journal of Psychiatry , 89, 103770.  \nDe Bot, K., Lowie, W., & Verspoor, M. (2007). A Dynamic Systems Theory approach to second language \nacquisition. Bilingualism: Language and Cognition , 10(1), 7 -21. \nhttps://doi.org/10.1017/S1366728906002732   \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., Eichstaedt, J. C., Hecht, C., \nJamieson, J., Johnson, M., Jones, M., Krettek -Cobb, D., Lai, L., JonesMitchell, N., Ong, D. C., Dweck, \nC. S., Gross, J. J., & Pennebaker, J. W. (20 23). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDergaa, I., Chamari, K., Zmijewski, P., & Ben Saad, H. (2023). From human writing to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 370,
      "text": "g to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023.125623   \nDhingra, S., Singh, M., Sb, V., Malviya, N., & Singh Gill, S. (2023). Mind meets machine: Unravelling GPT -4's \ncognitive psychology. arXiv preprint , arXiv:2303.11436. https://doi.org/10.48550/arXiv.2303.11436   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human participants? Trends \nin Cognitive Sciences , 27(7), 597 -600. https://doi.org/10.1016/j.tics.2023.04.008   \nDu, Y., Luo, D., Yan, R., Wang, X., Liu, H., Zhu, H., Song, Y., & Zhang, J. (2024). Enhancing job recommendation \nthrough llm -based generative adversarial networks. Proceedings of the AAAI Conference on Artificial \nIntelligence,  \nDubey, R., Hardy, M. D., Griffiths, T. L., & Bhui, R. (2024). AI -generated visuals of car -free US cities help \nimprove support for sustainable policies. Nature Sustainability , 7(4), 399 -403.  \nElyoseph, Z., & Levkovich, I. (2023). Beyond human expertise - the promise and limitationsof ChatGPT in suicide \nrisk assessment. Frontiers in Psychiatry , 14. https://doi.org/10.3389/fpsyt.2023.1213141   \nElyoseph, Z., & Levkovich, I. (2024). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 371,
      "text": "). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M., Laufer, M., Pohle, J., & Sofsky, F. (2023). Friend or foe? Exploring the implications of \nlarge language models on the science system. AI & Society . https://doi.org/10.1007/s00146 -023-01791 -\n1  \nFloridi, L., & Chiriatti, M. (2020). GPT -3: Its Nature, Scope, Limits, and Consequences. Minds and Machines , \n30(4), 681 -694. https://doi.org/10.1007/s11023 -020-09548 -1  \nFrank, M. C. (2023). Baby steps in evaluating the capacities of large language models. Nature Reviews Psychology , \n2(8), 451 -452. https://doi.org/10.1038/s44159 -023-00211 -x  \nGhafouri, M. (2024). ChatGPT: The catalyst for teacher -student rapport and grit development in L2 class. System , \n120, 103209.  \nGhafouri, M., Hassaskhah, J., & Mahdavi -Zafarghandi, A. (2024). From virtual assistant to writing mentor: \nExploring the impact of a ChatGPT -based writing instruction protocol on EFL teachers\u2019 self -efficacy and \nlearners\u2019 writing skill. Language Teaching Research , 13621688241239764.  \nGlaser, R. (1984). Education and thinking: The role of knowledge. American psychologist , 39(2), 93.  \nGoertzel, B. (2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 372,
      "text": "2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J., Mirza, M., Xu, B., Warde -Farley, D., Ozair, S., Courville, A., & Bengio, Y. \n(2020). Generative adversarial networks. Communications of the ACM , 63(11), 139 -144.  \nGraber -Stiehl, I. (2023). IS THE WORLD READY FOR AI -POWERED THERAPY? Nature , 617, 22-24. \nhttps://doi.org/10.1038/d41586 -023-01473 -4  \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, W. A. (2023). AI and \nthe transformation of social science research. Science , 380(6650), 1108 -1109. \nhttps://doi.org/10.1126/science.adi1778   \nGuo, Z., Lai, A., Thygesen, J. H., Farrington, J., Keen, T., & Li, K. (2024). Large language models for mental \nhealth applications: Systematic review. JMIR mental health , 11(1), e57400  \nGupta, M., Akiri, C., Aryal, K., Parker, E., & Praharaj, L. (2023). From ChatGPT to ThreatGPT: Impact of \nGenerative AI in Cybersecurity and Privacy. IEEE Access , 11, 80218 -80245. \nhttps://doi.org/10.1109/access.2023.3300381   \nHagendorff, T. (2023). Machine Psychology: Investigating Emergent Capabilities and Behavior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 373,
      "text": "avior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models. Proceedings of the National \nAcademy of Sciences , 121(24), e2317967121.  \nHagendorff, T., Fabi, S., & Kosinski, M. (2023). Human -like intuitive behavior and reasoning biases emerged in \nlarge language models but disappeared in ChatGPT. Nature Computational Science , 3(10), 833 -838. \nhttps://doi.org/10.1038/s43588 -023-00527 -x  \nHarding, J., D\u2019Alessandro, W., Laskowski, N. G., & Long, R. (2023). AI language models cannot replace human \nresearch participants. AI & Society . https://doi.org/10.1007/s00146 -023-01725 -x  \nHardy, M., Sucholutsky, I., Thompson, B., & Griffiths, T. (2023). Large language models meet cognitive science: \nLlms as tools, models, and participants. Proceedings of the annual meeting of the cognitive science \nsociety,  \nHayes, A. (2023). \u201cConversing\u201d with Qualitative Data: Enhancing Qualitative Research through Large Language \nModels (LLMs). PsyArXiv preprint . https://doi.org/10.31235/osf.io/yms8p   \nHendel, R., Geva, M., & Globerson, A. (2023). In -Context Learning Creates Task Vectors. arXiv preprint , \narXiv:2310.15916. https://doi.org/10.48550/arXiv.2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 374,
      "text": ".2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440. https://doi.org/10.1007/s10608 -\n012-9476 -1  \nHoltzman, A., West, P., & Zettlemoyer, L. (2023). Generative Models as a Complex Systems Science: How can \nwe make sense of large language model behavior? arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.00189   \nHothersall, D., & Lovett, B. J. (2022). History of psychology . Cambridge University Press.  \nHuang, J., & Chang, K. C. -C. (2022). Towards Reasoning in Large Language Models: A Survey. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10403   \nHutson, M. (2023). Doing research with human subjects is costly and cumbersome.Can AI chatbots replace them? \nScience , 381(6654), 121 -123. https://doi.org/10.1126/science.adj6791   \nJin, C., Zhang, S., Shu, T., & Cui, Z. (2023). The Cultural Psychology of Large Language Models: Is ChatGPT a \nHolistic or Analytic Thinker? arXiv preprint . https://doi.org/10.48550/arXiv.2308.14242   \nJungherr, A. (2023). Using ChatGPT and Other Large Language Model (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 375,
      "text": "odel (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024). Exploring large language models as an integrated tool \nfor learning, teaching, and research through the Fogg Behavior Model: a comprehensive mixed -methods \nanalysis. Cogent Engineering , 11(1), 2353494.  \nKahneman, D. (2011). Thinking, fast and slow. Farrar, Straus and Giroux .  \nKasneci, E., Sessler, K., K\u00fcchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., \nG\u00fcnnemann, S., H\u00fcllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, \nO., Sailer, M., Schmidt, A., Seidel, T.,\u2026Kasn eci, G. (2023). ChatGPT for good? On opportunities and \nchallenges of large language models for education. Learning and Individual Differences , 103. \nhttps://doi.org/10.1016/j.lindif.2023.102274   \nKe, L., Zhang, G., He, J., Li, Y., Li, Y., Liu, X., & Fang, P. (2023). Pilot Selection in the Era of Virtual Reality: \nAlgorithms for Accurate and Interpretable Machine Learning Models. Aerospace , 10(5). \nhttps://doi.org/10.3390/aerospace10050394   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings of the National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 376,
      "text": "National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10.48550/arXiv.2303.15727   \nLee, B. C., & Chung, J. (2024). An empirical investigation of the impact of ChatGPT on creativity. Nature Human \nBehaviour , 8(10), 1906 -1914.  \nLi, J., Tang, T., Zhao, W. X., Nie, J. -Y., & Wen, J. -R. (2022). Pretrained Language Models for Text Generation: A \nSurvey. arXiv preprint , arXiv:2201.05273. https://doi.org/10.48550/arXiv.2201.05273   \nLi, M., Enkhtur, A., Cheng, F., & Yamamoto, B. A. (2023). Ethical implications of ChatGPT in higher education: \nA scoping review. arXiv preprint . https://doi.org/10.48550/arXiv.2311.14378   \nLi, T., Lu, J., Chu, C., Zeng, T., Zheng, Y., Li, M., Huang, H., Wu, B., Liu, Z., & Ma, K. (2024). Scisafeeval: a \ncomprehensive benchmark for safety alignment of large language models in scientific tasks. arXiv \npreprint arXiv:2410.03769 .  \nLi, X., Li, Y., Liu, L., Bing, L., & Joty, S. (2022). Does GPT -3 Demonstrate Psychopathy? Evaluating Large \nLanguage Models from a Psychological Perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10529   \nLiu, J. M., Li, D., Cao, H., Ren, T., Liao, Z., & Wu, J. (2023). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 377,
      "text": "3). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre -train, Prompt, and Predict: A Systematic \nSurvey of Prompting Methods in Natural Language Processing. ACM Computing Surveys , 55(9), 1 -35. \nhttps://doi.org/10.1145/3560815   \nLiu, X., Ji, K., Fu, Y., Tam, W., Du, Z., Yang, Z., & Tang, J. (2022). P -Tuning: Prompt Tuning Can Be Comparable \nto Fine -tuning Across Scales and Tasks. Proceedings of the 60th Annual Meeting of the Association for \nComputational Linguistics (Volume 2: Short Papers), Dublin, Ireland.  \nLiu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., Wu, Z., Zhao, L., Zhu, D., Li, \nX., Qiang, N., Shen, D., Liu, T., & Ge, B. (2023). Summary of ChatGPT -Related research and perspective \ntowards the future of large language models. Meta -Radiology , 1(2). \nhttps://doi.org/10.1016/j.metrad.2023.100017   \nLoconte, R., Orr\u00f9, G., Tribastone, M., Pietrini, P., & Sartori, G. (2023). Challenging ChatGPT's \"intelligence\" \nwith human tools: A Neuropsychological Investigation on Prefrontal Functioning of a Large Language \nModel. SSRN preprint . https://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 378,
      "text": "ttps://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI. Proceedings of the 2024 ACM Conference on \nInternational Computing Education Research -Volume 1,  \nLuo, X., Chen, F., Zhu, D., Wang, L., Wang, Z., Liu, H., Lyu, M., Wang, Y., Wang, Q., & Chen, Y. (2024). Potential \nRoles of Large Language Models in the Production of Systematic Reviews and Meta -Analyses. Journal \nof Medical Internet Research , 26, e56780.  \nMachin, M. A., Machin, T. M., & Gasson, N. (2024). Comparing ChatGPT With Experts\u2019 Responses to Scenarios \nthat Assess Psychological Literacy. Psychology Learning & Teaching , 14757257241241592.  \nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., & Fedorenko, E. (2023). \nDissociating language and thought in large language models: a cognitive perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2301.06627   \nMarjieh, R., Sucholutsky, I., Rijn, P. v., Jacoby, N., & Griffiths, T. L. (2023). Large language models predict human \nsensory judgments across six modalities. arXiv preprint . https://doi.org/10.48550/arXiv.2302.01308   \nMichelson, M., & Reuter, K. (2019). The significant cost of systematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 379,
      "text": "ematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi.org/10.1016/j.conctc.2019.100443   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022). Who is GPT -3? An Exploration of Personality, Values and \nDemographics. arXiv preprint . https://doi.org/10.48550/arXiv.2209.14338   \nMitchell, M. (2023). AI's challenge of understanding the world. Science , 382(6671). \nhttps://doi.org/10.1126/science.adm8175   \nNazario -Johnson, L., Zaki, H. A., & Tung, G. A. (2023). Use of large language models to predict neuroimaging. \nJournal of the American College of Radiology , 20(10), 1004 -1009. \nhttps://doi.org/10.1016/j.jacr.2023.06.008   \nNewell, A. (1990). Unified theories of cognition . Harvard University Press.  \nNisbett, R. E., Peng, K., Choi, I., & Norenzayan, A. (2001). Culture and systems of thought: holistic versus \nanalytic cognition. Psychological review , 108(2), 291 -310. https://doi.org/10.1037//0033 -\n295X.108.2.291   \nNoy, S., & Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. \nScience , 381(6654), 187 -192.  \nOpenAI. (2023). GPT -4 Technical Report. arXiv preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 380,
      "text": "preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT. Frontiers in Artificial Intelligence , 6, 1199350. \nhttps://doi.org/10.3389/frai.2023.1199350   \nPal, R., Garg, H., Patel, S., & Sethi, T. (2023). Bias Amplification in Intersectional Subpopulations for Clinical \nPhenotyping by Large Language Models. medRxiv preprint . \nhttps://doi.org/10.1101/2023.03.22.23287585   \nPark, B., & Judd, C. M. (2005). Rethinking the Link Between Categorization and Prejudice Within the Social \nCognition Perspective. Personality and Social Psychology Review , 9(2), 108 -130. \nhttps://doi.org/10.1207/s15327957pspr0902_2   \nPark, J. S., Popowski, L., Cai, C., Morris, M. R., Liang, P., & Bernstein, M. S. (2022). Social simulacra: Creating \npopulated prototypes for social computing systems. Proceedings of the 35th Annual ACM Symposium \non User Interface Software and Technology,  \nPark, P. S., Schoenegger, P., & Zhu, C. (2024). Diminished diversity -of-thought in a standard large language model. \nBehavior Research Methods , 1-17.  \nPark, Y. J., Kaplan, D., Ren, Z., Hsu, C. -W., Li, C., Xu, H., Li, S., & Li, J. (2024). Can ChatGPT be used to \ngenerate scientific hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 381,
      "text": "ic hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi.org/10.1101/2023.07.17.549421   \nPeng, Y., Han, J., Zhang, Z., Fan, L., Liu, T., Qi, S., Feng, X., Ma, Y., Wang, Y., & Zhu, S. -C. (2023). The Tong \nTest: Evaluating Artificial General Intelligence Through Dynamic Embodied Physical and Social \nInteractions. Engineering . https://doi.org/10.1016/j.eng.2023.07.006   \nPeters, H., & Matz, S. (2023). Large Language Models Can Infer Psychological Dispositions of Social Media \nUsers. arXiv preprint . https://doi.org/10.48550/arXiv.2309.08631   \nPorsdam Mann, S., Vazirani, A. A., Aboy, M., Earp, B. D., Minssen, T., Cohen, I. G., & Savulescu, J. (2024). \nGuidelines for ethical use and acknowledgement of large language models in academic writing. Nature \nMachine Intelligence , 1-3. \nQureshi, R., Shaughnessy, D., Gill, K. A. R., Robinson, K. A., Li, T., & Agai, E. (2023). Are ChatGPT and large \nlanguage models \"the answer\" to bringing us closer to systematic review automation? Systematic Reviews , \n12(1), 72. https://doi.org/10.1186/s13643 -023-02243 -z  \nRane, N., Choudhary, S., & Rane, J. (2024). Gemini versus ChatGPT: applications, performance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 382,
      "text": "rformance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R., Robertson, C., & Bavel, J. J. V. (2023). GPT is an effective \ntool for multilingual psychological text analysis. PsyArXiv preprint . https://doi.org/10.31234/osf.io/sekf5   \nSalah, M., Al Halbusi, H., & Abdelfattah, F. (2023). May the force of text data analysis be with you: Unleashing \nthe power of generative AI for social psychology research. Computers in Human Behavior: Artificial \nHumans , 1(2). https://doi.org/10.1016/j.chbah.2023.100006   \nSallam, M. (2023). ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the \nPromising Perspectives and Valid Concerns. Healthcare (Basel) , 11(6). \nhttps://doi.org/10.3390/healthcare11060887   \nSap, M., LeBras, R., Fried, D., & Choi, Y. (2022). Neural Theory -of-Mind? On the Limits of Social Intelligence \nin Large LMs. arXiv preprint . https://doi.org/10.48550/arXiv.2210.13312   \nSartori, G., & Orr\u00f9, G. (2023). Language models and psychological sciences. Frontiers in Psychology , 14. \nhttps://doi.org/10.3389/fpsyg.2023.1279317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 383,
      "text": "9317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023). Clinical science and practice in the age of large language models and \ngenerative artificial intelligence. Journal of Consulting and Clinical Psychology , 91(10), 559 -561. \nhttps://doi.org/10.1037/ccp0000848   \nSeals, S. M., & Shalin, V. L. (2023). Long -form analogies generated by chatGPT lack human -like psycholinguistic \nproperties. arXiv preprint . https://doi.org/10.48550/arxiv.2306.04537   \nSejnowski, T. (2022). Large Language Models and the Reverse Turing Test. arXiv preprint . \nhttps://doi.org/10.48550/arxiv.2207.14382   \nSha, H., Mu, Y., Jiang, Y., Chen, L., Xu, C., Luo, P., Eben Li, S., Tomizuka, M., Zhan, W., & Ding, M. (2023). \nLanguageMPC : Large Language Models as Decision Makers for Autonomous Driving. arXiv preprint , \narXiv:2310.03026. https://doi.org/10.48550/arXiv.2310.03026   \nSharma, A., Lin, I. W., Miner, A. S., Atkins, D. C., & Althoff, T. (2023). Human \u2013AI collaboration enables more \nempathic conversations in text -based peer -to-peer mental health support. Nature Machine Intelligence , \n5(1), 46 -57. https://doi.org/10.1038/s42256 -022-00593 -2  \nSimon, H. A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 384,
      "text": "A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K. (2023). Leveraging Cognitive Science for Testing Large Language \nModels. 2023 IEEE International Conference On Artificial Intelligence Testing (AITest),  \nStade, E. C., Stirman, S. W., Ungar, L., Boland, C. L., Schwartz, H. A., Yaden, D. B., Sedoc, J., Derubeis, R. J., \nWiller, R., & Eichstaedt, J. C. (2023). Large Language Models Could Change the Future of Behavioral \nHealthcare: A Proposal for Responsible De velopment and Evaluation. PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/cuzvr   \nStella, M., Hills, T. T., & Kenett, Y. N. (2023). Using cognitive psychology to understand GPT -like models needs \nto extend beyond human biases. Proceedings of the National Academy of Sciences of the United States \nof America , 120(43), e2312911120. https://doi.org/10.1073/pnas.2312911120   \nStevenson, C., Smal, I., Baas, M., Grasman, R., & Maas, H. v. d. (2022). Putting GPT -3's Creativity to the \n(Alternative Uses) Test. arXiv preprint . https://doi.org/10.48550/arXiv.2206.08932   \nStojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 103,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 385,
      "text": "knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022). AI bot ChatGPT writes smart essays \u2014 should professors worry? Nature . \nhttps://doi.org/10.1038/d41586 -022-04397 -7  \nSufyan, N. S., Fadhel, F. H., Alkhathami, S. S., & Mukhadi, J. Y. (2024). Artificial intelligence and social \nintelligence: preliminary comparison study between AI models and psychologists. Frontiers in \nPsychology , 15, 1353022.  \nSuri, G., Slater, L. R., Ziaee, A., & Nguyen, M. (2024). Do large language models show decision heuristics similar \nto humans? A case study using GPT -3.5. Journal of Experimental Psychology: General .  \nTajfel, H. (1982). Social psychology of intergroup relations. Annual Review of Psychology , 33(1), 1 -39.  \nTalboy, A. N., & Fuller, E. (2023). Challenging the appearance of machine intelligence: Cognitive bias in LLMs. \narXiv preprint . https://doi.org/10.48550/arXiv.2304.01358   \nTamkin, A., Brundage, M., Clark, J., & Ganguli, D. (2021). Understanding the Capabilities, Limitations, and \nSocietal Impact of Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2102.02503   \nThirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 104,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 386,
      "text": "ovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K., Huang, Z., Zhao, Y., & Peng, K. (2024). Automating psychological hypothesis generation with \nAI: when large language models meet causal graph. Humanities and Social Sciences Communications , \n11(1), 896. https://doi.org/10.1057/s41599 -024-03407 -5  \nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., & \nBhosale, S. (2023). Llama 2: Open foundation and fine -tuned chat models. arXiv preprint \narXiv:2307.09288 .  \nTrott, S., Jones, C., Chang, T., Michaelov, J., & Bergen, B. (2023). Do large language models know what humans \nknow? Cognitive Science , 47(7), e13309.  \nVan Dis, E. A., Bollen, J., Zuidema, W., van Rooij, R., & Bockting, C. L. (2023). ChatGPT: five priorities for \nresearch. Nature , 614(7947), 224 -226. https://doi.org/10.1038/d41586 -023-00288 -7  \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin , I. (2017). \nAttention is all you need. Advances in neural information processing systems , 30.  \nVzorinab, G. D., Bukinichac, A. M., Sedykha, A. V., Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 105,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 387,
      "text": "Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., Chandak, P., Liu, S., Van Katwyk, P., Deac, A., Anandkumar, \nA., Bergen, K., Gomes, C. P., Ho, S., Kohli, P., Lasenby, J., Leskovec, J., Liu, T. Y., Manrai, A.,\u2026Zitnik, \nM. (2023). Scientific discovery i n the age of artificial intelligence. Nature , 620(7972), 47 -60. \nhttps://doi.org/10.1038/s41586 -023-06221 -2  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language models. Nature \nHuman Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -023-01659 -w  \nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, \nD., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J., & Fedus, W. (2022). Emergent Abilities \nof Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2206.07682   \nYang, F., Chen, Z., Jiang, Z., Cho, E., Huang, X., & Lu, Y. (2023). Palr: Personalization aware llms for \nrecommendation. arXiv preprint arXiv:2305.07622 .  \nYildirim, I., & Paul, L. A. (2023). From task structures to world models: What do LLMs know? arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 106,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 388,
      "text": "arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing. PsyArXiv preprint . https://doi.org/10.31234/osf.io/9ymfz   \nZeiler, M. (2014). Visualizing and Understanding Convolutional Networks. European conference on computer \nvision/arXiv,  \nZhang, J., Xu, X., & Deng, S. (2023). Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology \nView. arXiv preprint , arXiv:2310.02124. https://doi.org/10.48550/arXiv.2310.02124   \nZhang, Z., Chadwick, G., McNally, H., Zhao, Y., & Mullins, R. (2023). Llm4dv: Using large language models for \nhardware test stimuli generation. arXiv preprint arXiv:2310.04535 .  \nZhao, Y., Huang, Z., Seligman, M., & Peng, K. (2024). Risk and prosocial behavioural cues elicit human -like \nresponse patterns from AI chatbots. Scientific Reports , 14(1), 7095.  \nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I., & Pan, S. (2023). Large Language Models \nfor Scientific Synthesis, Inference and Explanation. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2310.07984   \nZhong, Y., Chen, Y. J., Zhou, Y., Lyu, Y. A., Yin, J. J., & Gao, Y. J. (2023). The Artificial intelligence large language \nmodels and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 107,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 389,
      "text": "els and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z., Zhao, G., Zhang, Z., Mao, Q., Wang, S., & Chen, E. \n(2023). Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective. arXiv \npreprint . https://doi.org/10.48550/arXiv.2306.10512   \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 108,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 390,
      "text": "s, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 391,
      "text": "Exploring the Frontiers of LLMs in Psychological Applications: A \nComprehensive Review  \n \nLuoma Ke1, Song Tong1,2*, Peng Cheng3, Kaiping Peng1,* \n1. Department of Psychological and Cognitive Sciences , Tsinghua University  \n2. Department of Psychology, Beijing Normal University  \n3. School of Social Science, Tsinghua University  \n* Corresponding authors: tong.song.53w@kyoto -u.jp; pengkp@tsinghua,edu.cn  \n \nAbstract  \nThis review explores the frontiers of large language models (LLMs) in psychological applications. \nPsychology has undergone several theoretical changes, and the current use of artificial intelligence (AI) and \nmachine learning, particularly LLMs, promises to  open up new research directions. We aim to provide a \ndetailed exploration of how LLMs are transforming psychological research. We discuss the impact of LLMs \nacross various branches of psychology \u2014including cognitive and behavioral, clinical and counseling,  \neducational and developmental, and social and cultural psychology \u2014highlighting their ability to model \npatterns, cognition, and behavior similar to those observed in humans. Furthermore, we explore the ability \nof such models to generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 392,
      "text": "generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology. We emphasize the importance of addressing technical and ethical challenges, including data \nprivacy, the ethics of using LLMs in psychological research, and the need for a deeper understanding of \nthese models\u2019 limitations. Researchers should use LLMs responsibly in psychological studies, adhering to \nethical standards and considering the pote ntial consequences of deploying these technologies in sensitive \nareas. Overall, this review provides a comprehensive overview of the current state of LLMs in psychology, \nexploring the potential benefits and challenges. We hope it can serve as a call to act ion for researchers to \nresponsibly leverage LLMs\u2019 advantages while addressing the associated risks.  \nKeywords large language models (LLMs); machine learning; artificial intelligence (AI); psychology; \nresearch methods  \n \n1. Introduction  \nArtificial intelligence (AI) has a history spanning nearly seven decades, beginning with the 1956 \nDartmouth Conference. The field has recently been revolutionized with the advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 393,
      "text": "he advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g., solving difficult tasks in math, coding, vision, \nmedicine, law, and psychology) (Bubeck et al., 2023) , exemplifying the concept of \u201cAI for science\u201d  (Wang \net al., 2023) . LLMs mark a critical juncture in the evolution of machine learning and AI, propelled by their \nexpansive size and sophisticated neural architectures that incorporate attention mechanisms  (V aswani et al., \n2017) . These models incorporate cognitive principles  (Binz & Schulz, 2023a)  and exhibit emergent \nproperties comparable to those seen in complex physical systems  (Wei et al., 2022) . This has enhanced their \nability to process and represent concepts and high -level semantics (J. Li et al., 2022)  while also deepening \nour insights into human cognitive processes  (Sejnowski, 2022) . In psychological applications, these \ndevelopments are reshaping interactions among data, language, and the environment  (De Bot et al., 2007; \nDemszky et al., 2023) , contributing significantly to various fields, including clinical  (Thirunavukarasu et al., \n2023) , developmental (Frank, 2023; Hagendorff, 2023) , and social psychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 394,
      "text": "sychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis.  \n1.1.  The LLM concept: From machine learning to capability emergence  \nGenerative AI evolved from advances in pattern  recognition capability. While convolutional neural \nnetworks (CNNs) excelled at recognizing objects and concepts, the next challenge was to use this recognition \ncapability for a generation. For example, if a CNN can identify \u201cage\u201d in portraits, we can use that \nunderstanding to modify \u201cage\u201d in any portrait. This generative approach first succeeded in computer vision \nthrough models such as generative adversarial networks (Goodfellow et al., 2020)  and deconvolution (Zeiler, \n2014) , which could create realistic images based on learned patterns. The same generative principles were \nthen applied to language, leading to LLMs that could generate contextually relevant text. LLMs represent a \nparticularly significant leap in the capabilitie s of generative AI. These models are designed to process natural \nlanguage text and generate contextually relevant text.  LLMs like GPT -4, LLaMA,  Claude, and  Gemini \nleverage the transformer architecture (V aswani et al., 2017), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 395,
      "text": "17), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks. For instance, LLaMA focuses on efficient training processes \n(Touvron et al., 2023) , Claude emphasizes safety and alignment (Li et al., 2024) , and Gemini integrates \nadvanced reasoning capabilities (Rane et al., 2024) . LLaMA \u2019s open -source nature allows local deployment \nand efficient training, making it suitable for psychological studies needing rapid iteration or customization, \nsuch as behavioral modeling ( Binz and Schulz (2023a) . Claude, designed for safety and alignment, is less \ncommonly used in psychology research and more oriented toward knowledge -based tasks (Li et al., 2024). \nGPT-4, with its large -scale parameters and broad training data, supports a wide range of tasks, including \ncognitive simulations and clinical assessments.  These differences guide model selection based on research \nneeds like accessibility, task specificity, or data scale.  \nWhile these models highlight the versatility of LLMs, it is essential to distinguish between specific \nproducts designed for particular interactions, such as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 396,
      "text": "as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction. This range of applications demonstrates that LLMs\u2019 capabilities are \nemergent, manifesting new abilities as the model size increases. Performance improvements on  log-log \nscales sometimes experience \u201cbreaks\u201d where unexpected capabilities emerge from complex interactions \nwithin the models (Wei et al., 2022) . \nAt the heart of LLMs is the transformer architecture, a deep neural network with an attention mechanism \nthat efficiently processes sequential data in parallel (V aswani et al., 2017) ; this works in a manner somewhat \nsimilar to human brain functions. This architecture has revolutionized the field of natural language \nprocessing. The self -attention mechanism of the transformer architecture captures contextual relationships \nin textual dat a, allowing for more sophisticated language understanding. Notably, the \u201clarge\u201d in LLM refers \nto the many parameters and massive amounts of training data used to fine -tune these models, typically \nbillions of parameters and terabytes of text (Binz & Schulz, 2023b) , in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 397,
      "text": "in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages. (1) Pretraining: LLMs are pretrained on large amounts of textual data to \nlearn intricate linguistic, syntactic, and textua l structures, where the model learns to predict the next token \nthrough unsupervised learning, resulting in a base model that captures the statistical patterns of language (P . \nLiu et al., 2023) . (2) Alignment: Supervised learning is used to create a foundation model that can better \ninteract with users in the intended ways, which typically involves instruction tuning and reinforcement \nlearning based on human feedback. After the foundation model i s available, domain -specific fine -tuning can \nadapt the model for particular applications (Liu et al., 2022) . This fine -tuning process ensures the model can \ngenerate contextually relevant responses and engage in meaningful conversations or tasks. Through these \nstages of development, LLMs demonstrate increasingly sophisticated text -generation capabilities, includi ng \nresponse generation, content summarization, translation, and compositional text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 398,
      "text": "nal text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models. Finally, LLMs exhibit \u201cobserved capability emergence\u201d \nwhen integrated into various applications and systems, in addition to performing tasks that require a deep \nunderstanding of language and context, thus often achieving human -like or superhuman performance in \nspecific experimental tasks, such as analogical reasoning (Webb et al., 2023) , creativity (Stevenson et al., \n2022) , and emotion recognition (Patel & Fan, 2023) . \nTherefore, LLMs can provide valuable insights into how such technologies can simulate or augment \nprocesses traditionally associated with human cognition. Specifically, LLMs maintain a balance between \nlogical processing and the use of cognitive shortcuts (heuristics), and they adapt their reas oning strategies to \noptimize between accuracy and effort. This aligns with the principles of resource -rational human cognition, \nas discussed in dual -process theory (Mukherjee & Chang, 2024). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 399,
      "text": "24). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) . These parallels allow for the exploration of AI applications in \nareas such as cognitive psychology (Sartori & Orr\u00f9, 2023) , language acquisition (Jungherr, 2023) , and even \nmental health (Lamichhane, 2023) . Moreover, the study of LLMs contributes to our understanding of the \nhuman mind, offering a computational perspective on language processing, decision -making (Sha et al., \n2023) , and learning mechanisms (Hendel et al., 2023) . The fusion of such disciplines could drive \nadvancements in AI and provide a computational framework for investigating processes related to human \ncognition.  \n1.2.  Psychology and AI  \nPsychology, as a science that explores the human mind and behavior, has undergone significant \ntheoretical changes since the late nineteenth century, with psychoanalysis and behaviorism extending to \ncognitive psychology (Hothersall & Lovett, 2022) . This history marks a shift in the focus of psychology \nresearch, reflecting the academic trend of moving from observing behavioral manifestations to exploring in -\ndepth psychological connotations. Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 400,
      "text": ". Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology. In clinical and \ncounseling psychology, research on cognitive psychology supports diagnosing and treating psychological \ndisorders. It deepens our understanding of the psycho logical mechanisms underlying emotions, stress, and \nhuman behavior. Psychotherapies such as cognitive -behavioral therapy (Hofmann et al., 2012)  and \npsychodynamic therapy have become essential tools for promoting mental health and emotional regulation. \nIn educational and developmental psychology, the development of cognitive psychology has fostered a \ndeeper understanding of the roles of perceptual  and affective factors in learning processes (Glaser, 1984) , \nwhich has led to innovations in teaching methods and learning strategies. In social and cultural psychology, \ncognitive psychology research helps explain individuals\u2019 behaviors and mental processes in different social \nand cultural contexts, exploring how cultural differences affect cognitive patterns, values, and behavioral \nnorms, especially in the context of globalization, interaction, and integration. In social psychology, \nmeanwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 401,
      "text": "nwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) . \nAI is becoming an increasingly influential tool in psycho -cognitive research. Simon (1979)  was among \nthe first to recognize the potential of computational models to simulate aspects of human cognitive processes. \nCurrently, LLMs can process and generate human -like texts and perform certain tasks in a manner similar to \nhuman cognition (Bubeck et al., 2023) . LLMs also offer a unique computational perspective for the study of \nhuman cognition. For example, GPT -3 can solve vignette -based tasks similar to or better than human subjects \nand can perform rational decision -making based on descriptions, outperforming humans in the multiarmed \nbandit task (Binz & Schulz, 2023b) . Furthermore, after extensive testing, GPT -3 is able to solve complex \nanalogical problems at levels comparable to human performance, and analogical reasoning is an essential \nhallmark of human intelligence (Webb et al., 2023) . Moreover, fine -tuning across multiple tasks can allow \nLLMs to predict human behavior in previously unseen tasks \u2014that is, LLMs can be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 402,
      "text": "n be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general.  \nNewell (1990)  offered a structured framework for analyzing human behavior, categorizing cognitive and \nbehavioral processes into four distinct layers based on their time scales (Fig. 1a). At the biological level, the \nfocus is on physiological and neural processes occurr ing at rapid time scales, ranging from milliseconds to \none second. This level can include neural responses and sensory processing, which form the foundation of \nhuman cognition. The cognitive level pertains to mechanisms such as attention, perception, and s hort-term \nmemory, which operate at intermediate time scales, typically between one second and one minute. These \nprocesses enable fundamental cognitive functions. At the rational level, the framework considers more \ncomplex cognitive activities such as probl em-solving, planning, and decision -making. Such activities occur \nover longer time scales, spanning several minutes to a few hours, and involve sustained cognitive \nengagement. Finally, the social level considers behaviors shaped by social interaction and cultural influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 403,
      "text": "influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition. It underscores the multifaceted \nnature of human behavior, highlighting the relationship between rapid physiological p rocesses and the more \nprolonged, socially influenced aspects of human cognition.  Figure 1 integrates this framework by mapping \npsychological domains (e.g., cognitive, social) onto these timescales, demonstrating LLMs \u2019 ability to \nsimulate behaviors \u2014from short -term processes like memory retrieval to long -term phenomena like cultural \ntrends. Emergent properties (e.g., cognitive simulation) connect these domains to practical research tools \n(e.g., stimuli generation), with bidirectional influence refinin g both a pplications and properties.  \nTherefore, by analyzing LLM application across these four levels (Fig. 1a), it is possible to further \nexplore their potential for modeling and studying human cognition and behavior (Fig. 1b), as well as their \nunique role in psycho -cognitive processes. Rece nt research has revealed significant advancements in LLMs\u2019 \nability to perform complex human -like cognitive and social tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 404,
      "text": "cial tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al. (2023)  demonstrated LLMs\u2019 proficiency in simulating human social \ninteractions and perceptual processing, respectively. Orru et al. (2023)  and (Webb et al., 2023)  highlighted \nLLMs\u2019 capabilities in complex problem -solving and reasoning while Hagendorff et al. (2023)  focused on \ndecision -making processes. Stevenson et al. (2022)  documented LLMs\u2019 potential for creativity, and Patel \nand Fan (2023)  demonstrated their emotion -recognition abilities. Taken together, such findings highlight the \nexpanding role of LLMs in representing and augmenting human cognitive and social functions, marking \nsignificant progress in AI research.   \nAs general -purpose cognitive models (Binz & Schulz, 2023a) , LLMs offer new perspectives and \napproaches for research in the fields of cognitive and behavioral psychology, clinical and counseling \npsychology, educational and developmental psychology, and social and cultural psychology, at different time \nscales of hu man behavior (Fig. 1a).  LLMs can also be used as research aids (Fig. 1c) to help psychologists \nwith everything from literature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 405,
      "text": "ature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al., 2023)  to promote scholarly communication: academic writing (Dergaa et al., 2023; Stokel -\nWalker, 2022)  or peer review (Chiang & Lee, 2023; Van Dis et al., 2023) . Thus, LLMs can potentially \nbecome research assistants for psychologists, helping them improve their research efficiency.  \n \nFig. 1 LLMs in Psychological Research Across Timescales. (a) Domains (e.g., Cognitive & Behavioral, \nSocial & Cultural) mapped to timescales of behavior; (b) Emergent properties (e.g., cognitive simulation) \nenabling domain -specific modeling; (c) LLMs as research tools (e.g., stimuli generation). Double -sided \narrows indicate that emergent properties bridge domains and tools, supporting applications (e.g., memory  \nretrieval) and refining properties through usage . \n \n1.3.  Objectives and significance of the present review  \nThis review aims to provide a comprehensive analysis of the applications and effects of LLMs in \npsychological research. To ensure a systematic and rigorous review, we established specific inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 406,
      "text": "ic inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science. Our initial keyword selection \u2014\n\u201cGPT-3\u201d, \u201cChatGPT \u201d, \u201cGPT-4\u201d, \u201clarge language models \u201d, and \u201cpsychology \u201d\u2014was determined during the \nliterature collection in October 2023, when GPT -based models were predominant in psychological research \n(e.g., Binz & Schulz, 2023b; Bubeck et al., 2023). At the time, open -source models like LLaMA (Touvron \net al., 2023) and propr ietary models like Claude had limited psychology -specific applications. To maintain \na focused scope, we did not retrospectively expand search terms but included diverse LLMs via manual \nscreening. To reflect recent developments, an updated search incorporat ed studies from 2024.  \nTo bolster the integrity of our data extraction process, two interdisciplinary researchers (male, 33 and \n41 years) specializing in information science and psychology conducted the encoding and screening. Our \n\ninclusion criteria required the selected studies to (1) explore the application or analysis of LLMs in \npsychological contexts; (2) be peer -reviewed journal articles or high -impact conference proceedings; and (3) \npresent empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 407,
      "text": "present empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature. Articles without a \npsychological focus or those addressing non -LLM -based AI systems were excluded.  The study selection \ninvolved screening 191 identified studies, analyzing 100 full -text articles, and ultimately including 4 7 studies \ncategorized into various psychological subfields. Each of these studies met stringent inclusion criteria, \nensuring they contributed meaningfully to our understanding of LLMs in psychological research.  \nIn this review, we systematically examine the use of LLMs in various psychological domains by \nanalyzing their application at different behavioral time scales. The rest of the paper is structured as follows. \nIn section 2, we explore LLMs in cognitive and be havioral psychology. In section 3, the roles of LLMs in \nclinical and counseling psychology are discussed. Subsequently, educational and developmental psychology \nare addressed in section 4, followed by social and cultural psychology in section 5, outlining LLMs\u2019 \ncontributions to each area. While psychological techniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 408,
      "text": "hniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research. The primary focus of this review is how LLMs facilitate and advance \npsychological research across these domains. For a deeper understanding of the effect of LLMs on \npsychological research, an overview of LLMs\u2019 potential as tools for scientific research is given in section 6. \nIn section 7, the challenges and future research directions with regard to applying LLMs to psychological \ncontexts are provided. Finally, conclusions are presented in section 8, with a summary of LLMs\u2019 applications \nin psychology and rec ommendations for future work. Importantly, we propose strategies for integrating \nLLMs into psychological research and provide insights into interpreting such models from a psychological \nstandpoint, contributing to their safety and interpretability.  \n \n2. LLMs in cognitive and behavioral psychology  \nWithin the multilevel time scales of human behavior (Newell, 1990) , cognitive and behavioral \npsychology has primarily focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 409,
      "text": "focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning. Cognitive  and behavioral psychology typically uses experimental methods to study \nthese cognitive processes, controlling and observing behaviors and responses under specific conditions. The \nrecent emergence of LLMs has reinvigorated the discussion on whether such models might exhibit patterns \nresembling human cognitive processes; if so,  it may be possible to study the \u201ccognitive processes\u201d of LLMs, \nwhich could provide valuable insights into human cognitive phenomena and serve as a valuable addition to \nexisting research methods in cognitive psychology. The foundational technology underlyi ng large language \nmodels (LLMs) is the generative pre -trained transformer (GPT) architecture, which employs deep neural \nnetworks to process and generate human -like text. GPT models function through mechanisms, such as \nattention mechanisms and token predict ion, enabling them to capture complex linguistic patterns and \ngenerate contextually coherent outputs. These foundational technologies have transformed natural language \nprocessing (NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 410,
      "text": "(NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) . The \nincorporation of such architectures into psychological research has initiated discussions regarding their \npotential to simulate cognitive phenomena.  \nBinz and Schulz (2023a)  found that fine -tuning multiple tasks enabled an LLM to predict human \nbehavior in previously unseen tasks, suggesting that LLMs can be adapted to become generalist cognitive \nmodels. In another study, the same authors tested GPT -3 using tools from cognitiv e psychology and showed \nthat it made better decisions than humans and outperformed them in the multiarmed bandit task (Binz & \nSchulz, 2023b) . Other studies have shown that LLMs can display perceptual judgment (Marjieh et al., 2023) , \nreasoning (Webb et al., 2023) , and decision -making abilities (Hagendorff et al., 2023) , as well as creativity \n(Stevenson et al., 2022)  and problem -solving (Orru et al., 2023) . One study found that an LLM had the \nmental ability of a seven -year-old child based on a false -belief task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 411,
      "text": "ef task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al. (2023)  designed a series of semantic illusion and cognitive \nreflection tests designed to elicit intuitive but erroneous responses (these are conventionally used to study \nhuman reasoning and decision -making) and then ran the tests for LLMs. They conducted an anal ysis of \nmodel performance on a Cognitive Reflection Test (CRT) task and a semantic illusion task to elucidate their \ncognitive processes, drawing upon System 1 and System 2 thinking, as conceptualized by Daniel Kahneman \nin his seminal work Thinking, Fast, a nd Slow (Kahneman, 2011) , which represent fundamental constructs \nfor understanding human cognitive processes. System 1 refers to intuitive and automatic thinking, whereas \nSystem 2 involves rational, deliberate decision -making processes. This framework provides a theoretical \nbasis for interpreting how LLMs simulate human -like cognitive behaviors during these tasks. They observe \nhow these models show correct responses in these tasks and avoid pitfalls. The performance of the models \nin the CRT task were further evaluated by prev enting them from chain -thinking to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 412,
      "text": "ing to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors. Table 1 provides a summary of the applications of \nLLMs to cognitive and behavioral psychology.  \nTable 1  Applications of large language models (LLMs) in cognitive and behavioral psychology study.  \nReference  Research Question  Research method  Key finding  \n \nHuman -like Cognitive Abilities  \nBinz and \nSchulz \n(2023b)  How does GPT -3 perform on \ncognitive psychology tasks, \nincluding decision -making, \ninformation search, and causal \nreasoning?  GPT-3 was tested using canonical \ncognitive psychology experiments \nand compared to human \nperformance.  GPT-3 excels in decision -making and \nreinforcement learning but struggles with \ntask perturbations, directed exploration, \nand causal reasoning.  \nStevenson et \nal. (2022)  Can GPT -3 generate creative \nsolutions comparable to humans in \nGuilford\u2019s Alternative Uses Test \n(AUT)?  GPT-3\u2019s responses to AUT were \nevaluated for originality, usefulness, \nsurprise, and flexibility, using expert \nratings and semantic distance \nanalysis, and compared with human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 413,
      "text": "th human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal. (2023)  Can LLMs recover perceptual \ninformation from language, and \nhow do they reflect cross -linguistic \nvariations?  GPT-3, GPT -3.5, GPT -4 were tested \non six psychophysical datasets and a \nmultilingual color -naming task to \ncompare their outputs with human \nperceptual data.  LLMs like GPT -4 align closely with \nhuman perceptual data, recover \nrepresentations such as the color wheel, \nand reflect cross -linguistic perceptual \nvariations, demonstrating their ability to \nextract perceptual information from \nlanguage.  \nLoconte et \nal. (2023)  How do various LLMs perform on \nneuropsychological tests assessing \nprefrontal functions compared to \nhuman cognitive abilities?  GPT-3.5, GPT -4,were evaluated on \ntasks related to planning, semantic \nunderstanding, and Theory of Mind.  Findings indicate that GPT -4 generally \nmeets normative human standards, \nwhereas  Claude2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 414,
      "text": "2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal. (2023)  How does GPT -4 perform on \ncognitive psychology tasks \ncompared to prior state -of-the-art \nmodels?  GPT-4 was evaluated on cognitive \npsychology datasets \n(CommonsenseQA, SuperGLUE, \nMATH, HANS) to analyze its \nintegration of cognitive processes \nwith contextual information.  GPT-4 demonstrates high accuracy on \ncognitive psychology tasks, surpassing \nprior models, and showcases significant \npotential to bridge human and machine \nreasoning.  \nHagendorff \n(2024)  Can modern LLMs understand and \napply deception strategies?  Experiments tested LLMs on \ninducing false beliefs, using chain -\nof-thought reasoning, and displaying \nMachiavellian behavior in simple \nand complex deception scenarios.  GPT-4 demonstrates advanced deceptive \nbehavior, succeeding in 99.16% of simple \nand 71.46% of complex scenarios, \nhighlighting the emergence of \nsophisticated deception abilities absent in \nearlier models.  \n \nExperimental Methodologies for Cognitive Research Using LLMs  \nBinz and \nSchulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 415,
      "text": "Schulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors.  Fine-tuned LLaMA outperforms \ntraditional cognitive models, accurately \nmodel individual behavior, and predict \nunseen human responses.  \nDubey et al. \n(2024)  How can generative AI tools be \nutilized to streamline the creation of \nexperimental stimuli in \npsychological research and \ninfluence public attitudes toward \nsustainable policies?  DALL -E 2 was employed to generate \nrealistic visual stimuli of car -free \nurban environments, which were \nthen presented to participants to \nmeasure attitudes toward sustainable \npolicies.  By using DALL -E 2, the study \ndemonstrated that generative AI tools can \nenhance the design process of \nexperimental stimuli, offering greater \ncontrol, diversity, and scalability, thereby \neffectively influencing participants' \nattitudes.  \nNote: The AUT is a psychological test that measures creativity by asking participants to think of as many \nuses as possible for a common object; DALL -E 2 is developed by OpenAI that generates detailed and \nrealistic images from textual descriptions to explore AI's potential in creative fields.  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 416,
      "text": ".  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al. (2024) , for \ninstance, used DALL -E 21 to create realistic visual stimuli depicting car -free urban environments, which \ninfluenced participants\u2019 attitudes toward sustainable policies. Such tools streamline the stimulus design \nprocess by providing control, diversity, and scalability. Similarly, LLMs have been employed in hardware \ntesting to generate tailored stimuli, outperforming traditional methods in specific scenarios (Z. Zhang et al., \n2023) . Charness et al. (2023)  further demonstrated the use of LLMs for enhancing experimental workflows \nby refining task instructions, ensuring consistency, and monitoring participant engagement. By leveraging \ntheir flexibility and scalability, LLMs can provide novel methods for advan cing experimental psychology. \nThese applications facilitate the exploration of complex cognitive phenomena and the development of \ninnovative research designs while also complementing traditional psychological research frameworks \n(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 417,
      "text": "(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3. LLMs in clinical and counseling psychology  \nClinical and counseling psychology focuses on assessing, diagnosing, treating, and preventing mental \nhealth problems. These processes often involve medium - to long -term periods. In the multilevel time scales \nof human behavior (Newell, 1990) , clinical and counseling psychology involves assessing everyday \nbehavioral acts (about a few hours to a day), habitual thinking (about a day to a few months), and \npsychological disorders (a few months to many years), among others (Fig. 1). The application  of LLMs in \nclinical and counseling psychology can be broadly divided into two categories: psychological assessment \nand psychological intervention. Psychological assessment focuses on improving the ecological validity, \nscalability, and accuracy of measurin g mental health states while psychological interventions consider how \nLLMs can be used for scalable and personalized mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 418,
      "text": "d mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) . LLMs are expected to be used in clinical psychology and counseling \n \n1 Note: Although DALL -E 2 is not an LLM, we included this study due to its reliance on Transformer -\nbased semantic understanding, a cornerstone of LLM research, and its demonstrated utility in generating \ncontrolled visual stimuli for psychological experiments.  \n \nbecause they can parse human language and generate human -like responses, categorize text, and flexibly \nadapt conversational styles representing different theoretical orientations (Stade et al., 2023) . This leads to \nthe following question: How do LLMs work in psychotherapy, and can they replace human psychotherapists?  \nAn LLM is a basic generalized model with the ability to learn from small samples (Brown et al., 2020) , \nwhich allows it to quickly become an \u201cexpert\u201d in the clinical and counseling domain with only a small \namount of data to learn from. For example, LLMs trained on clinical content can identify more specific \nfactors of change that can help psychologists und erstand the process of clinical intervention, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 419,
      "text": "on, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al., 2023)  and respond \nappropriately. They can also perform complex mental health evaluations (Patel & Fan, 2023; Schaaff et al., \n2023) , such as suicide risk assessment and schizophrenia prognosis. For example, Elyoseph and Levkovich \n(2024)  found that GPT -4, Google Bard, and Claude produced evaluations consistent with professional \nbenchmarks in treated schizophrenia cases, though GPT -3.5 exhibited overly pessimistic predictions. Other \nresearch has shown that GPT -3.5 excels in clinical psychi atric cases, achieving top grades in diagnosis and \nmanagement across 61% of cases, with only minor discrepancies in more complex scenarios (D\u2019Souza et al., \n2023) . \nIn psychological interventions, LLMs have shown significant potential for delivering scalable and \npersonalized mental health support (Blyler & Seligman, 2023a, 2023b) . For example, Blyler and Seligman \n(2023a) demonstrated that GPT -4 can generate personalized therapeutic strategies by analyzing narrative \nidentities. These strategies were found to be valid and reasonable, highlighting GPT -4\u2019s utility as a supportive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 420,
      "text": "portive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19.6% and significantly \nboosted self -efficacy among users struggling to pro vide support. Furthermore, J. M. Liu et al. (2023)  \nevaluated ChatCounselor, a model trained on a domain -specific dataset of psychologist \u2013client conversations, \nand found it outperformed open -source models, thereby demonstrating the importance of domain -specific \ntraining for improving counseling capabilitie s. Table 2 summarizes the applications of LLMs to clinical and \ncounseling psychology.  \nThe above research cases, which demonstrate LLMs\u2019 ability to provide clinicians with adequate mental \nhealth support (Schueller & Morris, 2023) , hold promise for addressing insufficient capacity in the mental \nhealth care system and offering more individualized treatment services, even potentially fully automating \npsychotherapy in the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 421,
      "text": "the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies . \nReferences  Research question  Research method  Key finding  \n \nPsychological Assessment Using LLMs  \nElyoseph and \nLevkovich \n(2023)  How effective and accurate \nare ChatGPT in assessing \nsuicide risk?  The study evaluated ChatGPT's \nanalysis of a text vignette depicting a \nhypothetical patient with varied \npsychological states, comparing its \nassessments to those of mental health \nprofessionals.  The study found that ChatGPT consistently \nunderestimated suicide risk and mental \nresilience compared to mental health \nprofessionals, suggesting that reliance on \nChatGPT for suicide risk assessment could \nlead to inaccurately low evaluations.  \nElyoseph and \nLevkovich \n(2024)  How do LLMs compare to \nmental health professionals \nin assessing schizophrenia \nprognosis and treatment \noutcomes?  Vignettes were used to compare the \nassessments of four LLMs (GPT -3.5, \nGPT-4, Bard, Claude) against \nprofessional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 422,
      "text": "ional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3.5)  in addressing clinical \npsychiatric cases and \nsupporting mental health \ncare?  ChatGPT was tested on 100 clinical \npsychiatric vignettes, and expert \npsychiatrists graded its responses \nacross 10 categories.  ChatGPT  excelled in management and \ndiagnosis, earning top grades in 61% of cases, \nwith no major errors but minor discrepancies \nin complex cases.  \nSufyan et al. \n(2024)  How do the social \nintelligence (SI) levels of \nLLMs compare to human \npsychologists?  Social intelligence scores of ChatGPT \n(4), Bard, and Bing were compared \nwith 180 counseling psychology \nstudents (bachelor\u2019s and PhD levels) . ChatGPT surpassed all psychologists in \nsocial intelligence, Bing outperformed most \nbachelor\u2019s and some PhDs, while Bard \naligned with bachelor\u2019s students but fell \nbehind PhDs.  \n \nPsychological Interventions with LLMs  \nBlyler and \nSeligman \n(2023a)  Can GPT-4 generate \npersonalized therapeutic \nstrategies based on narrative \nidentity?  GPT-4 analyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 423,
      "text": "nalyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching.  \nBlyler and \nSeligman \n(2023b)  Can GPT-4 generate \naccurate and insightful \npersonal narratives to \nsupport self -discovery in \ntherapy and coaching?  GPT-4 processed 50 stream -of-\nconsciousness thoughts from 26 \nparticipants to create personalized \nnarratives, which participants evaluated \nfor accuracy, surprise, and self -insight.  96% of participants rated the narratives as \naccurate, and 73% reported gaining new self -\ninsights, suggesting GPT-4\u2019s potential for \nenhancing self -discovery in therapeutic \ncontexts.  \nSharma et al. \n(2023)  Can AI enhance empathy in \npeer-to-peer mental health \nsupport?  Tested HAILEY  which based on GPT -\n2, which  offering real -time empathic \nfeedback, in a trial with 300 peer \nsupporters on TalkLife.  HAILEY improved empathy by 19.6% \noverall and 38.9% for those struggling with \nsupport, boosting self -efficacy without \ncreating reliance.  \nJ. M. Liu et al. \n(2023)  How to improve  LLM  in \nproviding mental health \nsupport compared to other \nmodels?  ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 424,
      "text": "ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics.  ChatCounselor outperforms LLaMA, \nChatGLM  and approaches GPT-4\u2019s \nperformance, highlighting the impact of \ndomain -specific training on counseling \ncapabilities.  \n4. LLMs in educational and developmental psychology  \n Educational and developmental psychology is concerned with learning processes, knowledge \naccumulation, skill development, and changes in individual psychology in educational environments. \nEducational and developmental psychology is mainly positioned at th e relatively medium - to long -term level \n(Newell, 1990), reflecting the ongoing learning and development that characterize the educational process. \nA national survey found that only 3 months after the public release of GPT, 40% of US teachers used it \nweekly for lesson planning, highlighting the growing impact of LLMs in education.  \nTable 3 summarizes the applications of LLMs in educational and developmental psychology, which can \nbe broadly divided into two categories: developmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 425,
      "text": "evelopmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g., theory of mind and emotional reasoning) and how such capabilities \nmight advance our understanding of human cognitive and emotional development. Kosinski (2024) , for \ninstance, tested different LLMs in 40 false -belief tasks and found that GPT -4 achieved 75% accuracy, \ncomparable to the performance of a six -year-old child, while older models performed significantly worse. \nVzorinab et al. (2024)  used the Mayer \u2013Salovey \u2013Caruso Emotional Intelligence Test (MSCEIT) to evaluate \nGPT-4\u2019s emotional intelligence. While GPT -4 excelled at understanding and managing emotions, its \nreflective analysis resembled the early developmental stages of human emotional  reasoning.  \nThe study of using LLMs for education and learning applications focuses on leveraging LLMs to address \nchallenges in education, such as providing personalized learning and improving learning motivation. LLMs \nlearn from massive amounts of data taken from boo ks and the Internet (Binz & Schulz, 2023b ) and can be \nused as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 426,
      "text": "ed as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al. (2024) , for \ninstance, found that an AI tutor powered by GPT -3 improved academic performance by up to 15 percentile \npoints through personalized learning strategies. Stojanov (2023)  used the following approach to explore \nGPT\u2019s potential as a learning tool: First, he set learning objectives and had \u201cconversations\u201d with GPT about \nits functionality for 4 hours. For the next 3 hours, he continued the discussion with GPT and watched some \nrelevant videos on YouTube. He experienced positive feedback from his interactions with GPT and found it \nto be a motivating and relevant learning experience.  \n \nTable 3  Applications of LLMs in educational and developmental psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nDevelopmental Research with LLMs  \nKosinski \n(2024)  Can LLMs demonstrate theory \nof mind (ToM) abilities?  Eleven  different  LLMs were tested on 40 \nfalse -belief tasks, requiring success in \neight related scenarios per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 427,
      "text": "os per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal. (2024)  How does GPT -4\u2019s emotional \nintelligence align with \ndevelopmental patterns in \nhuman emotional reasoning?  GPT-4 was evaluated using the Mayer -\nSalovey -Caruso Emotional Intelligence \nTest (MSCEIT) through text -based \nprompts.  GPT-4 excels in understanding and \nmanaging emotions but shows limited \nreflective analysis, resembling early \ndevelopmental stages in human \nemotional reasoning.  \nTrott et al. \n(2023)  How does exposure to language \ninfluence the development of \ntheory of mind in humans and \nAI? A linguistic False Belief Task was \npresented to humans and GPT -3 to assess \nbelief attribution abilities.  GPT-3\u2019s partial success suggests that \nwhile language exposure contributes to \nbelief reasoning, other developmental \nmechanisms unique to humans are \ncrucial for fully developing theory of \nmind.  \n \nLLMs for Education and Learning Applications  \nStojanov \n(2023)  How effective is GPT as a \nlearning aid in scaffolding \nunderstanding of a specific \ntopic? An autoethnographic study exploring the \nauthor\u2019s personal experience using \nChat GPT (3.5)  to learn about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 428,
      "text": "about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge.  \nJyothy et al. \n(2024)  What factors influence the \nadoption of LLMs like \nChat GPT in learning, teaching, \nand research?  The Fogg Behavior Model (FBM) was \napplied to analyze the motivations, \nabilities, and perceptions of students, \nteachers, and researchers toward LLM \nuse. User motivation and ability drive LLM \nadoption, but limitations like teacher \nhesitance and technical challenges hinder \nbroader integration.  \nLogacheva et \nal. (2024)  Can GPT-4 generate \npersonalized programming \nexercises to enhance student \nengagement and learning?  GPT-4-generated exercises were \nevaluated in an introductory \nprogramming course by students and \ninstructors for quality and engagement.  GPT-4 effectively produced high -quality, \nengaging exercises, offering \npersonalized and scalable practice \nmaterials for programming education.  \nMachin et al. \n(2024)  Can GPT demonstrate \npsychological literacy \ncomparable to subject matter \nexperts (SMEs) in psychology \nresearch methods?  GPT rated 13 research scenarios, and its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 429,
      "text": "nd its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy.  \nGhafouri \n(2024)  Can a ChatGPT-based rapport -\nbuilding protocol (CGRBP) \nenhance L2 (Second Language) \ngrit in English learners?  A 16 -week experimental study compared \n30 EFL learners (15 experimental, 15 \ncontrol) using pre -test post -test ANCOV A \nanalysis.  CGRBP significantly improved L2 grit, \ndemonstrating its potential to foster \nemotional support and learning \nmotivation.  \nGhafouri et \nal. (2024)  Can ChatGPT match expert \npsychological literacy in \nevaluating research methods?  The study compared responses from \nChatGPT to 13 psychological research \nmethod scenarios against ratings by \nsubject matter experts.  ChatGPT \u2019s responses correlated strongly \nwith expert evaluations, suggesting its \npotential as an educational tool in \npsychology, though its usage should be \napproached with caution.  \nBaillifard et \nal. (2024)  Can AI tutors improve \nacademic performance through \npersonalized learning \nstrategies?  A semester -long study with 51 \npsychology students using a GPT -3-\npowered AI tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 430,
      "text": "tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results.  \nNote\uff1a Theory of mind (ToM) is the cognitive ability to attribute mental states to oneself and others \uff1b the \nFogg Behavior Model (FBM) explains behavior as a product of motivation, ability, and prompts.  \n \n \n \n \n5. LLMs in social and cultural psychology  \nSocial and cultural psychology explores how individuals interact with and are influenced by their social \nand cultural environments. It focused on interpersonal dynamics, group behavior, social cognition, and the \nlong-term formation and transformation of at titudes and norms (Tajfel, 1982 ). Such phenomena occur at \nvarious time scales, from immediate social interactions to cultural changes evolving over several years \n(Newell, 1990 ). LLMs provide valuable tools for advancing social and cultural psychology. By analyzing \ntextual datasets, simulating social interactions, and modeling human -like behaviors, LLMs can provide \ninsights into the dynamics of social cognition, group processes, and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 431,
      "text": ", and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts.  \nResearch on LLMs in social and cultural psychology can be categorized into three main areas: cultural \nand cognitive understanding, social interactions and behavioral simulations, and practical applications. First, \nLLMs have many similarities with humans re garding social cognition. For example, research has found that \nLLMs reflect a variety of typical human cognitive biases in judgment and decision -making, such as the \nanchoring effect, the representativeness heuristic, and base -rate neglect (Talboy & Fuller, 2023 ). In addition, \ncultural psychology research has identified significant differences in the cognitive processes of Easterners \nand Westerners when processing information and making judgments (Nisbett et al., 2001 ); in this regard, \nLLM consistently favors holistic Eastern ways of thinking (Jin et al., 2023 ). Second, LLMs have been shown \nto characterize human groups in social interaction settings. It has been shown that LLMs can replicate the \nresults of Milgram\u2019s electroshock experiments (Aher et al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 432,
      "text": "al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 ). \nThird, LLMs are increasingly used as proxies for human participants in psychological research. One \nstudy, for example, explored the potential of LLMs to serve as valid proxies for specific human subgroups \nin social science research; it found that LLMs cont ained information that went far beyond superficial \nsimilarity, reflecting the complex interplay between ideas, attitudes, and sociocultural contexts that \ncharacterizes human attitudes (Argyle et al., 2022 ). In addition, LLM has been tested for personality and \nvalues, obtaining results comparable to those for human samples, indicating their potential as psychological \nresearch tools (Miotto et al., 2022 ). Within this broader perspective, industrial and organizational psychology \nhas increasingly employed LLMs, particularly in employee selection and workplace optimization, \ndemonstrating their broader utility for understanding human behavior in structured en vironments. For \nexample, LLMs have been shown to improve the accuracy and efficiency of recruitment systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 433,
      "text": "t systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates. LLMs have also been integrated into \nsystems such as PALR (personalization -aware LLMs for recommendation) to dynamically align individual \ncapabilities with o rganizational needs. Such systems significantly reduce inefficiencies in hiring processes \nand enhance predictions about job performance by identifying nuanced compatibility factors in resumes and \ncover letters (Yang et al., 2023 ). Beyond individual applications, LLMs have contributed to understanding \nbroader organizational cultures and transformational dynamics by providing insights into how group \ninteractions and leadership styles influence workplace outcomes (Noy & Zhang, 2023 ). In the context of \nemployee productivity, experiments using LLMs have revealed substantial benefits. For instance, \nprofessionals using ChatGPT in workplace writing tasks improved productivity by reducing task completion \ntime by 40% and enhancing output qu ality by 18%, indicating its potential to effectively augment mid -level \nprofessional tasks (Noy & Zhang, 2023 ). Similarly, research on creativity has demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 434,
      "text": "as demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology.  \nLLMs have many applications in social and cultural psychology, allowing us to test theories and \nhypotheses about human behavior in social and cultural interaction settings. Zhao et al. (2024) , for instance, \nexamined whether AI chatbots can adjust their financial decisions and prosocial behaviors based on \nemotional cues, similar to humans. It was hypothesized that bots would take fewer risks when exposed to \nfear cues and more risks with joy cue s. Emotional primes (fear, joy, or neutral) were applied, and investment \ndecisions were analyzed. Additionally, prosocial responses, such as donating to a sick friend, were measured \nto assess how LLMs adapt behaviorally under emotional influences.  These findings highlight LLMs \u2019 ability \nto model complex social dynamics and cultural influences. The next section broadens this perspective, \nexploring LLMs \u2019 potential as versatile research tools for psychologists.  \n \n \n \nTable 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 435,
      "text": "Table 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al. \n(2023)  Do LLMs exhibit biases \ntoward WEIRD (Western, \nEducated, Industrialized, \nRich, Democratic) societies in \npsychological tasks?  LLMs\u2019 responses on psychological measures \nwere compared to cross -cultural human data.  LLMs closely align with WEIRD \ncognitive patterns but show declining \naccuracy with non -WEIRD \npopulations (r = -0.70), revealing a \nWEIRD bias.  \nJin et al. \n(2023)  Does GPT exhibit cultural \ncognitive traits aligned with \nEastern or Western thinking?  GPT was evaluated using cognitive and value \njudgment  scales.  GPT leans towards Eastern holistic \nthinking in cognitive tasks but shows \nno cultural bias in value judgments, \nlikely influenced by its training data \nand methods.  \nSchaaff et al. \n(2023)  How empathetic is GPT \ncompared to humans?  GPT\u2019s empathy was evaluated through \nemotion recognition tasks, conversational \nanalysis, and five empathy -related \nquestionnaires.  GPT accurately identified emotions in \n91.7% of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 436,
      "text": "of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3.5, and GPT -4 match human \nempathy and emotion \nidentification?  Empathy and emotional understanding were \nassessed using TAS -20 (Toronto Alexithymia \nScale -20) and EQ -60 (Emotional Quotient \nInventory -60), comparing LLM responses to \nhuman benchmarks.  GPT-4 approached human -level \nemotional intelligence, outperforming \nBard and GPT -3.5, which showed \nalexithymic tendencies.  \nX. Wang et \nal. (2023)  How do LLMs compare to \nhumans in emotional \nintelligence?  A psychometric assessment focusing on \nEmotion Understanding  was developed and \napplied to mainstream LLMs, benchmarking \nthem against over 500 human participants.  GPT-4 scored higher than 89% of \nhumans in emotional intelligence, with \nLLMs showing above -average \nemotional intelligence  but using non -\nhuman mechanisms influenced by \nmodel design.  \nX. Li et al. \n(2022)  Are LLMs psychologically \nsafe, and how can fine -tuning \nimprove their safety?  LLMs were assessed using the Short Dark \nTriad (SD -3), Big Five Inventory (BFI), and \nwell-being tests to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 437,
      "text": "to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al. \n(2022)  What are GPT -3\u2019s personality \ntraits and values as assessed \nby validated psychological \ntools? Administered validated personality and values \nmeasurement tools to GPT -3, including a \nmodel response memory to assess value \nalignment.  GPT-3 exhibits personality traits and \nvalues similar to human samples, \nproviding initial evidence of \npsychological assessment in LLMs.   \n \nSocial Interactions and Behavioral Simulations  \nZhao et al. \n(2024)  Can LLMs like GPT adapt \nresponses to emotional primes \nin decision -making?  Tested GPT -4 and 3.5 with scenarios eliciting \npositive, negative, or neutral emotions.  GPT-4 showed distinct emotional \nresponse patterns, exceeding GPT -3.5, \nindicating advanced modulation but no \ntrue emotions.  \nAher et al. \n(2023)  Can LLMs accurately \nsimulate human behaviors, \nand what biases emerge in \ntheir simulations?  Introduced Turing Experiments to evaluate \nLLMs against findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 438,
      "text": "st findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal. (2023)  Do LLMs exhibit biases \ntoward math and STEM, and \nhow do these biases compare \nacross models and with \nhumans?  Using Behavioral Forma Mentis Networks, \nbiases in GPT -3, GPT -3.5, GPT -4, and high \nschool students were analyzed through a \nlanguage generation task.  Newer LLMs (GPT -4) show reduced \nnegative bias and richer semantic \nassociations toward math and STEM \ncompared to older models and \nhumans, suggesting advancements in \nreducing stereotypes.  \nAlmeida et \nal. (2024)  How do state -of-the-art LLMs \nreason about moral and legal \nissues, and how do their \nresponses align with human \njudgments?  Eight experimental psychology studies were \nreplicated using Google\u2019s Gemini Pro, \nAnthropic\u2019s Claude 2.1, GPT -4, and Meta\u2019s \nLlama 2 Chat 70b. Model responses were \ncompared to human responses to assess \nalignment and systematic differences.  GPT -4 showed the best human \nalignment among LLMs but \nexaggerated effects and reduced \nvariance, highlighting biases that limit \ntheir suitability as substitutes for \nhuman participants in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 439,
      "text": "in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks.  ChatGPT improved productivity (40% \nfaster task completion, 18% better \nquality).  \nLee and \nChung \n(2024)  How does ChatGPT influence \ncreativity?  Measured creativity using associative and \ndivergent thinking tasks.  ChatGPT supports incremental \ncreativity but is less effective for \nradical innovation.  \nYang et al. \n(2023)  Can LLMs personalize job \nrecommendations?  PALR(personalization -aware LLMs for \nrecommendation) integrated interaction data \nwith LLMs for dynamic recommendations.  PALR enhanced predictions of job \nperformance and improved role \nmatching.  \nDu et al. \n(2024)  How can LLMs improve job \nrecommendations?  Used GANs with LLMs to refine low -quality \nresumes.  GAN -based systems predicted better \njob fit and reduced hiring \ninefficiencies.  \nAkata et al. \n(2023)  How do LLMs perform in \nsocial interaction tasks \ninvolving cooperation and \ncoordination?  LLMs played repeated two -player games (e.g., \nPrisoner\u2019s Dilemma, Battle of the Sexes) with \nother LLMs and human -like strategies to \nanalyze their behavior.  LLMs perform well in self -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 440,
      "text": "lf -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al. \n(2024)  Does GPT exhibit heuristics \nand context -sensitive \nresponses similar to those \nobserved in human decision -\nmaking?  Four studies tested GPT\u2019s responses to \nprompts designed to assess cognitive biases \n(anchoring, representativeness, availability \nheuristic, framing effect, endowment effect) \nand compared them to human participant \nresponses.  GPT demonstrated biases consistent \nwith human heuristics across all \nstudies, suggesting that language \npatterns alone may contribute to these \neffects, independent of human \ncognitive and affective processes.  \nPark et al. \n(2022)  How can designers predict \nand refine social behaviors in \nlarge -scale social computing \nsystems before deployment?  Developed \u201csocial simulacra,\u201d an LLM -driven \nsimulation that generates realistic community \ninteractions based on design inputs (goals, \nrules, personas), allowing scenario testing and \niterative design refinement.  Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 441,
      "text": "Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al. \n(2022)  Can LLMs demonstrate social \nintelligence and Theory of \nMind (ToM)?  LLMs were evaluated using SocialIQa (social \nintents and reactions) and ToMi (mental states \nand realities), with results contextualized \nthrough pragmatics theories.  LLMs, including GPT -4, perform \nbelow human levels (55% on \nSocialIQa, 60% on ToMi), indicating \nthat scaling alone does not yield ToM, \nhighlighting the need for person -\ncentric NLP approaches.  \nArgyle et al. \n(2022)  Can GPT -3 reliably emulate \nhuman subpopulations for \nsocial science research?  GPT-3 was conditioned on sociodemographic \nbackstories from U.S. surveys, creating \n\u201csilicon samples,\u201d which were compared to \nhuman survey data.  GPT-3 exhibits nuanced, \ndemographically aligned biases, \nindicating its potential as a tool for \nstudying human behavior and societal \ndynamics.  \nP. S. Park et \nal. (2024)  Can GPT -3.5 simulate human \nparticipants and replicate \nsocial science study results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 442,
      "text": "udy results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37.5% of study \nresults but exhibited uniform \nresponses (\u201ccorrect answer\u201d effect) \nand skewed conservative in moral \nfoundation surveys, questioning its \nreliability and diversity as a human \nparticipant substitute.  \nNote:  WEIRD (Western, Educated, Industrialized, Rich, Democratic) refers to societies that represent a \nminority of the global population but are often overrepresented in psychological research.  \n \n6. LLMs as research tools in psychology  \nSections 2 -5 illustrate LLMs \u2019 applications across cognitive, clinical, educational, and social psychology, \nrevealing their potential to transform research practices. Together, these advancements speed up \npsychological research with new tools, encourage collaboration with fields like c omputer science and \nlinguistics, and improve theoretical models through behavioral simulation \u2014key ways LLMs advance \npsychology. Building on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 443,
      "text": "on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5). By reducing subjective bias and minimizing human variability in tasks like stimulus generation \n(Section 2), standardized assessments (Section 3), and data inter pretation (Section 4), LLMs enhance \nobjectivity and efficiency across these applications.  \nFor instance, LLMs can automate systematic reviews and meta -analyses, revolutionizing evidence \nsynthesis and provide actionable insights for psychologists, as grounded in cognitive and behavioral \nprinciples  (e.g., in Sections 2 and 3).  This capacity extends to enhancing psychologists \u2019 workflows, \nbuilding on productivity improvements noted in Section 5, through tools like literature review, hypothesis \ngeneration, experimental design, experimental subjects, and data analysis (Table 5).  \nTable 5. LLMs as research tools in psychology study.  \nTopic  Related study  \nLiterature review  LLMs can summarize the researched literature (Dis, Bollen, Zuidema, Rooij, & Bockting, 2023) , complete literature \nreview tasks (Qureshi et al., 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 444,
      "text": ", 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al., 2022) \u3002 \nHypothesis \ngeneration  LLMs can generate hypotheses from scientific literature, make inferences based on scientific data, and then clarify \ntheir conclusions through interpretation (Zheng et al., 2023) , and can quickly and automatically test these research \nhypotheses and learn from mistakes . \nExperimental \ndesign  \n LLMs provide text -based material for experimental design, thereby optimizing the research process and reducing \nexperimental complexity. By employing these models, researchers can easily create experimental stimuli, develop \ntest items, and even simulate interactive sessions in con trolled environments  (Aher, Arriaga, & Kalai, 2022; Akata \net al., 2023) , providing a high degree of control and precision to the experimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 445,
      "text": "erimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al., 2023) , their use in place of human participation in experiments \nsaves time and costs and can be applied to some experiments where human participation is not appropriate (Hutson, \n2023 ), they can be combined with factors such as the specific research topic, the task, and the sample, and the use \nof LLM as an alternative to research participants where appropriate (Dillion et al., 2023 ). \nData analysis  LLMs can efficiently analyze massive amounts of textual data to gain insights into human behavior and emotions \nat an unprecedented scale  (Patel & Fan, 2023) , can analyze textual data in multiple languages, and accurately detect \nmental structures within it (Rathje et al., 2023) , can draw mental profiles from social media data (Peters & Matz, \n2023)\u3002 \nScholarly \nCommunication  LLMs can also help humans in writing (Dergaa et al., 2023 ; Stokel -Walker, 2022 ; Van Dis et al., 2023 ). LLMs were \nused in two natural language processing tasks and a human expert to assess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 446,
      "text": "ess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D. students struggling to finish their dissertations, to peer reviewers submitting \nanalyses under time pressure (Van Dis et al., 2023 ). \n \n6.1.  Automated literature review and meta -analysis  \nConducting a literature review meta -analysis is a complex, arduous process that requires significant \ntime and expertise (Michelson & Reuter, 2019 ). Nature reported that researchers have used GPT as a research \nassistant to summarize literature (Dis et al.  2023) . In one study, researchers used GPT to complete certain \nsystematic literature review tasks (Qureshi et al., 2023) . In another study, a literature review article was \ncreated using GPT with the application of digital twins in the health field; the results showed that knowledge \ncompilation and representation were accelerated with the help of LLMs. However, their academi c validity \nneeds to be further verified (Ayd\u0131n & Karaarslan, 2022) . Researchers have also specifically trained LLMs to \nsupport the practical needs of scientific research (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 447,
      "text": "ch (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal. (2024)  demonstrated that LLMs can screen literature, extract data, and generate statistical codes for meta -\nanalyses, significantly reducing workload while maintaining recall rates comparable to manual curation. \nSimilarly, Tong et al. (2024)  used LLMs to extract causal pairs from 43,312 psychology articles, achieving \nan 86.98% success rate in pair extraction through adaptive prompting. As discussed in section 3, LLMs have \nshown strong capabilities in extracting causal relationships from large  textual datasets, underscoring their \npotential to streamline evidence synthesis for systematic reviews and meta -analyses. Nevertheless, while \nLLMs excel in organizing qualitative data and identifying conceptual patterns, they face challenges in \nextracting  the precise numerical data necessary for meta -analyses. For example, although LLM -based tools \ncan retrieve and summarize outcome measures, manual validation remains essential to ensure accuracy, \nespecially when processing complex figures or tables.  \nIn summary, LLMs can speed up the process of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 448,
      "text": "ess of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2.  Hypothesis generation and experimental design  \nHypothesis -driven research is at the core of scientific activity. LLMs can generate hypotheses from \nscientific literature, make inferences based on data, and then clarify conclusions through interpretation \n(Banker et al., 2024 ; Zheng et al., 2023 ). Although LLMs are capable of becoming \u201chypothesis machines,\u201d \ntheir logical and mathematical derivation capabilities still need improvement to eliminate factual errors, \nquickly test hypotheses, and learn from mistakes (Y . J. Park et al., 2024 ) . As innovative tools, LLMs have \ngreat potential for use in psychological experiments, given their ability to provide text -based material for \nexperimental designs, thus optimizing the research process and reducing experimental complexity. Using \nsuch model s researchers can easily create experimental stimuli, develop test items, and even simulate \ninteractive sessions in controlled environments (Aher, Arriaga, & Kalai, 2022; Akata et al., 2023) , providing \na high degree of control and precision in the experimental process.  \nIn conclusion, LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 449,
      "text": "LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3.  LLMs as subjects in psychological experiments  \nAlthough LLMs can simulate some human behaviors and responses \u2014which provides an opportunity \nto test theories and hypotheses about human behavior (Grossmann et al., 2023) \u2014there is still some \ncontroversy on whether LLMs can be used as a substitute for human subjects in psychological research. \nWhile recognizing that certain problems persist (e.g., biases and insufficiently trained data), some \nresearchers have suggested that LLMs can be used as substitutes for human participants to save time and \ncost and can be applied to experiments that are not suitable for human participation (Hutson,2023) . Others \nhave proposed using LLMs as an alternative method of studying participants when appropriate, based on \ntheir performance in conjunction with factors such as specific research topics, tasks, and samples (Dillion et \nal., 2023 ). However, it is also believed that although LLMs can significantly affect scientific research, they \nare unlikely to replace human participants in any meaningful way (Harding et al., 2023 ). At the same time, \nsome studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 450,
      "text": "some studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects.  \nIn conclusion, although LLMs can simulate human judgment, their simulation of human thinking \nremains limited, and their output should be validated and interpreted with caution when used as \npsychological subjects.  \n6.4.  Tools for data analysis  \nVarious forms of AI have long been used to analyze psychological data, such as flight data for pilot \nscreening (Ke et al., 2023 ). Machine learning algorithms facilitate the processing of large datasets, \nidentifying patterns and correlations that might otherwise be overlooked. However, LLMs take this \ncapability to a new level; they can efficiently analyze massive amounts of textual data on an unprecedented \nscale to derive insights into human behavior and emotions (Patel & Fan, 2023) . For psychological research, \nthis means faster and more comprehensive data analysis, leading to more reliable, nuanced findings. LLMs \ncan analyze textual data in multiple languages, accurately detect psychological structures within them \n(Rathje et al., 20 23), and generate psychological profiles from social media data (Peters & Matz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 451,
      "text": "atz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation. Yet, LLMs cannot \noutperform experienced neuroradiologists, suggestin g the need for continued improvement in the medical \ncontext (Nazario -Johnson et al., 2023 ). These findings demonstrate the great potential of LLMs for \nevaluating and analyzing data.  \n6.5.  Promoting scholarly communication  \nScholarly communication is a cornerstone of academic research, encompassing the processes of \ncreating, evaluating, and disseminating knowledge. It includes writing research papers, conducting peer \nreviews, and ensuring that findings are communicated transp arently and ethically. In psychology, this process \nis particularly complex owing to the field\u2019s diverse theoretical frameworks and methodological approaches, \nranging from experimental to qualitative research. The discipline\u2019s focus on human behavior and it s \nintersection with technology demands precise and ethical communication practices.  \nIt has been argued that LLMs currently cannot completely replace human writing and instead can only \nanswer questions and generate naturally fluent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 452,
      "text": "uent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing. The experimental group that used GPT was found to be similar to the control group \nin terms of writing quality, speed, and authenticity; the authors suggested that this could be because \nexperienced researchers can better guide GPT to produce high -quality information. By contrast, students \u2014\nwho have less writing experience than researchers \u2014found that GPT did not perform as effectively (Ba\u0161i\u0107 et \nal., 2023 ). Another article discussed the prospects and potential threats of GPT in academic writing, \nemphasizing that using GPT in academic research should prioritize peer -reviewed scholarly sources. Yet, \nGPT\u2019s potential advantages for academic research, including the handling of large amounts of textual data \nand the automatic generation of abstracts and research questions (Dergaa et al., 2023 ), were highlighted. \nFurthermore, LLMs can potentially be used for peer review (Van Dis et al., 2023 ). The decisions/judgments \nof LLMs in a text -evaluation task were found to be consistent with those of human experts (Chiang & Lee, \n2023) . \nIn conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 453,
      "text": "n conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually. They \ncan be used to scan academic papers and extract es sential details, generate objective and unbiased abstracts, \nand create research questions in social psychology (Banker et al., 2023 ; Tong et al., 2024 ). However, \nresearchers must exercise caution when using them as they can also introduce false or biased information \ninto papers, leading to unintentional plagiarism and the misattribution of concepts (Van Dis et al., 2023 ). \n \n \n7. Challenges and future directions  \n7.1.  Challenges and limitations  \nLLMs have enormous potential to simulate complex cognitive processes, providing researchers with \nnew tools to explore the mechanisms of human cognition and behavior for wide -ranging application in \nvarious fields, including clinical and counseling psycholog y, educational and developmental psychology, \nand social and cultural psychology. However, LLM output should not be mistaken for the presence of thought \nbut instead viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 454,
      "text": "d viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding. \nThe interpretation of LLMs\u2019 capabilities must be based on an understanding of their limitations and the \nnature of their operations, which might differ fu ndamentally from human cognition. It is essential, then, to \nfocus on the potential of LLMs in psychological research while also acknowledging the technical and ethical \nchallenges that might arise.  \nFirst, despite the emergence of LLM competence (Wei et al., 2022 ), its internal working mechanism \nremains a black box from a cognitive and behavioral psychology perspective. For example, LLMs perform \nimpressively on tasks requiring formal linguistic competence (including knowledge of the rules and patterns \nof a particul ar language) but fail many tests requiring functional competence (the set of cognitive abilities \nneeded to understand and use language in the real world) (Mahowald et al., 2023 ). They excel in analogical \nand moral reasoning tasks but perform poorly on spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 455,
      "text": "spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 ). For example, gatekeepers, patients, and even mental \nhealth professionals who use GPT to assess suicide risk or improve decision -making might receive \ninaccurate assessments that underestimate risk (Elyoseph & Levkovich, 2023 ) or bias clinician decision -\nmaking, which can lead to healthcare inequities (Pal et al., 2023 ). In addition, LLMs in psychiatry research \nand practice have been associated with potential bias and privacy violations (Zhong et al., 2023 ). \nThird, LLMs face application challenges in fields such as educational, developmental, and social and \ncultural psychology. It is evident that when applied in education, LLMs have the potential for output bias \nand misuse (Kasneci et al., 2023 ). One study found that texts generated by GPT were not always consistent \nor logical and sometimes even contradictory (Stojanov, 2023 ). In the field of social and cultural psychology, \nLLMs exhibit cognitive biases (Talboy & Fuller, 2023 ) and cultural biases (Atari et al., 2023 ) similar to those \nof humans, in addition to implicitly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 456,
      "text": "citly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings.  \nFinally, LLMs have some limitations as aids to scientific research. With regard to writing, for example, \nLLMs currently cannot fully replace humans. Instead, they answer questions and generate naturally flowing, \ninformative content lacking real intelligenc e (Stokel -Walker, 2022) . Although macrolanguage models can \nsimulate human judgment when used as experimental subjects, there are still limits to their \u201cunderstanding\u201d \nof human thought (Dillion et al., 2023 ). Van Dis et al. (2023)  noted that LLMs might accelerate innovation, \nshorten publication times, and increase scientific diversity and equality. However, they might also reduce \nthe quality and transparency of research and fundamentally alter scientists\u2019 autonomy as human research ers. \nIn summary, while LLMs offer extraordinary capabilities for psychological research, they also present \nchallenges related to bias, ethical issues, data security, transparency, and technical expertise. Researchers \nshould be fully aware of these challenges wh en using LLMs and adopt the following steps for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 457,
      "text": "s for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation. Third, use diverse training data to \nreduce cultural or gender biases. Fourth , in sensitive areas like mental health, limit use to assist \u2014not \nreplace\u2014judgment and train users to interpret outputs critically. These steps, supported by recent studies \n(Abdurahman et al., 2024; Guo et al., 2024; Porsdam Mann et al., 2024), address ethi cal concerns in \npsychological research.  Table 6 summarizes the challenges and limitations of LLMs in psychological \napplications.  \nTable 6  Challenges and limitations of LLMs in psychological applications.  \nChallenges  Author  Details  \nCogniti ve and Behavior al Psychology  \nLack of Real -World \nUnderstanding  Mitchell \n(2023)  LLMs lack real -world understanding, abstract reasoning, and intent comprehension.  \nLack of Meta -\nknowledge  Stella et al. \n(2023)  LLMs fabricate information (hallucination) and lack curiosity/meta -knowledge.  \nCausal Reasoning and \nCreativity  Sartori and \nOrr\u00f9 (2023)  Poor causal reasoning, dependence on biased training data, lack of creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 458,
      "text": "creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al. \n(2023)  Forgetting knowledge in new tasks, poor common -sense reasoning, inconsistent problem -\nsolving.  \nModel Behavior \nChallenges  Holtzman et \nal. (2023)  Lack of interpretability and formal behavioral descriptions makes systematic analysis difficult.  \nPsycholinguistic \nFeatures  Seals and \nShalin \n(2023)  GPT and human -generated analogies differed in these stylistic dimensions, these lexical \nfeatures, their choice of words for these features and these devices that help readers understand \ntext. GPT may lack human cognitive and psycholinguistic features when generating analogies.  \nClinic and Counseling  Psychology  \nTechnical Limitations& \nPatient Connection \nIssues  Stade et al. \n(2023)  Difficulty assessing suicide risk, substance abuse, safety issues, and interpreting nonverbal \ncues& Problems forming therapeutic relationships, interpreting nonverbal behaviors.  \n \nEducation and Development  Psychology  \nIntegrity and Ethics \nIssues  Li et al. \n(2023)  Academic integrity concerns, misinformation, data privacy, and impact on critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 459,
      "text": "n critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity.& \nLimited support for diverse languages and equitable access.  \nSocial and Culture  Psychology  \nLiability and Privacy \nIssues  Fecher et al. \n(2023)  Liability issues: challenging traditional mechanisms of authorship and liability. Bias issues: \naffecting the objectivity and impartiality of science. Privacy and data protection issues: may be \nprivacy issues with the training data of LLMs. Intellectual pro perty issues: potential legal \ndisputes. Environmental issues: generating large amounts of carbon emissions, which can have \na negative impact on the environment.  \nGlobal Diversity \nIgnorance  Atari et al. \n(2023)  Ignoring global psychological diversity (e.g., tend to favor the psychological characteristics of \nWEIRD societies) and which can lead to prejudice and discrimination against people of other \ncultures and backgrounds. Differences in values and moral judgment s and which can lead to \nproblems of communication and understanding in multicultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 460,
      "text": "icultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal. (202 4) Reduced innovation and development, bias and discrimination, culture clash and conflict, \ndifferences in values and morals and entrenchment of the status quo.  \nSocial Context \nLimitations  Salah et al. \n(2023)  Limited understanding of social context: Although GPT  performs well in syntax and general \nsemantics, it still has limitations in capturing the nuances of social language.  Ethical challenges: \nAI-generated fake content can lead to ethical issues including digital personhood, informed \nconsent, potential manipulation, and the implications of using AI to simulate human \ninteractions.  \nBias and Misleading Hayes Potential biases: if the training data contain biases, LLMs may learn and replicate them. Data \nOutputs  (2023)  privacy and consent issues: Text generated using LLMs may involve data privacy and consent \nissues.  Output may be non -humanly understandable: although LLMs generate text that closely \nresembles human language, they do not truly understand the content and may generate absurd \nor misleading responses.  \nTraining Data Bias  Miotto et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 461,
      "text": "to et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements.  \nResponsibility and control: Due to the complexity of language models, it is difficult to determine \nwho is responsible for the model's output, which can lead to attribution of problems and lack of \ncontrols.  \nPropagation of Harm  Bender et \nal. (2021)  Potential Harm: LLMs may lead to the propagation of harmful ideas such as stereotyping, \ndiscrimination, and extremism, and may lead to misinformation and bullying when generating \ntext. Data bias and unfairness: leading to potential harm to marginalized communities. \nAutomating bias: exacerbating existing biases and discrimination.  Enhancement of authoritative \nviewpoints: LLMs may reinforce dominant viewpoints in the training data, further undermining \nmarginalized people.  \nAlignment Challenges  Tamkin et \nal. (2021)  Alignment: In order to better align models with human values, algorithmic improvements are \nneeded to increase factual accuracy and robustness against adversarial samples. In addition, \nappropriate values need to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 462,
      "text": "to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al. \n(2020)  Misuse of language modeling: GPT -3 may be used to generate fake news, spread extremist \nideas, conduct cyber -attacks and other malicious uses.  Fairness, bias, and representation: GPT -\n3 may carry bias against gender, race, and religion, among others, sparking related \ncontroversies.  News generation: News generated by GPT -3 may be difficult to distinguish from \nreal news, leading to confusing and misleading information.  \nResearch Tools  \nPlagiarism and \nCopyright Issues  Sallam \n(2023)  Plagiarism: content generated by GPT may be considered plagiarized, violating academic \nnorms.  Copyright issues:  Is the generated content owned by GPT or by the user?  Transparency \nissues: The workings of GPT may not be transparent, making it difficult for users to understand \nthe source of generated content. Liability issues: who is responsible for GPT when generating \nincorrect content?  \nTransparency \nLimitations  Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 463,
      "text": "Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content.  Legal \nand Ethical Issues: Generative AI models may involve intellectual property, privacy, and ethical \nissues, requiring attention to compliance with relevant laws and regulations during use.  \nAcademic Integrity \nConcerns  Dergaa et \nal. (2023)  Integration of erroneous or biased information. Problems with citing original sources and \nauthors. Impact on academic integrity and quality. Increased inequity and inequality: Difficulty \nin recognizing AI -generated content. Academic evaluation and recognit ion issues. Direct \nreplacement for academic researchers: GPT is not a complete replacement for academic \nresearchers as it has limitations in certain types of academic research.  \nPrivacy and Bias Risks  Peters and \nMatz \n(2023)  User privacy: LLMs can infer psychological traits from a user's social media data, which may \nviolate the user's privacy. Potential bias: LLMs may create potential bias in the inference \nprocess, which may lead to unfair treatment of specific groups (e.g., gender, age, etc.). Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 464,
      "text": ". Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al. \n(2023)  Academic misconduct: GPT may be used for academic cheating, such as generating false papers \nor assignments.  Challenges in the medical field: GPT  has limitations in medical image analysis, \nwhich may lead to wrong diagnosis and jeopardize patients' health.  \n \n7.2.  Future directions and emergent trends  \nCurrently, LLMs are used in different areas of psychology, including cognitive and behavioral, clinical \nand counseling, educational and developmental, and social and cultural psychology. As the capabilities of \nLLMs are further enhanced, their potential applications in psychology will continue to develop.  \nFirst, in the field of cognitive and behavioral psychology, with the emergence of multimodal LLMs \n(OpenAI, 2023 ), it is possible to combine visual and auditory information with textual data to better \nunderstand and model emotions, behaviors, and mental states for cognition. However, neuroimaging data \ncan be used to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 465,
      "text": "to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought.  \nSecond, in the field of clinical and counseling psychology, on the one hand, personal data, such as social \nmedia posts, medical records, or wearable device data, can be used to create tailored, personalized LLMs \nthat provide more accurate and relevant insi ghts into an individual\u2019s state of mind. At the same time, the \nstrengths of human clinical and counseling expertise can be combined with the scalability and computational \npower of LLMs to create new diagnostic treatment and intervention tools. In addition,  in educational and \ndevelopmental psychology and social and cultural psychology, it is essential to build ethical LLMs and \nensure they are designed and deployed in a way that respects privacy and uses data fairly and responsibly.  \nUltimately, LLMs represent a systematic project whose future development cannot be achieved without \nthe interdisciplinary collaboration of researchers in diverse fields such as psychology, computer science, and \nlinguistics. For psychology researchers, acce ssible open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 466,
      "text": "ble open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application.  \nTable 7  Future directions and emergent trends of LLMs in psychological applications . \nAuthor  Future directions and emergent trends  \nCognition and Behavior  \nD'Oria (2023)  Delving into Human -Computer Interaction (HCI) to understand AI's ability to mimic human behavior.  Exploring how \nAI language modeling can be applied in the human sciences to improve research efficiency and quality  \nCrockett and \nMesseri (2023)  Focus on the costs of adopting alternative human narratives in cognitive science research, such as masking the human \nlabor behind them and the impact on human well -being.  Concern about the impact of technological developments on \nscientific work and human understanding to ensure that cognitive scientists remain proactive in technological advances.  \nBinz and \nSchulz \n(2023b)  Explore ways to make LLMs more stable and robust in the face of descriptive tasks.  \nInvestigate whether LLMs can learn to explore purposefully and how to better utilize causal knowledge in tasks.  Analyze \nthe performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 467,
      "text": "the performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans.  \nHuang and \nChang (2022)  Improve the reasoning ability of LLMs to encourage reasoning by optimizing training data, model architecture, and \noptimization goals.  Develop more appropriate evaluation methods and benchmarks to measure the reasoning ability of \nLLMs to better reflect the true reasoning ability of the models.  Investigate the potential of LLMs in different applications \n(e.g., problem solving, decision making and planning tasks).  Explore other forms of reasoning (e.g., inductive and \nretrospective reasoning).  \nClinic and Counseling  \nAbd-Alrazaq \net al. (2019)  Develop more chatbots for people with mental illness, especially for those with disorders such as schizophrenia, \nobsessive -compulsive disorder and bipolar disorder.  \nImplement more chatbots in developing countries to address the shortage of mental health professionals.  Conduct more \nrandomized controlled trials to evaluate the effectiveness of chatbots in mental health.  \nStade et al. \n(2023)  Developing new therapeutic techniques and evidence -based practices (EBPs). Focus on evidence -based practices first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 468,
      "text": "es first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success.  Involve interdisciplinary collaboration. \nFocuses on therapist and patient trust and usability. Criteria for designing effective clinical LLMs.  \nDemszky et al. \n(2023)  Development of high -quality cornerstone datasets: these datasets need to encompass populations and psychological \nconstructs of interest and be associated with psychologically important outcomes (e.g., actual behaviors, mindfulness, \nhealth, and mental well -being). Focus on future research directions in consumer neuroscience and clinical neuroscience: \nresearch in these areas may involve the neural systems of marketing -related behaviors, decision neuroscience, \nneuroeconomics, and more.  \nEducation and Development  \nHagendorff \n(2023)  Developmental psychology: examining how LLMs develop cognitively, socially, and emotionally over the lifespan and \nhow these models can be optimized for specific tasks and situations. Learning psychology: studying how LLMs acquire \nand retain knowledge and s kills, and how to optimize these models to improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 469,
      "text": "o improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities.  Investigate ways to combine static text with rich social intelligence and interaction data to improve \nsocial intelligence in LLMs. Investigate the theoretical -psychological abilities of LLMs in more naturalistic settings to \nreveal their performance in real -world scenarios.   \nArgyle et al. \n(2022)  Investigate the algorithmic fidelity of the GPT -3 model and how appropriate conditioning can allow the model to \naccurately simulate the response distributions of various human subgroups.  Created \"in silico samples\" by conditioning \non the socio -demographic backgrounds of real human participants in multiple large U.S. surveys.  \nSchaaff et al. \n(2023)  Developing more advanced models: to more accurately capture the emotional context of conversations and improve \nemotional understanding and expression.  Measuring the emotional capabilities of bots: to investigate how to assess the \nemotional capabilities of chatbots in order to better understand how they behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 470,
      "text": "ey behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al. \n(2023)  Cross -cultural CSS research: future research should separately consider the utility of LLMs for cross -cultural CSS in \norder to better serve social science research in different cultural contexts.  Future research could explore contrastive or \ncausal explanations in LLMs.  New paradigms for social science and AI collaboration.  \nResearch Tools  \nVan Dis et al. \n(2023)  Invest in truly open LLMs: develop and implement open -source AI technologies to increase transparency and democratic \ncontrol.  Embrace the advantages of AI: utilize AI to accelerate innovation and breakthroughs at all academic stages, \nwhile focusing on issues of ethics and human autonomy.  Broaden the discussion: organize international forums to \ndiscuss the development and responsible use of LLMs in research, including issues of diversity and inequality.  \nFecher et al. \n(2023)  Analyzing the risks and opportunities of LLMs for science systems. Examining how LLMs affect academic quality \nassurance mechanisms, academic misconduct, and scientific integrity. Exploring the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 471,
      "text": "the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8. Conclusion  \nWith the rapid development of AI technologies, especially the continuous advancement of LLMs, \nmachine learning has reached the point where it can recognize and generate human language. This \ndevelopment is not simply a technological breakthrough for the fie ld of psychology, but it opens the door to \na range of potential applications.  \nFirst, in the field of cognitive and behavioral psychology, LLMs are excelling in a variety of cognitive \ntasks. Although there are still limitations in causal cognition and planning, these models resurrect the \nprinciple of association, demonstrating the ab ility to associate at a distance and reason in complex ways. At \nthe same time, the ability to adapt LLMs to cognitive models is a significant strength of psychological \nresearch, allowing for new explorations of human cognitive and behavioral processing mec hanisms.  \nSecond, in clinical and counseling psychology, LLMs can be used as preliminary diagnostic tools for \nmental health. While traditional mental health diagnosis relies on the experience of professionals and direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 472,
      "text": "nd direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content. Importantly, while such \ndiagnoses cannot wholly replace professional psychological assessment, they can serve as a n effective \nadjunct to help psychologists understand a patient\u2019s condition more quickly, or play a role in primary mental \nhealth interventions. Meanwhile, personalized psychological intervention is another critical application \ndirection for LLMs. By combining informat ion about an individual\u2019s health data and lifestyle habits, these \nmodels can provide tailored psychological advice and intervention programs. Such personalized approaches \ncould be crucial for improving the effectiveness of psychological interventions.  \nThird, LLMs have the same potential for application in both educational and developmental psychology \nand social and cultural psychology. For example, LLMs provide interactive and personalized learning \nexperiences or generate research tasks based on real -life applications that increase motivation and enhance \nlearning. In addition, by analyzing large amounts of social media data, these models can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 473,
      "text": "s can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency. Researchers can \nuse these models to quickly organize and analyze large amounts of literature, thus saving time. These models \ncan also assist with experimental design, dat a analysis, and even promoting scholarly communication, \nmaking psychological research more efficient and precise.  \nIn light of the above, LLMs have promising applications for psychology, such as research support, \ncognitive modeling, individualized intervention, and personalized learning. LLMs also have the potential to \ndramatically improve our understanding of human co mmunication, thought processes, and behaviors, \nleading to the development of more comprehensive theories of mind and cognitive science. At the same time, \nit is important to be aware of the related risks and challenges and to ensure adherence to ethical sta ndards, \nespecially with regard to individual privacy and data security. It is also important to recognize that no matter \nhow technologically advanced they are, LLMs can only partially replace the judgment and experience of \nhuman professionals. Therefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 474,
      "text": "herefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019). An overview \nof the features of chatbots in mental health: A scoping review. International Journal of Medical \nInformatics , 132, 103978. https://doi.org/10.1016/j.ijmedinf.2019.103978   \nAbdurahman, S., Atari, M., Karimi -Malekabadi , F., Xue, M. J., Trager, J., Park, P. S., ... & Dehghani, M. (2024). \nPerils and opportunities in using large language models in psychological research. PNAS nexus , 3(7), \npgae245.  \nAbramski, K., Citraro, S., Lombardi, L., Rossetti, G., & Stella, M. (2023). Cognitive network science reveals bias \nin gpt -3, gpt -3.5 turbo, and gpt -4 mirroring math anxiety in high -school students. Big Data and Cognitive \nComputing , 7(3), 124.  \nAgrawal, S. (2023). Are LLMs the Master of All Trades? : Exploring Domain -Agnostic Reasoning Skills of LLMs. \narXiv preprint . https://doi.org/10.48550/arxiv.2303.12810   \nAher, G., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate multiple humans and \nreplicate human subject studies  Proceedings of the 40th International Conference on Machine Learning, \nHonolulu, Hawaii, USA.  \nAkata, E., Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 475,
      "text": "Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M., Shamsan, M. A. A., Hezam, T. A., & Mohammed, A. A. Q. (2023). Impact of ChatGPT on Learning \nMotivation. Journal of English Studies in Arabia Felix , 2(1), 41 -49. \nhttps://doi.org/10.56540/jesaf.v2i1.51   \nAlmeida, G. F., Nunes, J. L., Engelmann, N., Wiegmann, A., & de Ara\u00fajo, M. (2024). Exploring the psychology \nof LLMs\u2019 moral and legal reasoning. Artificial intelligence , 333, 104145.  \nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J., Rytting, C., & Wingate, D. (2022). Out of One, Many: Using \nLanguage Models to Simulate Human Samples. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2209.06899   \nAtari, M., Xue, M. J., Park, P. S., Blasi, D. E., & Henrich, J. (2023). Which Humans? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/5b26t   \nAyd\u0131n, \u00d6., & Karaarslan, E. (2022). OpenAI ChatGPT Generated Literature Review: Digital Twin in Healthcare. \nEmerging Computer Technologies (2), 22 -31. https://doi.org/10.2139/ssrn.4308687   \nBaillifard, A., Gabella, M., Lavenex, P. B., & Martarelli, C. S. (2024). Effective learning with a personal AI tutor: \nA case study. Education and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 476,
      "text": "and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10.31234/osf.io/kv6f7   \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2024). Machine -assisted social psychology hypothesis \ngeneration. American psychologist , 79(6), 789.  \nBa\u0161i\u0107, \u017d., Banovac, A., Kru\u017ei\u0107, I., & Jerkovi\u0107, I. (2023). ChatGPT -3.5 as writing assistance in students\u2019 essays. \nHumanities and Social Sciences Communications , 10(1). https://doi.org/10.1057/s41599 -023-02269 -7  \nBender, E. M., Gebru, T., McMillan -Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: \nCan Language Models Be Too Big?  Proceedings of the 2021 ACM Conference on Fairness, \nAccountability, and Transparency, Virtual Event, Canada. https://doi.org/10.1145/3442188.3445922  \nBinz, M., & Schulz, E. (2023a). Turning large language models into cognitive models. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2306.03917   \nBinz, M., & Schulz, E. (2023b). Using cognitive psychology to understand GPT -3. Proceedings of the National \nAcademy of Sciences of the United States of America , 120(6), e2218523120. \nhttps://doi.org/10.1073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 477,
      "text": "073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b). Personal narrative and stream of consciousness: an AI approach. The \nJournal of Positive Psychology , 1-7. https://doi.org/10.1080/17439760.2023.2257666   \nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \nAskell, A., Agarwal, S., Herbert -Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. \nM., Wu, J., Winter, C.,\u2026Amodei, D. (2 020). Language Models are Few -Shot Learners. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2005.14165   \nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E. K., Kamar, E., Lee, P., Lee, Y. T., Li, Y. -F., \nLundberg, S. M., Nori, H., Palangi, H., Ribeiro, M. T., & Zhang, Y. (2023). Sparks of Artificial General \nIntelligence: Early experiments with GPT -4. arXiv preprint . https://doi.org/10.48550/arXiv.2303.12712   \nCharness, G., Jabarian, B., & List, J. A. (2023). Generation next: Experimentation with ai .  \nChiang, C. -H., & Lee, H. -y. (2023). Can Large Language Models Be an Alternative to Human Evaluations? arXiv \npreprint . https://doi.org/10.48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 478,
      "text": ".48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023). Can AI Language Models Improve Human Sciences Research? A Phenomenological Analysis \nand Future Directions. Encyclopaideia , 27(66), 77 -92. https://doi.org/10.6092/issn.1825 -8670/16554   \nD\u2019Souza, R. F., Amanullah, S., Mathew, M., & Surapaneni, K. M. (2023). Appraising the performance of ChatGPT \nin psychiatry using 100 clinical case vignettes. Asian Journal of Psychiatry , 89, 103770.  \nDe Bot, K., Lowie, W., & Verspoor, M. (2007). A Dynamic Systems Theory approach to second language \nacquisition. Bilingualism: Language and Cognition , 10(1), 7 -21. \nhttps://doi.org/10.1017/S1366728906002732   \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., Eichstaedt, J. C., Hecht, C., \nJamieson, J., Johnson, M., Jones, M., Krettek -Cobb, D., Lai, L., JonesMitchell, N., Ong, D. C., Dweck, \nC. S., Gross, J. J., & Pennebaker, J. W. (20 23). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDergaa, I., Chamari, K., Zmijewski, P., & Ben Saad, H. (2023). From human writing to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 479,
      "text": "g to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023.125623   \nDhingra, S., Singh, M., Sb, V., Malviya, N., & Singh Gill, S. (2023). Mind meets machine: Unravelling GPT -4's \ncognitive psychology. arXiv preprint , arXiv:2303.11436. https://doi.org/10.48550/arXiv.2303.11436   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human participants? Trends \nin Cognitive Sciences , 27(7), 597 -600. https://doi.org/10.1016/j.tics.2023.04.008   \nDu, Y., Luo, D., Yan, R., Wang, X., Liu, H., Zhu, H., Song, Y., & Zhang, J. (2024). Enhancing job recommendation \nthrough llm -based generative adversarial networks. Proceedings of the AAAI Conference on Artificial \nIntelligence,  \nDubey, R., Hardy, M. D., Griffiths, T. L., & Bhui, R. (2024). AI -generated visuals of car -free US cities help \nimprove support for sustainable policies. Nature Sustainability , 7(4), 399 -403.  \nElyoseph, Z., & Levkovich, I. (2023). Beyond human expertise - the promise and limitationsof ChatGPT in suicide \nrisk assessment. Frontiers in Psychiatry , 14. https://doi.org/10.3389/fpsyt.2023.1213141   \nElyoseph, Z., & Levkovich, I. (2024). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 480,
      "text": "). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M., Laufer, M., Pohle, J., & Sofsky, F. (2023). Friend or foe? Exploring the implications of \nlarge language models on the science system. AI & Society . https://doi.org/10.1007/s00146 -023-01791 -\n1  \nFloridi, L., & Chiriatti, M. (2020). GPT -3: Its Nature, Scope, Limits, and Consequences. Minds and Machines , \n30(4), 681 -694. https://doi.org/10.1007/s11023 -020-09548 -1  \nFrank, M. C. (2023). Baby steps in evaluating the capacities of large language models. Nature Reviews Psychology , \n2(8), 451 -452. https://doi.org/10.1038/s44159 -023-00211 -x  \nGhafouri, M. (2024). ChatGPT: The catalyst for teacher -student rapport and grit development in L2 class. System , \n120, 103209.  \nGhafouri, M., Hassaskhah, J., & Mahdavi -Zafarghandi, A. (2024). From virtual assistant to writing mentor: \nExploring the impact of a ChatGPT -based writing instruction protocol on EFL teachers\u2019 self -efficacy and \nlearners\u2019 writing skill. Language Teaching Research , 13621688241239764.  \nGlaser, R. (1984). Education and thinking: The role of knowledge. American psychologist , 39(2), 93.  \nGoertzel, B. (2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 481,
      "text": "2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J., Mirza, M., Xu, B., Warde -Farley, D., Ozair, S., Courville, A., & Bengio, Y. \n(2020). Generative adversarial networks. Communications of the ACM , 63(11), 139 -144.  \nGraber -Stiehl, I. (2023). IS THE WORLD READY FOR AI -POWERED THERAPY? Nature , 617, 22-24. \nhttps://doi.org/10.1038/d41586 -023-01473 -4  \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, W. A. (2023). AI and \nthe transformation of social science research. Science , 380(6650), 1108 -1109. \nhttps://doi.org/10.1126/science.adi1778   \nGuo, Z., Lai, A., Thygesen, J. H., Farrington, J., Keen, T., & Li, K. (2024). Large language models for mental \nhealth applications: Systematic review. JMIR mental health , 11(1), e57400  \nGupta, M., Akiri, C., Aryal, K., Parker, E., & Praharaj, L. (2023). From ChatGPT to ThreatGPT: Impact of \nGenerative AI in Cybersecurity and Privacy. IEEE Access , 11, 80218 -80245. \nhttps://doi.org/10.1109/access.2023.3300381   \nHagendorff, T. (2023). Machine Psychology: Investigating Emergent Capabilities and Behavior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 482,
      "text": "avior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models. Proceedings of the National \nAcademy of Sciences , 121(24), e2317967121.  \nHagendorff, T., Fabi, S., & Kosinski, M. (2023). Human -like intuitive behavior and reasoning biases emerged in \nlarge language models but disappeared in ChatGPT. Nature Computational Science , 3(10), 833 -838. \nhttps://doi.org/10.1038/s43588 -023-00527 -x  \nHarding, J., D\u2019Alessandro, W., Laskowski, N. G., & Long, R. (2023). AI language models cannot replace human \nresearch participants. AI & Society . https://doi.org/10.1007/s00146 -023-01725 -x  \nHardy, M., Sucholutsky, I., Thompson, B., & Griffiths, T. (2023). Large language models meet cognitive science: \nLlms as tools, models, and participants. Proceedings of the annual meeting of the cognitive science \nsociety,  \nHayes, A. (2023). \u201cConversing\u201d with Qualitative Data: Enhancing Qualitative Research through Large Language \nModels (LLMs). PsyArXiv preprint . https://doi.org/10.31235/osf.io/yms8p   \nHendel, R., Geva, M., & Globerson, A. (2023). In -Context Learning Creates Task Vectors. arXiv preprint , \narXiv:2310.15916. https://doi.org/10.48550/arXiv.2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 483,
      "text": ".2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440. https://doi.org/10.1007/s10608 -\n012-9476 -1  \nHoltzman, A., West, P., & Zettlemoyer, L. (2023). Generative Models as a Complex Systems Science: How can \nwe make sense of large language model behavior? arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.00189   \nHothersall, D., & Lovett, B. J. (2022). History of psychology . Cambridge University Press.  \nHuang, J., & Chang, K. C. -C. (2022). Towards Reasoning in Large Language Models: A Survey. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10403   \nHutson, M. (2023). Doing research with human subjects is costly and cumbersome.Can AI chatbots replace them? \nScience , 381(6654), 121 -123. https://doi.org/10.1126/science.adj6791   \nJin, C., Zhang, S., Shu, T., & Cui, Z. (2023). The Cultural Psychology of Large Language Models: Is ChatGPT a \nHolistic or Analytic Thinker? arXiv preprint . https://doi.org/10.48550/arXiv.2308.14242   \nJungherr, A. (2023). Using ChatGPT and Other Large Language Model (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 484,
      "text": "odel (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024). Exploring large language models as an integrated tool \nfor learning, teaching, and research through the Fogg Behavior Model: a comprehensive mixed -methods \nanalysis. Cogent Engineering , 11(1), 2353494.  \nKahneman, D. (2011). Thinking, fast and slow. Farrar, Straus and Giroux .  \nKasneci, E., Sessler, K., K\u00fcchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., \nG\u00fcnnemann, S., H\u00fcllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, \nO., Sailer, M., Schmidt, A., Seidel, T.,\u2026Kasn eci, G. (2023). ChatGPT for good? On opportunities and \nchallenges of large language models for education. Learning and Individual Differences , 103. \nhttps://doi.org/10.1016/j.lindif.2023.102274   \nKe, L., Zhang, G., He, J., Li, Y., Li, Y., Liu, X., & Fang, P. (2023). Pilot Selection in the Era of Virtual Reality: \nAlgorithms for Accurate and Interpretable Machine Learning Models. Aerospace , 10(5). \nhttps://doi.org/10.3390/aerospace10050394   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings of the National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 485,
      "text": "National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10.48550/arXiv.2303.15727   \nLee, B. C., & Chung, J. (2024). An empirical investigation of the impact of ChatGPT on creativity. Nature Human \nBehaviour , 8(10), 1906 -1914.  \nLi, J., Tang, T., Zhao, W. X., Nie, J. -Y., & Wen, J. -R. (2022). Pretrained Language Models for Text Generation: A \nSurvey. arXiv preprint , arXiv:2201.05273. https://doi.org/10.48550/arXiv.2201.05273   \nLi, M., Enkhtur, A., Cheng, F., & Yamamoto, B. A. (2023). Ethical implications of ChatGPT in higher education: \nA scoping review. arXiv preprint . https://doi.org/10.48550/arXiv.2311.14378   \nLi, T., Lu, J., Chu, C., Zeng, T., Zheng, Y., Li, M., Huang, H., Wu, B., Liu, Z., & Ma, K. (2024). Scisafeeval: a \ncomprehensive benchmark for safety alignment of large language models in scientific tasks. arXiv \npreprint arXiv:2410.03769 .  \nLi, X., Li, Y., Liu, L., Bing, L., & Joty, S. (2022). Does GPT -3 Demonstrate Psychopathy? Evaluating Large \nLanguage Models from a Psychological Perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10529   \nLiu, J. M., Li, D., Cao, H., Ren, T., Liao, Z., & Wu, J. (2023). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 486,
      "text": "3). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre -train, Prompt, and Predict: A Systematic \nSurvey of Prompting Methods in Natural Language Processing. ACM Computing Surveys , 55(9), 1 -35. \nhttps://doi.org/10.1145/3560815   \nLiu, X., Ji, K., Fu, Y., Tam, W., Du, Z., Yang, Z., & Tang, J. (2022). P -Tuning: Prompt Tuning Can Be Comparable \nto Fine -tuning Across Scales and Tasks. Proceedings of the 60th Annual Meeting of the Association for \nComputational Linguistics (Volume 2: Short Papers), Dublin, Ireland.  \nLiu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., Wu, Z., Zhao, L., Zhu, D., Li, \nX., Qiang, N., Shen, D., Liu, T., & Ge, B. (2023). Summary of ChatGPT -Related research and perspective \ntowards the future of large language models. Meta -Radiology , 1(2). \nhttps://doi.org/10.1016/j.metrad.2023.100017   \nLoconte, R., Orr\u00f9, G., Tribastone, M., Pietrini, P., & Sartori, G. (2023). Challenging ChatGPT's \"intelligence\" \nwith human tools: A Neuropsychological Investigation on Prefrontal Functioning of a Large Language \nModel. SSRN preprint . https://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 487,
      "text": "ttps://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI. Proceedings of the 2024 ACM Conference on \nInternational Computing Education Research -Volume 1,  \nLuo, X., Chen, F., Zhu, D., Wang, L., Wang, Z., Liu, H., Lyu, M., Wang, Y., Wang, Q., & Chen, Y. (2024). Potential \nRoles of Large Language Models in the Production of Systematic Reviews and Meta -Analyses. Journal \nof Medical Internet Research , 26, e56780.  \nMachin, M. A., Machin, T. M., & Gasson, N. (2024). Comparing ChatGPT With Experts\u2019 Responses to Scenarios \nthat Assess Psychological Literacy. Psychology Learning & Teaching , 14757257241241592.  \nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., & Fedorenko, E. (2023). \nDissociating language and thought in large language models: a cognitive perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2301.06627   \nMarjieh, R., Sucholutsky, I., Rijn, P. v., Jacoby, N., & Griffiths, T. L. (2023). Large language models predict human \nsensory judgments across six modalities. arXiv preprint . https://doi.org/10.48550/arXiv.2302.01308   \nMichelson, M., & Reuter, K. (2019). The significant cost of systematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 488,
      "text": "ematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi.org/10.1016/j.conctc.2019.100443   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022). Who is GPT -3? An Exploration of Personality, Values and \nDemographics. arXiv preprint . https://doi.org/10.48550/arXiv.2209.14338   \nMitchell, M. (2023). AI's challenge of understanding the world. Science , 382(6671). \nhttps://doi.org/10.1126/science.adm8175   \nNazario -Johnson, L., Zaki, H. A., & Tung, G. A. (2023). Use of large language models to predict neuroimaging. \nJournal of the American College of Radiology , 20(10), 1004 -1009. \nhttps://doi.org/10.1016/j.jacr.2023.06.008   \nNewell, A. (1990). Unified theories of cognition . Harvard University Press.  \nNisbett, R. E., Peng, K., Choi, I., & Norenzayan, A. (2001). Culture and systems of thought: holistic versus \nanalytic cognition. Psychological review , 108(2), 291 -310. https://doi.org/10.1037//0033 -\n295X.108.2.291   \nNoy, S., & Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. \nScience , 381(6654), 187 -192.  \nOpenAI. (2023). GPT -4 Technical Report. arXiv preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 489,
      "text": "preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT. Frontiers in Artificial Intelligence , 6, 1199350. \nhttps://doi.org/10.3389/frai.2023.1199350   \nPal, R., Garg, H., Patel, S., & Sethi, T. (2023). Bias Amplification in Intersectional Subpopulations for Clinical \nPhenotyping by Large Language Models. medRxiv preprint . \nhttps://doi.org/10.1101/2023.03.22.23287585   \nPark, B., & Judd, C. M. (2005). Rethinking the Link Between Categorization and Prejudice Within the Social \nCognition Perspective. Personality and Social Psychology Review , 9(2), 108 -130. \nhttps://doi.org/10.1207/s15327957pspr0902_2   \nPark, J. S., Popowski, L., Cai, C., Morris, M. R., Liang, P., & Bernstein, M. S. (2022). Social simulacra: Creating \npopulated prototypes for social computing systems. Proceedings of the 35th Annual ACM Symposium \non User Interface Software and Technology,  \nPark, P. S., Schoenegger, P., & Zhu, C. (2024). Diminished diversity -of-thought in a standard large language model. \nBehavior Research Methods , 1-17.  \nPark, Y. J., Kaplan, D., Ren, Z., Hsu, C. -W., Li, C., Xu, H., Li, S., & Li, J. (2024). Can ChatGPT be used to \ngenerate scientific hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 490,
      "text": "ic hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi.org/10.1101/2023.07.17.549421   \nPeng, Y., Han, J., Zhang, Z., Fan, L., Liu, T., Qi, S., Feng, X., Ma, Y., Wang, Y., & Zhu, S. -C. (2023). The Tong \nTest: Evaluating Artificial General Intelligence Through Dynamic Embodied Physical and Social \nInteractions. Engineering . https://doi.org/10.1016/j.eng.2023.07.006   \nPeters, H., & Matz, S. (2023). Large Language Models Can Infer Psychological Dispositions of Social Media \nUsers. arXiv preprint . https://doi.org/10.48550/arXiv.2309.08631   \nPorsdam Mann, S., Vazirani, A. A., Aboy, M., Earp, B. D., Minssen, T., Cohen, I. G., & Savulescu, J. (2024). \nGuidelines for ethical use and acknowledgement of large language models in academic writing. Nature \nMachine Intelligence , 1-3. \nQureshi, R., Shaughnessy, D., Gill, K. A. R., Robinson, K. A., Li, T., & Agai, E. (2023). Are ChatGPT and large \nlanguage models \"the answer\" to bringing us closer to systematic review automation? Systematic Reviews , \n12(1), 72. https://doi.org/10.1186/s13643 -023-02243 -z  \nRane, N., Choudhary, S., & Rane, J. (2024). Gemini versus ChatGPT: applications, performance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 491,
      "text": "rformance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R., Robertson, C., & Bavel, J. J. V. (2023). GPT is an effective \ntool for multilingual psychological text analysis. PsyArXiv preprint . https://doi.org/10.31234/osf.io/sekf5   \nSalah, M., Al Halbusi, H., & Abdelfattah, F. (2023). May the force of text data analysis be with you: Unleashing \nthe power of generative AI for social psychology research. Computers in Human Behavior: Artificial \nHumans , 1(2). https://doi.org/10.1016/j.chbah.2023.100006   \nSallam, M. (2023). ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the \nPromising Perspectives and Valid Concerns. Healthcare (Basel) , 11(6). \nhttps://doi.org/10.3390/healthcare11060887   \nSap, M., LeBras, R., Fried, D., & Choi, Y. (2022). Neural Theory -of-Mind? On the Limits of Social Intelligence \nin Large LMs. arXiv preprint . https://doi.org/10.48550/arXiv.2210.13312   \nSartori, G., & Orr\u00f9, G. (2023). Language models and psychological sciences. Frontiers in Psychology , 14. \nhttps://doi.org/10.3389/fpsyg.2023.1279317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 492,
      "text": "9317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023). Clinical science and practice in the age of large language models and \ngenerative artificial intelligence. Journal of Consulting and Clinical Psychology , 91(10), 559 -561. \nhttps://doi.org/10.1037/ccp0000848   \nSeals, S. M., & Shalin, V. L. (2023). Long -form analogies generated by chatGPT lack human -like psycholinguistic \nproperties. arXiv preprint . https://doi.org/10.48550/arxiv.2306.04537   \nSejnowski, T. (2022). Large Language Models and the Reverse Turing Test. arXiv preprint . \nhttps://doi.org/10.48550/arxiv.2207.14382   \nSha, H., Mu, Y., Jiang, Y., Chen, L., Xu, C., Luo, P., Eben Li, S., Tomizuka, M., Zhan, W., & Ding, M. (2023). \nLanguageMPC : Large Language Models as Decision Makers for Autonomous Driving. arXiv preprint , \narXiv:2310.03026. https://doi.org/10.48550/arXiv.2310.03026   \nSharma, A., Lin, I. W., Miner, A. S., Atkins, D. C., & Althoff, T. (2023). Human \u2013AI collaboration enables more \nempathic conversations in text -based peer -to-peer mental health support. Nature Machine Intelligence , \n5(1), 46 -57. https://doi.org/10.1038/s42256 -022-00593 -2  \nSimon, H. A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 493,
      "text": "A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K. (2023). Leveraging Cognitive Science for Testing Large Language \nModels. 2023 IEEE International Conference On Artificial Intelligence Testing (AITest),  \nStade, E. C., Stirman, S. W., Ungar, L., Boland, C. L., Schwartz, H. A., Yaden, D. B., Sedoc, J., Derubeis, R. J., \nWiller, R., & Eichstaedt, J. C. (2023). Large Language Models Could Change the Future of Behavioral \nHealthcare: A Proposal for Responsible De velopment and Evaluation. PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/cuzvr   \nStella, M., Hills, T. T., & Kenett, Y. N. (2023). Using cognitive psychology to understand GPT -like models needs \nto extend beyond human biases. Proceedings of the National Academy of Sciences of the United States \nof America , 120(43), e2312911120. https://doi.org/10.1073/pnas.2312911120   \nStevenson, C., Smal, I., Baas, M., Grasman, R., & Maas, H. v. d. (2022). Putting GPT -3's Creativity to the \n(Alternative Uses) Test. arXiv preprint . https://doi.org/10.48550/arXiv.2206.08932   \nStojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 103,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 494,
      "text": "knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022). AI bot ChatGPT writes smart essays \u2014 should professors worry? Nature . \nhttps://doi.org/10.1038/d41586 -022-04397 -7  \nSufyan, N. S., Fadhel, F. H., Alkhathami, S. S., & Mukhadi, J. Y. (2024). Artificial intelligence and social \nintelligence: preliminary comparison study between AI models and psychologists. Frontiers in \nPsychology , 15, 1353022.  \nSuri, G., Slater, L. R., Ziaee, A., & Nguyen, M. (2024). Do large language models show decision heuristics similar \nto humans? A case study using GPT -3.5. Journal of Experimental Psychology: General .  \nTajfel, H. (1982). Social psychology of intergroup relations. Annual Review of Psychology , 33(1), 1 -39.  \nTalboy, A. N., & Fuller, E. (2023). Challenging the appearance of machine intelligence: Cognitive bias in LLMs. \narXiv preprint . https://doi.org/10.48550/arXiv.2304.01358   \nTamkin, A., Brundage, M., Clark, J., & Ganguli, D. (2021). Understanding the Capabilities, Limitations, and \nSocietal Impact of Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2102.02503   \nThirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 104,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 495,
      "text": "ovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K., Huang, Z., Zhao, Y., & Peng, K. (2024). Automating psychological hypothesis generation with \nAI: when large language models meet causal graph. Humanities and Social Sciences Communications , \n11(1), 896. https://doi.org/10.1057/s41599 -024-03407 -5  \nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., & \nBhosale, S. (2023). Llama 2: Open foundation and fine -tuned chat models. arXiv preprint \narXiv:2307.09288 .  \nTrott, S., Jones, C., Chang, T., Michaelov, J., & Bergen, B. (2023). Do large language models know what humans \nknow? Cognitive Science , 47(7), e13309.  \nVan Dis, E. A., Bollen, J., Zuidema, W., van Rooij, R., & Bockting, C. L. (2023). ChatGPT: five priorities for \nresearch. Nature , 614(7947), 224 -226. https://doi.org/10.1038/d41586 -023-00288 -7  \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin , I. (2017). \nAttention is all you need. Advances in neural information processing systems , 30.  \nVzorinab, G. D., Bukinichac, A. M., Sedykha, A. V., Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 105,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 496,
      "text": "Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., Chandak, P., Liu, S., Van Katwyk, P., Deac, A., Anandkumar, \nA., Bergen, K., Gomes, C. P., Ho, S., Kohli, P., Lasenby, J., Leskovec, J., Liu, T. Y., Manrai, A.,\u2026Zitnik, \nM. (2023). Scientific discovery i n the age of artificial intelligence. Nature , 620(7972), 47 -60. \nhttps://doi.org/10.1038/s41586 -023-06221 -2  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language models. Nature \nHuman Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -023-01659 -w  \nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, \nD., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J., & Fedus, W. (2022). Emergent Abilities \nof Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2206.07682   \nYang, F., Chen, Z., Jiang, Z., Cho, E., Huang, X., & Lu, Y. (2023). Palr: Personalization aware llms for \nrecommendation. arXiv preprint arXiv:2305.07622 .  \nYildirim, I., & Paul, L. A. (2023). From task structures to world models: What do LLMs know? arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 106,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 497,
      "text": "arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing. PsyArXiv preprint . https://doi.org/10.31234/osf.io/9ymfz   \nZeiler, M. (2014). Visualizing and Understanding Convolutional Networks. European conference on computer \nvision/arXiv,  \nZhang, J., Xu, X., & Deng, S. (2023). Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology \nView. arXiv preprint , arXiv:2310.02124. https://doi.org/10.48550/arXiv.2310.02124   \nZhang, Z., Chadwick, G., McNally, H., Zhao, Y., & Mullins, R. (2023). Llm4dv: Using large language models for \nhardware test stimuli generation. arXiv preprint arXiv:2310.04535 .  \nZhao, Y., Huang, Z., Seligman, M., & Peng, K. (2024). Risk and prosocial behavioural cues elicit human -like \nresponse patterns from AI chatbots. Scientific Reports , 14(1), 7095.  \nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I., & Pan, S. (2023). Large Language Models \nfor Scientific Synthesis, Inference and Explanation. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2310.07984   \nZhong, Y., Chen, Y. J., Zhou, Y., Lyu, Y. A., Yin, J. J., & Gao, Y. J. (2023). The Artificial intelligence large language \nmodels and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 107,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 498,
      "text": "els and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z., Zhao, G., Zhang, Z., Mao, Q., Wang, S., & Chen, E. \n(2023). Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective. arXiv \npreprint . https://doi.org/10.48550/arXiv.2306.10512   \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 108,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 499,
      "text": "s, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 500,
      "text": "Exploring the Frontiers of LLMs in Psychological Applications: A \nComprehensive Review  \n \nLuoma Ke1, Song Tong1,2*, Peng Cheng3, Kaiping Peng1,* \n1. Department of Psychological and Cognitive Sciences , Tsinghua University  \n2. Department of Psychology, Beijing Normal University  \n3. School of Social Science, Tsinghua University  \n* Corresponding authors: tong.song.53w@kyoto -u.jp; pengkp@tsinghua,edu.cn  \n \nAbstract  \nThis review explores the frontiers of large language models (LLMs) in psychological applications. \nPsychology has undergone several theoretical changes, and the current use of artificial intelligence (AI) and \nmachine learning, particularly LLMs, promises to  open up new research directions. We aim to provide a \ndetailed exploration of how LLMs are transforming psychological research. We discuss the impact of LLMs \nacross various branches of psychology \u2014including cognitive and behavioral, clinical and counseling,  \neducational and developmental, and social and cultural psychology \u2014highlighting their ability to model \npatterns, cognition, and behavior similar to those observed in humans. Furthermore, we explore the ability \nof such models to generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 501,
      "text": "generate coherent, contextua lly relevant text, offering innovative tools for literature \nreviews, hypothesis generation, experimental designs, experimental subjects, and data analysis in \npsychology. We emphasize the importance of addressing technical and ethical challenges, including data \nprivacy, the ethics of using LLMs in psychological research, and the need for a deeper understanding of \nthese models\u2019 limitations. Researchers should use LLMs responsibly in psychological studies, adhering to \nethical standards and considering the pote ntial consequences of deploying these technologies in sensitive \nareas. Overall, this review provides a comprehensive overview of the current state of LLMs in psychology, \nexploring the potential benefits and challenges. We hope it can serve as a call to act ion for researchers to \nresponsibly leverage LLMs\u2019 advantages while addressing the associated risks.  \nKeywords large language models (LLMs); machine learning; artificial intelligence (AI); psychology; \nresearch methods  \n \n1. Introduction  \nArtificial intelligence (AI) has a history spanning nearly seven decades, beginning with the 1956 \nDartmouth Conference. The field has recently been revolutionized with the advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 502,
      "text": "he advent of large language models \n(LLMs) such as ChatGPT, Google\u2019s Bard, and Meta\u2019s LL aMA. Among them, GPT -4, in particular, could \nsignify a paradigm shift given its impressive capabilities (e.g., solving difficult tasks in math, coding, vision, \nmedicine, law, and psychology) (Bubeck et al., 2023) , exemplifying the concept of \u201cAI for science\u201d  (Wang \net al., 2023) . LLMs mark a critical juncture in the evolution of machine learning and AI, propelled by their \nexpansive size and sophisticated neural architectures that incorporate attention mechanisms  (V aswani et al., \n2017) . These models incorporate cognitive principles  (Binz & Schulz, 2023a)  and exhibit emergent \nproperties comparable to those seen in complex physical systems  (Wei et al., 2022) . This has enhanced their \nability to process and represent concepts and high -level semantics (J. Li et al., 2022)  while also deepening \nour insights into human cognitive processes  (Sejnowski, 2022) . In psychological applications, these \ndevelopments are reshaping interactions among data, language, and the environment  (De Bot et al., 2007; \nDemszky et al., 2023) , contributing significantly to various fields, including clinical  (Thirunavukarasu et al., \n2023) , developmental (Frank, 2023; Hagendorff, 2023) , and social psychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 503,
      "text": "sychology (Hardy et al., 2023; J. Zhang \net al., 2023) . Moreover,  LLMs have had profound effects on psychological research methods, offering novel \napproaches and tools for exploration and analysis.  \n1.1.  The LLM concept: From machine learning to capability emergence  \nGenerative AI evolved from advances in pattern  recognition capability. While convolutional neural \nnetworks (CNNs) excelled at recognizing objects and concepts, the next challenge was to use this recognition \ncapability for a generation. For example, if a CNN can identify \u201cage\u201d in portraits, we can use that \nunderstanding to modify \u201cage\u201d in any portrait. This generative approach first succeeded in computer vision \nthrough models such as generative adversarial networks (Goodfellow et al., 2020)  and deconvolution (Zeiler, \n2014) , which could create realistic images based on learned patterns. The same generative principles were \nthen applied to language, leading to LLMs that could generate contextually relevant text. LLMs represent a \nparticularly significant leap in the capabilitie s of generative AI. These models are designed to process natural \nlanguage text and generate contextually relevant text.  LLMs like GPT -4, LLaMA,  Claude, and  Gemini \nleverage the transformer architecture (V aswani et al., 2017), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 504,
      "text": "17), which employs sophisticated neu ral networks \nand attention mechanisms to revolutionize natural language processing. Each model is optimized uniquely \nto enhance performance across diverse tasks. For instance, LLaMA focuses on efficient training processes \n(Touvron et al., 2023) , Claude emphasizes safety and alignment (Li et al., 2024) , and Gemini integrates \nadvanced reasoning capabilities (Rane et al., 2024) . LLaMA \u2019s open -source nature allows local deployment \nand efficient training, making it suitable for psychological studies needing rapid iteration or customization, \nsuch as behavioral modeling ( Binz and Schulz (2023a) . Claude, designed for safety and alignment, is less \ncommonly used in psychology research and more oriented toward knowledge -based tasks (Li et al., 2024). \nGPT-4, with its large -scale parameters and broad training data, supports a wide range of tasks, including \ncognitive simulations and clinical assessments.  These differences guide model selection based on research \nneeds like accessibility, task specificity, or data scale.  \nWhile these models highlight the versatility of LLMs, it is essential to distinguish between specific \nproducts designed for particular interactions, such as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 505,
      "text": "as ChatGPT for conversational applications, and the \nbroader capabilities of LLMs that extend beyond ch at interfaces to include text generation, summarization, \ntranslation, and embedding extraction. This range of applications demonstrates that LLMs\u2019 capabilities are \nemergent, manifesting new abilities as the model size increases. Performance improvements on  log-log \nscales sometimes experience \u201cbreaks\u201d where unexpected capabilities emerge from complex interactions \nwithin the models (Wei et al., 2022) . \nAt the heart of LLMs is the transformer architecture, a deep neural network with an attention mechanism \nthat efficiently processes sequential data in parallel (V aswani et al., 2017) ; this works in a manner somewhat \nsimilar to human brain functions. This architecture has revolutionized the field of natural language \nprocessing. The self -attention mechanism of the transformer architecture captures contextual relationships \nin textual dat a, allowing for more sophisticated language understanding. Notably, the \u201clarge\u201d in LLM refers \nto the many parameters and massive amounts of training data used to fine -tune these models, typically \nbillions of parameters and terabytes of text (Binz & Schulz, 2023b) , in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 506,
      "text": "in addition to \u201cmastering the world\u201d  \n(Yildirim & Paul, 2023) . \nThe process of large language modeling, from machine learning to the emergence of competence, can be \ndivided into several key stages. (1) Pretraining: LLMs are pretrained on large amounts of textual data to \nlearn intricate linguistic, syntactic, and textua l structures, where the model learns to predict the next token \nthrough unsupervised learning, resulting in a base model that captures the statistical patterns of language (P . \nLiu et al., 2023) . (2) Alignment: Supervised learning is used to create a foundation model that can better \ninteract with users in the intended ways, which typically involves instruction tuning and reinforcement \nlearning based on human feedback. After the foundation model i s available, domain -specific fine -tuning can \nadapt the model for particular applications (Liu et al., 2022) . This fine -tuning process ensures the model can \ngenerate contextually relevant responses and engage in meaningful conversations or tasks. Through these \nstages of development, LLMs demonstrate increasingly sophisticated text -generation capabilities, includi ng \nresponse generation, content summarization, translation, and compositional text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 507,
      "text": "nal text generation  (Bubeck et al., \n2023) . The ability to effectively process and represent context is a critical factor underlying the observed \nemergence of advanced capabilities in these models. Finally, LLMs exhibit \u201cobserved capability emergence\u201d \nwhen integrated into various applications and systems, in addition to performing tasks that require a deep \nunderstanding of language and context, thus often achieving human -like or superhuman performance in \nspecific experimental tasks, such as analogical reasoning (Webb et al., 2023) , creativity (Stevenson et al., \n2022) , and emotion recognition (Patel & Fan, 2023) . \nTherefore, LLMs can provide valuable insights into how such technologies can simulate or augment \nprocesses traditionally associated with human cognition. Specifically, LLMs maintain a balance between \nlogical processing and the use of cognitive shortcuts (heuristics), and they adapt their reas oning strategies to \noptimize between accuracy and effort. This aligns with the principles of resource -rational human cognition, \nas discussed in dual -process theory (Mukherjee & Chang, 2024). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 508,
      "text": "24). For instance, LLMs generate and process \nnatural language, demonst rating structural and functional parallels with certain aspects of human linguistic \nand cognitive mechanisms (Goertzel, 2023) . These parallels allow for the exploration of AI applications in \nareas such as cognitive psychology (Sartori & Orr\u00f9, 2023) , language acquisition (Jungherr, 2023) , and even \nmental health (Lamichhane, 2023) . Moreover, the study of LLMs contributes to our understanding of the \nhuman mind, offering a computational perspective on language processing, decision -making (Sha et al., \n2023) , and learning mechanisms (Hendel et al., 2023) . The fusion of such disciplines could drive \nadvancements in AI and provide a computational framework for investigating processes related to human \ncognition.  \n1.2.  Psychology and AI  \nPsychology, as a science that explores the human mind and behavior, has undergone significant \ntheoretical changes since the late nineteenth century, with psychoanalysis and behaviorism extending to \ncognitive psychology (Hothersall & Lovett, 2022) . This history marks a shift in the focus of psychology \nresearch, reflecting the academic trend of moving from observing behavioral manifestations to exploring in -\ndepth psychological connotations. Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 509,
      "text": ". Each of these phases has led to a deepening understanding o f the psycho -\ncognitive processes of human beings.  \nUnderstanding human psycho -cognitive processes is therefore crucial for psychology. In clinical and \ncounseling psychology, research on cognitive psychology supports diagnosing and treating psychological \ndisorders. It deepens our understanding of the psycho logical mechanisms underlying emotions, stress, and \nhuman behavior. Psychotherapies such as cognitive -behavioral therapy (Hofmann et al., 2012)  and \npsychodynamic therapy have become essential tools for promoting mental health and emotional regulation. \nIn educational and developmental psychology, the development of cognitive psychology has fostered a \ndeeper understanding of the roles of perceptual  and affective factors in learning processes (Glaser, 1984) , \nwhich has led to innovations in teaching methods and learning strategies. In social and cultural psychology, \ncognitive psychology research helps explain individuals\u2019 behaviors and mental processes in different social \nand cultural contexts, exploring how cultural differences affect cognitive patterns, values, and behavioral \nnorms, especially in the context of globalization, interaction, and integration. In social psychology, \nmeanwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 510,
      "text": "nwhile, cognitive psychology research on group behavior, social influence, prej udice, and discrimination \nholds great value for promoting social harmony and mutual understanding (Park & Judd, 2005) . \nAI is becoming an increasingly influential tool in psycho -cognitive research. Simon (1979)  was among \nthe first to recognize the potential of computational models to simulate aspects of human cognitive processes. \nCurrently, LLMs can process and generate human -like texts and perform certain tasks in a manner similar to \nhuman cognition (Bubeck et al., 2023) . LLMs also offer a unique computational perspective for the study of \nhuman cognition. For example, GPT -3 can solve vignette -based tasks similar to or better than human subjects \nand can perform rational decision -making based on descriptions, outperforming humans in the multiarmed \nbandit task (Binz & Schulz, 2023b) . Furthermore, after extensive testing, GPT -3 is able to solve complex \nanalogical problems at levels comparable to human performance, and analogical reasoning is an essential \nhallmark of human intelligence (Webb et al., 2023) . Moreover, fine -tuning across multiple tasks can allow \nLLMs to predict human behavior in previously unseen tasks \u2014that is, LLMs can be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 511,
      "text": "n be adapted to general -\npurpose cognitive models (Binz & Schulz, 2023a) , potentially opening up new research directions that could \ntransform cognitive psychology and behavioral science in general.  \nNewell (1990)  offered a structured framework for analyzing human behavior, categorizing cognitive and \nbehavioral processes into four distinct layers based on their time scales (Fig. 1a). At the biological level, the \nfocus is on physiological and neural processes occurr ing at rapid time scales, ranging from milliseconds to \none second. This level can include neural responses and sensory processing, which form the foundation of \nhuman cognition. The cognitive level pertains to mechanisms such as attention, perception, and s hort-term \nmemory, which operate at intermediate time scales, typically between one second and one minute. These \nprocesses enable fundamental cognitive functions. At the rational level, the framework considers more \ncomplex cognitive activities such as probl em-solving, planning, and decision -making. Such activities occur \nover longer time scales, spanning several minutes to a few hours, and involve sustained cognitive \nengagement. Finally, the social level considers behaviors shaped by social interaction and cultural influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 512,
      "text": "influence, \noperating at the longest time scale, ranging fr om hours to days or longer. This level concerns the effects of \nsocial communication, group behavior, and cultural influences on cognition. It underscores the multifaceted \nnature of human behavior, highlighting the relationship between rapid physiological p rocesses and the more \nprolonged, socially influenced aspects of human cognition.  Figure 1 integrates this framework by mapping \npsychological domains (e.g., cognitive, social) onto these timescales, demonstrating LLMs \u2019 ability to \nsimulate behaviors \u2014from short -term processes like memory retrieval to long -term phenomena like cultural \ntrends. Emergent properties (e.g., cognitive simulation) connect these domains to practical research tools \n(e.g., stimuli generation), with bidirectional influence refinin g both a pplications and properties.  \nTherefore, by analyzing LLM application across these four levels (Fig. 1a), it is possible to further \nexplore their potential for modeling and studying human cognition and behavior (Fig. 1b), as well as their \nunique role in psycho -cognitive processes. Rece nt research has revealed significant advancements in LLMs\u2019 \nability to perform complex human -like cognitive and social tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 513,
      "text": "cial tasks (Grossmann et al., 2023; Marjieh et al., \n2023; Orru et al., 2023; Pal et al., 2023; Stevenson et al., 2022; Webb et al., 2023) . For instance,  Grossmann \net al. (2023)  and Marjieh et al. (2023)  demonstrated LLMs\u2019 proficiency in simulating human social \ninteractions and perceptual processing, respectively. Orru et al. (2023)  and (Webb et al., 2023)  highlighted \nLLMs\u2019 capabilities in complex problem -solving and reasoning while Hagendorff et al. (2023)  focused on \ndecision -making processes. Stevenson et al. (2022)  documented LLMs\u2019 potential for creativity, and Patel \nand Fan (2023)  demonstrated their emotion -recognition abilities. Taken together, such findings highlight the \nexpanding role of LLMs in representing and augmenting human cognitive and social functions, marking \nsignificant progress in AI research.   \nAs general -purpose cognitive models (Binz & Schulz, 2023a) , LLMs offer new perspectives and \napproaches for research in the fields of cognitive and behavioral psychology, clinical and counseling \npsychology, educational and developmental psychology, and social and cultural psychology, at different time \nscales of hu man behavior (Fig. 1a).  LLMs can also be used as research aids (Fig. 1c) to help psychologists \nwith everything from literature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 514,
      "text": "ature reviews (Ayd\u0131n & Karaarslan, 2022; Qureshi et al., 2023) , experimental \nsubjects (Dillion et al., 2023; Hutson, 2023) , and data analysis (Patel & Fan, 2023; Peters & Matz, 2023; \nRathje et al., 2023)  to promote scholarly communication: academic writing (Dergaa et al., 2023; Stokel -\nWalker, 2022)  or peer review (Chiang & Lee, 2023; Van Dis et al., 2023) . Thus, LLMs can potentially \nbecome research assistants for psychologists, helping them improve their research efficiency.  \n \nFig. 1 LLMs in Psychological Research Across Timescales. (a) Domains (e.g., Cognitive & Behavioral, \nSocial & Cultural) mapped to timescales of behavior; (b) Emergent properties (e.g., cognitive simulation) \nenabling domain -specific modeling; (c) LLMs as research tools (e.g., stimuli generation). Double -sided \narrows indicate that emergent properties bridge domains and tools, supporting applications (e.g., memory  \nretrieval) and refining properties through usage . \n \n1.3.  Objectives and significance of the present review  \nThis review aims to provide a comprehensive analysis of the applications and effects of LLMs in \npsychological research. To ensure a systematic and rigorous review, we established specific inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 515,
      "text": "ic inclusion and \nexclusion criteria. The review focuses on literature p ublished between 2020 and 2024, sourced from relevant \nacademic databases, including Google Scholar, arXiv, and Web of Science. Our initial keyword selection \u2014\n\u201cGPT-3\u201d, \u201cChatGPT \u201d, \u201cGPT-4\u201d, \u201clarge language models \u201d, and \u201cpsychology \u201d\u2014was determined during the \nliterature collection in October 2023, when GPT -based models were predominant in psychological research \n(e.g., Binz & Schulz, 2023b; Bubeck et al., 2023). At the time, open -source models like LLaMA (Touvron \net al., 2023) and propr ietary models like Claude had limited psychology -specific applications. To maintain \na focused scope, we did not retrospectively expand search terms but included diverse LLMs via manual \nscreening. To reflect recent developments, an updated search incorporat ed studies from 2024.  \nTo bolster the integrity of our data extraction process, two interdisciplinary researchers (male, 33 and \n41 years) specializing in information science and psychology conducted the encoding and screening. Our \n\ninclusion criteria required the selected studies to (1) explore the application or analysis of LLMs in \npsychological contexts; (2) be peer -reviewed journal articles or high -impact conference proceedings; and (3) \npresent empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 516,
      "text": "present empirical data, theoretical discussi ons, or methodological advancements. We selectively included \npreprint articles if they addressed emerging trends or filled notable gaps in the literature. Articles without a \npsychological focus or those addressing non -LLM -based AI systems were excluded.  The study selection \ninvolved screening 191 identified studies, analyzing 100 full -text articles, and ultimately including 4 7 studies \ncategorized into various psychological subfields. Each of these studies met stringent inclusion criteria, \nensuring they contributed meaningfully to our understanding of LLMs in psychological research.  \nIn this review, we systematically examine the use of LLMs in various psychological domains by \nanalyzing their application at different behavioral time scales. The rest of the paper is structured as follows. \nIn section 2, we explore LLMs in cognitive and be havioral psychology. In section 3, the roles of LLMs in \nclinical and counseling psychology are discussed. Subsequently, educational and developmental psychology \nare addressed in section 4, followed by social and cultural psychology in section 5, outlining LLMs\u2019 \ncontributions to each area. While psychological techniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 517,
      "text": "hniques are occasionally utilized to assess the capabilities \nof LLMs, this approach is employed to enhance understanding of their suitability and potential as instruments \nfor psychological research. The primary focus of this review is how LLMs facilitate and advance \npsychological research across these domains. For a deeper understanding of the effect of LLMs on \npsychological research, an overview of LLMs\u2019 potential as tools for scientific research is given in section 6. \nIn section 7, the challenges and future research directions with regard to applying LLMs to psychological \ncontexts are provided. Finally, conclusions are presented in section 8, with a summary of LLMs\u2019 applications \nin psychology and rec ommendations for future work. Importantly, we propose strategies for integrating \nLLMs into psychological research and provide insights into interpreting such models from a psychological \nstandpoint, contributing to their safety and interpretability.  \n \n2. LLMs in cognitive and behavioral psychology  \nWithin the multilevel time scales of human behavior (Newell, 1990) , cognitive and behavioral \npsychology has primarily focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 518,
      "text": "focused on the study of cognitive processes at sub -hourly time scales, which \nencompass human engagement in perception, memory, thinking, decision -making, problem -solving, and \nconscious planning. Cognitive  and behavioral psychology typically uses experimental methods to study \nthese cognitive processes, controlling and observing behaviors and responses under specific conditions. The \nrecent emergence of LLMs has reinvigorated the discussion on whether such models might exhibit patterns \nresembling human cognitive processes; if so,  it may be possible to study the \u201ccognitive processes\u201d of LLMs, \nwhich could provide valuable insights into human cognitive phenomena and serve as a valuable addition to \nexisting research methods in cognitive psychology. The foundational technology underlyi ng large language \nmodels (LLMs) is the generative pre -trained transformer (GPT) architecture, which employs deep neural \nnetworks to process and generate human -like text. GPT models function through mechanisms, such as \nattention mechanisms and token predict ion, enabling them to capture complex linguistic patterns and \ngenerate contextually coherent outputs. These foundational technologies have transformed natural language \nprocessing (NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 519,
      "text": "(NLP) by expanding the capacity for both comprehension and generation of text  across diverse \napplications, from conversational agents to content creation (Brown et al., 2020; Vaswani et al., 2017) . The \nincorporation of such architectures into psychological research has initiated discussions regarding their \npotential to simulate cognitive phenomena.  \nBinz and Schulz (2023a)  found that fine -tuning multiple tasks enabled an LLM to predict human \nbehavior in previously unseen tasks, suggesting that LLMs can be adapted to become generalist cognitive \nmodels. In another study, the same authors tested GPT -3 using tools from cognitiv e psychology and showed \nthat it made better decisions than humans and outperformed them in the multiarmed bandit task (Binz & \nSchulz, 2023b) . Other studies have shown that LLMs can display perceptual judgment (Marjieh et al., 2023) , \nreasoning (Webb et al., 2023) , and decision -making abilities (Hagendorff et al., 2023) , as well as creativity \n(Stevenson et al., 2022)  and problem -solving (Orru et al., 2023) . One study found that an LLM had the \nmental ability of a seven -year-old child based on a false -belief task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 520,
      "text": "ef task (which is considered the gold standard \nfor testing theory of mind in humans) (Kosinski, 2024) . Exploring the reasoning capabilities and decision -\nmaking processes of LLMs, Hagendorff et al. (2023)  designed a series of semantic illusion and cognitive \nreflection tests designed to elicit intuitive but erroneous responses (these are conventionally used to study \nhuman reasoning and decision -making) and then ran the tests for LLMs. They conducted an anal ysis of \nmodel performance on a Cognitive Reflection Test (CRT) task and a semantic illusion task to elucidate their \ncognitive processes, drawing upon System 1 and System 2 thinking, as conceptualized by Daniel Kahneman \nin his seminal work Thinking, Fast, a nd Slow (Kahneman, 2011) , which represent fundamental constructs \nfor understanding human cognitive processes. System 1 refers to intuitive and automatic thinking, whereas \nSystem 2 involves rational, deliberate decision -making processes. This framework provides a theoretical \nbasis for interpreting how LLMs simulate human -like cognitive behaviors during these tasks. They observe \nhow these models show correct responses in these tasks and avoid pitfalls. The performance of the models \nin the CRT task were further evaluated by prev enting them from chain -thinking to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 521,
      "text": "ing to reason. The results showed \nthat as model size and language capability increased, the LLMs increasingly exhibited human -like intuitive \nthinking (System 1) and the associated cognitive errors. Table 1 provides a summary of the applications of \nLLMs to cognitive and behavioral psychology.  \nTable 1  Applications of large language models (LLMs) in cognitive and behavioral psychology study.  \nReference  Research Question  Research method  Key finding  \n \nHuman -like Cognitive Abilities  \nBinz and \nSchulz \n(2023b)  How does GPT -3 perform on \ncognitive psychology tasks, \nincluding decision -making, \ninformation search, and causal \nreasoning?  GPT-3 was tested using canonical \ncognitive psychology experiments \nand compared to human \nperformance.  GPT-3 excels in decision -making and \nreinforcement learning but struggles with \ntask perturbations, directed exploration, \nand causal reasoning.  \nStevenson et \nal. (2022)  Can GPT -3 generate creative \nsolutions comparable to humans in \nGuilford\u2019s Alternative Uses Test \n(AUT)?  GPT-3\u2019s responses to AUT were \nevaluated for originality, usefulness, \nsurprise, and flexibility, using expert \nratings and semantic distance \nanalysis, and compared with human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 522,
      "text": "th human \ndata.  Humans currently outperform GPT -3 in \ncreativity, but GPT -3 shows potential to \nclose the gap in future, raising questions \nabout AI creativity and its evaluation.  \nMarjieh et \nal. (2023)  Can LLMs recover perceptual \ninformation from language, and \nhow do they reflect cross -linguistic \nvariations?  GPT-3, GPT -3.5, GPT -4 were tested \non six psychophysical datasets and a \nmultilingual color -naming task to \ncompare their outputs with human \nperceptual data.  LLMs like GPT -4 align closely with \nhuman perceptual data, recover \nrepresentations such as the color wheel, \nand reflect cross -linguistic perceptual \nvariations, demonstrating their ability to \nextract perceptual information from \nlanguage.  \nLoconte et \nal. (2023)  How do various LLMs perform on \nneuropsychological tests assessing \nprefrontal functions compared to \nhuman cognitive abilities?  GPT-3.5, GPT -4,were evaluated on \ntasks related to planning, semantic \nunderstanding, and Theory of Mind.  Findings indicate that GPT -4 generally \nmeets normative human standards, \nwhereas  Claude2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 523,
      "text": "2, and Llama2 show \nvariable and often limited abilities, \nparticularly in planning and Theory of \nMind, underscoring the challenges in \nmimicking complex human cognitive \nfunctions.  \nDhingra et \nal. (2023)  How does GPT -4 perform on \ncognitive psychology tasks \ncompared to prior state -of-the-art \nmodels?  GPT-4 was evaluated on cognitive \npsychology datasets \n(CommonsenseQA, SuperGLUE, \nMATH, HANS) to analyze its \nintegration of cognitive processes \nwith contextual information.  GPT-4 demonstrates high accuracy on \ncognitive psychology tasks, surpassing \nprior models, and showcases significant \npotential to bridge human and machine \nreasoning.  \nHagendorff \n(2024)  Can modern LLMs understand and \napply deception strategies?  Experiments tested LLMs on \ninducing false beliefs, using chain -\nof-thought reasoning, and displaying \nMachiavellian behavior in simple \nand complex deception scenarios.  GPT-4 demonstrates advanced deceptive \nbehavior, succeeding in 99.16% of simple \nand 71.46% of complex scenarios, \nhighlighting the emergence of \nsophisticated deception abilities absent in \nearlier models.  \n \nExperimental Methodologies for Cognitive Research Using LLMs  \nBinz and \nSchulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 524,
      "text": "Schulz \n(2023a)  Can fine -tuned Mata \u2019s LLaMA  \naccurately model human behavior?  LLaMA was fine-tuned on \npsychological experiment data and \ntested on decision -making tasks and \nunseen behaviors.  Fine-tuned LLaMA outperforms \ntraditional cognitive models, accurately \nmodel individual behavior, and predict \nunseen human responses.  \nDubey et al. \n(2024)  How can generative AI tools be \nutilized to streamline the creation of \nexperimental stimuli in \npsychological research and \ninfluence public attitudes toward \nsustainable policies?  DALL -E 2 was employed to generate \nrealistic visual stimuli of car -free \nurban environments, which were \nthen presented to participants to \nmeasure attitudes toward sustainable \npolicies.  By using DALL -E 2, the study \ndemonstrated that generative AI tools can \nenhance the design process of \nexperimental stimuli, offering greater \ncontrol, diversity, and scalability, thereby \neffectively influencing participants' \nattitudes.  \nNote: The AUT is a psychological test that measures creativity by asking participants to think of as many \nuses as possible for a common object; DALL -E 2 is developed by OpenAI that generates detailed and \nrealistic images from textual descriptions to explore AI's potential in creative fields.  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 525,
      "text": ".  \nBeyond theoretical evaluations, LLMs have demonstrated practical value in experimental psychology, \nparticularly in stimulus generation and experimental design (Zhuang et al., 2023) . Dubey et al. (2024) , for \ninstance, used DALL -E 21 to create realistic visual stimuli depicting car -free urban environments, which \ninfluenced participants\u2019 attitudes toward sustainable policies. Such tools streamline the stimulus design \nprocess by providing control, diversity, and scalability. Similarly, LLMs have been employed in hardware \ntesting to generate tailored stimuli, outperforming traditional methods in specific scenarios (Z. Zhang et al., \n2023) . Charness et al. (2023)  further demonstrated the use of LLMs for enhancing experimental workflows \nby refining task instructions, ensuring consistency, and monitoring participant engagement. By leveraging \ntheir flexibility and scalability, LLMs can provide novel methods for advan cing experimental psychology. \nThese applications facilitate the exploration of complex cognitive phenomena and the development of \ninnovative research designs while also complementing traditional psychological research frameworks \n(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 526,
      "text": "(Srinivasan et al., 2023) . However, the interpretation of LLM outputs requires careful contextualization to \navoid overstating their capabilities or equating them with human cognitive processes.  \n3. LLMs in clinical and counseling psychology  \nClinical and counseling psychology focuses on assessing, diagnosing, treating, and preventing mental \nhealth problems. These processes often involve medium - to long -term periods. In the multilevel time scales \nof human behavior (Newell, 1990) , clinical and counseling psychology involves assessing everyday \nbehavioral acts (about a few hours to a day), habitual thinking (about a day to a few months), and \npsychological disorders (a few months to many years), among others (Fig. 1). The application  of LLMs in \nclinical and counseling psychology can be broadly divided into two categories: psychological assessment \nand psychological intervention. Psychological assessment focuses on improving the ecological validity, \nscalability, and accuracy of measurin g mental health states while psychological interventions consider how \nLLMs can be used for scalable and personalized mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 527,
      "text": "d mental health support, such as life coaching. According to \nrelated reports, there has been a public rush to use LLMs such as GPT for mental  health screening and \ntreatment (Demszky et al., 2023) . LLMs are expected to be used in clinical psychology and counseling \n \n1 Note: Although DALL -E 2 is not an LLM, we included this study due to its reliance on Transformer -\nbased semantic understanding, a cornerstone of LLM research, and its demonstrated utility in generating \ncontrolled visual stimuli for psychological experiments.  \n \nbecause they can parse human language and generate human -like responses, categorize text, and flexibly \nadapt conversational styles representing different theoretical orientations (Stade et al., 2023) . This leads to \nthe following question: How do LLMs work in psychotherapy, and can they replace human psychotherapists?  \nAn LLM is a basic generalized model with the ability to learn from small samples (Brown et al., 2020) , \nwhich allows it to quickly become an \u201cexpert\u201d in the clinical and counseling domain with only a small \namount of data to learn from. For example, LLMs trained on clinical content can identify more specific \nfactors of change that can help psychologists und erstand the process of clinical intervention, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 528,
      "text": "on, thus opening \nthe black box of psychotherapy (Schueller & Morris, 2023) . Regarding psychological assessment, studies \nhave demonstrated that LLMs can effectively recognize emotions (Sharma et al., 2023)  and respond \nappropriately. They can also perform complex mental health evaluations (Patel & Fan, 2023; Schaaff et al., \n2023) , such as suicide risk assessment and schizophrenia prognosis. For example, Elyoseph and Levkovich \n(2024)  found that GPT -4, Google Bard, and Claude produced evaluations consistent with professional \nbenchmarks in treated schizophrenia cases, though GPT -3.5 exhibited overly pessimistic predictions. Other \nresearch has shown that GPT -3.5 excels in clinical psychi atric cases, achieving top grades in diagnosis and \nmanagement across 61% of cases, with only minor discrepancies in more complex scenarios (D\u2019Souza et al., \n2023) . \nIn psychological interventions, LLMs have shown significant potential for delivering scalable and \npersonalized mental health support (Blyler & Seligman, 2023a, 2023b) . For example, Blyler and Seligman \n(2023a) demonstrated that GPT -4 can generate personalized therapeutic strategies by analyzing narrative \nidentities. These strategies were found to be valid and reasonable, highlighting GPT -4\u2019s utility as a supportive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 529,
      "text": "portive \ntool in therapy and coaching. For peer -to-peer mental health support, Sharma et al. (2023) designed an AI \nsystem offering real -time empathic feedback, which improved overall empathy by 19.6% and significantly \nboosted self -efficacy among users struggling to pro vide support. Furthermore, J. M. Liu et al. (2023)  \nevaluated ChatCounselor, a model trained on a domain -specific dataset of psychologist \u2013client conversations, \nand found it outperformed open -source models, thereby demonstrating the importance of domain -specific \ntraining for improving counseling capabilitie s. Table 2 summarizes the applications of LLMs to clinical and \ncounseling psychology.  \nThe above research cases, which demonstrate LLMs\u2019 ability to provide clinicians with adequate mental \nhealth support (Schueller & Morris, 2023) , hold promise for addressing insufficient capacity in the mental \nhealth care system and offering more individualized treatment services, even potentially fully automating \npsychotherapy in the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies ."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 530,
      "text": "the future (Stade et al., 2023) . It is essential to ensure that LLM is safe and privacy -\nprotective in psychotherapy.  \nTable 2  Applications of LLMs in clinical and counseling psychology studies . \nReferences  Research question  Research method  Key finding  \n \nPsychological Assessment Using LLMs  \nElyoseph and \nLevkovich \n(2023)  How effective and accurate \nare ChatGPT in assessing \nsuicide risk?  The study evaluated ChatGPT's \nanalysis of a text vignette depicting a \nhypothetical patient with varied \npsychological states, comparing its \nassessments to those of mental health \nprofessionals.  The study found that ChatGPT consistently \nunderestimated suicide risk and mental \nresilience compared to mental health \nprofessionals, suggesting that reliance on \nChatGPT for suicide risk assessment could \nlead to inaccurately low evaluations.  \nElyoseph and \nLevkovich \n(2024)  How do LLMs compare to \nmental health professionals \nin assessing schizophrenia \nprognosis and treatment \noutcomes?  Vignettes were used to compare the \nassessments of four LLMs (GPT -3.5, \nGPT-4, Bard, Claude) against \nprofessional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 531,
      "text": "ional and public benchmarks.  GPT-4, Bard, and Claude aligned with \nprofessional views on treated cases, while \nGPT-3.5 was overly pessimistic.  \nD\u2019Souza et al. \n(2023)  How effective is Chat GPT \n(3.5)  in addressing clinical \npsychiatric cases and \nsupporting mental health \ncare?  ChatGPT was tested on 100 clinical \npsychiatric vignettes, and expert \npsychiatrists graded its responses \nacross 10 categories.  ChatGPT  excelled in management and \ndiagnosis, earning top grades in 61% of cases, \nwith no major errors but minor discrepancies \nin complex cases.  \nSufyan et al. \n(2024)  How do the social \nintelligence (SI) levels of \nLLMs compare to human \npsychologists?  Social intelligence scores of ChatGPT \n(4), Bard, and Bing were compared \nwith 180 counseling psychology \nstudents (bachelor\u2019s and PhD levels) . ChatGPT surpassed all psychologists in \nsocial intelligence, Bing outperformed most \nbachelor\u2019s and some PhDs, while Bard \naligned with bachelor\u2019s students but fell \nbehind PhDs.  \n \nPsychological Interventions with LLMs  \nBlyler and \nSeligman \n(2023a)  Can GPT-4 generate \npersonalized therapeutic \nstrategies based on narrative \nidentity?  GPT-4 analyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 532,
      "text": "nalyzed five narrative identities \nto recommend tailored interventions.  GPT-4 effectively crafted personalized \nstrategies, demonstrating its potential as a \nsupportive tool for therapy and coaching.  \nBlyler and \nSeligman \n(2023b)  Can GPT-4 generate \naccurate and insightful \npersonal narratives to \nsupport self -discovery in \ntherapy and coaching?  GPT-4 processed 50 stream -of-\nconsciousness thoughts from 26 \nparticipants to create personalized \nnarratives, which participants evaluated \nfor accuracy, surprise, and self -insight.  96% of participants rated the narratives as \naccurate, and 73% reported gaining new self -\ninsights, suggesting GPT-4\u2019s potential for \nenhancing self -discovery in therapeutic \ncontexts.  \nSharma et al. \n(2023)  Can AI enhance empathy in \npeer-to-peer mental health \nsupport?  Tested HAILEY  which based on GPT -\n2, which  offering real -time empathic \nfeedback, in a trial with 300 peer \nsupporters on TalkLife.  HAILEY improved empathy by 19.6% \noverall and 38.9% for those struggling with \nsupport, boosting self -efficacy without \ncreating reliance.  \nJ. M. Liu et al. \n(2023)  How to improve  LLM  in \nproviding mental health \nsupport compared to other \nmodels?  ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 533,
      "text": "ChatCounselor, trained on the Psych8k \ndataset of 260 psychologist -client \nconversations, was evaluated using the \nCounseling Bench with real -world \ncounseling questions and psychological \nmetrics.  ChatCounselor outperforms LLaMA, \nChatGLM  and approaches GPT-4\u2019s \nperformance, highlighting the impact of \ndomain -specific training on counseling \ncapabilities.  \n4. LLMs in educational and developmental psychology  \n Educational and developmental psychology is concerned with learning processes, knowledge \naccumulation, skill development, and changes in individual psychology in educational environments. \nEducational and developmental psychology is mainly positioned at th e relatively medium - to long -term level \n(Newell, 1990), reflecting the ongoing learning and development that characterize the educational process. \nA national survey found that only 3 months after the public release of GPT, 40% of US teachers used it \nweekly for lesson planning, highlighting the growing impact of LLMs in education.  \nTable 3 summarizes the applications of LLMs in educational and developmental psychology, which can \nbe broadly divided into two categories: developmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 534,
      "text": "evelopmental research with LLMs and using LLMs for education \nand learning applications. Here, developmental research  seeks to determine whether LLMs can simulate \nhuman developmental processes (e.g., theory of mind and emotional reasoning) and how such capabilities \nmight advance our understanding of human cognitive and emotional development. Kosinski (2024) , for \ninstance, tested different LLMs in 40 false -belief tasks and found that GPT -4 achieved 75% accuracy, \ncomparable to the performance of a six -year-old child, while older models performed significantly worse. \nVzorinab et al. (2024)  used the Mayer \u2013Salovey \u2013Caruso Emotional Intelligence Test (MSCEIT) to evaluate \nGPT-4\u2019s emotional intelligence. While GPT -4 excelled at understanding and managing emotions, its \nreflective analysis resembled the early developmental stages of human emotional  reasoning.  \nThe study of using LLMs for education and learning applications focuses on leveraging LLMs to address \nchallenges in education, such as providing personalized learning and improving learning motivation. LLMs \nlearn from massive amounts of data taken from boo ks and the Internet (Binz & Schulz, 2023b ) and can be \nused as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 535,
      "text": "ed as more knowledgeable learning aids (Stojanov, 2023 ), provide personalized learning experiences \n(Kasneci et al., 2023 ), and enhance the motivation to learn (Ali et al., 2023 ). Baillifard et al. (2024) , for \ninstance, found that an AI tutor powered by GPT -3 improved academic performance by up to 15 percentile \npoints through personalized learning strategies. Stojanov (2023)  used the following approach to explore \nGPT\u2019s potential as a learning tool: First, he set learning objectives and had \u201cconversations\u201d with GPT about \nits functionality for 4 hours. For the next 3 hours, he continued the discussion with GPT and watched some \nrelevant videos on YouTube. He experienced positive feedback from his interactions with GPT and found it \nto be a motivating and relevant learning experience.  \n \nTable 3  Applications of LLMs in educational and developmental psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nDevelopmental Research with LLMs  \nKosinski \n(2024)  Can LLMs demonstrate theory \nof mind (ToM) abilities?  Eleven  different  LLMs were tested on 40 \nfalse -belief tasks, requiring success in \neight related scenarios per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 536,
      "text": "os per task. \nPerformance was compared across model \nversions.  GPT-4 achieved 75% accuracy, \ncomparable to 6 -year-old children, while \nolder models performed significantly \nworse.  \nVzorinab et \nal. (2024)  How does GPT -4\u2019s emotional \nintelligence align with \ndevelopmental patterns in \nhuman emotional reasoning?  GPT-4 was evaluated using the Mayer -\nSalovey -Caruso Emotional Intelligence \nTest (MSCEIT) through text -based \nprompts.  GPT-4 excels in understanding and \nmanaging emotions but shows limited \nreflective analysis, resembling early \ndevelopmental stages in human \nemotional reasoning.  \nTrott et al. \n(2023)  How does exposure to language \ninfluence the development of \ntheory of mind in humans and \nAI? A linguistic False Belief Task was \npresented to humans and GPT -3 to assess \nbelief attribution abilities.  GPT-3\u2019s partial success suggests that \nwhile language exposure contributes to \nbelief reasoning, other developmental \nmechanisms unique to humans are \ncrucial for fully developing theory of \nmind.  \n \nLLMs for Education and Learning Applications  \nStojanov \n(2023)  How effective is GPT as a \nlearning aid in scaffolding \nunderstanding of a specific \ntopic? An autoethnographic study exploring the \nauthor\u2019s personal experience using \nChat GPT (3.5)  to learn about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 537,
      "text": "about its technical \naspects.  ChatGPT supports learning through \nmotivating feedback but often provides \nsuperficial, inconsistent, and \ncontradictory responses, risking \noverestimation of knowledge.  \nJyothy et al. \n(2024)  What factors influence the \nadoption of LLMs like \nChat GPT in learning, teaching, \nand research?  The Fogg Behavior Model (FBM) was \napplied to analyze the motivations, \nabilities, and perceptions of students, \nteachers, and researchers toward LLM \nuse. User motivation and ability drive LLM \nadoption, but limitations like teacher \nhesitance and technical challenges hinder \nbroader integration.  \nLogacheva et \nal. (2024)  Can GPT-4 generate \npersonalized programming \nexercises to enhance student \nengagement and learning?  GPT-4-generated exercises were \nevaluated in an introductory \nprogramming course by students and \ninstructors for quality and engagement.  GPT-4 effectively produced high -quality, \nengaging exercises, offering \npersonalized and scalable practice \nmaterials for programming education.  \nMachin et al. \n(2024)  Can GPT demonstrate \npsychological literacy \ncomparable to subject matter \nexperts (SMEs) in psychology \nresearch methods?  GPT rated 13 research scenarios, and its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 538,
      "text": "nd its \nresponses were statistically compared to \nSME evaluations.  GPT showed strong alignment with SME \nratings (r\u2009=\u2009.73 \u2013.80), indicating its \npotential to match SME -level \npsychological literacy.  \nGhafouri \n(2024)  Can a ChatGPT-based rapport -\nbuilding protocol (CGRBP) \nenhance L2 (Second Language) \ngrit in English learners?  A 16 -week experimental study compared \n30 EFL learners (15 experimental, 15 \ncontrol) using pre -test post -test ANCOV A \nanalysis.  CGRBP significantly improved L2 grit, \ndemonstrating its potential to foster \nemotional support and learning \nmotivation.  \nGhafouri et \nal. (2024)  Can ChatGPT match expert \npsychological literacy in \nevaluating research methods?  The study compared responses from \nChatGPT to 13 psychological research \nmethod scenarios against ratings by \nsubject matter experts.  ChatGPT \u2019s responses correlated strongly \nwith expert evaluations, suggesting its \npotential as an educational tool in \npsychology, though its usage should be \napproached with caution.  \nBaillifard et \nal. (2024)  Can AI tutors improve \nacademic performance through \npersonalized learning \nstrategies?  A semester -long study with 51 \npsychology students using a GPT -3-\npowered AI tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 539,
      "text": "tutor for personalized \nretrieval practice and progress modeling.  Active AI tutor use improved grades by \nup to 15 percentile points, with strong \nalignment between AI predictions and \nexam results.  \nNote\uff1a Theory of mind (ToM) is the cognitive ability to attribute mental states to oneself and others \uff1b the \nFogg Behavior Model (FBM) explains behavior as a product of motivation, ability, and prompts.  \n \n \n \n \n5. LLMs in social and cultural psychology  \nSocial and cultural psychology explores how individuals interact with and are influenced by their social \nand cultural environments. It focused on interpersonal dynamics, group behavior, social cognition, and the \nlong-term formation and transformation of at titudes and norms (Tajfel, 1982 ). Such phenomena occur at \nvarious time scales, from immediate social interactions to cultural changes evolving over several years \n(Newell, 1990 ). LLMs provide valuable tools for advancing social and cultural psychology. By analyzing \ntextual datasets, simulating social interactions, and modeling human -like behaviors, LLMs can provide \ninsights into the dynamics of social cognition, group processes, and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 540,
      "text": ", and cultural norms (Salah et al., 2023 ). Their \nscalability and ability to quantify patterns across time scales make them powerful instruments for examining \nhuman interactions in diverse contexts.  \nResearch on LLMs in social and cultural psychology can be categorized into three main areas: cultural \nand cognitive understanding, social interactions and behavioral simulations, and practical applications. First, \nLLMs have many similarities with humans re garding social cognition. For example, research has found that \nLLMs reflect a variety of typical human cognitive biases in judgment and decision -making, such as the \nanchoring effect, the representativeness heuristic, and base -rate neglect (Talboy & Fuller, 2023 ). In addition, \ncultural psychology research has identified significant differences in the cognitive processes of Easterners \nand Westerners when processing information and making judgments (Nisbett et al., 2001 ); in this regard, \nLLM consistently favors holistic Eastern ways of thinking (Jin et al., 2023 ). Second, LLMs have been shown \nto characterize human groups in social interaction settings. It has been shown that LLMs can replicate the \nresults of Milgram\u2019s electroshock experiments (Aher et al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 541,
      "text": "al., 2023 ), show better gaming abilities in specific \ngames (Akata et al., 2023 ), and exhibit different risk -taking and prosocial behaviors under different \nemotional states (Yukun et al., 2023 ). \nThird, LLMs are increasingly used as proxies for human participants in psychological research. One \nstudy, for example, explored the potential of LLMs to serve as valid proxies for specific human subgroups \nin social science research; it found that LLMs cont ained information that went far beyond superficial \nsimilarity, reflecting the complex interplay between ideas, attitudes, and sociocultural contexts that \ncharacterizes human attitudes (Argyle et al., 2022 ). In addition, LLM has been tested for personality and \nvalues, obtaining results comparable to those for human samples, indicating their potential as psychological \nresearch tools (Miotto et al., 2022 ). Within this broader perspective, industrial and organizational psychology \nhas increasingly employed LLMs, particularly in employee selection and workplace optimization, \ndemonstrating their broader utility for understanding human behavior in structured en vironments. For \nexample, LLMs have been shown to improve the accuracy and efficiency of recruitment systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 542,
      "text": "t systems in terms of \nassessing candidate fit and simulating workplace behaviors (Du et al., 2024 ). This approach can help mitigate \nbiases and expand accessibility to a broader range of candidates. LLMs have also been integrated into \nsystems such as PALR (personalization -aware LLMs for recommendation) to dynamically align individual \ncapabilities with o rganizational needs. Such systems significantly reduce inefficiencies in hiring processes \nand enhance predictions about job performance by identifying nuanced compatibility factors in resumes and \ncover letters (Yang et al., 2023 ). Beyond individual applications, LLMs have contributed to understanding \nbroader organizational cultures and transformational dynamics by providing insights into how group \ninteractions and leadership styles influence workplace outcomes (Noy & Zhang, 2023 ). In the context of \nemployee productivity, experiments using LLMs have revealed substantial benefits. For instance, \nprofessionals using ChatGPT in workplace writing tasks improved productivity by reducing task completion \ntime by 40% and enhancing output qu ality by 18%, indicating its potential to effectively augment mid -level \nprofessional tasks (Noy & Zhang, 2023 ). Similarly, research on creativity has demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 543,
      "text": "as demonstrated LLMs\u2019 ability \nto help solve organizational problems requiring innovative thinking (Lee & Chung, 2024 ). Table 4 \nsummarizes the applications of LLMs to social and cultural psychology.  \nLLMs have many applications in social and cultural psychology, allowing us to test theories and \nhypotheses about human behavior in social and cultural interaction settings. Zhao et al. (2024) , for instance, \nexamined whether AI chatbots can adjust their financial decisions and prosocial behaviors based on \nemotional cues, similar to humans. It was hypothesized that bots would take fewer risks when exposed to \nfear cues and more risks with joy cue s. Emotional primes (fear, joy, or neutral) were applied, and investment \ndecisions were analyzed. Additionally, prosocial responses, such as donating to a sick friend, were measured \nto assess how LLMs adapt behaviorally under emotional influences.  These findings highlight LLMs \u2019 ability \nto model complex social dynamics and cultural influences. The next section broadens this perspective, \nexploring LLMs \u2019 potential as versatile research tools for psychologists.  \n \n \n \nTable 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 544,
      "text": "Table 4  Applications of LLMs in social and cultural psychology stud ies. \nReferences  Research question  Research method  Key finding  \n \nCultural and Cognitive Understanding with LLMs  \nAtari et al. \n(2023)  Do LLMs exhibit biases \ntoward WEIRD (Western, \nEducated, Industrialized, \nRich, Democratic) societies in \npsychological tasks?  LLMs\u2019 responses on psychological measures \nwere compared to cross -cultural human data.  LLMs closely align with WEIRD \ncognitive patterns but show declining \naccuracy with non -WEIRD \npopulations (r = -0.70), revealing a \nWEIRD bias.  \nJin et al. \n(2023)  Does GPT exhibit cultural \ncognitive traits aligned with \nEastern or Western thinking?  GPT was evaluated using cognitive and value \njudgment  scales.  GPT leans towards Eastern holistic \nthinking in cognitive tasks but shows \nno cultural bias in value judgments, \nlikely influenced by its training data \nand methods.  \nSchaaff et al. \n(2023)  How empathetic is GPT \ncompared to humans?  GPT\u2019s empathy was evaluated through \nemotion recognition tasks, conversational \nanalysis, and five empathy -related \nquestionnaires.  GPT accurately identified emotions in \n91.7% of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 545,
      "text": "of cases, showed parallel \nemotions in 70.7%, and scored below \naverage humans but above individuals \nwith Asperger syndrome on empathy \nmeasures.  \nPatel and \nFan (2023)  Can LLMs like Bard, GPT -\n3.5, and GPT -4 match human \nempathy and emotion \nidentification?  Empathy and emotional understanding were \nassessed using TAS -20 (Toronto Alexithymia \nScale -20) and EQ -60 (Emotional Quotient \nInventory -60), comparing LLM responses to \nhuman benchmarks.  GPT-4 approached human -level \nemotional intelligence, outperforming \nBard and GPT -3.5, which showed \nalexithymic tendencies.  \nX. Wang et \nal. (2023)  How do LLMs compare to \nhumans in emotional \nintelligence?  A psychometric assessment focusing on \nEmotion Understanding  was developed and \napplied to mainstream LLMs, benchmarking \nthem against over 500 human participants.  GPT-4 scored higher than 89% of \nhumans in emotional intelligence, with \nLLMs showing above -average \nemotional intelligence  but using non -\nhuman mechanisms influenced by \nmodel design.  \nX. Li et al. \n(2022)  Are LLMs psychologically \nsafe, and how can fine -tuning \nimprove their safety?  LLMs were assessed using the Short Dark \nTriad (SD -3), Big Five Inventory (BFI), and \nwell-being tests to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 546,
      "text": "to evaluate personality traits \nand the impact of fine -tuning.  LLMs exhibit elevated dark traits but \nshow improved well -being and \npsychological safety with targeted \nfine-tuning.  \nMiotto et al. \n(2022)  What are GPT -3\u2019s personality \ntraits and values as assessed \nby validated psychological \ntools? Administered validated personality and values \nmeasurement tools to GPT -3, including a \nmodel response memory to assess value \nalignment.  GPT-3 exhibits personality traits and \nvalues similar to human samples, \nproviding initial evidence of \npsychological assessment in LLMs.   \n \nSocial Interactions and Behavioral Simulations  \nZhao et al. \n(2024)  Can LLMs like GPT adapt \nresponses to emotional primes \nin decision -making?  Tested GPT -4 and 3.5 with scenarios eliciting \npositive, negative, or neutral emotions.  GPT-4 showed distinct emotional \nresponse patterns, exceeding GPT -3.5, \nindicating advanced modulation but no \ntrue emotions.  \nAher et al. \n(2023)  Can LLMs accurately \nsimulate human behaviors, \nand what biases emerge in \ntheir simulations?  Introduced Turing Experiments to evaluate \nLLMs against findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 547,
      "text": "st findings from classic behavioral \nstudies.  LLMs replicated most findings but \nshowed \u201chyper -accuracy distortion,\u201d \nraising concerns for applications in \neducation and the arts.  \nAbramski et \nal. (2023)  Do LLMs exhibit biases \ntoward math and STEM, and \nhow do these biases compare \nacross models and with \nhumans?  Using Behavioral Forma Mentis Networks, \nbiases in GPT -3, GPT -3.5, GPT -4, and high \nschool students were analyzed through a \nlanguage generation task.  Newer LLMs (GPT -4) show reduced \nnegative bias and richer semantic \nassociations toward math and STEM \ncompared to older models and \nhumans, suggesting advancements in \nreducing stereotypes.  \nAlmeida et \nal. (2024)  How do state -of-the-art LLMs \nreason about moral and legal \nissues, and how do their \nresponses align with human \njudgments?  Eight experimental psychology studies were \nreplicated using Google\u2019s Gemini Pro, \nAnthropic\u2019s Claude 2.1, GPT -4, and Meta\u2019s \nLlama 2 Chat 70b. Model responses were \ncompared to human responses to assess \nalignment and systematic differences.  GPT -4 showed the best human \nalignment among LLMs but \nexaggerated effects and reduced \nvariance, highlighting biases that limit \ntheir suitability as substitutes for \nhuman participants in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 548,
      "text": "in psychological \nresearch.  \n \nPractical Applications  with LLMs  \nNoy and \nZhang \n(2023)  How does generative AI affect \nemployee productivity?  Workplace experiments with ChatGPT on \nwriting tasks.  ChatGPT improved productivity (40% \nfaster task completion, 18% better \nquality).  \nLee and \nChung \n(2024)  How does ChatGPT influence \ncreativity?  Measured creativity using associative and \ndivergent thinking tasks.  ChatGPT supports incremental \ncreativity but is less effective for \nradical innovation.  \nYang et al. \n(2023)  Can LLMs personalize job \nrecommendations?  PALR(personalization -aware LLMs for \nrecommendation) integrated interaction data \nwith LLMs for dynamic recommendations.  PALR enhanced predictions of job \nperformance and improved role \nmatching.  \nDu et al. \n(2024)  How can LLMs improve job \nrecommendations?  Used GANs with LLMs to refine low -quality \nresumes.  GAN -based systems predicted better \njob fit and reduced hiring \ninefficiencies.  \nAkata et al. \n(2023)  How do LLMs perform in \nsocial interaction tasks \ninvolving cooperation and \ncoordination?  LLMs played repeated two -player games (e.g., \nPrisoner\u2019s Dilemma, Battle of the Sexes) with \nother LLMs and human -like strategies to \nanalyze their behavior.  LLMs perform well in self -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 549,
      "text": "lf -interest -\ndriven games but struggle with \ncoordination, with GPT -4 showing \nunforgiving behavior in the Prisoner\u2019s \nDilemma and difficulty adopting \nsimple coordination strategies.  \nSuri et al. \n(2024)  Does GPT exhibit heuristics \nand context -sensitive \nresponses similar to those \nobserved in human decision -\nmaking?  Four studies tested GPT\u2019s responses to \nprompts designed to assess cognitive biases \n(anchoring, representativeness, availability \nheuristic, framing effect, endowment effect) \nand compared them to human participant \nresponses.  GPT demonstrated biases consistent \nwith human heuristics across all \nstudies, suggesting that language \npatterns alone may contribute to these \neffects, independent of human \ncognitive and affective processes.  \nPark et al. \n(2022)  How can designers predict \nand refine social behaviors in \nlarge -scale social computing \nsystems before deployment?  Developed \u201csocial simulacra,\u201d an LLM -driven \nsimulation that generates realistic community \ninteractions based on design inputs (goals, \nrules, personas), allowing scenario testing and \niterative design refinement.  Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 550,
      "text": "Social simulacra accurately mimicked \nreal community behavior, supported \n\u201cwhat if?\u201d scenario exploration, and \nhelped designers improve system \ndesigns before large -scale \ndeployment.  \nSap et al. \n(2022)  Can LLMs demonstrate social \nintelligence and Theory of \nMind (ToM)?  LLMs were evaluated using SocialIQa (social \nintents and reactions) and ToMi (mental states \nand realities), with results contextualized \nthrough pragmatics theories.  LLMs, including GPT -4, perform \nbelow human levels (55% on \nSocialIQa, 60% on ToMi), indicating \nthat scaling alone does not yield ToM, \nhighlighting the need for person -\ncentric NLP approaches.  \nArgyle et al. \n(2022)  Can GPT -3 reliably emulate \nhuman subpopulations for \nsocial science research?  GPT-3 was conditioned on sociodemographic \nbackstories from U.S. surveys, creating \n\u201csilicon samples,\u201d which were compared to \nhuman survey data.  GPT-3 exhibits nuanced, \ndemographically aligned biases, \nindicating its potential as a tool for \nstudying human behavior and societal \ndynamics.  \nP. S. Park et \nal. (2024)  Can GPT -3.5 simulate human \nparticipants and replicate \nsocial science study results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 551,
      "text": "udy results?  Replicated 14 Many Labs 2 studies using \nGPT-3.5, analyzing response patterns and the \n\u201ccorrect answer\u201d effect through pre -registered \nand exploratory studies.  \n GPT-3.5 replicated 37.5% of study \nresults but exhibited uniform \nresponses (\u201ccorrect answer\u201d effect) \nand skewed conservative in moral \nfoundation surveys, questioning its \nreliability and diversity as a human \nparticipant substitute.  \nNote:  WEIRD (Western, Educated, Industrialized, Rich, Democratic) refers to societies that represent a \nminority of the global population but are often overrepresented in psychological research.  \n \n6. LLMs as research tools in psychology  \nSections 2 -5 illustrate LLMs \u2019 applications across cognitive, clinical, educational, and social psychology, \nrevealing their potential to transform research practices. Together, these advancements speed up \npsychological research with new tools, encourage collaboration with fields like c omputer science and \nlinguistics, and improve theoretical models through behavioral simulation \u2014key ways LLMs advance \npsychology. Building on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 552,
      "text": "on these foundations, this section explores LLMs as versatile research tools in \npsychology, supporting diverse tasks such as systematic reviews, literature review, and experimental design \n(Table 5). By reducing subjective bias and minimizing human variability in tasks like stimulus generation \n(Section 2), standardized assessments (Section 3), and data inter pretation (Section 4), LLMs enhance \nobjectivity and efficiency across these applications.  \nFor instance, LLMs can automate systematic reviews and meta -analyses, revolutionizing evidence \nsynthesis and provide actionable insights for psychologists, as grounded in cognitive and behavioral \nprinciples  (e.g., in Sections 2 and 3).  This capacity extends to enhancing psychologists \u2019 workflows, \nbuilding on productivity improvements noted in Section 5, through tools like literature review, hypothesis \ngeneration, experimental design, experimental subjects, and data analysis (Table 5).  \nTable 5. LLMs as research tools in psychology study.  \nTopic  Related study  \nLiterature review  LLMs can summarize the researched literature (Dis, Bollen, Zuidema, Rooij, & Bockting, 2023) , complete literature \nreview tasks (Qureshi et al., 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 553,
      "text": ", 2023) , and create literature review articles (Ayd\u0131n & Karaarslan, 2022) , at the same \ntime, there are LLM that has been specially trained to accomplish systematic literature reviews (Taylor et al., 2022) \u3002 \nHypothesis \ngeneration  LLMs can generate hypotheses from scientific literature, make inferences based on scientific data, and then clarify \ntheir conclusions through interpretation (Zheng et al., 2023) , and can quickly and automatically test these research \nhypotheses and learn from mistakes . \nExperimental \ndesign  \n LLMs provide text -based material for experimental design, thereby optimizing the research process and reducing \nexperimental complexity. By employing these models, researchers can easily create experimental stimuli, develop \ntest items, and even simulate interactive sessions in con trolled environments  (Aher, Arriaga, & Kalai, 2022; Akata \net al., 2023) , providing a high degree of control and precision to the experimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 554,
      "text": "erimental process.  \nExperimental \nsubjects  LLMs can simulate some human behaviors and responses, which provides an opportunity to test theories and \nhypotheses about human behavior (Grossmann et al., 2023) , their use in place of human participation in experiments \nsaves time and costs and can be applied to some experiments where human participation is not appropriate (Hutson, \n2023 ), they can be combined with factors such as the specific research topic, the task, and the sample, and the use \nof LLM as an alternative to research participants where appropriate (Dillion et al., 2023 ). \nData analysis  LLMs can efficiently analyze massive amounts of textual data to gain insights into human behavior and emotions \nat an unprecedented scale  (Patel & Fan, 2023) , can analyze textual data in multiple languages, and accurately detect \nmental structures within it (Rathje et al., 2023) , can draw mental profiles from social media data (Peters & Matz, \n2023)\u3002 \nScholarly \nCommunication  LLMs can also help humans in writing (Dergaa et al., 2023 ; Stokel -Walker, 2022 ; Van Dis et al., 2023 ). LLMs were \nused in two natural language processing tasks and a human expert to assess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 555,
      "text": "ess the quality of the text, and the results of \nthe assessment were consistent with those of the human expert (Chiang & Lee, 2023) , LLMs offer the opportunity \nto get things done quickly, from Ph.D. students struggling to finish their dissertations, to peer reviewers submitting \nanalyses under time pressure (Van Dis et al., 2023 ). \n \n6.1.  Automated literature review and meta -analysis  \nConducting a literature review meta -analysis is a complex, arduous process that requires significant \ntime and expertise (Michelson & Reuter, 2019 ). Nature reported that researchers have used GPT as a research \nassistant to summarize literature (Dis et al.  2023) . In one study, researchers used GPT to complete certain \nsystematic literature review tasks (Qureshi et al., 2023) . In another study, a literature review article was \ncreated using GPT with the application of digital twins in the health field; the results showed that knowledge \ncompilation and representation were accelerated with the help of LLMs. However, their academi c validity \nneeds to be further verified (Ayd\u0131n & Karaarslan, 2022) . Researchers have also specifically trained LLMs to \nsupport the practical needs of scientific research (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 556,
      "text": "ch (Taylor et al., 2022) , including the ability to perform \nsystematic literature reviews.  \nRecent studies have highlighted how LLMs can efficiently support meta -analysis. For instance, Luo et \nal. (2024)  demonstrated that LLMs can screen literature, extract data, and generate statistical codes for meta -\nanalyses, significantly reducing workload while maintaining recall rates comparable to manual curation. \nSimilarly, Tong et al. (2024)  used LLMs to extract causal pairs from 43,312 psychology articles, achieving \nan 86.98% success rate in pair extraction through adaptive prompting. As discussed in section 3, LLMs have \nshown strong capabilities in extracting causal relationships from large  textual datasets, underscoring their \npotential to streamline evidence synthesis for systematic reviews and meta -analyses. Nevertheless, while \nLLMs excel in organizing qualitative data and identifying conceptual patterns, they face challenges in \nextracting  the precise numerical data necessary for meta -analyses. For example, although LLM -based tools \ncan retrieve and summarize outcome measures, manual validation remains essential to ensure accuracy, \nespecially when processing complex figures or tables.  \nIn summary, LLMs can speed up the process of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 557,
      "text": "ess of literature review and meta -analysis. Researchers can \nuse such models to systematically review and synthesize existing research, improving the efficiency of \nevidence -based psychology.  \n6.2.  Hypothesis generation and experimental design  \nHypothesis -driven research is at the core of scientific activity. LLMs can generate hypotheses from \nscientific literature, make inferences based on data, and then clarify conclusions through interpretation \n(Banker et al., 2024 ; Zheng et al., 2023 ). Although LLMs are capable of becoming \u201chypothesis machines,\u201d \ntheir logical and mathematical derivation capabilities still need improvement to eliminate factual errors, \nquickly test hypotheses, and learn from mistakes (Y . J. Park et al., 2024 ) . As innovative tools, LLMs have \ngreat potential for use in psychological experiments, given their ability to provide text -based material for \nexperimental designs, thus optimizing the research process and reducing experimental complexity. Using \nsuch model s researchers can easily create experimental stimuli, develop test items, and even simulate \ninteractive sessions in controlled environments (Aher, Arriaga, & Kalai, 2022; Akata et al., 2023) , providing \na high degree of control and precision in the experimental process.  \nIn conclusion, LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 558,
      "text": "LLMs provide powerful, flexible tools for psychological research, from hypothesis \ngeneration to experimental design, which can help researchers achieve more precise, efficient research goals.  \n6.3.  LLMs as subjects in psychological experiments  \nAlthough LLMs can simulate some human behaviors and responses \u2014which provides an opportunity \nto test theories and hypotheses about human behavior (Grossmann et al., 2023) \u2014there is still some \ncontroversy on whether LLMs can be used as a substitute for human subjects in psychological research. \nWhile recognizing that certain problems persist (e.g., biases and insufficiently trained data), some \nresearchers have suggested that LLMs can be used as substitutes for human participants to save time and \ncost and can be applied to experiments that are not suitable for human participation (Hutson,2023) . Others \nhave proposed using LLMs as an alternative method of studying participants when appropriate, based on \ntheir performance in conjunction with factors such as specific research topics, tasks, and samples (Dillion et \nal., 2023 ). However, it is also believed that although LLMs can significantly affect scientific research, they \nare unlikely to replace human participants in any meaningful way (Harding et al., 2023 ). At the same time, \nsome studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 559,
      "text": "some studies of LLMs as subjects have shown that LLMs perform similarly to humans (Orru et al., 2023 ; P . \nS. Park et al., 2024 ), which might indicate LLMs\u2019 potential to replace humans as subjects.  \nIn conclusion, although LLMs can simulate human judgment, their simulation of human thinking \nremains limited, and their output should be validated and interpreted with caution when used as \npsychological subjects.  \n6.4.  Tools for data analysis  \nVarious forms of AI have long been used to analyze psychological data, such as flight data for pilot \nscreening (Ke et al., 2023 ). Machine learning algorithms facilitate the processing of large datasets, \nidentifying patterns and correlations that might otherwise be overlooked. However, LLMs take this \ncapability to a new level; they can efficiently analyze massive amounts of textual data on an unprecedented \nscale to derive insights into human behavior and emotions (Patel & Fan, 2023) . For psychological research, \nthis means faster and more comprehensive data analysis, leading to more reliable, nuanced findings. LLMs \ncan analyze textual data in multiple languages, accurately detect psychological structures within them \n(Rathje et al., 20 23), and generate psychological profiles from social media data (Peters & Matz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 560,
      "text": "atz, 2023) . \nLLMs have also demonstrated a degree of competence in the medical field; LLMs can, for example, predict \nthe optimal neuroradiographic imaging modality for a given clinical presentation. Yet, LLMs cannot \noutperform experienced neuroradiologists, suggestin g the need for continued improvement in the medical \ncontext (Nazario -Johnson et al., 2023 ). These findings demonstrate the great potential of LLMs for \nevaluating and analyzing data.  \n6.5.  Promoting scholarly communication  \nScholarly communication is a cornerstone of academic research, encompassing the processes of \ncreating, evaluating, and disseminating knowledge. It includes writing research papers, conducting peer \nreviews, and ensuring that findings are communicated transp arently and ethically. In psychology, this process \nis particularly complex owing to the field\u2019s diverse theoretical frameworks and methodological approaches, \nranging from experimental to qualitative research. The discipline\u2019s focus on human behavior and it s \nintersection with technology demands precise and ethical communication practices.  \nIt has been argued that LLMs currently cannot completely replace human writing and instead can only \nanswer questions and generate naturally fluent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 561,
      "text": "uent and informative content but with no real intelligence \u2014i.e., \ntext based on patterns of previously seen words (Stokel -Walker, 2022) . In one study, students used GPT as \nan aid in their writing. The experimental group that used GPT was found to be similar to the control group \nin terms of writing quality, speed, and authenticity; the authors suggested that this could be because \nexperienced researchers can better guide GPT to produce high -quality information. By contrast, students \u2014\nwho have less writing experience than researchers \u2014found that GPT did not perform as effectively (Ba\u0161i\u0107 et \nal., 2023 ). Another article discussed the prospects and potential threats of GPT in academic writing, \nemphasizing that using GPT in academic research should prioritize peer -reviewed scholarly sources. Yet, \nGPT\u2019s potential advantages for academic research, including the handling of large amounts of textual data \nand the automatic generation of abstracts and research questions (Dergaa et al., 2023 ), were highlighted. \nFurthermore, LLMs can potentially be used for peer review (Van Dis et al., 2023 ). The decisions/judgments \nof LLMs in a text -evaluation task were found to be consistent with those of human experts (Chiang & Lee, \n2023) . \nIn conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 562,
      "text": "n conclusion, LLMs such as GPT are potent tools for scholarly communication in psychology, capable \nof processing large amounts of textual data and automating tasks that were previously done manually. They \ncan be used to scan academic papers and extract es sential details, generate objective and unbiased abstracts, \nand create research questions in social psychology (Banker et al., 2023 ; Tong et al., 2024 ). However, \nresearchers must exercise caution when using them as they can also introduce false or biased information \ninto papers, leading to unintentional plagiarism and the misattribution of concepts (Van Dis et al., 2023 ). \n \n \n7. Challenges and future directions  \n7.1.  Challenges and limitations  \nLLMs have enormous potential to simulate complex cognitive processes, providing researchers with \nnew tools to explore the mechanisms of human cognition and behavior for wide -ranging application in \nvarious fields, including clinical and counseling psycholog y, educational and developmental psychology, \nand social and cultural psychology. However, LLM output should not be mistaken for the presence of thought \nbut instead viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 563,
      "text": "d viewed as complex pattern matching based on probabilistic modeling (Floridi & Chiriatti, 2020 ). \nAlthough LLMs show impressive performance, this differs from consciousness or genuine understanding. \nThe interpretation of LLMs\u2019 capabilities must be based on an understanding of their limitations and the \nnature of their operations, which might differ fu ndamentally from human cognition. It is essential, then, to \nfocus on the potential of LLMs in psychological research while also acknowledging the technical and ethical \nchallenges that might arise.  \nFirst, despite the emergence of LLM competence (Wei et al., 2022 ), its internal working mechanism \nremains a black box from a cognitive and behavioral psychology perspective. For example, LLMs perform \nimpressively on tasks requiring formal linguistic competence (including knowledge of the rules and patterns \nof a particul ar language) but fail many tests requiring functional competence (the set of cognitive abilities \nneeded to understand and use language in the real world) (Mahowald et al., 2023 ). They excel in analogical \nand moral reasoning tasks but perform poorly on spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 )."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 564,
      "text": "spatial reasoning tasks (Agrawal, 2023 ). \nSecond, while LLMs have accelerated the use of AI in clinical and counseling psychotherapy, privacy \nand ethical issues might arise (Graber -Stiehl, 2023 ). For example, gatekeepers, patients, and even mental \nhealth professionals who use GPT to assess suicide risk or improve decision -making might receive \ninaccurate assessments that underestimate risk (Elyoseph & Levkovich, 2023 ) or bias clinician decision -\nmaking, which can lead to healthcare inequities (Pal et al., 2023 ). In addition, LLMs in psychiatry research \nand practice have been associated with potential bias and privacy violations (Zhong et al., 2023 ). \nThird, LLMs face application challenges in fields such as educational, developmental, and social and \ncultural psychology. It is evident that when applied in education, LLMs have the potential for output bias \nand misuse (Kasneci et al., 2023 ). One study found that texts generated by GPT were not always consistent \nor logical and sometimes even contradictory (Stojanov, 2023 ). In the field of social and cultural psychology, \nLLMs exhibit cognitive biases (Talboy & Fuller, 2023 ) and cultural biases (Atari et al., 2023 ) similar to those \nof humans, in addition to implicitly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 565,
      "text": "citly darker personality patterns (X. Li et al., 2022 ). Bender et al. (2021)  \nsuggested that training data for LLMs might reflect social biases that continue to be perpetuated in research \nsettings.  \nFinally, LLMs have some limitations as aids to scientific research. With regard to writing, for example, \nLLMs currently cannot fully replace humans. Instead, they answer questions and generate naturally flowing, \ninformative content lacking real intelligenc e (Stokel -Walker, 2022) . Although macrolanguage models can \nsimulate human judgment when used as experimental subjects, there are still limits to their \u201cunderstanding\u201d \nof human thought (Dillion et al., 2023 ). Van Dis et al. (2023)  noted that LLMs might accelerate innovation, \nshorten publication times, and increase scientific diversity and equality. However, they might also reduce \nthe quality and transparency of research and fundamentally alter scientists\u2019 autonomy as human research ers. \nIn summary, while LLMs offer extraordinary capabilities for psychological research, they also present \nchallenges related to bias, ethical issues, data security, transparency, and technical expertise. Researchers \nshould be fully aware of these challenges wh en using LLMs and adopt the following steps for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 566,
      "text": "s for ethical use: \nFirst, disclose model details and methods transparently to ensure reproducibility. Second, verify outputs \nagainst literature or experts to address inaccuracies and misinformation. Third, use diverse training data to \nreduce cultural or gender biases. Fourth , in sensitive areas like mental health, limit use to assist \u2014not \nreplace\u2014judgment and train users to interpret outputs critically. These steps, supported by recent studies \n(Abdurahman et al., 2024; Guo et al., 2024; Porsdam Mann et al., 2024), address ethi cal concerns in \npsychological research.  Table 6 summarizes the challenges and limitations of LLMs in psychological \napplications.  \nTable 6  Challenges and limitations of LLMs in psychological applications.  \nChallenges  Author  Details  \nCogniti ve and Behavior al Psychology  \nLack of Real -World \nUnderstanding  Mitchell \n(2023)  LLMs lack real -world understanding, abstract reasoning, and intent comprehension.  \nLack of Meta -\nknowledge  Stella et al. \n(2023)  LLMs fabricate information (hallucination) and lack curiosity/meta -knowledge.  \nCausal Reasoning and \nCreativity  Sartori and \nOrr\u00f9 (2023)  Poor causal reasoning, dependence on biased training data, lack of creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 567,
      "text": "creativity and imagination.  \nMulti -Step Reasoning \nLimitations  Goertzel \n(2023)  Poor multi -step reasoning, lack of autonomy, poor real -world understanding.  \nCommon Sense \nReasoning  Peng et al. \n(2023)  Forgetting knowledge in new tasks, poor common -sense reasoning, inconsistent problem -\nsolving.  \nModel Behavior \nChallenges  Holtzman et \nal. (2023)  Lack of interpretability and formal behavioral descriptions makes systematic analysis difficult.  \nPsycholinguistic \nFeatures  Seals and \nShalin \n(2023)  GPT and human -generated analogies differed in these stylistic dimensions, these lexical \nfeatures, their choice of words for these features and these devices that help readers understand \ntext. GPT may lack human cognitive and psycholinguistic features when generating analogies.  \nClinic and Counseling  Psychology  \nTechnical Limitations& \nPatient Connection \nIssues  Stade et al. \n(2023)  Difficulty assessing suicide risk, substance abuse, safety issues, and interpreting nonverbal \ncues& Problems forming therapeutic relationships, interpreting nonverbal behaviors.  \n \nEducation and Development  Psychology  \nIntegrity and Ethics \nIssues  Li et al. \n(2023)  Academic integrity concerns, misinformation, data privacy, and impact on critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 568,
      "text": "n critical thinking.  \nBias and Over -\nReliance& Multilingual \nSupport Challenges   Kasneci et \nal. (2023)  Insufficient personalization, bias in teaching, over -reliance on models reduces creativity.& \nLimited support for diverse languages and equitable access.  \nSocial and Culture  Psychology  \nLiability and Privacy \nIssues  Fecher et al. \n(2023)  Liability issues: challenging traditional mechanisms of authorship and liability. Bias issues: \naffecting the objectivity and impartiality of science. Privacy and data protection issues: may be \nprivacy issues with the training data of LLMs. Intellectual pro perty issues: potential legal \ndisputes. Environmental issues: generating large amounts of carbon emissions, which can have \na negative impact on the environment.  \nGlobal Diversity \nIgnorance  Atari et al. \n(2023)  Ignoring global psychological diversity (e.g., tend to favor the psychological characteristics of \nWEIRD societies) and which can lead to prejudice and discrimination against people of other \ncultures and backgrounds. Differences in values and moral judgment s and which can lead to \nproblems of communication and understanding in multicultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 569,
      "text": "icultural societies. Self -identity and \nperceived social roles and which may lead to stereotypes and misconceptions about non -\nWEIRD populations).  \nCultural and Ethical \nTensions  P.S. Park et \nal. (202 4) Reduced innovation and development, bias and discrimination, culture clash and conflict, \ndifferences in values and morals and entrenchment of the status quo.  \nSocial Context \nLimitations  Salah et al. \n(2023)  Limited understanding of social context: Although GPT  performs well in syntax and general \nsemantics, it still has limitations in capturing the nuances of social language.  Ethical challenges: \nAI-generated fake content can lead to ethical issues including digital personhood, informed \nconsent, potential manipulation, and the implications of using AI to simulate human \ninteractions.  \nBias and Misleading Hayes Potential biases: if the training data contain biases, LLMs may learn and replicate them. Data \nOutputs  (2023)  privacy and consent issues: Text generated using LLMs may involve data privacy and consent \nissues.  Output may be non -humanly understandable: although LLMs generate text that closely \nresembles human language, they do not truly understand the content and may generate absurd \nor misleading responses.  \nTraining Data Bias  Miotto et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 570,
      "text": "to et al. \n(2022)  Bias and discrimination: LLMs may be affected by biases in the training data, which can \nproduce unfair results, such as reinforcing sexism in the translation of job advertisements.  \nResponsibility and control: Due to the complexity of language models, it is difficult to determine \nwho is responsible for the model's output, which can lead to attribution of problems and lack of \ncontrols.  \nPropagation of Harm  Bender et \nal. (2021)  Potential Harm: LLMs may lead to the propagation of harmful ideas such as stereotyping, \ndiscrimination, and extremism, and may lead to misinformation and bullying when generating \ntext. Data bias and unfairness: leading to potential harm to marginalized communities. \nAutomating bias: exacerbating existing biases and discrimination.  Enhancement of authoritative \nviewpoints: LLMs may reinforce dominant viewpoints in the training data, further undermining \nmarginalized people.  \nAlignment Challenges  Tamkin et \nal. (2021)  Alignment: In order to better align models with human values, algorithmic improvements are \nneeded to increase factual accuracy and robustness against adversarial samples. In addition, \nappropriate values need to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 571,
      "text": "to be made explicit for different usage scenario s. Societal Impact: \nWidespread use of LLMs may lead to problems such as information leakage and amplification \nof bias.  \nMisuse of LLMs  Brown et al. \n(2020)  Misuse of language modeling: GPT -3 may be used to generate fake news, spread extremist \nideas, conduct cyber -attacks and other malicious uses.  Fairness, bias, and representation: GPT -\n3 may carry bias against gender, race, and religion, among others, sparking related \ncontroversies.  News generation: News generated by GPT -3 may be difficult to distinguish from \nreal news, leading to confusing and misleading information.  \nResearch Tools  \nPlagiarism and \nCopyright Issues  Sallam \n(2023)  Plagiarism: content generated by GPT may be considered plagiarized, violating academic \nnorms.  Copyright issues:  Is the generated content owned by GPT or by the user?  Transparency \nissues: The workings of GPT may not be transparent, making it difficult for users to understand \nthe source of generated content. Liability issues: who is responsible for GPT when generating \nincorrect content?  \nTransparency \nLimitations  Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 572,
      "text": "Gupta et al. \n(2023)  Transparency and Explanation: The working mechanism of generative AI models may be \ndifficult to explain, which may lead users to doubt the credibility of the generated content.  Legal \nand Ethical Issues: Generative AI models may involve intellectual property, privacy, and ethical \nissues, requiring attention to compliance with relevant laws and regulations during use.  \nAcademic Integrity \nConcerns  Dergaa et \nal. (2023)  Integration of erroneous or biased information. Problems with citing original sources and \nauthors. Impact on academic integrity and quality. Increased inequity and inequality: Difficulty \nin recognizing AI -generated content. Academic evaluation and recognit ion issues. Direct \nreplacement for academic researchers: GPT is not a complete replacement for academic \nresearchers as it has limitations in certain types of academic research.  \nPrivacy and Bias Risks  Peters and \nMatz \n(2023)  User privacy: LLMs can infer psychological traits from a user's social media data, which may \nviolate the user's privacy. Potential bias: LLMs may create potential bias in the inference \nprocess, which may lead to unfair treatment of specific groups (e.g., gender, age, etc.). Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 573,
      "text": ". Data \nsecur ity: if the inferential power of LLMs is used maliciously, it may lead to data leakage, with \nserious implications for users' mental health.  \nMisconduct and \nLimitations  Y . Liu et al. \n(2023)  Academic misconduct: GPT may be used for academic cheating, such as generating false papers \nor assignments.  Challenges in the medical field: GPT  has limitations in medical image analysis, \nwhich may lead to wrong diagnosis and jeopardize patients' health.  \n \n7.2.  Future directions and emergent trends  \nCurrently, LLMs are used in different areas of psychology, including cognitive and behavioral, clinical \nand counseling, educational and developmental, and social and cultural psychology. As the capabilities of \nLLMs are further enhanced, their potential applications in psychology will continue to develop.  \nFirst, in the field of cognitive and behavioral psychology, with the emergence of multimodal LLMs \n(OpenAI, 2023 ), it is possible to combine visual and auditory information with textual data to better \nunderstand and model emotions, behaviors, and mental states for cognition. However, neuroimaging data \ncan be used to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 574,
      "text": "to inform the architectures and parameters of LLMs and  integrate that information with \ntraditional textual data to create more accurate and biologically sound models of human language and \nthought.  \nSecond, in the field of clinical and counseling psychology, on the one hand, personal data, such as social \nmedia posts, medical records, or wearable device data, can be used to create tailored, personalized LLMs \nthat provide more accurate and relevant insi ghts into an individual\u2019s state of mind. At the same time, the \nstrengths of human clinical and counseling expertise can be combined with the scalability and computational \npower of LLMs to create new diagnostic treatment and intervention tools. In addition,  in educational and \ndevelopmental psychology and social and cultural psychology, it is essential to build ethical LLMs and \nensure they are designed and deployed in a way that respects privacy and uses data fairly and responsibly.  \nUltimately, LLMs represent a systematic project whose future development cannot be achieved without \nthe interdisciplinary collaboration of researchers in diverse fields such as psychology, computer science, and \nlinguistics. For psychology researchers, acce ssible open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 575,
      "text": "ble open -source LLM frameworks and tools might become \nan integral part of their future research efforts. Table 7 summarizes LLMs\u2019 future directions and emergent \ntrends in psychological application.  \nTable 7  Future directions and emergent trends of LLMs in psychological applications . \nAuthor  Future directions and emergent trends  \nCognition and Behavior  \nD'Oria (2023)  Delving into Human -Computer Interaction (HCI) to understand AI's ability to mimic human behavior.  Exploring how \nAI language modeling can be applied in the human sciences to improve research efficiency and quality  \nCrockett and \nMesseri (2023)  Focus on the costs of adopting alternative human narratives in cognitive science research, such as masking the human \nlabor behind them and the impact on human well -being.  Concern about the impact of technological developments on \nscientific work and human understanding to ensure that cognitive scientists remain proactive in technological advances.  \nBinz and \nSchulz \n(2023b)  Explore ways to make LLMs more stable and robust in the face of descriptive tasks.  \nInvestigate whether LLMs can learn to explore purposefully and how to better utilize causal knowledge in tasks.  Analyze \nthe performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 576,
      "text": "the performance of LLMs in different tasks and contexts to see if they can adapt like humans.  Explore how LLMs \ndevelop and refine their cognitive abilities during natural interactions with humans.  \nHuang and \nChang (2022)  Improve the reasoning ability of LLMs to encourage reasoning by optimizing training data, model architecture, and \noptimization goals.  Develop more appropriate evaluation methods and benchmarks to measure the reasoning ability of \nLLMs to better reflect the true reasoning ability of the models.  Investigate the potential of LLMs in different applications \n(e.g., problem solving, decision making and planning tasks).  Explore other forms of reasoning (e.g., inductive and \nretrospective reasoning).  \nClinic and Counseling  \nAbd-Alrazaq \net al. (2019)  Develop more chatbots for people with mental illness, especially for those with disorders such as schizophrenia, \nobsessive -compulsive disorder and bipolar disorder.  \nImplement more chatbots in developing countries to address the shortage of mental health professionals.  Conduct more \nrandomized controlled trials to evaluate the effectiveness of chatbots in mental health.  \nStade et al. \n(2023)  Developing new therapeutic techniques and evidence -based practices (EBPs). Focus on evidence -based practices first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 577,
      "text": "es first: \nto create meaningful clinical impact in the short term, clinical LLM applications based on existing evidence -based \npsychotherapies and techniques will have the greatest chance of success.  Involve interdisciplinary collaboration. \nFocuses on therapist and patient trust and usability. Criteria for designing effective clinical LLMs.  \nDemszky et al. \n(2023)  Development of high -quality cornerstone datasets: these datasets need to encompass populations and psychological \nconstructs of interest and be associated with psychologically important outcomes (e.g., actual behaviors, mindfulness, \nhealth, and mental well -being). Focus on future research directions in consumer neuroscience and clinical neuroscience: \nresearch in these areas may involve the neural systems of marketing -related behaviors, decision neuroscience, \nneuroeconomics, and more.  \nEducation and Development  \nHagendorff \n(2023)  Developmental psychology: examining how LLMs develop cognitively, socially, and emotionally over the lifespan and \nhow these models can be optimized for specific tasks and situations. Learning psychology: studying how LLMs acquire \nand retain knowledge and s kills, and how to optimize these models to improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 578,
      "text": "o improve learning.  \nSociety and Culture  \nSap et al. \n(2022)  Explore more interactive and empirical training methods to help LLMs acquire true social intelligence and theoretical \nmental abilities.  Investigate ways to combine static text with rich social intelligence and interaction data to improve \nsocial intelligence in LLMs. Investigate the theoretical -psychological abilities of LLMs in more naturalistic settings to \nreveal their performance in real -world scenarios.   \nArgyle et al. \n(2022)  Investigate the algorithmic fidelity of the GPT -3 model and how appropriate conditioning can allow the model to \naccurately simulate the response distributions of various human subgroups.  Created \"in silico samples\" by conditioning \non the socio -demographic backgrounds of real human participants in multiple large U.S. surveys.  \nSchaaff et al. \n(2023)  Developing more advanced models: to more accurately capture the emotional context of conversations and improve \nemotional understanding and expression.  Measuring the emotional capabilities of bots: to investigate how to assess the \nemotional capabilities of chatbots in order to better understand how they behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 579,
      "text": "ey behave when interacting with humans.  Explore \nthe use of GPT as a support tool: investigate how GPT can be used to support people more empathetically and improve \nhuman well -being.  \nZiems et al. \n(2023)  Cross -cultural CSS research: future research should separately consider the utility of LLMs for cross -cultural CSS in \norder to better serve social science research in different cultural contexts.  Future research could explore contrastive or \ncausal explanations in LLMs.  New paradigms for social science and AI collaboration.  \nResearch Tools  \nVan Dis et al. \n(2023)  Invest in truly open LLMs: develop and implement open -source AI technologies to increase transparency and democratic \ncontrol.  Embrace the advantages of AI: utilize AI to accelerate innovation and breakthroughs at all academic stages, \nwhile focusing on issues of ethics and human autonomy.  Broaden the discussion: organize international forums to \ndiscuss the development and responsible use of LLMs in research, including issues of diversity and inequality.  \nFecher et al. \n(2023)  Analyzing the risks and opportunities of LLMs for science systems. Examining how LLMs affect academic quality \nassurance mechanisms, academic misconduct, and scientific integrity. Exploring the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 580,
      "text": "the impact of LLMs on academic \nreputation, evaluation systems, and knowledge dissemination. Examining how to balance the potential benefits from \nLLMs with adherence to scientific principles.  \n \n8. Conclusion  \nWith the rapid development of AI technologies, especially the continuous advancement of LLMs, \nmachine learning has reached the point where it can recognize and generate human language. This \ndevelopment is not simply a technological breakthrough for the fie ld of psychology, but it opens the door to \na range of potential applications.  \nFirst, in the field of cognitive and behavioral psychology, LLMs are excelling in a variety of cognitive \ntasks. Although there are still limitations in causal cognition and planning, these models resurrect the \nprinciple of association, demonstrating the ab ility to associate at a distance and reason in complex ways. At \nthe same time, the ability to adapt LLMs to cognitive models is a significant strength of psychological \nresearch, allowing for new explorations of human cognitive and behavioral processing mec hanisms.  \nSecond, in clinical and counseling psychology, LLMs can be used as preliminary diagnostic tools for \nmental health. While traditional mental health diagnosis relies on the experience of professionals and direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 581,
      "text": "nd direct \ninteraction with patients, LLMs can quickly id entify potential mental health problems, such as depression \nand anxiety, by analyzing an individual\u2019s verbal expressions and textual content. Importantly, while such \ndiagnoses cannot wholly replace professional psychological assessment, they can serve as a n effective \nadjunct to help psychologists understand a patient\u2019s condition more quickly, or play a role in primary mental \nhealth interventions. Meanwhile, personalized psychological intervention is another critical application \ndirection for LLMs. By combining informat ion about an individual\u2019s health data and lifestyle habits, these \nmodels can provide tailored psychological advice and intervention programs. Such personalized approaches \ncould be crucial for improving the effectiveness of psychological interventions.  \nThird, LLMs have the same potential for application in both educational and developmental psychology \nand social and cultural psychology. For example, LLMs provide interactive and personalized learning \nexperiences or generate research tasks based on real -life applications that increase motivation and enhance \nlearning. In addition, by analyzing large amounts of social media data, these models can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 582,
      "text": "s can help researchers \ntrack and analyze public sentiment changes to better understand psycho -social dynamics.  \nFinally, in psychological research, LLMs can drastically improve research efficiency. Researchers can \nuse these models to quickly organize and analyze large amounts of literature, thus saving time. These models \ncan also assist with experimental design, dat a analysis, and even promoting scholarly communication, \nmaking psychological research more efficient and precise.  \nIn light of the above, LLMs have promising applications for psychology, such as research support, \ncognitive modeling, individualized intervention, and personalized learning. LLMs also have the potential to \ndramatically improve our understanding of human co mmunication, thought processes, and behaviors, \nleading to the development of more comprehensive theories of mind and cognitive science. At the same time, \nit is important to be aware of the related risks and challenges and to ensure adherence to ethical sta ndards, \nespecially with regard to individual privacy and data security. It is also important to recognize that no matter \nhow technologically advanced they are, LLMs can only partially replace the judgment and experience of \nhuman professionals. Therefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 583,
      "text": "herefore, s uch models should be viewed as an aid rather than an all -in-one solution.  \nReferences  \nAbd-Alrazaq, A. A., Alajlani, M., Alalwan, A. A., Bewick, B. M., Gardner, P., & Househ, M. (2019). An overview \nof the features of chatbots in mental health: A scoping review. International Journal of Medical \nInformatics , 132, 103978. https://doi.org/10.1016/j.ijmedinf.2019.103978   \nAbdurahman, S., Atari, M., Karimi -Malekabadi , F., Xue, M. J., Trager, J., Park, P. S., ... & Dehghani, M. (2024). \nPerils and opportunities in using large language models in psychological research. PNAS nexus , 3(7), \npgae245.  \nAbramski, K., Citraro, S., Lombardi, L., Rossetti, G., & Stella, M. (2023). Cognitive network science reveals bias \nin gpt -3, gpt -3.5 turbo, and gpt -4 mirroring math anxiety in high -school students. Big Data and Cognitive \nComputing , 7(3), 124.  \nAgrawal, S. (2023). Are LLMs the Master of All Trades? : Exploring Domain -Agnostic Reasoning Skills of LLMs. \narXiv preprint . https://doi.org/10.48550/arxiv.2303.12810   \nAher, G., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate multiple humans and \nreplicate human subject studies  Proceedings of the 40th International Conference on Machine Learning, \nHonolulu, Hawaii, USA.  \nAkata, E., Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 584,
      "text": "Schulz, L., Coda -Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing repeated games with \nLarge Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2305.16867   \nAli, J. K. M., Shamsan, M. A. A., Hezam, T. A., & Mohammed, A. A. Q. (2023). Impact of ChatGPT on Learning \nMotivation. Journal of English Studies in Arabia Felix , 2(1), 41 -49. \nhttps://doi.org/10.56540/jesaf.v2i1.51   \nAlmeida, G. F., Nunes, J. L., Engelmann, N., Wiegmann, A., & de Ara\u00fajo, M. (2024). Exploring the psychology \nof LLMs\u2019 moral and legal reasoning. Artificial intelligence , 333, 104145.  \nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J., Rytting, C., & Wingate, D. (2022). Out of One, Many: Using \nLanguage Models to Simulate Human Samples. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2209.06899   \nAtari, M., Xue, M. J., Park, P. S., Blasi, D. E., & Henrich, J. (2023). Which Humans? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/5b26t   \nAyd\u0131n, \u00d6., & Karaarslan, E. (2022). OpenAI ChatGPT Generated Literature Review: Digital Twin in Healthcare. \nEmerging Computer Technologies (2), 22 -31. https://doi.org/10.2139/ssrn.4308687   \nBaillifard, A., Gabella, M., Lavenex, P. B., & Martarelli, C. S. (2024). Effective learning with a personal AI tutor: \nA case study. Education and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 585,
      "text": "and Information Technologies , 1-16.  \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2023). Machine -Assisted Social Psychology Hypothesis \nGeneration. PsyArXiv preprint . https://doi.org/10.31234/osf.io/kv6f7   \nBanker, S., Chatterjee, P., Mishra, H., & Mishra, A. (2024). Machine -assisted social psychology hypothesis \ngeneration. American psychologist , 79(6), 789.  \nBa\u0161i\u0107, \u017d., Banovac, A., Kru\u017ei\u0107, I., & Jerkovi\u0107, I. (2023). ChatGPT -3.5 as writing assistance in students\u2019 essays. \nHumanities and Social Sciences Communications , 10(1). https://doi.org/10.1057/s41599 -023-02269 -7  \nBender, E. M., Gebru, T., McMillan -Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: \nCan Language Models Be Too Big?  Proceedings of the 2021 ACM Conference on Fairness, \nAccountability, and Transparency, Virtual Event, Canada. https://doi.org/10.1145/3442188.3445922  \nBinz, M., & Schulz, E. (2023a). Turning large language models into cognitive models. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2306.03917   \nBinz, M., & Schulz, E. (2023b). Using cognitive psychology to understand GPT -3. Proceedings of the National \nAcademy of Sciences of the United States of America , 120(6), e2218523120. \nhttps://doi.org/10.1073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 586,
      "text": "073/pnas.2218523120   \nBlyler, A. P., & Seligman, M. E. P. (2023a). AI assistance for coaches and therapists. The Journal of Positive \nPsychology , 1-13.  \nBlyler, A. P., & Seligman, M. E. P. (2023b). Personal narrative and stream of consciousness: an AI approach. The \nJournal of Positive Psychology , 1-7. https://doi.org/10.1080/17439760.2023.2257666   \nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \nAskell, A., Agarwal, S., Herbert -Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. \nM., Wu, J., Winter, C.,\u2026Amodei, D. (2 020). Language Models are Few -Shot Learners. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2005.14165   \nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E. K., Kamar, E., Lee, P., Lee, Y. T., Li, Y. -F., \nLundberg, S. M., Nori, H., Palangi, H., Ribeiro, M. T., & Zhang, Y. (2023). Sparks of Artificial General \nIntelligence: Early experiments with GPT -4. arXiv preprint . https://doi.org/10.48550/arXiv.2303.12712   \nCharness, G., Jabarian, B., & List, J. A. (2023). Generation next: Experimentation with ai .  \nChiang, C. -H., & Lee, H. -y. (2023). Can Large Language Models Be an Alternative to Human Evaluations? arXiv \npreprint . https://doi.org/10.48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 587,
      "text": ".48550/arXiv.2305.01937   \nCrockett, M., & Messeri, L. (2023). Should large language models replace human participants? PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/4zdx9   \nD'Oria, M. (2023). Can AI Language Models Improve Human Sciences Research? A Phenomenological Analysis \nand Future Directions. Encyclopaideia , 27(66), 77 -92. https://doi.org/10.6092/issn.1825 -8670/16554   \nD\u2019Souza, R. F., Amanullah, S., Mathew, M., & Surapaneni, K. M. (2023). Appraising the performance of ChatGPT \nin psychiatry using 100 clinical case vignettes. Asian Journal of Psychiatry , 89, 103770.  \nDe Bot, K., Lowie, W., & Verspoor, M. (2007). A Dynamic Systems Theory approach to second language \nacquisition. Bilingualism: Language and Cognition , 10(1), 7 -21. \nhttps://doi.org/10.1017/S1366728906002732   \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., Eichstaedt, J. C., Hecht, C., \nJamieson, J., Johnson, M., Jones, M., Krettek -Cobb, D., Lai, L., JonesMitchell, N., Ong, D. C., Dweck, \nC. S., Gross, J. J., & Pennebaker, J. W. (20 23). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDergaa, I., Chamari, K., Zmijewski, P., & Ben Saad, H. (2023). From human writing to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 588,
      "text": "g to artificial intelligence \ngenerated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology \nof Sport , 40(2), 615 -622. https://doi.org/10.5114/biolsport.2023.125623   \nDhingra, S., Singh, M., Sb, V., Malviya, N., & Singh Gill, S. (2023). Mind meets machine: Unravelling GPT -4's \ncognitive psychology. arXiv preprint , arXiv:2303.11436. https://doi.org/10.48550/arXiv.2303.11436   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human participants? Trends \nin Cognitive Sciences , 27(7), 597 -600. https://doi.org/10.1016/j.tics.2023.04.008   \nDu, Y., Luo, D., Yan, R., Wang, X., Liu, H., Zhu, H., Song, Y., & Zhang, J. (2024). Enhancing job recommendation \nthrough llm -based generative adversarial networks. Proceedings of the AAAI Conference on Artificial \nIntelligence,  \nDubey, R., Hardy, M. D., Griffiths, T. L., & Bhui, R. (2024). AI -generated visuals of car -free US cities help \nimprove support for sustainable policies. Nature Sustainability , 7(4), 399 -403.  \nElyoseph, Z., & Levkovich, I. (2023). Beyond human expertise - the promise and limitationsof ChatGPT in suicide \nrisk assessment. Frontiers in Psychiatry , 14. https://doi.org/10.3389/fpsyt.2023.1213141   \nElyoseph, Z., & Levkovich, I. (2024). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 589,
      "text": "). Comparing the perspectives of generative AI, mental health experts, and \nthe general public on schizophrenia recovery: case vignette study. Jmir Mental Health , 11, e53043.  \nFecher, B., Hebing, M., Laufer, M., Pohle, J., & Sofsky, F. (2023). Friend or foe? Exploring the implications of \nlarge language models on the science system. AI & Society . https://doi.org/10.1007/s00146 -023-01791 -\n1  \nFloridi, L., & Chiriatti, M. (2020). GPT -3: Its Nature, Scope, Limits, and Consequences. Minds and Machines , \n30(4), 681 -694. https://doi.org/10.1007/s11023 -020-09548 -1  \nFrank, M. C. (2023). Baby steps in evaluating the capacities of large language models. Nature Reviews Psychology , \n2(8), 451 -452. https://doi.org/10.1038/s44159 -023-00211 -x  \nGhafouri, M. (2024). ChatGPT: The catalyst for teacher -student rapport and grit development in L2 class. System , \n120, 103209.  \nGhafouri, M., Hassaskhah, J., & Mahdavi -Zafarghandi, A. (2024). From virtual assistant to writing mentor: \nExploring the impact of a ChatGPT -based writing instruction protocol on EFL teachers\u2019 self -efficacy and \nlearners\u2019 writing skill. Language Teaching Research , 13621688241239764.  \nGlaser, R. (1984). Education and thinking: The role of knowledge. American psychologist , 39(2), 93.  \nGoertzel, B. (2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 590,
      "text": "2023). Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. arXiv \npreprint , arXiv:2309.10371. https://doi.org/10.48550/arXiv.2309.10371   \nGoodfellow, I., Pouget -Abadie, J., Mirza, M., Xu, B., Warde -Farley, D., Ozair, S., Courville, A., & Bengio, Y. \n(2020). Generative adversarial networks. Communications of the ACM , 63(11), 139 -144.  \nGraber -Stiehl, I. (2023). IS THE WORLD READY FOR AI -POWERED THERAPY? Nature , 617, 22-24. \nhttps://doi.org/10.1038/d41586 -023-01473 -4  \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, W. A. (2023). AI and \nthe transformation of social science research. Science , 380(6650), 1108 -1109. \nhttps://doi.org/10.1126/science.adi1778   \nGuo, Z., Lai, A., Thygesen, J. H., Farrington, J., Keen, T., & Li, K. (2024). Large language models for mental \nhealth applications: Systematic review. JMIR mental health , 11(1), e57400  \nGupta, M., Akiri, C., Aryal, K., Parker, E., & Praharaj, L. (2023). From ChatGPT to ThreatGPT: Impact of \nGenerative AI in Cybersecurity and Privacy. IEEE Access , 11, 80218 -80245. \nhttps://doi.org/10.1109/access.2023.3300381   \nHagendorff, T. (2023). Machine Psychology: Investigating Emergent Capabilities and Behavior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 591,
      "text": "avior in Large \nLanguage Models Using Psychological Methods. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2303.13988   \nHagendorff, T. (2024). Deception abilities emerged in large language models. Proceedings of the National \nAcademy of Sciences , 121(24), e2317967121.  \nHagendorff, T., Fabi, S., & Kosinski, M. (2023). Human -like intuitive behavior and reasoning biases emerged in \nlarge language models but disappeared in ChatGPT. Nature Computational Science , 3(10), 833 -838. \nhttps://doi.org/10.1038/s43588 -023-00527 -x  \nHarding, J., D\u2019Alessandro, W., Laskowski, N. G., & Long, R. (2023). AI language models cannot replace human \nresearch participants. AI & Society . https://doi.org/10.1007/s00146 -023-01725 -x  \nHardy, M., Sucholutsky, I., Thompson, B., & Griffiths, T. (2023). Large language models meet cognitive science: \nLlms as tools, models, and participants. Proceedings of the annual meeting of the cognitive science \nsociety,  \nHayes, A. (2023). \u201cConversing\u201d with Qualitative Data: Enhancing Qualitative Research through Large Language \nModels (LLMs). PsyArXiv preprint . https://doi.org/10.31235/osf.io/yms8p   \nHendel, R., Geva, M., & Globerson, A. (2023). In -Context Learning Creates Task Vectors. arXiv preprint , \narXiv:2310.15916. https://doi.org/10.48550/arXiv.2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 592,
      "text": ".2310.15916   \nHofmann, S. G., Asnaani, A., Vonk, I. J., Sawyer, A. T., & Fang, A. (2012). The Efficacy of Cognitive Behavioral \nTherapy: A Review of Meta -analyses. Cognit Ther Res , 36(5), 427 -440. https://doi.org/10.1007/s10608 -\n012-9476 -1  \nHoltzman, A., West, P., & Zettlemoyer, L. (2023). Generative Models as a Complex Systems Science: How can \nwe make sense of large language model behavior? arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.00189   \nHothersall, D., & Lovett, B. J. (2022). History of psychology . Cambridge University Press.  \nHuang, J., & Chang, K. C. -C. (2022). Towards Reasoning in Large Language Models: A Survey. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10403   \nHutson, M. (2023). Doing research with human subjects is costly and cumbersome.Can AI chatbots replace them? \nScience , 381(6654), 121 -123. https://doi.org/10.1126/science.adj6791   \nJin, C., Zhang, S., Shu, T., & Cui, Z. (2023). The Cultural Psychology of Large Language Models: Is ChatGPT a \nHolistic or Analytic Thinker? arXiv preprint . https://doi.org/10.48550/arXiv.2308.14242   \nJungherr, A. (2023). Using ChatGPT and Other Large Language Model (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 593,
      "text": "odel (LLM) Applications for Academic Paper \nAssignments . https://fis.uni -bamberg.de/handle/uniba/58950  \nurn:nbn:de:bvb:473 -irb-589507  \nJyothy, S., Kolil , V. K., Raman, R., & Achuthan, K. (2024). Exploring large language models as an integrated tool \nfor learning, teaching, and research through the Fogg Behavior Model: a comprehensive mixed -methods \nanalysis. Cogent Engineering , 11(1), 2353494.  \nKahneman, D. (2011). Thinking, fast and slow. Farrar, Straus and Giroux .  \nKasneci, E., Sessler, K., K\u00fcchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., \nG\u00fcnnemann, S., H\u00fcllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, \nO., Sailer, M., Schmidt, A., Seidel, T.,\u2026Kasn eci, G. (2023). ChatGPT for good? On opportunities and \nchallenges of large language models for education. Learning and Individual Differences , 103. \nhttps://doi.org/10.1016/j.lindif.2023.102274   \nKe, L., Zhang, G., He, J., Li, Y., Li, Y., Liu, X., & Fang, P. (2023). Pilot Selection in the Era of Virtual Reality: \nAlgorithms for Accurate and Interpretable Machine Learning Models. Aerospace , 10(5). \nhttps://doi.org/10.3390/aerospace10050394   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings of the National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 594,
      "text": "National \nAcademy of Sciences , 121(45), e2405460121.  \nLamichhane, B. (2023). Evaluation of ChatGPT for NLP -based Mental Health Applications. arXiv preprint , \narXiv:2303.15727. https://doi.org/10.48550/arXiv.2303.15727   \nLee, B. C., & Chung, J. (2024). An empirical investigation of the impact of ChatGPT on creativity. Nature Human \nBehaviour , 8(10), 1906 -1914.  \nLi, J., Tang, T., Zhao, W. X., Nie, J. -Y., & Wen, J. -R. (2022). Pretrained Language Models for Text Generation: A \nSurvey. arXiv preprint , arXiv:2201.05273. https://doi.org/10.48550/arXiv.2201.05273   \nLi, M., Enkhtur, A., Cheng, F., & Yamamoto, B. A. (2023). Ethical implications of ChatGPT in higher education: \nA scoping review. arXiv preprint . https://doi.org/10.48550/arXiv.2311.14378   \nLi, T., Lu, J., Chu, C., Zeng, T., Zheng, Y., Li, M., Huang, H., Wu, B., Liu, Z., & Ma, K. (2024). Scisafeeval: a \ncomprehensive benchmark for safety alignment of large language models in scientific tasks. arXiv \npreprint arXiv:2410.03769 .  \nLi, X., Li, Y., Liu, L., Bing, L., & Joty, S. (2022). Does GPT -3 Demonstrate Psychopathy? Evaluating Large \nLanguage Models from a Psychological Perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2212.10529   \nLiu, J. M., Li, D., Cao, H., Ren, T., Liao, Z., & Wu, J. (2023). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 595,
      "text": "3). ChatCounselor: A Large Language Models for \nMental Health Support. arXiv preprint , arXiv:2309.15461. https://doi.org/10.48550/arXiv.2309.15461   \nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre -train, Prompt, and Predict: A Systematic \nSurvey of Prompting Methods in Natural Language Processing. ACM Computing Surveys , 55(9), 1 -35. \nhttps://doi.org/10.1145/3560815   \nLiu, X., Ji, K., Fu, Y., Tam, W., Du, Z., Yang, Z., & Tang, J. (2022). P -Tuning: Prompt Tuning Can Be Comparable \nto Fine -tuning Across Scales and Tasks. Proceedings of the 60th Annual Meeting of the Association for \nComputational Linguistics (Volume 2: Short Papers), Dublin, Ireland.  \nLiu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., Wu, Z., Zhao, L., Zhu, D., Li, \nX., Qiang, N., Shen, D., Liu, T., & Ge, B. (2023). Summary of ChatGPT -Related research and perspective \ntowards the future of large language models. Meta -Radiology , 1(2). \nhttps://doi.org/10.1016/j.metrad.2023.100017   \nLoconte, R., Orr\u00f9, G., Tribastone, M., Pietrini, P., & Sartori, G. (2023). Challenging ChatGPT's \"intelligence\" \nwith human tools: A Neuropsychological Investigation on Prefrontal Functioning of a Large Language \nModel. SSRN preprint . https://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 596,
      "text": "ttps://doi.org/10.2139/ssrn.4471829   \nLogacheva, E., Hellas, A., Prather, J., Sarsa, S., & Leinonen, J. (2024). Evaluating Contextually Personalized \nProgramming Exercises Created with Generative AI. Proceedings of the 2024 ACM Conference on \nInternational Computing Education Research -Volume 1,  \nLuo, X., Chen, F., Zhu, D., Wang, L., Wang, Z., Liu, H., Lyu, M., Wang, Y., Wang, Q., & Chen, Y. (2024). Potential \nRoles of Large Language Models in the Production of Systematic Reviews and Meta -Analyses. Journal \nof Medical Internet Research , 26, e56780.  \nMachin, M. A., Machin, T. M., & Gasson, N. (2024). Comparing ChatGPT With Experts\u2019 Responses to Scenarios \nthat Assess Psychological Literacy. Psychology Learning & Teaching , 14757257241241592.  \nMahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B., & Fedorenko, E. (2023). \nDissociating language and thought in large language models: a cognitive perspective. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2301.06627   \nMarjieh, R., Sucholutsky, I., Rijn, P. v., Jacoby, N., & Griffiths, T. L. (2023). Large language models predict human \nsensory judgments across six modalities. arXiv preprint . https://doi.org/10.48550/arXiv.2302.01308   \nMichelson, M., & Reuter, K. (2019). The significant cost of systematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 597,
      "text": "ematic reviews and meta -analyses: A call for \ngreater involvement of machine learning to assess the promise of clinical trials. Contemporary Clinical \nTrials Communications , 16, 100443. https://doi.org/10.1016/j.conctc.2019.100443   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022). Who is GPT -3? An Exploration of Personality, Values and \nDemographics. arXiv preprint . https://doi.org/10.48550/arXiv.2209.14338   \nMitchell, M. (2023). AI's challenge of understanding the world. Science , 382(6671). \nhttps://doi.org/10.1126/science.adm8175   \nNazario -Johnson, L., Zaki, H. A., & Tung, G. A. (2023). Use of large language models to predict neuroimaging. \nJournal of the American College of Radiology , 20(10), 1004 -1009. \nhttps://doi.org/10.1016/j.jacr.2023.06.008   \nNewell, A. (1990). Unified theories of cognition . Harvard University Press.  \nNisbett, R. E., Peng, K., Choi, I., & Norenzayan, A. (2001). Culture and systems of thought: holistic versus \nanalytic cognition. Psychological review , 108(2), 291 -310. https://doi.org/10.1037//0033 -\n295X.108.2.291   \nNoy, S., & Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. \nScience , 381(6654), 187 -192.  \nOpenAI. (2023). GPT -4 Technical Report. arXiv preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 598,
      "text": "preprint . https://doi.org/10.48550/arXiv.2303.08774   \nOrru, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human -like problem -solving abilities in large \nlanguage models using ChatGPT. Frontiers in Artificial Intelligence , 6, 1199350. \nhttps://doi.org/10.3389/frai.2023.1199350   \nPal, R., Garg, H., Patel, S., & Sethi, T. (2023). Bias Amplification in Intersectional Subpopulations for Clinical \nPhenotyping by Large Language Models. medRxiv preprint . \nhttps://doi.org/10.1101/2023.03.22.23287585   \nPark, B., & Judd, C. M. (2005). Rethinking the Link Between Categorization and Prejudice Within the Social \nCognition Perspective. Personality and Social Psychology Review , 9(2), 108 -130. \nhttps://doi.org/10.1207/s15327957pspr0902_2   \nPark, J. S., Popowski, L., Cai, C., Morris, M. R., Liang, P., & Bernstein, M. S. (2022). Social simulacra: Creating \npopulated prototypes for social computing systems. Proceedings of the 35th Annual ACM Symposium \non User Interface Software and Technology,  \nPark, P. S., Schoenegger, P., & Zhu, C. (2024). Diminished diversity -of-thought in a standard large language model. \nBehavior Research Methods , 1-17.  \nPark, Y. J., Kaplan, D., Ren, Z., Hsu, C. -W., Li, C., Xu, H., Li, S., & Li, J. (2024). Can ChatGPT be used to \ngenerate scientific hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 599,
      "text": "ic hypotheses? Journal of Materiomics , 10(3), 578 -584.  \nPatel, S. C., & Fan, J. (2023). Identification and Description of Emotions by Current Large Language Models. \nbioRxiv preprint . https://doi.org/10.1101/2023.07.17.549421   \nPeng, Y., Han, J., Zhang, Z., Fan, L., Liu, T., Qi, S., Feng, X., Ma, Y., Wang, Y., & Zhu, S. -C. (2023). The Tong \nTest: Evaluating Artificial General Intelligence Through Dynamic Embodied Physical and Social \nInteractions. Engineering . https://doi.org/10.1016/j.eng.2023.07.006   \nPeters, H., & Matz, S. (2023). Large Language Models Can Infer Psychological Dispositions of Social Media \nUsers. arXiv preprint . https://doi.org/10.48550/arXiv.2309.08631   \nPorsdam Mann, S., Vazirani, A. A., Aboy, M., Earp, B. D., Minssen, T., Cohen, I. G., & Savulescu, J. (2024). \nGuidelines for ethical use and acknowledgement of large language models in academic writing. Nature \nMachine Intelligence , 1-3. \nQureshi, R., Shaughnessy, D., Gill, K. A. R., Robinson, K. A., Li, T., & Agai, E. (2023). Are ChatGPT and large \nlanguage models \"the answer\" to bringing us closer to systematic review automation? Systematic Reviews , \n12(1), 72. https://doi.org/10.1186/s13643 -023-02243 -z  \nRane, N., Choudhary, S., & Rane, J. (2024). Gemini versus ChatGPT: applications, performance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 600,
      "text": "rformance, architecture, \ncapabilities, and implementation. Performance, Architecture, Capabilities, and Implementation \n(February 13, 2024) .  \nRathje, S., Mirea, D. -M., Sucholutsky, I., Marjieh, R., Robertson, C., & Bavel, J. J. V. (2023). GPT is an effective \ntool for multilingual psychological text analysis. PsyArXiv preprint . https://doi.org/10.31234/osf.io/sekf5   \nSalah, M., Al Halbusi, H., & Abdelfattah, F. (2023). May the force of text data analysis be with you: Unleashing \nthe power of generative AI for social psychology research. Computers in Human Behavior: Artificial \nHumans , 1(2). https://doi.org/10.1016/j.chbah.2023.100006   \nSallam, M. (2023). ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the \nPromising Perspectives and Valid Concerns. Healthcare (Basel) , 11(6). \nhttps://doi.org/10.3390/healthcare11060887   \nSap, M., LeBras, R., Fried, D., & Choi, Y. (2022). Neural Theory -of-Mind? On the Limits of Social Intelligence \nin Large LMs. arXiv preprint . https://doi.org/10.48550/arXiv.2210.13312   \nSartori, G., & Orr\u00f9, G. (2023). Language models and psychological sciences. Frontiers in Psychology , 14. \nhttps://doi.org/10.3389/fpsyg.2023.1279317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 601,
      "text": "9317   \nSchaaff, K., Reinig, C., & Schlippe, T. (2023). Exploring ChatGPT's Empathic Abilities. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2308.03527   \nSchueller, S. M., & Morris, R. R. (2023). Clinical science and practice in the age of large language models and \ngenerative artificial intelligence. Journal of Consulting and Clinical Psychology , 91(10), 559 -561. \nhttps://doi.org/10.1037/ccp0000848   \nSeals, S. M., & Shalin, V. L. (2023). Long -form analogies generated by chatGPT lack human -like psycholinguistic \nproperties. arXiv preprint . https://doi.org/10.48550/arxiv.2306.04537   \nSejnowski, T. (2022). Large Language Models and the Reverse Turing Test. arXiv preprint . \nhttps://doi.org/10.48550/arxiv.2207.14382   \nSha, H., Mu, Y., Jiang, Y., Chen, L., Xu, C., Luo, P., Eben Li, S., Tomizuka, M., Zhan, W., & Ding, M. (2023). \nLanguageMPC : Large Language Models as Decision Makers for Autonomous Driving. arXiv preprint , \narXiv:2310.03026. https://doi.org/10.48550/arXiv.2310.03026   \nSharma, A., Lin, I. W., Miner, A. S., Atkins, D. C., & Althoff, T. (2023). Human \u2013AI collaboration enables more \nempathic conversations in text -based peer -to-peer mental health support. Nature Machine Intelligence , \n5(1), 46 -57. https://doi.org/10.1038/s42256 -022-00593 -2  \nSimon, H. A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 602,
      "text": "A. (1979). Information Processing Models of Cognition. Annual Review of Psychology , 30(1), 363 -396. \nhttps://doi.org/10.1146/annurev.ps.30.020179.002051   \nSrinivasan, R., Inakoshi, H., & Uchino, K. (2023). Leveraging Cognitive Science for Testing Large Language \nModels. 2023 IEEE International Conference On Artificial Intelligence Testing (AITest),  \nStade, E. C., Stirman, S. W., Ungar, L., Boland, C. L., Schwartz, H. A., Yaden, D. B., Sedoc, J., Derubeis, R. J., \nWiller, R., & Eichstaedt, J. C. (2023). Large Language Models Could Change the Future of Behavioral \nHealthcare: A Proposal for Responsible De velopment and Evaluation. PsyArXiv preprint . \nhttps://doi.org/10.31234/osf.io/cuzvr   \nStella, M., Hills, T. T., & Kenett, Y. N. (2023). Using cognitive psychology to understand GPT -like models needs \nto extend beyond human biases. Proceedings of the National Academy of Sciences of the United States \nof America , 120(43), e2312911120. https://doi.org/10.1073/pnas.2312911120   \nStevenson, C., Smal, I., Baas, M., Grasman, R., & Maas, H. v. d. (2022). Putting GPT -3's Creativity to the \n(Alternative Uses) Test. arXiv preprint . https://doi.org/10.48550/arXiv.2206.08932   \nStojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022)."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 103,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 603,
      "text": "knowledgeable other: an autoethnographic study. \nInternational Journal of Educational Technology in Higher Education , 20(1). \nhttps://doi.org/10.1186/s41239 -023-00404 -7  \nStokel -Walker, C. (2022). AI bot ChatGPT writes smart essays \u2014 should professors worry? Nature . \nhttps://doi.org/10.1038/d41586 -022-04397 -7  \nSufyan, N. S., Fadhel, F. H., Alkhathami, S. S., & Mukhadi, J. Y. (2024). Artificial intelligence and social \nintelligence: preliminary comparison study between AI models and psychologists. Frontiers in \nPsychology , 15, 1353022.  \nSuri, G., Slater, L. R., Ziaee, A., & Nguyen, M. (2024). Do large language models show decision heuristics similar \nto humans? A case study using GPT -3.5. Journal of Experimental Psychology: General .  \nTajfel, H. (1982). Social psychology of intergroup relations. Annual Review of Psychology , 33(1), 1 -39.  \nTalboy, A. N., & Fuller, E. (2023). Challenging the appearance of machine intelligence: Cognitive bias in LLMs. \narXiv preprint . https://doi.org/10.48550/arXiv.2304.01358   \nTamkin, A., Brundage, M., Clark, J., & Ganguli, D. (2021). Understanding the Capabilities, Limitations, and \nSocietal Impact of Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2102.02503   \nThirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 104,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 604,
      "text": "ovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). Large \nlanguage models in medicine. Nature Medicine , 29(8), 1930 -1940. https://doi.org/10.1038/s41591 -023-\n02448 -8  \nTong, S., Mao, K., Huang, Z., Zhao, Y., & Peng, K. (2024). Automating psychological hypothesis generation with \nAI: when large language models meet causal graph. Humanities and Social Sciences Communications , \n11(1), 896. https://doi.org/10.1057/s41599 -024-03407 -5  \nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., & \nBhosale, S. (2023). Llama 2: Open foundation and fine -tuned chat models. arXiv preprint \narXiv:2307.09288 .  \nTrott, S., Jones, C., Chang, T., Michaelov, J., & Bergen, B. (2023). Do large language models know what humans \nknow? Cognitive Science , 47(7), e13309.  \nVan Dis, E. A., Bollen, J., Zuidema, W., van Rooij, R., & Bockting, C. L. (2023). ChatGPT: five priorities for \nresearch. Nature , 614(7947), 224 -226. https://doi.org/10.1038/d41586 -023-00288 -7  \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin , I. (2017). \nAttention is all you need. Advances in neural information processing systems , 30.  \nVzorinab, G. D., Bukinichac, A. M., Sedykha, A. V., Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 105,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 605,
      "text": "Vetrovab, I. I., & Sergienkob, E. A. (2024). The Emotional \nIntelligence of the GPT -4 Large Language Model. Psychology in Russia: State of the art , 17(2), 85 -99.  \nWang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., Chandak, P., Liu, S., Van Katwyk, P., Deac, A., Anandkumar, \nA., Bergen, K., Gomes, C. P., Ho, S., Kohli, P., Lasenby, J., Leskovec, J., Liu, T. Y., Manrai, A.,\u2026Zitnik, \nM. (2023). Scientific discovery i n the age of artificial intelligence. Nature , 620(7972), 47 -60. \nhttps://doi.org/10.1038/s41586 -023-06221 -2  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language models. Nature \nHuman Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -023-01659 -w  \nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, \nD., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J., & Fedus, W. (2022). Emergent Abilities \nof Large Language Models. arXiv preprint . https://doi.org/10.48550/arXiv.2206.07682   \nYang, F., Chen, Z., Jiang, Z., Cho, E., Huang, X., & Lu, Y. (2023). Palr: Personalization aware llms for \nrecommendation. arXiv preprint arXiv:2305.07622 .  \nYildirim, I., & Paul, L. A. (2023). From task structures to world models: What do LLMs know? arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 106,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 606,
      "text": "arXiv preprint , \narXiv:2310.04276. https://doi.org/10.48550/arXiv.2310.04276   \nYukun, Z., Xu, L., Huang, Z., Peng, K., Seligman, M., Li, E., & Yu, F. (2023). AI chatbot responds to emotional \ncuing. PsyArXiv preprint . https://doi.org/10.31234/osf.io/9ymfz   \nZeiler, M. (2014). Visualizing and Understanding Convolutional Networks. European conference on computer \nvision/arXiv,  \nZhang, J., Xu, X., & Deng, S. (2023). Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology \nView. arXiv preprint , arXiv:2310.02124. https://doi.org/10.48550/arXiv.2310.02124   \nZhang, Z., Chadwick, G., McNally, H., Zhao, Y., & Mullins, R. (2023). Llm4dv: Using large language models for \nhardware test stimuli generation. arXiv preprint arXiv:2310.04535 .  \nZhao, Y., Huang, Z., Seligman, M., & Peng, K. (2024). Risk and prosocial behavioural cues elicit human -like \nresponse patterns from AI chatbots. Scientific Reports , 14(1), 7095.  \nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I., & Pan, S. (2023). Large Language Models \nfor Scientific Synthesis, Inference and Explanation. arXiv preprint . \nhttps://doi.org/10.48550/arXiv.2310.07984   \nZhong, Y., Chen, Y. J., Zhou, Y., Lyu, Y. A., Yin, J. J., & Gao, Y. J. (2023). The Artificial intelligence large language \nmodels and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z."
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 107,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 607,
      "text": "els and neuropsychiatry practice and research ethic. Asian Journal of Psychiatry , 84, 103577. \nhttps://doi.org/10.1016/j.ajp.2023.103577   \nZhuang, Y., Liu, Q., Ning, Y., Huang, W., Lv, R., Huang, Z., Zhao, G., Zhang, Z., Mao, Q., Wang, S., & Chen, E. \n(2023). Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective. arXiv \npreprint . https://doi.org/10.48550/arXiv.2306.10512   \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "e4252c05-d9bb-4b66-a5c7-4696ffda5ae7",
      "chunk_id": 108,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\e4252c05-d9bb-4b66-a5c7-4696ffda5ae7.pdf",
      "doc_id": 608,
      "text": "s, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2023). Can Large Language Models Transform \nComputational Social Science? arXiv preprint . https://doi.org/10.48550/arXiv.2305.03514"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 609,
      "text": "MACHINE PSYCHOLOGY\nThilo Hagendorff\u2217\nUniversity of StuttgartIshita Dasgupta\u2217\nGoogle DeepMindMarcel Binz\u2020\nHelmholtz Institute for\nHuman-Centered AIStephanie C.Y. Chan\u2020\nGoogle DeepMind\nAndrew Lampinen\u2020\nGoogle DeepMindJane X. Wang\u2020\nGoogle DeepMindZeynep Akata\nTU MunichEric Schulz\nHelmholtz Institute for\nHuman-Centered AI\nAugust 9, 2024\nABSTRACT\nLarge language models (LLMs) show increasingly advanced emergent capabilities and are being\nincorporated across various societal domains. Understanding their behavior and reasoning abilities\ntherefore holds significant importance. We argue that a fruitful direction for research is engaging\nLLMs in behavioral experiments inspired by psychology that have traditionally been aimed at\nunderstanding human cognition and behavior. In this article, we highlight and summarize theoretical\nperspectives, experimental paradigms, and computational analysis techniques that this approach\nbrings to the table. It paves the way for a \"machine psychology\" for generative artificial intelligence\n(AI) that goes beyond performance benchmarks and focuses instead on computational insights that\nmove us toward a better understanding and discovery of emergent abilities and behavioral patterns\nin LLMs. We review existing work taking this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 610,
      "text": "ng this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines. We posit that leveraging tools from experimental\npsychology to study AI will become increasingly valuable as models evolve to be more powerful,\nopaque, multi-modal, and integrated into complex real-world settings.\nIntroduction\nRecent advances in computing power, data availability, and machine learning algorithms have yielded powerful artificial\nintelligence systems that are used in almost all parts of society. Among these, large language models (LLMs), gigantic\nneural network architectures trained on large amounts of text, have seen a particularly meteoric rise in their influence.\nThe ability of LLMs to interface directly with natural language has made them accessible to the public in a way that\nwas not seen before, leading to widespread adoption with millions of daily users (Gemini Team et al., 2024; Anthropic,\n2024; OpenAI, 2022; OpenAI, 2023a). Also contributing to their rise in influence is that LLMs are wide-ranging in the\nkinds of tasks they can do \u2013 from writing text or code to calling functions, accessing the Internet, retrieving external\ninformation, reasoning about complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 611,
      "text": "complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al., 2022; Radford et al., 2023). The ever-growing capabilities of these systems make them challenging but also\nincreasingly important to characterize and understand, especially since these expanding capabilities also bring greater\npotential for unforeseen harm (Bommasani et al., 2021; Hagendorff, 2024b; Weidinger et al., 2022; Bender et al., 2021;\nSchramowski et al., 2022).\n\u2217Shared first authorship. Contact: thilo.hagendorff@iris.uni-stuttgart.de, idg@google.com\n\u2020Co-authors are listed in alphabetical order.arXiv:2303.13988v6  [cs.CL]  8 Aug 2024\nFigure 1: Overview of key concepts of machine psychology.\nUnderstanding behavioral patterns and emergent abilities in LLMs requires explaining their operating principles. Of the\napproaches focused on explaining AI systems, many rely on trying to understand the inner workings of these neural\nnetworks. This approach, often termed mechanistic interpretability, seeks to investigate LLMs by analyzing how their\nweights and activation patterns implement the observable behavior. It uses simplifications in terms of data, the model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 612,
      "text": "model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024). A related set of approaches draws inspiration\nmore directly from neuroscience to characterize broader correlational similarities and differences between the internal\nprocessing of LLMs and humans (Hosseini and Fedorenko, 2023; Kumar et al., 2022).\nIn contrast, this review focuses on the class of approaches that directly study the behavior of LLMs, analyzing\nrelationships between inputs and outputs instead of inspecting the inner workings. This approach includes not only\nanalyses of static trained models, but also experimental manipulations of inputs both during and after training. It\nalso encompasses analyses of inputs and outputs that reveal insights about internal mechanisms, even if those internal\nmechanisms are not directly inspected. For this set of approaches, experiments can be inspired by human psychology,\ncognitive science, and the behavioral sciences. This is what we want to term machine psychology (see Figure 1). Over\nseveral decades, the mentioned disciplines have developed a wide range of methods and frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 613,
      "text": "d frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well.\nThus far, the research community has responded to the challenges of understanding behavioral patterns and growing\ncapabilities in LLMs in several ways (Schwartz, 2022; Zhao, Chen, et al., 2023). The traditional machine learning\nbenchmark-driven approach has released new datasets that capture specific aspects only recently seen emerging in\nmodels (Srivastava et al., 2022; Hendrycks et al., 2021; Zellers et al., 2019). Traditional benchmarking aims primarily\nto enable the community to compare and optimize LLM performance. In contrast, machine psychology research is not\nprimarily interested in increasing (or measuring) an LLM\u2019s performance, but rather in understanding behavioral patterns.\nWhile traditional natural language processing benchmarks measure abilities such as translation, numerical reasoning, or\nfactual accuracy, machine psychology is also interested in how these observable abilities indirectly reflect the underlying\nconstructs and algorithms (Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 614,
      "text": "Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes.\nThe relative importance of behavior-based inspection (or psychology) versus internal inspection (or neuroscience) has\nbeen a long-standing debate (Jonas and Kording, 2017). We believe that both approaches have value for understanding\nboth humans and LLMs. Directly inspecting LLMs\u2019 behavior, however, does come with multiple advantages. The\nbehavior of LLMs is expressed at the interface of the model, where human users interact, and thus is what we ultimately\ncare about the most (Binz and Schulz, 2023; Chang and Bergen, 2024; Ivanova, 2023). Such behavior is often too\ncomplex to predict purely from our current mechanistic understanding of model weights and activation patterns (Gr\u00f6n\net al., 2003). Many interesting behaviors are only displayed by large models with billions of parameters (Kaplan et al.,\n2020; Wei, Tay, et al., 2022), and behavioral methods in psychology that treat behavior directly as the experimental\nvariable of interest scale gracefully with model size. Another practical advantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 615,
      "text": "dvantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public.\nIn this article, we review and chart future directions in this emerging field of directly modeling LLM behavior. We\noutline how established behavioral sciences can guide and inform our understanding of LLMs, and discuss important\ncaveats for when and how to apply methods to LLMs, given that they were originally developed for humans and\nanimals. In the first section, we discuss the theoretical frameworks developed and used in psychology to organize\nour understanding of intelligence and intelligent behaviors. We then review the many empirical paradigms that have\nbeen developed to study and characterize different aspects of intelligent behavior. Finally, we discuss and make\nrecommendations for robust empirical methods both for designing experiments and analyzing behavioral data. We end\nthe article by discussing the potentials and limitations of conducting machine psychology experiments with increasingly\ncapable black-box models.\nTheory: Evaluation paradigms for understanding intelligent systems\nThe traditional framework in machine learning algorithms has revolved around benchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 616,
      "text": "nchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance. Researchers train on a train dataset and evaluate on a held-out test\ndataset that was not seen during training. This framework does not generalize well to large-scale foundation models for\ntwo reasons. First, when using Internet-scale training data for models, this split has become harder to maintain (Li\nand Flanigan, 2023; Khan et al., 2023). Second, foundation models are only directly trained for next-token prediction\nbut exhibit many other \"intelligent\" behaviors that can, with some reservations (Schaeffer et al., 2023), be considered\nemergent. For example, practitioners did not explicitly encode or train for a transformer LLM\u2019s ability to learn from a\nfew examples in context (Brown et al., 2020), but it nonetheless arose from the machine learning architecture, data, and\nlearning signal (Chan et al., 2022; Oswald et al., 2023). Emergent behaviors can be difficult to study through the lens of\nthe components that gave rise to it (Anderson, 1972), and the ones that emerge can seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 617,
      "text": "n seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e. smaller scale datasets unsuitable for training\nand intended solely as a test set \u2013 to investigate model capabilities, e.g. the BIG-bench comprising more than 200 tests\n(Srivastava et al., 2022), the Abstraction and Reasoning Challenge (Chollet et al., 2020), as well as many others (Ivanova\net al., 2024; Mazumder et al., 2024). In several cases, these benchmarks already resemble evaluation frameworks\nfrom the behavioral sciences (Bubeck et al., 2023) \u2013 like personality tests, intelligence tests, implicit association tests,\netc. that are applied to humans \u2013 which similarly do not follow the train-test paradigm. They also tend to fall into\ntwo categories. Some evaluations focus on scalar performance metrics, e.g. intelligence quotients. Others focus on\ncharacterizing behavior, i.e. the questions are not designed with accuracy in mind, but designed to elicit responses that\nreveal behavioral strategies, or underlying constructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 618,
      "text": "ructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field.\nSeveral such diagnostic evaluations have been developed even for pre-LLM models where, despite the models being\ntrained for specific tasks, how to solve them is not specified. Such diagnostic datasets were used to expose the ways\nin which learned systems solved tasks \u2013 often counter to human intuitions (Geirhos et al., 2020; McCoy, Pavlick,\net al., 2019; Hermann and Lampinen, 2020; Dasgupta et al., 2022; Singla and Feizi, 2021). Researchers have also\nmade the case for borrowing from ethology, a branch of zoology that studies the behavior of non-human animals, to\nexplain machine behavior in machine learning systems (Rahwan et al., 2019). However, in the era of LLMs, not only\nare the how unspecified, but the model abilities themselves are neither directly known nor intentionally engineered.\nFurthermore, since LLMs can be evaluated via natural language, this can enhance or replace comparatively simpler\nmethods from ethology. This has led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 619,
      "text": "as led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats. In trying to shed light on the workings of a black-box system that can\nproduce language, it is tempting to use the simplest approach of asking the system about it. Self-report measures have\nbeen extensively used in psychology as well; but their reliability is questionable in humans (Jobe, 2003) as well as\nLLMs. Properties that such measures usually consider, such as personality, morality, or clinical disorders, are famously\nsensitive to prompting (Dominguez-Olmedo et al., 2023; R\u00f6ttger et al., 2024); to the extent that several recent works\neven simulate groups of humans of different social groups, opinions, and personalities with differently prompted LLMs\n3\n(Salewski et al., 2023; Park et al., 2022; Argyle et al., 2023; Shanahan et al., 2023). There remains value in using\nself-report stimuli from psychology \u2013 for example, to characterize behavior on a default prompt, as well as to understand\nhow steerable (i.e. sensitive to prompting) models are along these dimensions. But results drawn from these measures\nshould be taken contextually (e.g. as a property of a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 620,
      "text": "a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports. This tradition has yielded\nlasting understanding of natural intelligence (Frank et al., 2024), and is the tradition we argue is the most amenable\nfor transferring insights to machine psychology. In this paradigm, externally observed behavior continues to be the\nmeasured experimental variable, but stimuli are designed such that different observed behaviors map onto and measure\ndifferent internal representations, capabilities, or constructs \u2013 like compositionality, theory of mind, logic, causality, etc.\nA key principle is that experiments are hypothesis-driven: if the agent has representation or construct X, we would\nexpect to see behavior Y , otherwise we would see behavior Z. We highlight two key principles from this tradition that\nare crucial to keep in mind when performing and interpreting machine psychology evaluations. First, does seeing\nbehavior Y reliably imply having the construct X? To answer this, the design of a good control is crucial \u2013 to ensure that\nbehavior Y does not have another explanation and does, in fact, implicate X. A large part of experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 621,
      "text": "f experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology. Second, does the absence of behavior Y indicate the absence\nof the construct X? This is a more subtle question. Research in psychology often grapples with the fact that human\nperformance can be noisy or biased; for example, humans may make mistakes even on an easy calculation, or produce\nungrammatical language colloquially. These should not be taken to mean that they lack the abstract capability for math\nor language. These inconsistencies led to the concept of the performance-competence distinction (e.g. Chomsky, 1965):\nthat the way humans perform in a particular situation may not fully capture their underlying competence . More recent\nwork has suggested that similar issues apply when assessing the capabilities of machine learning systems (Firestone,\n2020), and particularly LLMs (Lampinen, 2022).\nParadigms: The many aspects of intelligent behavior\nThere are many aspects of intelligent behavior, each of which has been studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 622,
      "text": "en studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g. pupillometry) are not directly transferable to LLMs since they rely on the existence of a\nphysical body, several of these paradigms are purely linguistic and can be easily transferred. As LLMs expand in the\nkinds of stimuli they can interpret \u2013 e.g. visual (OpenAI, 2023b; Zhang, Huang, et al., 2024; Gemini Team et al., 2024)\n\u2013 and the ways in which they can interact with the world \u2013 e.g. embodiment and tool use (Mialon et al., 2023) \u2013, the\nspace of transferable paradigms increases. Humans also interact with several modalities, and the paradigms developed\nto understand us often compare and integrate these modalities (Schulze Buschoff et al., 2023) \u2013 e.g. the Stroop test\nwhich spans vision and reading capabilities (Scarpina and Tagini, 2017).\nIn this article, we focus on language-based tests, since these are the most widely used in the current research landscape.\nMoreover, we believe that even in light of the growing trend toward multi-modal models, language will remain a primary\nmodality due to its fundamental role in models\u2019 reasoning processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 623,
      "text": "processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning. Apart from these four areas, there are, of course, multiple other domains of psychology that\ncan also provide valuable paradigms for, for instance when investigating creativity in LLMs (Stevenson et al., 2022),\nclinical psychology (Li, Li, et al., 2022), moral behavior (Khandelwal et al., 2024), and others.\nHeuristics and biases\nThe heuristics and biases framework is one of the most influential research paradigms in psychology (Gigerenzer\nand Gaissmaier, 2011; Tversky and Kahneman, 1974). Heuristics are mental shortcuts that simplify reasoning or\ndecision-making processes, and this field studies how such shortcuts can help explain both the successes and the biases\nin human behavior. The large existing literature on heuristics and biases in humans is a fertile ground for examining\nsuch shortcuts in the newest generation of LLMs \u2013 whose capabilities now overlap more with the human abilities\nthis literature studies. Binz and Schulz (2023) were among the first to use this paradigm to better understand the\ndecision-making processes of LLMs. They found that GPT-3 (Brown et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 624,
      "text": "own et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al., 2023; Macmillan-Scott and Musolesi, 2024; Schulze Buschoff et al., 2023; Hayes et al., 2024;\nCoda-Forno, Binz, Wang, et al., 2024). Interestingly, there is evidence from several studies showing that, while the\nprevious generation of models frequently exhibited human-like heuristics and biases, they have largely disappeared\nin the latest generation of LLMs (Chen, Liu, et al., 2023; Hagendorff et al., 2023). The test stimuli were originally\ndesigned to be challenging for human study participants and possibly no longer challenge the growing reasoning\nabilities in LLMs. This could also be due to leakage into the training set \u2013 we discuss this challenge in the section on\ndesign and analysis.\nThe literature on heuristics and biases also suggests that how a problem is phrased can influence how people solve it\n(Cheng and Holyoak, 1985; Tversky and Kahneman, 1981). It is well-known that LLMs are also susceptible to similar\nmanipulations. For example, Dasgupta et al. (2022) have investigated whether LLMs are affected by the semantic\ncontent of logical reasoning problems using several existing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 625,
      "text": "ing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems. Likewise, Schubert et al., 2024 have shown that how LLMs learn in-context depends on the\nproblem formulation.\nFinally, people do not simply apply arbitrary heuristics. Instead, they use heuristics that are adapted to the problems\nthey encounter during their everyday interactions with the world (Todd and Gigerenzer, 2012). In the context of LLMs,\none can look at how the properties of the training data shape their behavior. For example, Chan et al., 2022 have\ndemonstrated that the presence of in-context learning in LLMs can be traced back to data distributional properties such\nas burstiness, where items appear in clusters rather than being uniformly distributed over time, and the presence of large\nnumbers of rarely occurring classes. Researchers also proposed that one should try to understand LLMs through the\nproblem they are trained to solve, similarly to how behavioral scientists attempt to understand human cognition through\nthe lens of ecological rationality (Todd and Gigerenzer, 2012; McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 626,
      "text": "McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives. This includes studying the various factors that influence development, such as social intelligence or social\nskills. By applying paradigms from this area of developmental psychology to LLMs, researchers can gain deeper\ninsights into how these models manage complex social interactions. In particular, once LLMs are deployed as chat\nagents, they should become versed in modeling human communicators. Therefore, it is important to assess the level of\nsocial intelligence in LLMs. One example in this context is the application of theory of mind tests to LLMs, where\nresearchers use tasks from human experiments, such as those famously conducted by Wimmer and Perner (1983) and\nPerner et al. (1987). While early experiments with models such as GPT-3 showed that they struggle to solve theory\nof mind tasks (Sap et al., 2022), later models demonstrate an increasing ability to reliably infer unobservable mental\nstates in others (Strachan et al., 2024; Holterman and Deemter, 2023; Moghaddam and Honey, 2023). Further related\nresearch examines how LLM performance on theory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 627,
      "text": "heory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al., 2024), or measures the robustness of theory of mind test setups against distracting alterations in the tasks\nLLMs receive as inputs (Ullman, 2023). As theory of mind tests measure, among other things, the ability to understand\nfalse beliefs, further research has explored the emerging capability of LLMs to induce false beliefs in other agents\n(Hagendorff, 2024a), or how LLMs trade off various communicative values like honesty and helpfulness (Liu et al.,\n2024) \u2013 these investigations also contribute to understanding and improving alignment with human values for AI safety\n(Ji et al., 2023).\nThe space of relevant paradigms increases as LLMs are allowed to interact through self-reflection (Nair et al., 2023),\nself-instruction (Wang, Wei, et al., 2022), or in swarms (Zhuge et al., 2023). For example, researchers looked at\ncooperative and coordinative behavior in LLMs playing games, revealing persistent behavioral signatures in the models\n(Akata et al., 2023). Similarly, researchers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 628,
      "text": "ers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024). Another study, which is influenced by works in human social psychology, looked at how multiple LLMs form\nand evolve networks, investigating micro-level network principles such as preferential attachment or triadic closure,\nas well as macro-level principles such as community structures (Papachristou and Yuan, 2024). In sum, machine\npsychology can reveal patterns of social behavior and interaction among LLMs, individually and collectively, be it for\n5\nproblem solving or world simulation (Guo et al., 2024). By drawing from human developmental psychology and social\ndynamics, researchers can better understand and design LLMs that navigate complex social interactions and exhibit\nadvanced social skills.\nPsychology of language\nA long history of work has studied the psychology of how humans use and understand language, ranging from how\nthey use semantic and syntactic features to understand a sentence to how they use pragmatic inferences in a discourse\ncontext to help interpret what someone has said. Correspondingly, a long-standing body of work has studied how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 629,
      "text": "how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al., 1989); more recently, researchers\nhave applied similar techniques to study LLMs. A wide range of work has studied what models learn about syntax\n(Linzen and Baroni, 2021), often using methods from psycholinguistics. For example, Wilcox et al. (2023) used\npsycholinguistics-inspired surprisal measures to show that LLMs learn filler-gap dependencies, a challenging syntactic\nstructure. Other researchers have used related measures to study what LLMs learn about the semantics of entailment\n(Merrill et al., 2024). Moreover, researchers used psycholinguistic techniques like priming to study how models\nrepresent and process language (Prasad et al., 2019; Sinclair et al., 2022), and methods like deconfounded stimuli to\nidentify where models may rely on semantic heuristics rather than syntax (McCoy, Pavlick, et al., 2019). Several recent\nworks (Hu, Floyd, et al., 2023; Ruis, Khan, et al., 2023) studied pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 630,
      "text": "ed pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain. In another study, researchers examined long-form analogies generated by ChatGPT, finding\nthat AI-generated analogies lack some human-like psycholinguistic properties (Seals and Shalin, 2023), particularly in\ntext cohesion, language, and readability. Furthermore, researchers applied garden path sentences \u2013 sentences that lead\nthe reader to initially interpret them incorrectly due to their ambiguous structure \u2013 to LLMs, showing that the models\nrespond similarly to humans (Aher et al., 2023; Christianson et al., 2001). At a higher level, some researchers have\ndrawn inspiration from aspects of human language development to attempt to identify the causes of the relative data\ninefficiency of language models (Warstadt et al., 2023; Frank, 2023). In each of these cases, methods and ideas from\npsychology and psycholinguistics provide guidance on how to assess processes through language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 631,
      "text": "h language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills. At first blush, it\nmay appear that experimental paradigms for the study of learning are less applicable to LLMs, given that the aim of\nbehavioral experiments is often to help uncover the underlying learning algorithm \u2013 whereas for LLMs the learning\nalgorithms used in training are designed and already known. However, the behavioral sciences can still benefit from the\nstudy of LLMs in this context, since LLMs exhibit learning abilities that were not explicitly designed into the models\n(they are emergent), and thus one does not understand the underlying learning algorithm. In particular, LLMs exhibit\nemergent in-context learning \u2013 the ability to learn from context (the prompt) without requiring any gradient-based\nupdates in weights (Brown et al., 2020). Understanding in-context learning is a burgeoning field that is rapidly gaining\nin importance, given the increasing size of LLMs context windows and consequent gains in capabilities, e.g. the\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 632,
      "text": "he\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024).\nUncovering the implicit learning algorithm implemented by in-context learning is a burgeoning research field, and\nutilizes many of the methods common in cognitive science. For example, multiple studies have compared the outputs of\ntransformer in-context learning with the outputs of hypothesized learning algorithms (Oswald et al., 2023; Aky\u00fcrek\net al., 2022). This is a staple of cognitive modeling, and could potentially benefit even further from model comparison\nprocedures from psychology and statistics (Yang, 2006; Arlot and Celisse, 2010; Vrieze, 2012). Recent work in\ncognitive science has used machine learning to discover new theories of human decision-making (Peterson et al., 2021)\n\u2013 it might be interesting to apply related approaches to in-context learning as well. Researchers might also benefit from\nconsidering particular models as normative starting points (Niv, 2009).\nResearchers may also wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 633,
      "text": "so wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time. These characteristics\n6\nare often not obvious even in cases where the learning algorithm is known, and thus researchers would like to understand\nthem not only for in-context learning, but also for other forms of LLM learning, e.g. self-supervised gradient-based\nlearning, reinforcement learning (Ouyang et al., 2022), or \"fast\" memory retrieval (Borgeaud et al., 2022; Lewis et al.,\n2020).\nTo characterize inductive biases and generalization of LLMs, researchers have borrowed both concepts and experimental\nparadigms from cognitive sciences (Schubert et al., 2024; Coda-Forno, Binz, Akata, et al., 2023) and Bayesian inference\n(Xie et al., 2022). Studies utilized paradigms for measuring systematic generalization to characterize those capabilities\nin LLMs, and as inspiration to improve these abilities (Lake and Baroni, 2023; Ruis, Andreas, et al., 2022). Webb\net al. (2023) created novel variants of classic analogy problems from cognitive science, in order to examine the\nanalogical capabilities of large language models. Chan et al. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 634,
      "text": "l. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers. Furthermore, researchers borrowed paradigms and measures from developmental psychology\nto characterize the domains where LLM inductive biases may match those of children, and where they may fall short\n(including in causal reasoning and innovation) (Kosoy et al., 2023; Yiu et al., 2023).\nTo characterize the data dependence of in-context learning, existing work has drawn inspiration from research in\ndevelopmental psychology on skewed and bursty distributions (Chan et al., 2022). An important aspect of data\ndependence is the structure of data over time (during training). AI researchers have long drawn inspiration from\ncurriculum learning in human and non-human animals to better understand how to structure training data so that earlier\nlearning on easier tasks can scaffold later learning on harder tasks (Bengio et al., 2009). There remain many areas\nof behavioral research on learning that may serve as rich sources of inspiration on data dependence, e.g. research on\nrepetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 635,
      "text": "epetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019). Data dependence is particularly\ninteresting for LLMs because text training data (being sourced largely from unstructured web-scale corpora) is very\ndifferent from the structured training data typically used for traditional discriminatory machine learning techniques, and\nbecause data is one of the major levers one can manipulate in training LLMs to adjust their behaviors.\nDesign and analysis: Good behavioral experimentation\nComputer science has not historically been an empirical science. While machine learning (especially since the era of\nneural network models) has been significantly driven by empirical rather than theoretical work, the settings under which\nthose protocols were developed \u2013 a test set that is fixed for all practitioners and is effectively infinitely large \u2013 no longer\nhold in the small test-only behavioral experiments setting. Current LLMs are famously sensitive to small changes in\nprompt structure or they rely on shallow syntactic heuristics (McCoy, Pavlick, et al., 2019), and studies that are not\ncareful about testing the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 636,
      "text": "ting the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al., 2020), and machine\npsychology should not share the same fate. In this section, we provide recommendations for sound methodologies in\nbehavioral test settings with LLMs, which should be valuable to practitioners in the field of machine psychology.\nPrompting methods and biases\nMany studies conducted in the field of machine psychology have a significant shortcoming in common, namely that they\ndo not avoid training data contamination. They use prompts from existing psychology studies and apply them to LLMs\nwithout changing their wording, task orders, etc. In this way, LLMs are likely to have already experienced identical\nor similar tasks during training, thus causing LLMs to simply reproduce known token patterns. When adopting test\nframeworks from psychology \u2013 meaning vignettes, cognitive tasks, or other test setups \u2013 researchers must ensure that\nLLMs have never seen the tests before and go beyond mere memorization. Hence, prompts may indeed be structurally\nlike already existing tasks, but they should contain new wordings, agents, orders, actions, etc. That being said, some\nexperiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 637,
      "text": "experiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024).\nAnother common shortcoming of several existing machine psychology studies is that they rely on small sample sizes or\nconvenience samples, meaning non-systematic sequences of prompts. Sampling biases in the used benchmarks or task\ndatasets, which are especially prevalent in small sample sizes, can diminish the quality of machine psychology studies.\n7\nThis is because slight changes in prompts can change model outputs significantly. Because of this high sensitivity to\nprompt wording, it is important to test multiple versions of one task and to create representative samples, meaning\nbatteries of varied prompts. Only in this way can one reliably measure whether a certain behavior is systematically\nreoccurring and generalizable (Yarkoni, 2022). Furthermore, LLMs can succumb to various biases influencing the\nprocessing of prompts (Zhao, Wallace, et al., 2021; Chan et al., 2022). Recency biases in LLMs, for instance, lead to a\ntendency to rely more heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 638,
      "text": "e heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data. Moreover,\nmajority label biases can cause LLMs to be skewed towards labels, classes, or examples that are frequent in a few-shot\nlearning setting. Technical biases like these can at least in part be controlled for when designing prompts or prompt\nvariations that tend to avoid triggering them. If this is not done, LLMs may rely on shortcuts exploiting such biases.\nEliciting capabilities with prompts\nThe standard prompt design, comprising a vignette plus an open- or close-ended question or task, can be enhanced\nby prefixes or suffixes eliciting improved reasoning capabilities in LLMs. On the other hand, omitting such prefixes\nand suffixes can lead to underestimations of the model\u2019s capabilities. Although it is likely that most specific prompt\naugmentations have a positive influence on one kind of task but not another, reducing our ability to systematically\nunderstand LLM behavior, a few prompt design approaches have nonetheless been found to confer broader performance\nbenefits. Most notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 639,
      "text": "t notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance. This can be extended\neven further by generating multiple chain-of-thought reasoning paths and taking the majority response as the final one\n(Wang, Wei, et al., 2022). Similar to chain-of-thought prompting is least-to-most prompting, which also decomposes\nproblems into a set of subproblems to increase accuracy in LLMs (Zhou et al., 2022). Yet another approach is to frame\nquestions in a multiple-choice format. This was shown to improve reasoning capabilities in some cases (Kadavath et al.,\n2022), but can also limit them because LLMs might be prompted to provide brief responses, thereby circumventing\nreasoning in the process of prompt completion. Nevertheless, many prominent NLP benchmarks use multiple choice\nformats instead of open-ended questions. Here, one must keep in mind that different expressions of the same concept\ncompete for probability, which can lower the chances of selecting the correct answer (Holtzman et al., 2021). Moreover,\none has to consider potential recency biases, which require neutralizing this effect by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 640,
      "text": "t by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al., 2020), where the LLM\u2019s performance improves after repeated exposure to a\ngiven task. Moreover, self-reflection, meaning the automated, recursive criticizing and subsequent self-improvement of\nLLM outputs by the LLM itself, is a further technique that can improve reasoning abilities (Nair et al., 2023; Kim et al.,\n2023). Regarding improvements in symbolic or numeric reasoning, another technique is to prompt LLMs to use code\nfor solving tasks (Zhang, Ge, et al., 2024). Eventually, all mentioned methods to improve reasoning can be not just\nleveraged for machine psychology; they can also become objects of study themselves.\nSetting parameters and evaluating outputs\nLLMs come with a variety of parameters researchers can set. For example, most models come in a variety of sizes.\nAnalyses across different sizes are valuable: while the largest ones usually have the highest capabilities, some recent\nworks find \"inverse-scaling\" (McKenzie et al., 2023). Moreover, temperature settings control randomness. If exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 641,
      "text": "exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice. The effect of temperature on capabilities is not\nestablished (Renze and Guven, 2024), and reporting averages or \"best of K\" \u2013 considering all the responses over K\nsamples that meet certain simple criteria, e.g. formatting (Chen, Tworek, et al., 2021) \u2013 is valuable.\nAfter conducting the experiments, a list of LLM responses must be evaluated and compared with the ground truth. The\nsimplest case is when the results can be framed and scored as a multiple-choice question \u2013 though even in this case,\nscoring the answers so that the model responds directly inline, rather than selecting a choice, can yield more signal\n(Hu and Levy, 2023). If possible, multiple scoring methods should be compared, to evaluate whether the effects are\ndependent on the scoring method (Tsvilodub et al., 2024). If the questions must be answered with free generations, the\nevaluation process can still be automated if the results exhibit sufficient simplicity and regularity, meaning that the LLM\nresponses are similar to the ground truth strings in terms of length and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 642,
      "text": "gth and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed. State-of-the-art LLMs, however, tend to produce highly variable and comprehensive\noutputs, which can complicate classification. While stop sequences, token limits, or prompt instructions that interrupt\nfurther text generation can facilitate classification by promoting output uniformity, they also improperly constrain LLM\nbehavior. Therefore, researchers are increasingly relying on LLM-based evaluations of outputs where a single model or\nmultiple stacked model instances perform the classification using carefully crafted instructions. Although this method\nmight still be inaccurate for very comprehensive outputs, a solution is to instruct the LLM under scrutiny to output\nits final answer or summary after a specific string sequence like \"####\" (Cobbe et al., 2021). This approach allows\nthe LLM to reason during verbose prompt completions, which is necessary for many prompt engineering techniques\nsuch as chain-of-thought reasoning. The classification then only involves processing the string following \"####\". If\nthis method still proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 643,
      "text": "ll proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out.\nDiscussion\nMachine psychology provides a new approach to explaining AI. Instead of interpreting a neural network\u2019s design\ncomponents (Barredo Arrieta et al., 2019), one analyzes the relationships between inputs and outputs, i.e. prompt\ndesign and prompt completion. Although this may allow the identification of hitherto unknown abilities or behavioral\ntraits in LLMs, interpreting LLM responses comes with a challenge. A strong tendency exists to confer mental concepts\nor psychological terms to LLMs that were hitherto reserved for human and animal minds. This tendency manifests in\ncommon terms like \"machine learning,\" but will become more prevalent in machine psychology when concepts such as\nreasoning (Huang and Chang, 2022), intuition (Hagendorff et al., 2023), creativity (Stevenson et al., 2022), intelligence\n(Webb et al., 2023), personality (Miotto et al., 2022), mental illnesses (Li, Li, et al., 2022), etc. are transferred to\nLLMs. In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 644,
      "text": ". In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024). Moreover, many\npsychological concepts are normatively laden and can foster mismatches in expectations between AI experts and the\npublic regarding machine capabilities (Shevlin and Halina, 2019). Nevertheless, the problem that many abilities in\nLLMs cannot be reasonably grasped by only referring to the inner workings of their neural architecture remains.\nBy adopting a concept from ethnography, one could call such an approach \"thin descriptions\" (Ryle, 1971; Geertz,\n1973), meaning that one only explains internal representations in AI systems, for instance via activation atlases, which\nvisualize how different parts of a neural network respond to various inputs (Carter et al., 2019). In this sense, LLMs\nsimply hijack humans\u2019 intuitions to explain machine behavior patterns by using psychological or other anthropocentric\nterms. Contrary to thin descriptions, though, there are \"thick descriptions.\" They imply using psychological terms to add\na layer of explainability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 645,
      "text": "ability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist. This holds for humans,\ntoo, where mental terms used to explain behavior do not directly correlate with specific sets of neural activations.\nBy postulating (mental) unobservable states, be it with regard to brains or artificial neural networks, one increases\nexplanatory resources (Sellars, 1997). Thick descriptions help in making sense of LLMs when thin descriptions are\ninsufficient to explain behavioral patterns. Thin descriptions assume that LLMs merely possess syntax or a statistical\ncapacity to associate words (Searle, 1980; Floridi and Chiriatti, 2020; Bender et al., 2021), but not semantics. Thick\ndescriptions, though, assume that LLMs show patterns and regularities that go beyond mere syntax. These patterns can\nbe explained by means of machine psychology.\nBeyond potential habituations regarding the use of terminology borrowed from psychology in the context of machines,\nmachine psychology, as a nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 646,
      "text": "nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments.\nThis new discipline of evaluating LLMs will become even more important when taking multimodal or augmented\nLLMs into account, meaning LLMs that are allowed to interact with images, external information sources, sensory\ndata, physical objects, and various other tools (Mialon et al., 2023; Schick et al., 2023; Ma et al., 2024). Moreover,\nonce test settings for machine psychology are established, researchers can investigate how LLMs develop over time by\napplying the same tasks multiple times, yielding longitudinal data. This data can serve as a baseline to extrapolate trends\nregarding the development of reasoning abilities in LLMs. Such estimations may be increasingly important for AI\nsafety and AI alignment research to predict future behavioral potentials in LLMs. By gaining a deeper understanding of\nthese potentials, machine psychology is providing a new approach to AI explainability as well as an important addition\nto traditional benchmarking methods in natural language processing.\n9\nAuthor contributions\nTH and ID conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 647,
      "text": "D conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure. All authors assisted\nwith iterations and edited and reviewed the paper.\nReferences\nAher, Gati, Rosa I. Arriaga, and Adam Tauman Kalai. \u201cUsing Large Language Models to Simulate Multiple Humans\nand Replicate Human Subject Studies\u201d. In: Proceedings of the 40th International Conference on Machine Learning .\n2023, pp. 1\u201335.\nAkata, Elif, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. \u201cPlaying repeated\ngames with Large Language Models\u201d. In: arXiv (2023), pp. 1\u201313.\nAky\u00fcrek, Ekin, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. \u201cWhat learning algorithm is in-context\nlearning? Investigations with linear models\u201d. In: arXiv (2022), pp. 1\u201329.\nAnderson, Philip W. \u201cMore is different: Broken symmetry and the nature of the hierarchical structure of science\u201d. In:\nScience 177.4047 (1972), pp. 393\u2013396.\nAnil, Cem et al. Many-shot jailbreaking . 2024.\nAnthropic. The Claude 3 Model Family: Opus, Sonnet, Haiku . 2024.\nArgyle, Lisa P, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, and David Wingate. \u201cOut of One,\nMany: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 648,
      "text": "any: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d. In: Statistics Surveys 4\n(2010), pp. 40\u201379.\nBaddeley, Alan. \u201cWorking memory\u201d. In: Current Biology 20.4 (2010), R136\u2013R140.\nBarredo Arrieta, Alejandro et al. \u201cExplainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and\nChallenges toward Responsible AI\u201d. In: Information Fusion 58 (2019), pp. 82\u2013115.\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. \u201cOn the Dangers of Stochastic\nParrots: Can Language Models Be Too Big?\u201d In: Proceedings of the 2021 ACM conference on fairness, accountability,\nand transparency . 2021, pp. 610\u2013623.\nBengio, Yoshua, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. \u201cCurriculum learning\u201d. In: Proceedings of the\n26th Annual International Conference on Machine Learning . 2009, pp. 41\u201348.\nBinz, Marcel and Eric Schulz. \u201cUsing cognitive psychology to understand GPT-3\u201d. In: Proceedings of the National\nAcademy of Sciences 120.6 (2023), pp. 1\u201310.\nBommasani, Rishi et al. \u201cOn the opportunities and risks of foundation models\u201d. In: arXiv (2021), pp. 1\u2013214.\nBorgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 649,
      "text": "nn, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed. by Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and\nSivan Sabato. V ol. 162. 2022, pp. 2206\u20132240.\nBoring, Edwin G. \u201cThe Nature and History of Experimental Control\u201d. In: The American Journal of Psychology 67.4\n(1954), pp. 573\u2013589.\nBowman, Samuel R., Gabor Angeli, Christopher Potts, and Christopher D. Manning. \u201cA large annotated corpus for\nlearning natural language inference\u201d. In: Proceedings of the 2015 Conference on Empirical Methods in Natural\nLanguage Processing . Ed. by Llu\u00eds M\u00e0rquez, Chris Callison-Burch, and Jian Su. 2015, pp. 632\u2013642.\nBrown, Tom et al. \u201cLanguage Models are Few-Shot Learners\u201d. In: Advances in Neural Information Processing Systems .\nEd. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33. Curran Associates, Inc., 2020,\npp. 1877\u20131901.\nBubeck, S\u00e9bastien et al. \u201cSparks of Artificial General Intelligence: Early experiments with GPT-4\u201d. In: arXiv (2023),\npp. 1\u2013155.\nCarter, Shan, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah. \u201cExploring Neural Networks with\nActivation Atlases\u201d. In: Distill 4.3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 650,
      "text": ".3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22.1 (2015), pp. 281\u2013288.\nChai, Wen Jia, Aini Ismafairus Abd Hamid, and Jafri Malin Abdullah. \u201cWorking Memory From the Psychological and\nNeurosciences Perspectives: A Review\u201d. In: Frontiers in Psychology 9 (2018), pp. 1\u201316.\n10\nChan, Stephanie, Adam Santoro, Andrew Lampinen, Jane Wang, Aaditya Singh, Pierre Richemond, James McClelland,\nand Felix Hill. \u201cData Distributional Properties Drive Emergent In-Context Learning in Transformers\u201d. In: Advances\nin Neural Information Processing Systems 35 (2022), pp. 18878\u201318891.\nChang, Tyler A and Benjamin K Bergen. \u201cLanguage Model Behavior: A Comprehensive Survey\u201d. In: Computational\nLinguistics 50.1 (2024), pp. 293\u2013350.\nChen, Mark, Jerry Tworek, et al. \u201cEvaluating Large Language Models Trained on Code\u201d. In: arXiv (2021), pp. 1\u201335.\nChen, Yiting, Tracy Xiao Liu, You Shan, and Songfa Zhong. \u201cThe emergence of economic rationality of GPT\u201d. In:\nProceedings of the National Academy of Sciences 120.51 (2023), e2316205120.\nCheng, Patricia W and Keith J Holyoak. \u201cPragmatic reasoning schemas\u201d. In: Cognitive Psychology 17.4 (1985),\npp. 391\u2013416.\nChollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 651,
      "text": "hollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam. Aspects of the Theory of Syntax . MIT Press, 1965.\nChristianson, Kiel, Andrew Hollingworth, John F. Halliwell, and Fernanda Ferreira. \u201cThematic Roles Assigned along\nthe Garden Path Linger\u201d. In: Cognitive Psychology 42.4 (2001), pp. 368\u2013407.\nCobbe, Karl et al. \u201cTraining Verifiers to Solve Math Word Problems\u201d. In: arXiv (2021), pp. 1\u201322.\nCoda-Forno, Julian, Marcel Binz, Zeynep Akata, Matt Botvinick, Jane Wang, and Eric Schulz. \u201cMeta-in-context learning\nin large language models\u201d. In: Advances in Neural Information Processing Systems 36 (2023), pp. 65189\u201365201.\nCoda-Forno, Julian, Marcel Binz, Jane X Wang, and Eric Schulz. \u201cCogBench: a large language model walks into a\npsychology lab\u201d. In: arXiv (2024), pp. 1\u201326.\nConmy, Arthur, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adri\u00e0 Garriga-Alonso. \u201cTowards\nAutomated Circuit Discovery for Mechanistic Interpretability\u201d. In: Advances in Neural Information Processing\nSystems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. Curran Associates,\nInc., 2023, pp. 16318\u201316352.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 652,
      "text": "2.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d. In: arXiv (2022),\npp. 1\u201336.\nDempster, Frank N. \u201cSpacing effects and their implications for theory and practice\u201d. In: Educational Psychology Review\n1.4 (1989), pp. 309\u2013330.\nDominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-D\u00fcnner. \u201cQuestioning the Survey Responses of\nLarge Language Models\u201d. In: arXiv (2023), pp. 1\u201325.\nDuijn, Max J. van, Bram van Dijk, Tom Kouwenhoven, Werner de Valk, Marco R. Spruit, and Peter van der Putten.\n\u201cTheory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children\nAged 7-10 on Advanced Tests\u201d. In: Proceedings of the 27th Conference on Computational Natural Language\nLearning (CoNLL) . Ed. by Jing Jiang, David Reitter, and Shumin Deng. 2023, pp. 389\u2013402.\nEdwards, Allen L. Statistical Methods for the Behavioral Sciences . Rinehart, 1954.\nElkins, Katherine and Jon Chun. \u201cCan GPT-3 Pass a Writer\u2019s Turing Test?\u201d In: Journal of Cultural Analytics 5.2 (2020),\npp. 1\u201316.\nElman, Jeffrey L. \u201cDistributed representations, simple recurrent networks, and grammatical structure\u201d. In: Machine\nLearning 7 (1991), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 653,
      "text": "91), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz. Research methods in the behavioral sciences. Holt, Rinehart and Winston,\n1953.\nFirestone, Chaz. \u201cPerformance vs. competence in human\u2013machine comparisons\u201d. In: Proceedings of the National\nAcademy of Sciences 117.43 (2020), pp. 26562\u201326571.\nFloridi, Luciano and Massimo Chiriatti. \u201cGPT-3: Its Nature, Scope, Limits, and Consequences\u201d. In: Minds and Machines\n30.4 (2020), pp. 681\u2013694.\nFrank, Michael C. \u201cBridging the data gap between children and large language models\u201d. In: Trends in Cognitive\nSciences 27.11 (2023), pp. 990\u2013992.\nFrank, Michael C., Mika Braginsky, Julie Cachia, Nicholas Coles, Tom E. Hardwicke, Robert D. Hawkins, Maya B.\nMathur, and Rondeline Williams. Experimentology: An Open Science Approach to Experimental Psychology Methods .\nMIT Press, 2024.\n11\nGao, Leo, Tom Dupr\u00e9 la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, and\nJeffrey Wu. \u201cScaling and evaluating sparse autoencoders\u201d. In: arXiv (2024), pp. 1\u201334.\nGeertz, Clifford. The Interpretation of Cultures: Selected Essays . Basic Books, 1973.\nGeirhos, Robert, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 654,
      "text": "acobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673.\nGemini Team et al. \u201cGemini 1.5: Unlocking multimodal understanding across millions of tokens of context\u201d. In: arXiv\n(2024), pp. 1\u201390.\nGigerenzer, Gerd and Wolfgang Gaissmaier. \u201cHeuristic decision making\u201d. In: Annual Review of Psychology 62 (2011),\npp. 451\u2013482.\nGreco, Claudio, Barbara Plank, Raquel Fern\u00e1ndez, and Raffaella Bernardi. \u201cPsycholinguistics Meets Continual Learning:\nMeasuring Catastrophic Forgetting in Visual Question Answering\u201d. In: Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics . Ed. by Anna Korhonen, David Traum, and Llu\u00eds M\u00e0rquez. Florence,\nItaly: Association for Computational Linguistics, 2019, pp. 3601\u20133605.\nGr\u00f6n, Georg, David Schul, V olker Bretschneider, AP Wunderlich, and Matthias W Riepe. \u201cAlike performance during\nnonverbal episodic learning from diversely imprinted neural networks\u201d. In: European Journal of Neuroscience 18.11\n(2003), pp. 3112\u20133120.\nGuo, Taicheng, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V . Chawla, Olaf Wiest, and Xiangliang\nZhang. \u201cLarge Language Model based Multi-Agents: A Survey of Progress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 655,
      "text": "ress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138.\n\u2013 \u201cMapping the Ethics of Generative AI: A Comprehensive Scoping Review\u201d. In: arXiv (2024), pp. 1\u201325.\nHagendorff, Thilo, Sarah Fabi, and Michal Kosinski. \u201cHuman-like intuitive behavior and reasoning biases emerged in\nlarge language models but disappeared in ChatGPT\u201d. In: Nature Computational Science 3.10 (2023), pp. 833\u2013838.\nHaibe-Kains, Benjamin et al. \u201cTransparency and reproducibility in artificial intelligence\u201d. In: Nature 586.7829 (2020),\npp. 1\u20137.\nHayes, William M, Nicolas Yax, and Stefano Palminteri. \u201cRelative Value Biases in Large Language Models\u201d. In: arXiv\n(2024), pp. 1\u20137.\nHendrycks, Dan, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Xiaodong Song, and\nJacob Steinhardt. \u201cMeasuring Mathematical Problem Solving With the MATH Dataset\u201d. In: Thirty-fifth Conference\non Neural Information Processing Systems . 2021, pp. 1\u201311.\nHermann, Katherine and Andrew Lampinen. \u201cWhat shapes feature representations? Exploring datasets, architectures,\nand training\u201d. In: 34th Conference on Neural Information Processing Systems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 656,
      "text": "tems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. \u201cSurface Form Competition: Why the\nHighest Probability Answer Isn\u2019t Always Right\u201d. In: Proceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing . Ed. by Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih.\n2021, pp. 7038\u20137051.\nHosseini, Eghbal A and Evelina Fedorenko. \u201cLarge language models implicitly learn to straighten neural sentence\ntrajectories to construct a predictive representation of natural language\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2023,\npp. 43918\u201343930.\nHu, Jennifer, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, and Edward Gibson. \u201cA fine-grained comparison of\npragmatic language understanding in humans and language models\u201d. In: The 61st Annual Meeting Of The Association\nFor Computational Linguistics . 2023, pp. 4194\u20134213.\nHu, Jennifer and Roger P Levy. \u201cPrompting is not a substitute for probability measurements in large language models\u201d.\nIn:The 2023 Conference on Empirical Methods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 657,
      "text": "ethods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A. \u201cRunning cognitive evaluations on large language models: The do\u2019s and the don\u2019ts\u201d. In: arXiv (2023),\npp. 1\u201312.\nIvanova, Anna A et al. \u201cElements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic\nworld knowledge in language models\u201d. In: arXiv (2024), pp. 1\u201321.\n12\nJagadish, Akshay K, Julian Coda-Forno, Mirko Thalmann, Eric Schulz, and Marcel Binz. \u201cHuman-like Category\nLearning by Injecting Ecological Priors from Large Language Models into Neural Networks\u201d. In: arXiv (2024),\npp. 1\u201327.\nJi, Jiaming et al. \u201cAI Alignment: A Comprehensive Survey\u201d. In: arXiv (2023), pp. 1\u2013102.\nJobe, Jared B. \u201cCognitive psychology and self-reports: models and methods\u201d. In: Quality of Life Research 12 (2003),\npp. 219\u2013227.\nJonas, Eric and Konrad Paul Kording. \u201cCould a Neuroscientist Understand a Microprocessor?\u201d In: PLOS Computational\nBiology 13.1 (2017), pp. 1\u201324.\nJones, Erik and Jacob Steinhardt. \u201cCapturing failures of large language models via human cognitive biases\u201d. In:\nAdvances in Neural Information Processing Systems 35 (2022), pp. 11785\u201311799.\nKadavath, Saurav et al. \u201cLanguage Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 658,
      "text": "Language Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M. Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, and Shafiq Joty.\n\u201cxCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and\nRetrieval\u201d. In: arXiv (2023), pp. 1\u201344.\nKhandelwal, Aditi, Utkarsh Agarwal, Kumar Tanmay, and Monojit Choudhury. \u201cDo Moral Judgment and Reasoning\nCapability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test\u201d. In: Proceedings\nof the 18th Conference of the European Chapter of the Association for Computational Linguistics . Association for\nComputational Linguistics, 2024, pp. 2882\u20132894.\nKim, Geunwoo, Pierre Baldi, and Stephen McAleer. \u201cLanguage Models can Solve Computer Tasks\u201d. In: arXiv (2023),\npp. 1\u201326.\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. \u201cLarge Language Models are\nZero-Shot Reasoners\u201d. In: arXiv (2022), pp. 1\u201336.\nKosoy, Eliza, Emily Rose Reagan, Leslie Lai, Alison Gopnik, and Danielle Krettek Cobb. \u201cComparing Machines\nand Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 659,
      "text": "Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311.\nKumar, Sreejan, Theodore R Sumers, Takateru Yamakoshi, Ariel Goldstein, Uri Hasson, Kenneth A Norman, Thomas L\nGriffiths, Robert D Hawkins, and Samuel A Nastase. \u201cReconstructing the cascade of language processing in the brain\nusing the internal computations of a transformer-based language model\u201d. In: BioRxiv (2022), pp. 1\u201356.\nLake, Brenden M. and Marco Baroni. \u201cHuman-like systematic generalization through a meta-learning neural network\u201d.\nIn:Nature 623 (2023), pp. 1\u201323.\nLampinen, Andrew Kyle. \u201cCan language models handle recursively nested grammatical structures? A case study on\ncomparing models and humans\u201d. In: arXiv (2022), pp. 1\u201322.\nLewis, Patrick et al. \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33.\nCurran Associates, Inc., 2020, pp. 9459\u20139474.\nLi, Changmao and Jeffrey Flanigan. \u201cTask Contamination: Language Models May Not Be Few-Shot Anymore\u201d. In:\narXiv (2023), pp. 1\u201320.\nLi, Xingxuan, Yutong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 660,
      "text": "tong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni. \u201cSyntactic Structure from Deep Learning\u201d. In: Annual Review of Linguistics 7.1 (2021),\npp. 195\u2013212.\nLiu, Ryan, Theodore R Sumers, Ishita Dasgupta, and Thomas L Griffiths. \u201cHow do Large Language Models Navigate\nConflicts between Honesty and Helpfulness?\u201d In: arXiv (2024), pp. 1\u201321.\nLo, Kai-Ling, Rami Ariss, and Philipp Kurz. \u201cGPoeT-2: A GPT-2 Based Poem Generator\u201d. In: arXiv (2022), pp. 1\u201310.\nMa, Yecheng Jason, William Liang, Hung-Ju Wang, Sam Wang, Yuke Zhu, Linxi Fan, Osbert Bastani, and Dinesh\nJayaraman. \u201cDrEureka: Language Model Guided Sim-To-Real Transfer\u201d. In: Robotics: Science and Systems (RSS) .\n2024, pp. 1\u201328.\nMacmillan-Scott, Olivia and Mirco Musolesi. \u201c(Ir)rationality and cognitive biases in large language models\u201d. In: Royal\nSociety Open Science 11 (2024), pp. 1\u201314.\nMahowald, Kyle, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko.\n\u201cDissociating language and thought in large language models\u201d. In: Trends in Cognitive Sciences 28.6 (2024), pp. 517\u2013\n540.\n13\nMazumder, Mark et al. \u201cDataPerf: Benchmarks for Data-Centric AI Development\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 661,
      "text": "lopment\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St. John, and Roman Taraban. \u201cSentence comprehension: A parallel distributed processing\napproach\u201d. In: Language and Cognitive Processes 4.3-4 (1989), SI287\u2013SI335.\nMcCoy, R Thomas, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L Griffiths. \u201cEmbers of Autoregression:\nUnderstanding Large Language Models Through the Problem They are Trained to Solve\u201d. In: arXiv (2023), pp. 1\u201384.\nMcCoy, Tom, Ellie Pavlick, and Tal Linzen. \u201cRight for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\nLanguage Inference\u201d. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .\n2019, pp. 3428\u20133448.\nMcKenzie, Ian R. et al. \u201cInverse Scaling: When Bigger Isn\u2019t Better\u201d. In: arXiv (2023), pp. 1\u201339.\nMerrill, William, Zhaofeng Wu, Norihito Naka, Yoon Kim, and Tal Linzen. \u201cCan You Learn Semantics Through\nNext-Word Prediction? The Case of Entailment\u201d. In: arXiv (2024), pp. 1\u201322.\nMialon, Gr\u00e9goire, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, and Roberta et al Raileanu.\n\u201cAugmented Language Models: a Survey\u201d. In: arXiv (2023), pp. 1\u201333.\nMiotto, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 662,
      "text": "o, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey. \u201cBoosting Theory-of-Mind Performance in Large Language\nModels via Prompting\u201d. In: arXiv (2023), pp. 1\u201327.\nMunkhdalai, Tsendsuren, Manaal Faruqui, and Siddharth Gopal. \u201cLeave No Context Behind: Efficient Infinite Context\nTransformers with Infini-attention\u201d. In: arXiv (2024), pp. 1\u201312.\nNair, Varun, Elliot Schumacher, Geoffrey Tso, and Anitha Kannan. \u201cDERA: Enhancing Large Language Model\nCompletions with Dialog-Enabled Resolving Agents\u201d. In: arXiv (2023), pp. 1\u201338.\nNiv, Yael. Reinforcement learning in the brain . 2009.\nOpen Science Collaboration. \u201cEstimating the reproducibility of psychological science\u201d. In: Science 349.6251 (2015),\npp. 1\u201310.\nOpenAI. ChatGPT: Optimizing Language Models for Dialogue . 2022. URL:https://openai.com/blog/chatgpt/\n(visited on 02/13/2023).\n\u2013GPT-4 Technical Report . 2023. URL:https://cdn.openai.com/papers/gpt-4.pdf (visited on 03/19/2023).\n\u2013GPT-4V(ision) System Card . 2023. URL:https://cdn.openai.com/papers/GPTV_System_Card.pdf (visited\non 10/13/2023).\nOswald, Johannes von, Eyvind Niklasson, Ettore Randazzo, Jo\u00e3o Sacramento, Alexander Mordvintsev, Andrey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 663,
      "text": "drey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174.\nOuyang, Long et al. \u201cTraining language models to follow instructions with human feedback\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh.\nV ol. 35. 2022, pp. 27730\u201327744.\nPapachristou, Marios and Yuan Yuan. \u201cNetwork Formation and Dynamics Among Multi-LLMs\u201d. In: arXiv (2024),\npp. 1\u201327.\nPark, Joon Sung, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. \u201cSocial\nSimulacra: Creating Populated Prototypes for Social Computing Systems\u201d. In: Proceedings of the 35th Annual ACM\nSymposium on User Interface Software and Technology . 2022, pp. 1\u201318.\nPerner, Josef, Susan R. Leekam, and Heinz Wimmer. \u201cThree-year-olds\u2019 difficulty with false belief: The case for a\nconceptual deficit\u201d. In: The British Journal of Developmental Psychology 5.2 (1987), pp. 125\u2013137.\nPeterson, Joshua C., David D. Bourgin, Mayank Agrawal, Daniel Reichman, and Thomas L. Griffiths. Using large-scale\nexperiments and machine learning to discover theories of human decision-making . 2021.\nPhelps, Steve and Yvan I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 664,
      "text": "van I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338.\nPrasad, Grusha, Marten Van Schijndel, and Tal Linzen. \u201cUsing Priming to Uncover the Organization of Syntactic\nRepresentations in Neural Language Models\u201d. In: 23rd Conference on Computational Natural Language Learning,\nCoNLL 2019 . 2019, pp. 66\u201376.\nRadford, Alec, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. \u201cRobust speech\nrecognition via large-scale weak supervision\u201d. In: International Conference on Machine Learning . 2023, pp. 28492\u2013\n28518.\n14\nRahwan, Iyad, Manuel Cebrian, Nick Obradovich, Josh Bongard, Jean-Fran\u00e7ois Bonnefon, and Cynthia et al Breazeal.\n\u201cMachine behaviour\u201d. In: Nature 568.7753 (2019), pp. 477\u2013486.\nRenze, Matthew and Erhan Guven. \u201cThe Effect of Sampling Temperature on Problem Solving in Large Language\nModels\u201d. In: arXiv (2024).\nR\u00f6ttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Sch\u00fctze, and Dirk\nHovy. \u201cPolitical Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in\nLarge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 665,
      "text": "rge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139.\nRuis, Laura Eline, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rockt\u00e4schel, and Edward Grefenstette. \u201cThe\nGoldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs\u201d. In:\nAdvances in Neural Information Processing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt,\nand S. Levine. V ol. 36. 2023, pp. 20827\u201320905.\nRussakovsky, Olga et al. \u201cImageNet Large Scale Visual Recognition Challenge\u201d. In: International Journal of Computer\nVision 115 (2015), pp. 211\u2013252.\nRyle, Gilbert. Collected Papers . Hutchinson, 1971.\nSalewski, Leonard, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, and Zeynep Akata. \u201cIn-Context Impersonation\nReveals Large Language Models\u2019 Strengths and Biases\u201d. In: arXiv (2023), pp. 1\u201327.\nSap, Maarten, Ronan Le Bras, Daniel Fried, and Yejin Choi. \u201cNeural Theory-of-Mind? On the Limits of Social\nIntelligence in Large LMs\u201d. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language\nProcessing . Ed. by Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang. Association for Computational Linguistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 666,
      "text": "guistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo. \u201cAre Emergent Abilities of Large Language Models a Mirage?\u201d\nIn:Proceedings of the 37th International Conference on Neural Information Processing Systems . 2425. Curran\nAssociates Inc., 2023, pp. 1\u201317.\nSchick, Timo, Jane Dwivedi-Yu, Roberto Dess\u00ec, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda,\nand Thomas Scialom. \u201cToolformer: Language Models Can Teach Themselves to Use Tools\u201d. In: arXiv (2023),\npp. 1\u201317.\nSchramowski, Patrick, Cigdem Turan, Nico Andersen, Constantin A Rothkopf, and Kristian Kersting. \u201cLarge pre-trained\nlanguage models contain human-like biases of what is right and wrong to do\u201d. In: Nature Machine Intelligence 4.3\n(2022), pp. 258\u2013268.\nSchubert, Johannes A, Akshay K Jagadish, Marcel Binz, and Eric Schulz. \u201cIn-context learning agents are asymmetric\nbelief updaters\u201d. In: arXiv (2024), pp. 1\u201316.\nSchulze Buschoff, Luca M, Elif Akata, Matthias Bethge, and Eric Schulz. \u201cVisual cognition in multimodal large\nlanguage models\u201d. In: arXiv (2023), pp. 1\u201318.\nSchwartz, Matthew D. \u201cShould artificial intelligence be interpretable to humans?\u201d In: Nature Reviews Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 667,
      "text": "Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R. \u201cMinds, brains, and programs\u201d. In: Behavioral and Brain Sciences 568.7753 (1980), pp. 417\u2013424.\nSellars, Wilfrid. Empiricism and the Philosophy of Mind . Harvard University Press, 1997.\nShanahan, Murray. \u201cTalking About Large Language Models\u201d. In: arXiv (2022), pp. 1\u201311.\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. \u201cRole play with large language models\u201d. In: Nature 623.7987\n(2023), pp. 493\u2013498.\nShevlin, Henry and Marta Halina. \u201cApply rich psychological terms in AI with care\u201d. In: Nature Machine Intelligence 1\n(2019), pp. 165\u2013167.\nSinclair, Arabella, Jaap Jumelet, Willem Zuidema, and Raquel Fern\u00e1ndez. \u201cStructural Persistence in Language Models:\nPriming as a Window into Abstract Language Representations\u201d. In: Transactions of the Association for Computational\nLinguistics 10 (2022), pp. 1031\u20131050.\nSingla, Sahil and Soheil Feizi. \u201cCausal ImageNet: How to discover spurious features in Deep Learning?\u201d In: arXiv\n(2021), pp. 1\u201376.\nSrivastava, Aarohi et al. \u201cBeyond the Imitation Game: Quantifying and extrapolating the capabilities of language\nmodels\u201d. In: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 668,
      "text": "n: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135.\nStolfo, Alessandro, Yonatan Belinkov, and Mrinmaya Sachan. \u201cA Mechanistic Interpretation of Arithmetic Reasoning in\nLanguage Models using Causal Mediation Analysis\u201d. In: Proceedings of the 2023 Conference on Empirical Methods\nin Natural Language Processing . 2023, pp. 7035\u20137052.\nStrachan, James W. A. et al. \u201cTesting theory of mind in large language models and humans\u201d. In: Nature Human\nBehaviour 8 (2024), pp. 1285\u20131295.\nStreet, Winnie et al. \u201cLLMs achieve adult human performance on higher-order theory of mind tasks\u201d. In: arXiv (2024),\npp. 1\u201318.\nTodd, Peter M and Gerd Gigerenzer. Ecological Rationality: Intelligence in the World . Oxford University Press, 2012.\nTsvilodub, Polina, Hening Wang, Sharon Grosch, and Michael Franke. \u201cPredictions from language models for multiple-\nchoice tasks are not robust under variation of scoring methods\u201d. In: arXiv (2024), pp. 1\u20138.\nTversky, Amos and Daniel Kahneman. \u201cJudgment under Uncertainty: Heuristics and Biases\u201d. In: Science 185.4157\n(1974), pp. 1124\u20131131.\n\u2013 \u201cThe Framing of Decisions and the Psychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 669,
      "text": "sychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I. \u201cModel selection and psychological theory: a discussion of the differences between the Akaike\ninformation criterion (AIC) and the Bayesian information criterion (BIC)\u201d. In: Psychological Methods 17.2 (2012),\npp. 228\u2013243.\nWang, Kevin, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. \u201cInterpretability in the Wild:\na Circuit for Indirect Object Identification in GPT-2 small\u201d. In: arXiv (2022), pp. 1\u201325.\nWang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny\nZhou. \u201cSelf-Consistency Improves Chain of Thought Reasoning in Language Models\u201d. In: arXiv (2022), pp. 1\u201324.\nWarstadt, Alex et al. \u201cFindings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible\nCorpora\u201d. In: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language\nLearning . Ed. by Alex Warstadt et al. Association for Computational Linguistics, 2023, pp. 1\u201334.\nWebb, Taylor, Keith J Holyoak, and Hongjing Lu. \u201cEmergent analogical reasoning in large language models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 670,
      "text": "models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330.\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Le Quoc, and Denny Zhou.\n\u201cChain of Thought Prompting Elicits Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201341.\nWeidinger, Laura, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, and John et al Mellor. \u201cTaxonomy\nof Risks posed by Language Models\u201d. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and\nTransparency . Association for Computing Machinery, 2022, pp. 214\u2013229.\nWilcox, Ethan Gotlieb, Richard Futrell, and Roger Levy. \u201cUsing Computational Models to Test Syntactic Learnability\u201d.\nIn:Linguistic Inquiry (2023), pp. 1\u201344.\nWimmer, H. and J Perner. \u201cBeliefs about beliefs: representation and constraining function of wrong beliefs in young\nchildren\u2019s understanding of deception\u201d. In: Cognition 13.1 (1983), pp. 103\u2013128.\nXie, Sang Michael, Aditi Raghunathan, Percy Liang, and Tengyu Ma. \u201cAn Explanation of In-context Learning as\nImplicit Bayesian Inference\u201d. In: International Conference on Learning Representations . 2022, pp. 1\u201325.\nYang, Yuhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 671,
      "text": "uhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337.\nYax, Nicolas, Hernan Anll\u00f3, and Stefano Palminteri. \u201cStudying and improving reasoning in humans and machines\u201d. In:\nCommunications Psychology 2.1 (2024), pp. 1\u201316.\nYiu, Eunice, Eliza Kosoy, and Alison Gopnik. \u201cTransmission Versus Truth, Imitation Versus Innovation: What Children\nCan Do That Large Language and Language-and-Vision Models Cannot (Yet)\u201d. In: Perspectives on Psychological\nScience 0.0 (2023), pp. 1\u201310.\nZellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. \u201cHellaSwag: Can a Machine Really Finish\nYour Sentence?\u201d In: Annual Meeting of the Association for Computational Linguistics . 2019, pp. 1\u201310.\nZhang, Jingyi, Jiaxing Huang, Sheng Jin, and Shijian Lu. \u201cVision-Language Models for Vision Tasks: A Survey\u201d. In:\narXiv (2024), pp. 1\u201324.\n16\nZhang, Tianhua, Jiaxin Ge, et al. \u201cNatural Language Embedded Programs for Hybrid Language Symbolic Reasoning\u201d.\nIn:Findings of the Association for Computational Linguistics: NAACL 2024 . Ed. by Kevin Duh, Helena Gomez, and\nSteven Bethard. 2024, pp. 4131\u20134155.\nZhao, Haiyan, Hanjie Chen, F. Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 672,
      "text": "gyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z., Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. \u201cCalibrate Before Use: Improving Few-Shot\nPerformance of Language Models\u201d. In: arXiv (2021), pp. 1\u201315.\nZheng, Xiaosen, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, and Min Lin. \u201cImproved Few-Shot Jailbreaking Can\nCircumvent Aligned Language Models and Their Defenses\u201d. In: arXiv (2024), pp. 1\u201322.\nZhou, Denny, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, and Xuezhi et al Wang. \u201cLeast-to-Most Prompting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 673,
      "text": "mpting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 674,
      "text": "MACHINE PSYCHOLOGY\nThilo Hagendorff\u2217\nUniversity of StuttgartIshita Dasgupta\u2217\nGoogle DeepMindMarcel Binz\u2020\nHelmholtz Institute for\nHuman-Centered AIStephanie C.Y. Chan\u2020\nGoogle DeepMind\nAndrew Lampinen\u2020\nGoogle DeepMindJane X. Wang\u2020\nGoogle DeepMindZeynep Akata\nTU MunichEric Schulz\nHelmholtz Institute for\nHuman-Centered AI\nAugust 9, 2024\nABSTRACT\nLarge language models (LLMs) show increasingly advanced emergent capabilities and are being\nincorporated across various societal domains. Understanding their behavior and reasoning abilities\ntherefore holds significant importance. We argue that a fruitful direction for research is engaging\nLLMs in behavioral experiments inspired by psychology that have traditionally been aimed at\nunderstanding human cognition and behavior. In this article, we highlight and summarize theoretical\nperspectives, experimental paradigms, and computational analysis techniques that this approach\nbrings to the table. It paves the way for a \"machine psychology\" for generative artificial intelligence\n(AI) that goes beyond performance benchmarks and focuses instead on computational insights that\nmove us toward a better understanding and discovery of emergent abilities and behavioral patterns\nin LLMs. We review existing work taking this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 675,
      "text": "ng this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines. We posit that leveraging tools from experimental\npsychology to study AI will become increasingly valuable as models evolve to be more powerful,\nopaque, multi-modal, and integrated into complex real-world settings.\nIntroduction\nRecent advances in computing power, data availability, and machine learning algorithms have yielded powerful artificial\nintelligence systems that are used in almost all parts of society. Among these, large language models (LLMs), gigantic\nneural network architectures trained on large amounts of text, have seen a particularly meteoric rise in their influence.\nThe ability of LLMs to interface directly with natural language has made them accessible to the public in a way that\nwas not seen before, leading to widespread adoption with millions of daily users (Gemini Team et al., 2024; Anthropic,\n2024; OpenAI, 2022; OpenAI, 2023a). Also contributing to their rise in influence is that LLMs are wide-ranging in the\nkinds of tasks they can do \u2013 from writing text or code to calling functions, accessing the Internet, retrieving external\ninformation, reasoning about complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 676,
      "text": "complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al., 2022; Radford et al., 2023). The ever-growing capabilities of these systems make them challenging but also\nincreasingly important to characterize and understand, especially since these expanding capabilities also bring greater\npotential for unforeseen harm (Bommasani et al., 2021; Hagendorff, 2024b; Weidinger et al., 2022; Bender et al., 2021;\nSchramowski et al., 2022).\n\u2217Shared first authorship. Contact: thilo.hagendorff@iris.uni-stuttgart.de, idg@google.com\n\u2020Co-authors are listed in alphabetical order.arXiv:2303.13988v6  [cs.CL]  8 Aug 2024\nFigure 1: Overview of key concepts of machine psychology.\nUnderstanding behavioral patterns and emergent abilities in LLMs requires explaining their operating principles. Of the\napproaches focused on explaining AI systems, many rely on trying to understand the inner workings of these neural\nnetworks. This approach, often termed mechanistic interpretability, seeks to investigate LLMs by analyzing how their\nweights and activation patterns implement the observable behavior. It uses simplifications in terms of data, the model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 677,
      "text": "model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024). A related set of approaches draws inspiration\nmore directly from neuroscience to characterize broader correlational similarities and differences between the internal\nprocessing of LLMs and humans (Hosseini and Fedorenko, 2023; Kumar et al., 2022).\nIn contrast, this review focuses on the class of approaches that directly study the behavior of LLMs, analyzing\nrelationships between inputs and outputs instead of inspecting the inner workings. This approach includes not only\nanalyses of static trained models, but also experimental manipulations of inputs both during and after training. It\nalso encompasses analyses of inputs and outputs that reveal insights about internal mechanisms, even if those internal\nmechanisms are not directly inspected. For this set of approaches, experiments can be inspired by human psychology,\ncognitive science, and the behavioral sciences. This is what we want to term machine psychology (see Figure 1). Over\nseveral decades, the mentioned disciplines have developed a wide range of methods and frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 678,
      "text": "d frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well.\nThus far, the research community has responded to the challenges of understanding behavioral patterns and growing\ncapabilities in LLMs in several ways (Schwartz, 2022; Zhao, Chen, et al., 2023). The traditional machine learning\nbenchmark-driven approach has released new datasets that capture specific aspects only recently seen emerging in\nmodels (Srivastava et al., 2022; Hendrycks et al., 2021; Zellers et al., 2019). Traditional benchmarking aims primarily\nto enable the community to compare and optimize LLM performance. In contrast, machine psychology research is not\nprimarily interested in increasing (or measuring) an LLM\u2019s performance, but rather in understanding behavioral patterns.\nWhile traditional natural language processing benchmarks measure abilities such as translation, numerical reasoning, or\nfactual accuracy, machine psychology is also interested in how these observable abilities indirectly reflect the underlying\nconstructs and algorithms (Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 679,
      "text": "Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes.\nThe relative importance of behavior-based inspection (or psychology) versus internal inspection (or neuroscience) has\nbeen a long-standing debate (Jonas and Kording, 2017). We believe that both approaches have value for understanding\nboth humans and LLMs. Directly inspecting LLMs\u2019 behavior, however, does come with multiple advantages. The\nbehavior of LLMs is expressed at the interface of the model, where human users interact, and thus is what we ultimately\ncare about the most (Binz and Schulz, 2023; Chang and Bergen, 2024; Ivanova, 2023). Such behavior is often too\ncomplex to predict purely from our current mechanistic understanding of model weights and activation patterns (Gr\u00f6n\net al., 2003). Many interesting behaviors are only displayed by large models with billions of parameters (Kaplan et al.,\n2020; Wei, Tay, et al., 2022), and behavioral methods in psychology that treat behavior directly as the experimental\nvariable of interest scale gracefully with model size. Another practical advantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 680,
      "text": "dvantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public.\nIn this article, we review and chart future directions in this emerging field of directly modeling LLM behavior. We\noutline how established behavioral sciences can guide and inform our understanding of LLMs, and discuss important\ncaveats for when and how to apply methods to LLMs, given that they were originally developed for humans and\nanimals. In the first section, we discuss the theoretical frameworks developed and used in psychology to organize\nour understanding of intelligence and intelligent behaviors. We then review the many empirical paradigms that have\nbeen developed to study and characterize different aspects of intelligent behavior. Finally, we discuss and make\nrecommendations for robust empirical methods both for designing experiments and analyzing behavioral data. We end\nthe article by discussing the potentials and limitations of conducting machine psychology experiments with increasingly\ncapable black-box models.\nTheory: Evaluation paradigms for understanding intelligent systems\nThe traditional framework in machine learning algorithms has revolved around benchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 681,
      "text": "nchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance. Researchers train on a train dataset and evaluate on a held-out test\ndataset that was not seen during training. This framework does not generalize well to large-scale foundation models for\ntwo reasons. First, when using Internet-scale training data for models, this split has become harder to maintain (Li\nand Flanigan, 2023; Khan et al., 2023). Second, foundation models are only directly trained for next-token prediction\nbut exhibit many other \"intelligent\" behaviors that can, with some reservations (Schaeffer et al., 2023), be considered\nemergent. For example, practitioners did not explicitly encode or train for a transformer LLM\u2019s ability to learn from a\nfew examples in context (Brown et al., 2020), but it nonetheless arose from the machine learning architecture, data, and\nlearning signal (Chan et al., 2022; Oswald et al., 2023). Emergent behaviors can be difficult to study through the lens of\nthe components that gave rise to it (Anderson, 1972), and the ones that emerge can seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 682,
      "text": "n seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e. smaller scale datasets unsuitable for training\nand intended solely as a test set \u2013 to investigate model capabilities, e.g. the BIG-bench comprising more than 200 tests\n(Srivastava et al., 2022), the Abstraction and Reasoning Challenge (Chollet et al., 2020), as well as many others (Ivanova\net al., 2024; Mazumder et al., 2024). In several cases, these benchmarks already resemble evaluation frameworks\nfrom the behavioral sciences (Bubeck et al., 2023) \u2013 like personality tests, intelligence tests, implicit association tests,\netc. that are applied to humans \u2013 which similarly do not follow the train-test paradigm. They also tend to fall into\ntwo categories. Some evaluations focus on scalar performance metrics, e.g. intelligence quotients. Others focus on\ncharacterizing behavior, i.e. the questions are not designed with accuracy in mind, but designed to elicit responses that\nreveal behavioral strategies, or underlying constructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 683,
      "text": "ructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field.\nSeveral such diagnostic evaluations have been developed even for pre-LLM models where, despite the models being\ntrained for specific tasks, how to solve them is not specified. Such diagnostic datasets were used to expose the ways\nin which learned systems solved tasks \u2013 often counter to human intuitions (Geirhos et al., 2020; McCoy, Pavlick,\net al., 2019; Hermann and Lampinen, 2020; Dasgupta et al., 2022; Singla and Feizi, 2021). Researchers have also\nmade the case for borrowing from ethology, a branch of zoology that studies the behavior of non-human animals, to\nexplain machine behavior in machine learning systems (Rahwan et al., 2019). However, in the era of LLMs, not only\nare the how unspecified, but the model abilities themselves are neither directly known nor intentionally engineered.\nFurthermore, since LLMs can be evaluated via natural language, this can enhance or replace comparatively simpler\nmethods from ethology. This has led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 684,
      "text": "as led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats. In trying to shed light on the workings of a black-box system that can\nproduce language, it is tempting to use the simplest approach of asking the system about it. Self-report measures have\nbeen extensively used in psychology as well; but their reliability is questionable in humans (Jobe, 2003) as well as\nLLMs. Properties that such measures usually consider, such as personality, morality, or clinical disorders, are famously\nsensitive to prompting (Dominguez-Olmedo et al., 2023; R\u00f6ttger et al., 2024); to the extent that several recent works\neven simulate groups of humans of different social groups, opinions, and personalities with differently prompted LLMs\n3\n(Salewski et al., 2023; Park et al., 2022; Argyle et al., 2023; Shanahan et al., 2023). There remains value in using\nself-report stimuli from psychology \u2013 for example, to characterize behavior on a default prompt, as well as to understand\nhow steerable (i.e. sensitive to prompting) models are along these dimensions. But results drawn from these measures\nshould be taken contextually (e.g. as a property of a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 685,
      "text": "a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports. This tradition has yielded\nlasting understanding of natural intelligence (Frank et al., 2024), and is the tradition we argue is the most amenable\nfor transferring insights to machine psychology. In this paradigm, externally observed behavior continues to be the\nmeasured experimental variable, but stimuli are designed such that different observed behaviors map onto and measure\ndifferent internal representations, capabilities, or constructs \u2013 like compositionality, theory of mind, logic, causality, etc.\nA key principle is that experiments are hypothesis-driven: if the agent has representation or construct X, we would\nexpect to see behavior Y , otherwise we would see behavior Z. We highlight two key principles from this tradition that\nare crucial to keep in mind when performing and interpreting machine psychology evaluations. First, does seeing\nbehavior Y reliably imply having the construct X? To answer this, the design of a good control is crucial \u2013 to ensure that\nbehavior Y does not have another explanation and does, in fact, implicate X. A large part of experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 686,
      "text": "f experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology. Second, does the absence of behavior Y indicate the absence\nof the construct X? This is a more subtle question. Research in psychology often grapples with the fact that human\nperformance can be noisy or biased; for example, humans may make mistakes even on an easy calculation, or produce\nungrammatical language colloquially. These should not be taken to mean that they lack the abstract capability for math\nor language. These inconsistencies led to the concept of the performance-competence distinction (e.g. Chomsky, 1965):\nthat the way humans perform in a particular situation may not fully capture their underlying competence . More recent\nwork has suggested that similar issues apply when assessing the capabilities of machine learning systems (Firestone,\n2020), and particularly LLMs (Lampinen, 2022).\nParadigms: The many aspects of intelligent behavior\nThere are many aspects of intelligent behavior, each of which has been studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 687,
      "text": "en studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g. pupillometry) are not directly transferable to LLMs since they rely on the existence of a\nphysical body, several of these paradigms are purely linguistic and can be easily transferred. As LLMs expand in the\nkinds of stimuli they can interpret \u2013 e.g. visual (OpenAI, 2023b; Zhang, Huang, et al., 2024; Gemini Team et al., 2024)\n\u2013 and the ways in which they can interact with the world \u2013 e.g. embodiment and tool use (Mialon et al., 2023) \u2013, the\nspace of transferable paradigms increases. Humans also interact with several modalities, and the paradigms developed\nto understand us often compare and integrate these modalities (Schulze Buschoff et al., 2023) \u2013 e.g. the Stroop test\nwhich spans vision and reading capabilities (Scarpina and Tagini, 2017).\nIn this article, we focus on language-based tests, since these are the most widely used in the current research landscape.\nMoreover, we believe that even in light of the growing trend toward multi-modal models, language will remain a primary\nmodality due to its fundamental role in models\u2019 reasoning processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 688,
      "text": "processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning. Apart from these four areas, there are, of course, multiple other domains of psychology that\ncan also provide valuable paradigms for, for instance when investigating creativity in LLMs (Stevenson et al., 2022),\nclinical psychology (Li, Li, et al., 2022), moral behavior (Khandelwal et al., 2024), and others.\nHeuristics and biases\nThe heuristics and biases framework is one of the most influential research paradigms in psychology (Gigerenzer\nand Gaissmaier, 2011; Tversky and Kahneman, 1974). Heuristics are mental shortcuts that simplify reasoning or\ndecision-making processes, and this field studies how such shortcuts can help explain both the successes and the biases\nin human behavior. The large existing literature on heuristics and biases in humans is a fertile ground for examining\nsuch shortcuts in the newest generation of LLMs \u2013 whose capabilities now overlap more with the human abilities\nthis literature studies. Binz and Schulz (2023) were among the first to use this paradigm to better understand the\ndecision-making processes of LLMs. They found that GPT-3 (Brown et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 689,
      "text": "own et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al., 2023; Macmillan-Scott and Musolesi, 2024; Schulze Buschoff et al., 2023; Hayes et al., 2024;\nCoda-Forno, Binz, Wang, et al., 2024). Interestingly, there is evidence from several studies showing that, while the\nprevious generation of models frequently exhibited human-like heuristics and biases, they have largely disappeared\nin the latest generation of LLMs (Chen, Liu, et al., 2023; Hagendorff et al., 2023). The test stimuli were originally\ndesigned to be challenging for human study participants and possibly no longer challenge the growing reasoning\nabilities in LLMs. This could also be due to leakage into the training set \u2013 we discuss this challenge in the section on\ndesign and analysis.\nThe literature on heuristics and biases also suggests that how a problem is phrased can influence how people solve it\n(Cheng and Holyoak, 1985; Tversky and Kahneman, 1981). It is well-known that LLMs are also susceptible to similar\nmanipulations. For example, Dasgupta et al. (2022) have investigated whether LLMs are affected by the semantic\ncontent of logical reasoning problems using several existing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 690,
      "text": "ing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems. Likewise, Schubert et al., 2024 have shown that how LLMs learn in-context depends on the\nproblem formulation.\nFinally, people do not simply apply arbitrary heuristics. Instead, they use heuristics that are adapted to the problems\nthey encounter during their everyday interactions with the world (Todd and Gigerenzer, 2012). In the context of LLMs,\none can look at how the properties of the training data shape their behavior. For example, Chan et al., 2022 have\ndemonstrated that the presence of in-context learning in LLMs can be traced back to data distributional properties such\nas burstiness, where items appear in clusters rather than being uniformly distributed over time, and the presence of large\nnumbers of rarely occurring classes. Researchers also proposed that one should try to understand LLMs through the\nproblem they are trained to solve, similarly to how behavioral scientists attempt to understand human cognition through\nthe lens of ecological rationality (Todd and Gigerenzer, 2012; McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 691,
      "text": "McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives. This includes studying the various factors that influence development, such as social intelligence or social\nskills. By applying paradigms from this area of developmental psychology to LLMs, researchers can gain deeper\ninsights into how these models manage complex social interactions. In particular, once LLMs are deployed as chat\nagents, they should become versed in modeling human communicators. Therefore, it is important to assess the level of\nsocial intelligence in LLMs. One example in this context is the application of theory of mind tests to LLMs, where\nresearchers use tasks from human experiments, such as those famously conducted by Wimmer and Perner (1983) and\nPerner et al. (1987). While early experiments with models such as GPT-3 showed that they struggle to solve theory\nof mind tasks (Sap et al., 2022), later models demonstrate an increasing ability to reliably infer unobservable mental\nstates in others (Strachan et al., 2024; Holterman and Deemter, 2023; Moghaddam and Honey, 2023). Further related\nresearch examines how LLM performance on theory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 692,
      "text": "heory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al., 2024), or measures the robustness of theory of mind test setups against distracting alterations in the tasks\nLLMs receive as inputs (Ullman, 2023). As theory of mind tests measure, among other things, the ability to understand\nfalse beliefs, further research has explored the emerging capability of LLMs to induce false beliefs in other agents\n(Hagendorff, 2024a), or how LLMs trade off various communicative values like honesty and helpfulness (Liu et al.,\n2024) \u2013 these investigations also contribute to understanding and improving alignment with human values for AI safety\n(Ji et al., 2023).\nThe space of relevant paradigms increases as LLMs are allowed to interact through self-reflection (Nair et al., 2023),\nself-instruction (Wang, Wei, et al., 2022), or in swarms (Zhuge et al., 2023). For example, researchers looked at\ncooperative and coordinative behavior in LLMs playing games, revealing persistent behavioral signatures in the models\n(Akata et al., 2023). Similarly, researchers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 693,
      "text": "ers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024). Another study, which is influenced by works in human social psychology, looked at how multiple LLMs form\nand evolve networks, investigating micro-level network principles such as preferential attachment or triadic closure,\nas well as macro-level principles such as community structures (Papachristou and Yuan, 2024). In sum, machine\npsychology can reveal patterns of social behavior and interaction among LLMs, individually and collectively, be it for\n5\nproblem solving or world simulation (Guo et al., 2024). By drawing from human developmental psychology and social\ndynamics, researchers can better understand and design LLMs that navigate complex social interactions and exhibit\nadvanced social skills.\nPsychology of language\nA long history of work has studied the psychology of how humans use and understand language, ranging from how\nthey use semantic and syntactic features to understand a sentence to how they use pragmatic inferences in a discourse\ncontext to help interpret what someone has said. Correspondingly, a long-standing body of work has studied how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 694,
      "text": "how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al., 1989); more recently, researchers\nhave applied similar techniques to study LLMs. A wide range of work has studied what models learn about syntax\n(Linzen and Baroni, 2021), often using methods from psycholinguistics. For example, Wilcox et al. (2023) used\npsycholinguistics-inspired surprisal measures to show that LLMs learn filler-gap dependencies, a challenging syntactic\nstructure. Other researchers have used related measures to study what LLMs learn about the semantics of entailment\n(Merrill et al., 2024). Moreover, researchers used psycholinguistic techniques like priming to study how models\nrepresent and process language (Prasad et al., 2019; Sinclair et al., 2022), and methods like deconfounded stimuli to\nidentify where models may rely on semantic heuristics rather than syntax (McCoy, Pavlick, et al., 2019). Several recent\nworks (Hu, Floyd, et al., 2023; Ruis, Khan, et al., 2023) studied pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 695,
      "text": "ed pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain. In another study, researchers examined long-form analogies generated by ChatGPT, finding\nthat AI-generated analogies lack some human-like psycholinguistic properties (Seals and Shalin, 2023), particularly in\ntext cohesion, language, and readability. Furthermore, researchers applied garden path sentences \u2013 sentences that lead\nthe reader to initially interpret them incorrectly due to their ambiguous structure \u2013 to LLMs, showing that the models\nrespond similarly to humans (Aher et al., 2023; Christianson et al., 2001). At a higher level, some researchers have\ndrawn inspiration from aspects of human language development to attempt to identify the causes of the relative data\ninefficiency of language models (Warstadt et al., 2023; Frank, 2023). In each of these cases, methods and ideas from\npsychology and psycholinguistics provide guidance on how to assess processes through language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 696,
      "text": "h language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills. At first blush, it\nmay appear that experimental paradigms for the study of learning are less applicable to LLMs, given that the aim of\nbehavioral experiments is often to help uncover the underlying learning algorithm \u2013 whereas for LLMs the learning\nalgorithms used in training are designed and already known. However, the behavioral sciences can still benefit from the\nstudy of LLMs in this context, since LLMs exhibit learning abilities that were not explicitly designed into the models\n(they are emergent), and thus one does not understand the underlying learning algorithm. In particular, LLMs exhibit\nemergent in-context learning \u2013 the ability to learn from context (the prompt) without requiring any gradient-based\nupdates in weights (Brown et al., 2020). Understanding in-context learning is a burgeoning field that is rapidly gaining\nin importance, given the increasing size of LLMs context windows and consequent gains in capabilities, e.g. the\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 697,
      "text": "he\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024).\nUncovering the implicit learning algorithm implemented by in-context learning is a burgeoning research field, and\nutilizes many of the methods common in cognitive science. For example, multiple studies have compared the outputs of\ntransformer in-context learning with the outputs of hypothesized learning algorithms (Oswald et al., 2023; Aky\u00fcrek\net al., 2022). This is a staple of cognitive modeling, and could potentially benefit even further from model comparison\nprocedures from psychology and statistics (Yang, 2006; Arlot and Celisse, 2010; Vrieze, 2012). Recent work in\ncognitive science has used machine learning to discover new theories of human decision-making (Peterson et al., 2021)\n\u2013 it might be interesting to apply related approaches to in-context learning as well. Researchers might also benefit from\nconsidering particular models as normative starting points (Niv, 2009).\nResearchers may also wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 698,
      "text": "so wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time. These characteristics\n6\nare often not obvious even in cases where the learning algorithm is known, and thus researchers would like to understand\nthem not only for in-context learning, but also for other forms of LLM learning, e.g. self-supervised gradient-based\nlearning, reinforcement learning (Ouyang et al., 2022), or \"fast\" memory retrieval (Borgeaud et al., 2022; Lewis et al.,\n2020).\nTo characterize inductive biases and generalization of LLMs, researchers have borrowed both concepts and experimental\nparadigms from cognitive sciences (Schubert et al., 2024; Coda-Forno, Binz, Akata, et al., 2023) and Bayesian inference\n(Xie et al., 2022). Studies utilized paradigms for measuring systematic generalization to characterize those capabilities\nin LLMs, and as inspiration to improve these abilities (Lake and Baroni, 2023; Ruis, Andreas, et al., 2022). Webb\net al. (2023) created novel variants of classic analogy problems from cognitive science, in order to examine the\nanalogical capabilities of large language models. Chan et al. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 699,
      "text": "l. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers. Furthermore, researchers borrowed paradigms and measures from developmental psychology\nto characterize the domains where LLM inductive biases may match those of children, and where they may fall short\n(including in causal reasoning and innovation) (Kosoy et al., 2023; Yiu et al., 2023).\nTo characterize the data dependence of in-context learning, existing work has drawn inspiration from research in\ndevelopmental psychology on skewed and bursty distributions (Chan et al., 2022). An important aspect of data\ndependence is the structure of data over time (during training). AI researchers have long drawn inspiration from\ncurriculum learning in human and non-human animals to better understand how to structure training data so that earlier\nlearning on easier tasks can scaffold later learning on harder tasks (Bengio et al., 2009). There remain many areas\nof behavioral research on learning that may serve as rich sources of inspiration on data dependence, e.g. research on\nrepetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 700,
      "text": "epetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019). Data dependence is particularly\ninteresting for LLMs because text training data (being sourced largely from unstructured web-scale corpora) is very\ndifferent from the structured training data typically used for traditional discriminatory machine learning techniques, and\nbecause data is one of the major levers one can manipulate in training LLMs to adjust their behaviors.\nDesign and analysis: Good behavioral experimentation\nComputer science has not historically been an empirical science. While machine learning (especially since the era of\nneural network models) has been significantly driven by empirical rather than theoretical work, the settings under which\nthose protocols were developed \u2013 a test set that is fixed for all practitioners and is effectively infinitely large \u2013 no longer\nhold in the small test-only behavioral experiments setting. Current LLMs are famously sensitive to small changes in\nprompt structure or they rely on shallow syntactic heuristics (McCoy, Pavlick, et al., 2019), and studies that are not\ncareful about testing the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 701,
      "text": "ting the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al., 2020), and machine\npsychology should not share the same fate. In this section, we provide recommendations for sound methodologies in\nbehavioral test settings with LLMs, which should be valuable to practitioners in the field of machine psychology.\nPrompting methods and biases\nMany studies conducted in the field of machine psychology have a significant shortcoming in common, namely that they\ndo not avoid training data contamination. They use prompts from existing psychology studies and apply them to LLMs\nwithout changing their wording, task orders, etc. In this way, LLMs are likely to have already experienced identical\nor similar tasks during training, thus causing LLMs to simply reproduce known token patterns. When adopting test\nframeworks from psychology \u2013 meaning vignettes, cognitive tasks, or other test setups \u2013 researchers must ensure that\nLLMs have never seen the tests before and go beyond mere memorization. Hence, prompts may indeed be structurally\nlike already existing tasks, but they should contain new wordings, agents, orders, actions, etc. That being said, some\nexperiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 702,
      "text": "experiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024).\nAnother common shortcoming of several existing machine psychology studies is that they rely on small sample sizes or\nconvenience samples, meaning non-systematic sequences of prompts. Sampling biases in the used benchmarks or task\ndatasets, which are especially prevalent in small sample sizes, can diminish the quality of machine psychology studies.\n7\nThis is because slight changes in prompts can change model outputs significantly. Because of this high sensitivity to\nprompt wording, it is important to test multiple versions of one task and to create representative samples, meaning\nbatteries of varied prompts. Only in this way can one reliably measure whether a certain behavior is systematically\nreoccurring and generalizable (Yarkoni, 2022). Furthermore, LLMs can succumb to various biases influencing the\nprocessing of prompts (Zhao, Wallace, et al., 2021; Chan et al., 2022). Recency biases in LLMs, for instance, lead to a\ntendency to rely more heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 703,
      "text": "e heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data. Moreover,\nmajority label biases can cause LLMs to be skewed towards labels, classes, or examples that are frequent in a few-shot\nlearning setting. Technical biases like these can at least in part be controlled for when designing prompts or prompt\nvariations that tend to avoid triggering them. If this is not done, LLMs may rely on shortcuts exploiting such biases.\nEliciting capabilities with prompts\nThe standard prompt design, comprising a vignette plus an open- or close-ended question or task, can be enhanced\nby prefixes or suffixes eliciting improved reasoning capabilities in LLMs. On the other hand, omitting such prefixes\nand suffixes can lead to underestimations of the model\u2019s capabilities. Although it is likely that most specific prompt\naugmentations have a positive influence on one kind of task but not another, reducing our ability to systematically\nunderstand LLM behavior, a few prompt design approaches have nonetheless been found to confer broader performance\nbenefits. Most notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 704,
      "text": "t notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance. This can be extended\neven further by generating multiple chain-of-thought reasoning paths and taking the majority response as the final one\n(Wang, Wei, et al., 2022). Similar to chain-of-thought prompting is least-to-most prompting, which also decomposes\nproblems into a set of subproblems to increase accuracy in LLMs (Zhou et al., 2022). Yet another approach is to frame\nquestions in a multiple-choice format. This was shown to improve reasoning capabilities in some cases (Kadavath et al.,\n2022), but can also limit them because LLMs might be prompted to provide brief responses, thereby circumventing\nreasoning in the process of prompt completion. Nevertheless, many prominent NLP benchmarks use multiple choice\nformats instead of open-ended questions. Here, one must keep in mind that different expressions of the same concept\ncompete for probability, which can lower the chances of selecting the correct answer (Holtzman et al., 2021). Moreover,\none has to consider potential recency biases, which require neutralizing this effect by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 705,
      "text": "t by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al., 2020), where the LLM\u2019s performance improves after repeated exposure to a\ngiven task. Moreover, self-reflection, meaning the automated, recursive criticizing and subsequent self-improvement of\nLLM outputs by the LLM itself, is a further technique that can improve reasoning abilities (Nair et al., 2023; Kim et al.,\n2023). Regarding improvements in symbolic or numeric reasoning, another technique is to prompt LLMs to use code\nfor solving tasks (Zhang, Ge, et al., 2024). Eventually, all mentioned methods to improve reasoning can be not just\nleveraged for machine psychology; they can also become objects of study themselves.\nSetting parameters and evaluating outputs\nLLMs come with a variety of parameters researchers can set. For example, most models come in a variety of sizes.\nAnalyses across different sizes are valuable: while the largest ones usually have the highest capabilities, some recent\nworks find \"inverse-scaling\" (McKenzie et al., 2023). Moreover, temperature settings control randomness. If exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 706,
      "text": "exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice. The effect of temperature on capabilities is not\nestablished (Renze and Guven, 2024), and reporting averages or \"best of K\" \u2013 considering all the responses over K\nsamples that meet certain simple criteria, e.g. formatting (Chen, Tworek, et al., 2021) \u2013 is valuable.\nAfter conducting the experiments, a list of LLM responses must be evaluated and compared with the ground truth. The\nsimplest case is when the results can be framed and scored as a multiple-choice question \u2013 though even in this case,\nscoring the answers so that the model responds directly inline, rather than selecting a choice, can yield more signal\n(Hu and Levy, 2023). If possible, multiple scoring methods should be compared, to evaluate whether the effects are\ndependent on the scoring method (Tsvilodub et al., 2024). If the questions must be answered with free generations, the\nevaluation process can still be automated if the results exhibit sufficient simplicity and regularity, meaning that the LLM\nresponses are similar to the ground truth strings in terms of length and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 707,
      "text": "gth and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed. State-of-the-art LLMs, however, tend to produce highly variable and comprehensive\noutputs, which can complicate classification. While stop sequences, token limits, or prompt instructions that interrupt\nfurther text generation can facilitate classification by promoting output uniformity, they also improperly constrain LLM\nbehavior. Therefore, researchers are increasingly relying on LLM-based evaluations of outputs where a single model or\nmultiple stacked model instances perform the classification using carefully crafted instructions. Although this method\nmight still be inaccurate for very comprehensive outputs, a solution is to instruct the LLM under scrutiny to output\nits final answer or summary after a specific string sequence like \"####\" (Cobbe et al., 2021). This approach allows\nthe LLM to reason during verbose prompt completions, which is necessary for many prompt engineering techniques\nsuch as chain-of-thought reasoning. The classification then only involves processing the string following \"####\". If\nthis method still proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 708,
      "text": "ll proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out.\nDiscussion\nMachine psychology provides a new approach to explaining AI. Instead of interpreting a neural network\u2019s design\ncomponents (Barredo Arrieta et al., 2019), one analyzes the relationships between inputs and outputs, i.e. prompt\ndesign and prompt completion. Although this may allow the identification of hitherto unknown abilities or behavioral\ntraits in LLMs, interpreting LLM responses comes with a challenge. A strong tendency exists to confer mental concepts\nor psychological terms to LLMs that were hitherto reserved for human and animal minds. This tendency manifests in\ncommon terms like \"machine learning,\" but will become more prevalent in machine psychology when concepts such as\nreasoning (Huang and Chang, 2022), intuition (Hagendorff et al., 2023), creativity (Stevenson et al., 2022), intelligence\n(Webb et al., 2023), personality (Miotto et al., 2022), mental illnesses (Li, Li, et al., 2022), etc. are transferred to\nLLMs. In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 709,
      "text": ". In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024). Moreover, many\npsychological concepts are normatively laden and can foster mismatches in expectations between AI experts and the\npublic regarding machine capabilities (Shevlin and Halina, 2019). Nevertheless, the problem that many abilities in\nLLMs cannot be reasonably grasped by only referring to the inner workings of their neural architecture remains.\nBy adopting a concept from ethnography, one could call such an approach \"thin descriptions\" (Ryle, 1971; Geertz,\n1973), meaning that one only explains internal representations in AI systems, for instance via activation atlases, which\nvisualize how different parts of a neural network respond to various inputs (Carter et al., 2019). In this sense, LLMs\nsimply hijack humans\u2019 intuitions to explain machine behavior patterns by using psychological or other anthropocentric\nterms. Contrary to thin descriptions, though, there are \"thick descriptions.\" They imply using psychological terms to add\na layer of explainability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 710,
      "text": "ability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist. This holds for humans,\ntoo, where mental terms used to explain behavior do not directly correlate with specific sets of neural activations.\nBy postulating (mental) unobservable states, be it with regard to brains or artificial neural networks, one increases\nexplanatory resources (Sellars, 1997). Thick descriptions help in making sense of LLMs when thin descriptions are\ninsufficient to explain behavioral patterns. Thin descriptions assume that LLMs merely possess syntax or a statistical\ncapacity to associate words (Searle, 1980; Floridi and Chiriatti, 2020; Bender et al., 2021), but not semantics. Thick\ndescriptions, though, assume that LLMs show patterns and regularities that go beyond mere syntax. These patterns can\nbe explained by means of machine psychology.\nBeyond potential habituations regarding the use of terminology borrowed from psychology in the context of machines,\nmachine psychology, as a nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 711,
      "text": "nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments.\nThis new discipline of evaluating LLMs will become even more important when taking multimodal or augmented\nLLMs into account, meaning LLMs that are allowed to interact with images, external information sources, sensory\ndata, physical objects, and various other tools (Mialon et al., 2023; Schick et al., 2023; Ma et al., 2024). Moreover,\nonce test settings for machine psychology are established, researchers can investigate how LLMs develop over time by\napplying the same tasks multiple times, yielding longitudinal data. This data can serve as a baseline to extrapolate trends\nregarding the development of reasoning abilities in LLMs. Such estimations may be increasingly important for AI\nsafety and AI alignment research to predict future behavioral potentials in LLMs. By gaining a deeper understanding of\nthese potentials, machine psychology is providing a new approach to AI explainability as well as an important addition\nto traditional benchmarking methods in natural language processing.\n9\nAuthor contributions\nTH and ID conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 712,
      "text": "D conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure. All authors assisted\nwith iterations and edited and reviewed the paper.\nReferences\nAher, Gati, Rosa I. Arriaga, and Adam Tauman Kalai. \u201cUsing Large Language Models to Simulate Multiple Humans\nand Replicate Human Subject Studies\u201d. In: Proceedings of the 40th International Conference on Machine Learning .\n2023, pp. 1\u201335.\nAkata, Elif, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. \u201cPlaying repeated\ngames with Large Language Models\u201d. In: arXiv (2023), pp. 1\u201313.\nAky\u00fcrek, Ekin, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. \u201cWhat learning algorithm is in-context\nlearning? Investigations with linear models\u201d. In: arXiv (2022), pp. 1\u201329.\nAnderson, Philip W. \u201cMore is different: Broken symmetry and the nature of the hierarchical structure of science\u201d. In:\nScience 177.4047 (1972), pp. 393\u2013396.\nAnil, Cem et al. Many-shot jailbreaking . 2024.\nAnthropic. The Claude 3 Model Family: Opus, Sonnet, Haiku . 2024.\nArgyle, Lisa P, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, and David Wingate. \u201cOut of One,\nMany: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 713,
      "text": "any: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d. In: Statistics Surveys 4\n(2010), pp. 40\u201379.\nBaddeley, Alan. \u201cWorking memory\u201d. In: Current Biology 20.4 (2010), R136\u2013R140.\nBarredo Arrieta, Alejandro et al. \u201cExplainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and\nChallenges toward Responsible AI\u201d. In: Information Fusion 58 (2019), pp. 82\u2013115.\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. \u201cOn the Dangers of Stochastic\nParrots: Can Language Models Be Too Big?\u201d In: Proceedings of the 2021 ACM conference on fairness, accountability,\nand transparency . 2021, pp. 610\u2013623.\nBengio, Yoshua, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. \u201cCurriculum learning\u201d. In: Proceedings of the\n26th Annual International Conference on Machine Learning . 2009, pp. 41\u201348.\nBinz, Marcel and Eric Schulz. \u201cUsing cognitive psychology to understand GPT-3\u201d. In: Proceedings of the National\nAcademy of Sciences 120.6 (2023), pp. 1\u201310.\nBommasani, Rishi et al. \u201cOn the opportunities and risks of foundation models\u201d. In: arXiv (2021), pp. 1\u2013214.\nBorgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 714,
      "text": "nn, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed. by Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and\nSivan Sabato. V ol. 162. 2022, pp. 2206\u20132240.\nBoring, Edwin G. \u201cThe Nature and History of Experimental Control\u201d. In: The American Journal of Psychology 67.4\n(1954), pp. 573\u2013589.\nBowman, Samuel R., Gabor Angeli, Christopher Potts, and Christopher D. Manning. \u201cA large annotated corpus for\nlearning natural language inference\u201d. In: Proceedings of the 2015 Conference on Empirical Methods in Natural\nLanguage Processing . Ed. by Llu\u00eds M\u00e0rquez, Chris Callison-Burch, and Jian Su. 2015, pp. 632\u2013642.\nBrown, Tom et al. \u201cLanguage Models are Few-Shot Learners\u201d. In: Advances in Neural Information Processing Systems .\nEd. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33. Curran Associates, Inc., 2020,\npp. 1877\u20131901.\nBubeck, S\u00e9bastien et al. \u201cSparks of Artificial General Intelligence: Early experiments with GPT-4\u201d. In: arXiv (2023),\npp. 1\u2013155.\nCarter, Shan, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah. \u201cExploring Neural Networks with\nActivation Atlases\u201d. In: Distill 4.3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 715,
      "text": ".3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22.1 (2015), pp. 281\u2013288.\nChai, Wen Jia, Aini Ismafairus Abd Hamid, and Jafri Malin Abdullah. \u201cWorking Memory From the Psychological and\nNeurosciences Perspectives: A Review\u201d. In: Frontiers in Psychology 9 (2018), pp. 1\u201316.\n10\nChan, Stephanie, Adam Santoro, Andrew Lampinen, Jane Wang, Aaditya Singh, Pierre Richemond, James McClelland,\nand Felix Hill. \u201cData Distributional Properties Drive Emergent In-Context Learning in Transformers\u201d. In: Advances\nin Neural Information Processing Systems 35 (2022), pp. 18878\u201318891.\nChang, Tyler A and Benjamin K Bergen. \u201cLanguage Model Behavior: A Comprehensive Survey\u201d. In: Computational\nLinguistics 50.1 (2024), pp. 293\u2013350.\nChen, Mark, Jerry Tworek, et al. \u201cEvaluating Large Language Models Trained on Code\u201d. In: arXiv (2021), pp. 1\u201335.\nChen, Yiting, Tracy Xiao Liu, You Shan, and Songfa Zhong. \u201cThe emergence of economic rationality of GPT\u201d. In:\nProceedings of the National Academy of Sciences 120.51 (2023), e2316205120.\nCheng, Patricia W and Keith J Holyoak. \u201cPragmatic reasoning schemas\u201d. In: Cognitive Psychology 17.4 (1985),\npp. 391\u2013416.\nChollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 716,
      "text": "hollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam. Aspects of the Theory of Syntax . MIT Press, 1965.\nChristianson, Kiel, Andrew Hollingworth, John F. Halliwell, and Fernanda Ferreira. \u201cThematic Roles Assigned along\nthe Garden Path Linger\u201d. In: Cognitive Psychology 42.4 (2001), pp. 368\u2013407.\nCobbe, Karl et al. \u201cTraining Verifiers to Solve Math Word Problems\u201d. In: arXiv (2021), pp. 1\u201322.\nCoda-Forno, Julian, Marcel Binz, Zeynep Akata, Matt Botvinick, Jane Wang, and Eric Schulz. \u201cMeta-in-context learning\nin large language models\u201d. In: Advances in Neural Information Processing Systems 36 (2023), pp. 65189\u201365201.\nCoda-Forno, Julian, Marcel Binz, Jane X Wang, and Eric Schulz. \u201cCogBench: a large language model walks into a\npsychology lab\u201d. In: arXiv (2024), pp. 1\u201326.\nConmy, Arthur, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adri\u00e0 Garriga-Alonso. \u201cTowards\nAutomated Circuit Discovery for Mechanistic Interpretability\u201d. In: Advances in Neural Information Processing\nSystems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. Curran Associates,\nInc., 2023, pp. 16318\u201316352.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 717,
      "text": "2.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d. In: arXiv (2022),\npp. 1\u201336.\nDempster, Frank N. \u201cSpacing effects and their implications for theory and practice\u201d. In: Educational Psychology Review\n1.4 (1989), pp. 309\u2013330.\nDominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-D\u00fcnner. \u201cQuestioning the Survey Responses of\nLarge Language Models\u201d. In: arXiv (2023), pp. 1\u201325.\nDuijn, Max J. van, Bram van Dijk, Tom Kouwenhoven, Werner de Valk, Marco R. Spruit, and Peter van der Putten.\n\u201cTheory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children\nAged 7-10 on Advanced Tests\u201d. In: Proceedings of the 27th Conference on Computational Natural Language\nLearning (CoNLL) . Ed. by Jing Jiang, David Reitter, and Shumin Deng. 2023, pp. 389\u2013402.\nEdwards, Allen L. Statistical Methods for the Behavioral Sciences . Rinehart, 1954.\nElkins, Katherine and Jon Chun. \u201cCan GPT-3 Pass a Writer\u2019s Turing Test?\u201d In: Journal of Cultural Analytics 5.2 (2020),\npp. 1\u201316.\nElman, Jeffrey L. \u201cDistributed representations, simple recurrent networks, and grammatical structure\u201d. In: Machine\nLearning 7 (1991), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 718,
      "text": "91), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz. Research methods in the behavioral sciences. Holt, Rinehart and Winston,\n1953.\nFirestone, Chaz. \u201cPerformance vs. competence in human\u2013machine comparisons\u201d. In: Proceedings of the National\nAcademy of Sciences 117.43 (2020), pp. 26562\u201326571.\nFloridi, Luciano and Massimo Chiriatti. \u201cGPT-3: Its Nature, Scope, Limits, and Consequences\u201d. In: Minds and Machines\n30.4 (2020), pp. 681\u2013694.\nFrank, Michael C. \u201cBridging the data gap between children and large language models\u201d. In: Trends in Cognitive\nSciences 27.11 (2023), pp. 990\u2013992.\nFrank, Michael C., Mika Braginsky, Julie Cachia, Nicholas Coles, Tom E. Hardwicke, Robert D. Hawkins, Maya B.\nMathur, and Rondeline Williams. Experimentology: An Open Science Approach to Experimental Psychology Methods .\nMIT Press, 2024.\n11\nGao, Leo, Tom Dupr\u00e9 la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, and\nJeffrey Wu. \u201cScaling and evaluating sparse autoencoders\u201d. In: arXiv (2024), pp. 1\u201334.\nGeertz, Clifford. The Interpretation of Cultures: Selected Essays . Basic Books, 1973.\nGeirhos, Robert, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 719,
      "text": "acobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673.\nGemini Team et al. \u201cGemini 1.5: Unlocking multimodal understanding across millions of tokens of context\u201d. In: arXiv\n(2024), pp. 1\u201390.\nGigerenzer, Gerd and Wolfgang Gaissmaier. \u201cHeuristic decision making\u201d. In: Annual Review of Psychology 62 (2011),\npp. 451\u2013482.\nGreco, Claudio, Barbara Plank, Raquel Fern\u00e1ndez, and Raffaella Bernardi. \u201cPsycholinguistics Meets Continual Learning:\nMeasuring Catastrophic Forgetting in Visual Question Answering\u201d. In: Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics . Ed. by Anna Korhonen, David Traum, and Llu\u00eds M\u00e0rquez. Florence,\nItaly: Association for Computational Linguistics, 2019, pp. 3601\u20133605.\nGr\u00f6n, Georg, David Schul, V olker Bretschneider, AP Wunderlich, and Matthias W Riepe. \u201cAlike performance during\nnonverbal episodic learning from diversely imprinted neural networks\u201d. In: European Journal of Neuroscience 18.11\n(2003), pp. 3112\u20133120.\nGuo, Taicheng, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V . Chawla, Olaf Wiest, and Xiangliang\nZhang. \u201cLarge Language Model based Multi-Agents: A Survey of Progress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 720,
      "text": "ress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138.\n\u2013 \u201cMapping the Ethics of Generative AI: A Comprehensive Scoping Review\u201d. In: arXiv (2024), pp. 1\u201325.\nHagendorff, Thilo, Sarah Fabi, and Michal Kosinski. \u201cHuman-like intuitive behavior and reasoning biases emerged in\nlarge language models but disappeared in ChatGPT\u201d. In: Nature Computational Science 3.10 (2023), pp. 833\u2013838.\nHaibe-Kains, Benjamin et al. \u201cTransparency and reproducibility in artificial intelligence\u201d. In: Nature 586.7829 (2020),\npp. 1\u20137.\nHayes, William M, Nicolas Yax, and Stefano Palminteri. \u201cRelative Value Biases in Large Language Models\u201d. In: arXiv\n(2024), pp. 1\u20137.\nHendrycks, Dan, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Xiaodong Song, and\nJacob Steinhardt. \u201cMeasuring Mathematical Problem Solving With the MATH Dataset\u201d. In: Thirty-fifth Conference\non Neural Information Processing Systems . 2021, pp. 1\u201311.\nHermann, Katherine and Andrew Lampinen. \u201cWhat shapes feature representations? Exploring datasets, architectures,\nand training\u201d. In: 34th Conference on Neural Information Processing Systems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 721,
      "text": "tems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. \u201cSurface Form Competition: Why the\nHighest Probability Answer Isn\u2019t Always Right\u201d. In: Proceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing . Ed. by Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih.\n2021, pp. 7038\u20137051.\nHosseini, Eghbal A and Evelina Fedorenko. \u201cLarge language models implicitly learn to straighten neural sentence\ntrajectories to construct a predictive representation of natural language\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2023,\npp. 43918\u201343930.\nHu, Jennifer, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, and Edward Gibson. \u201cA fine-grained comparison of\npragmatic language understanding in humans and language models\u201d. In: The 61st Annual Meeting Of The Association\nFor Computational Linguistics . 2023, pp. 4194\u20134213.\nHu, Jennifer and Roger P Levy. \u201cPrompting is not a substitute for probability measurements in large language models\u201d.\nIn:The 2023 Conference on Empirical Methods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 722,
      "text": "ethods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A. \u201cRunning cognitive evaluations on large language models: The do\u2019s and the don\u2019ts\u201d. In: arXiv (2023),\npp. 1\u201312.\nIvanova, Anna A et al. \u201cElements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic\nworld knowledge in language models\u201d. In: arXiv (2024), pp. 1\u201321.\n12\nJagadish, Akshay K, Julian Coda-Forno, Mirko Thalmann, Eric Schulz, and Marcel Binz. \u201cHuman-like Category\nLearning by Injecting Ecological Priors from Large Language Models into Neural Networks\u201d. In: arXiv (2024),\npp. 1\u201327.\nJi, Jiaming et al. \u201cAI Alignment: A Comprehensive Survey\u201d. In: arXiv (2023), pp. 1\u2013102.\nJobe, Jared B. \u201cCognitive psychology and self-reports: models and methods\u201d. In: Quality of Life Research 12 (2003),\npp. 219\u2013227.\nJonas, Eric and Konrad Paul Kording. \u201cCould a Neuroscientist Understand a Microprocessor?\u201d In: PLOS Computational\nBiology 13.1 (2017), pp. 1\u201324.\nJones, Erik and Jacob Steinhardt. \u201cCapturing failures of large language models via human cognitive biases\u201d. In:\nAdvances in Neural Information Processing Systems 35 (2022), pp. 11785\u201311799.\nKadavath, Saurav et al. \u201cLanguage Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 723,
      "text": "Language Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M. Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, and Shafiq Joty.\n\u201cxCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and\nRetrieval\u201d. In: arXiv (2023), pp. 1\u201344.\nKhandelwal, Aditi, Utkarsh Agarwal, Kumar Tanmay, and Monojit Choudhury. \u201cDo Moral Judgment and Reasoning\nCapability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test\u201d. In: Proceedings\nof the 18th Conference of the European Chapter of the Association for Computational Linguistics . Association for\nComputational Linguistics, 2024, pp. 2882\u20132894.\nKim, Geunwoo, Pierre Baldi, and Stephen McAleer. \u201cLanguage Models can Solve Computer Tasks\u201d. In: arXiv (2023),\npp. 1\u201326.\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. \u201cLarge Language Models are\nZero-Shot Reasoners\u201d. In: arXiv (2022), pp. 1\u201336.\nKosoy, Eliza, Emily Rose Reagan, Leslie Lai, Alison Gopnik, and Danielle Krettek Cobb. \u201cComparing Machines\nand Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 724,
      "text": "Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311.\nKumar, Sreejan, Theodore R Sumers, Takateru Yamakoshi, Ariel Goldstein, Uri Hasson, Kenneth A Norman, Thomas L\nGriffiths, Robert D Hawkins, and Samuel A Nastase. \u201cReconstructing the cascade of language processing in the brain\nusing the internal computations of a transformer-based language model\u201d. In: BioRxiv (2022), pp. 1\u201356.\nLake, Brenden M. and Marco Baroni. \u201cHuman-like systematic generalization through a meta-learning neural network\u201d.\nIn:Nature 623 (2023), pp. 1\u201323.\nLampinen, Andrew Kyle. \u201cCan language models handle recursively nested grammatical structures? A case study on\ncomparing models and humans\u201d. In: arXiv (2022), pp. 1\u201322.\nLewis, Patrick et al. \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33.\nCurran Associates, Inc., 2020, pp. 9459\u20139474.\nLi, Changmao and Jeffrey Flanigan. \u201cTask Contamination: Language Models May Not Be Few-Shot Anymore\u201d. In:\narXiv (2023), pp. 1\u201320.\nLi, Xingxuan, Yutong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 725,
      "text": "tong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni. \u201cSyntactic Structure from Deep Learning\u201d. In: Annual Review of Linguistics 7.1 (2021),\npp. 195\u2013212.\nLiu, Ryan, Theodore R Sumers, Ishita Dasgupta, and Thomas L Griffiths. \u201cHow do Large Language Models Navigate\nConflicts between Honesty and Helpfulness?\u201d In: arXiv (2024), pp. 1\u201321.\nLo, Kai-Ling, Rami Ariss, and Philipp Kurz. \u201cGPoeT-2: A GPT-2 Based Poem Generator\u201d. In: arXiv (2022), pp. 1\u201310.\nMa, Yecheng Jason, William Liang, Hung-Ju Wang, Sam Wang, Yuke Zhu, Linxi Fan, Osbert Bastani, and Dinesh\nJayaraman. \u201cDrEureka: Language Model Guided Sim-To-Real Transfer\u201d. In: Robotics: Science and Systems (RSS) .\n2024, pp. 1\u201328.\nMacmillan-Scott, Olivia and Mirco Musolesi. \u201c(Ir)rationality and cognitive biases in large language models\u201d. In: Royal\nSociety Open Science 11 (2024), pp. 1\u201314.\nMahowald, Kyle, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko.\n\u201cDissociating language and thought in large language models\u201d. In: Trends in Cognitive Sciences 28.6 (2024), pp. 517\u2013\n540.\n13\nMazumder, Mark et al. \u201cDataPerf: Benchmarks for Data-Centric AI Development\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 726,
      "text": "lopment\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St. John, and Roman Taraban. \u201cSentence comprehension: A parallel distributed processing\napproach\u201d. In: Language and Cognitive Processes 4.3-4 (1989), SI287\u2013SI335.\nMcCoy, R Thomas, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L Griffiths. \u201cEmbers of Autoregression:\nUnderstanding Large Language Models Through the Problem They are Trained to Solve\u201d. In: arXiv (2023), pp. 1\u201384.\nMcCoy, Tom, Ellie Pavlick, and Tal Linzen. \u201cRight for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\nLanguage Inference\u201d. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .\n2019, pp. 3428\u20133448.\nMcKenzie, Ian R. et al. \u201cInverse Scaling: When Bigger Isn\u2019t Better\u201d. In: arXiv (2023), pp. 1\u201339.\nMerrill, William, Zhaofeng Wu, Norihito Naka, Yoon Kim, and Tal Linzen. \u201cCan You Learn Semantics Through\nNext-Word Prediction? The Case of Entailment\u201d. In: arXiv (2024), pp. 1\u201322.\nMialon, Gr\u00e9goire, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, and Roberta et al Raileanu.\n\u201cAugmented Language Models: a Survey\u201d. In: arXiv (2023), pp. 1\u201333.\nMiotto, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 727,
      "text": "o, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey. \u201cBoosting Theory-of-Mind Performance in Large Language\nModels via Prompting\u201d. In: arXiv (2023), pp. 1\u201327.\nMunkhdalai, Tsendsuren, Manaal Faruqui, and Siddharth Gopal. \u201cLeave No Context Behind: Efficient Infinite Context\nTransformers with Infini-attention\u201d. In: arXiv (2024), pp. 1\u201312.\nNair, Varun, Elliot Schumacher, Geoffrey Tso, and Anitha Kannan. \u201cDERA: Enhancing Large Language Model\nCompletions with Dialog-Enabled Resolving Agents\u201d. In: arXiv (2023), pp. 1\u201338.\nNiv, Yael. Reinforcement learning in the brain . 2009.\nOpen Science Collaboration. \u201cEstimating the reproducibility of psychological science\u201d. In: Science 349.6251 (2015),\npp. 1\u201310.\nOpenAI. ChatGPT: Optimizing Language Models for Dialogue . 2022. URL:https://openai.com/blog/chatgpt/\n(visited on 02/13/2023).\n\u2013GPT-4 Technical Report . 2023. URL:https://cdn.openai.com/papers/gpt-4.pdf (visited on 03/19/2023).\n\u2013GPT-4V(ision) System Card . 2023. URL:https://cdn.openai.com/papers/GPTV_System_Card.pdf (visited\non 10/13/2023).\nOswald, Johannes von, Eyvind Niklasson, Ettore Randazzo, Jo\u00e3o Sacramento, Alexander Mordvintsev, Andrey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 728,
      "text": "drey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174.\nOuyang, Long et al. \u201cTraining language models to follow instructions with human feedback\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh.\nV ol. 35. 2022, pp. 27730\u201327744.\nPapachristou, Marios and Yuan Yuan. \u201cNetwork Formation and Dynamics Among Multi-LLMs\u201d. In: arXiv (2024),\npp. 1\u201327.\nPark, Joon Sung, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. \u201cSocial\nSimulacra: Creating Populated Prototypes for Social Computing Systems\u201d. In: Proceedings of the 35th Annual ACM\nSymposium on User Interface Software and Technology . 2022, pp. 1\u201318.\nPerner, Josef, Susan R. Leekam, and Heinz Wimmer. \u201cThree-year-olds\u2019 difficulty with false belief: The case for a\nconceptual deficit\u201d. In: The British Journal of Developmental Psychology 5.2 (1987), pp. 125\u2013137.\nPeterson, Joshua C., David D. Bourgin, Mayank Agrawal, Daniel Reichman, and Thomas L. Griffiths. Using large-scale\nexperiments and machine learning to discover theories of human decision-making . 2021.\nPhelps, Steve and Yvan I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 729,
      "text": "van I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338.\nPrasad, Grusha, Marten Van Schijndel, and Tal Linzen. \u201cUsing Priming to Uncover the Organization of Syntactic\nRepresentations in Neural Language Models\u201d. In: 23rd Conference on Computational Natural Language Learning,\nCoNLL 2019 . 2019, pp. 66\u201376.\nRadford, Alec, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. \u201cRobust speech\nrecognition via large-scale weak supervision\u201d. In: International Conference on Machine Learning . 2023, pp. 28492\u2013\n28518.\n14\nRahwan, Iyad, Manuel Cebrian, Nick Obradovich, Josh Bongard, Jean-Fran\u00e7ois Bonnefon, and Cynthia et al Breazeal.\n\u201cMachine behaviour\u201d. In: Nature 568.7753 (2019), pp. 477\u2013486.\nRenze, Matthew and Erhan Guven. \u201cThe Effect of Sampling Temperature on Problem Solving in Large Language\nModels\u201d. In: arXiv (2024).\nR\u00f6ttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Sch\u00fctze, and Dirk\nHovy. \u201cPolitical Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in\nLarge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 730,
      "text": "rge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139.\nRuis, Laura Eline, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rockt\u00e4schel, and Edward Grefenstette. \u201cThe\nGoldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs\u201d. In:\nAdvances in Neural Information Processing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt,\nand S. Levine. V ol. 36. 2023, pp. 20827\u201320905.\nRussakovsky, Olga et al. \u201cImageNet Large Scale Visual Recognition Challenge\u201d. In: International Journal of Computer\nVision 115 (2015), pp. 211\u2013252.\nRyle, Gilbert. Collected Papers . Hutchinson, 1971.\nSalewski, Leonard, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, and Zeynep Akata. \u201cIn-Context Impersonation\nReveals Large Language Models\u2019 Strengths and Biases\u201d. In: arXiv (2023), pp. 1\u201327.\nSap, Maarten, Ronan Le Bras, Daniel Fried, and Yejin Choi. \u201cNeural Theory-of-Mind? On the Limits of Social\nIntelligence in Large LMs\u201d. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language\nProcessing . Ed. by Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang. Association for Computational Linguistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 731,
      "text": "guistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo. \u201cAre Emergent Abilities of Large Language Models a Mirage?\u201d\nIn:Proceedings of the 37th International Conference on Neural Information Processing Systems . 2425. Curran\nAssociates Inc., 2023, pp. 1\u201317.\nSchick, Timo, Jane Dwivedi-Yu, Roberto Dess\u00ec, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda,\nand Thomas Scialom. \u201cToolformer: Language Models Can Teach Themselves to Use Tools\u201d. In: arXiv (2023),\npp. 1\u201317.\nSchramowski, Patrick, Cigdem Turan, Nico Andersen, Constantin A Rothkopf, and Kristian Kersting. \u201cLarge pre-trained\nlanguage models contain human-like biases of what is right and wrong to do\u201d. In: Nature Machine Intelligence 4.3\n(2022), pp. 258\u2013268.\nSchubert, Johannes A, Akshay K Jagadish, Marcel Binz, and Eric Schulz. \u201cIn-context learning agents are asymmetric\nbelief updaters\u201d. In: arXiv (2024), pp. 1\u201316.\nSchulze Buschoff, Luca M, Elif Akata, Matthias Bethge, and Eric Schulz. \u201cVisual cognition in multimodal large\nlanguage models\u201d. In: arXiv (2023), pp. 1\u201318.\nSchwartz, Matthew D. \u201cShould artificial intelligence be interpretable to humans?\u201d In: Nature Reviews Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 732,
      "text": "Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R. \u201cMinds, brains, and programs\u201d. In: Behavioral and Brain Sciences 568.7753 (1980), pp. 417\u2013424.\nSellars, Wilfrid. Empiricism and the Philosophy of Mind . Harvard University Press, 1997.\nShanahan, Murray. \u201cTalking About Large Language Models\u201d. In: arXiv (2022), pp. 1\u201311.\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. \u201cRole play with large language models\u201d. In: Nature 623.7987\n(2023), pp. 493\u2013498.\nShevlin, Henry and Marta Halina. \u201cApply rich psychological terms in AI with care\u201d. In: Nature Machine Intelligence 1\n(2019), pp. 165\u2013167.\nSinclair, Arabella, Jaap Jumelet, Willem Zuidema, and Raquel Fern\u00e1ndez. \u201cStructural Persistence in Language Models:\nPriming as a Window into Abstract Language Representations\u201d. In: Transactions of the Association for Computational\nLinguistics 10 (2022), pp. 1031\u20131050.\nSingla, Sahil and Soheil Feizi. \u201cCausal ImageNet: How to discover spurious features in Deep Learning?\u201d In: arXiv\n(2021), pp. 1\u201376.\nSrivastava, Aarohi et al. \u201cBeyond the Imitation Game: Quantifying and extrapolating the capabilities of language\nmodels\u201d. In: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 733,
      "text": "n: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135.\nStolfo, Alessandro, Yonatan Belinkov, and Mrinmaya Sachan. \u201cA Mechanistic Interpretation of Arithmetic Reasoning in\nLanguage Models using Causal Mediation Analysis\u201d. In: Proceedings of the 2023 Conference on Empirical Methods\nin Natural Language Processing . 2023, pp. 7035\u20137052.\nStrachan, James W. A. et al. \u201cTesting theory of mind in large language models and humans\u201d. In: Nature Human\nBehaviour 8 (2024), pp. 1285\u20131295.\nStreet, Winnie et al. \u201cLLMs achieve adult human performance on higher-order theory of mind tasks\u201d. In: arXiv (2024),\npp. 1\u201318.\nTodd, Peter M and Gerd Gigerenzer. Ecological Rationality: Intelligence in the World . Oxford University Press, 2012.\nTsvilodub, Polina, Hening Wang, Sharon Grosch, and Michael Franke. \u201cPredictions from language models for multiple-\nchoice tasks are not robust under variation of scoring methods\u201d. In: arXiv (2024), pp. 1\u20138.\nTversky, Amos and Daniel Kahneman. \u201cJudgment under Uncertainty: Heuristics and Biases\u201d. In: Science 185.4157\n(1974), pp. 1124\u20131131.\n\u2013 \u201cThe Framing of Decisions and the Psychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 734,
      "text": "sychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I. \u201cModel selection and psychological theory: a discussion of the differences between the Akaike\ninformation criterion (AIC) and the Bayesian information criterion (BIC)\u201d. In: Psychological Methods 17.2 (2012),\npp. 228\u2013243.\nWang, Kevin, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. \u201cInterpretability in the Wild:\na Circuit for Indirect Object Identification in GPT-2 small\u201d. In: arXiv (2022), pp. 1\u201325.\nWang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny\nZhou. \u201cSelf-Consistency Improves Chain of Thought Reasoning in Language Models\u201d. In: arXiv (2022), pp. 1\u201324.\nWarstadt, Alex et al. \u201cFindings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible\nCorpora\u201d. In: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language\nLearning . Ed. by Alex Warstadt et al. Association for Computational Linguistics, 2023, pp. 1\u201334.\nWebb, Taylor, Keith J Holyoak, and Hongjing Lu. \u201cEmergent analogical reasoning in large language models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 735,
      "text": "models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330.\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Le Quoc, and Denny Zhou.\n\u201cChain of Thought Prompting Elicits Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201341.\nWeidinger, Laura, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, and John et al Mellor. \u201cTaxonomy\nof Risks posed by Language Models\u201d. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and\nTransparency . Association for Computing Machinery, 2022, pp. 214\u2013229.\nWilcox, Ethan Gotlieb, Richard Futrell, and Roger Levy. \u201cUsing Computational Models to Test Syntactic Learnability\u201d.\nIn:Linguistic Inquiry (2023), pp. 1\u201344.\nWimmer, H. and J Perner. \u201cBeliefs about beliefs: representation and constraining function of wrong beliefs in young\nchildren\u2019s understanding of deception\u201d. In: Cognition 13.1 (1983), pp. 103\u2013128.\nXie, Sang Michael, Aditi Raghunathan, Percy Liang, and Tengyu Ma. \u201cAn Explanation of In-context Learning as\nImplicit Bayesian Inference\u201d. In: International Conference on Learning Representations . 2022, pp. 1\u201325.\nYang, Yuhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 736,
      "text": "uhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337.\nYax, Nicolas, Hernan Anll\u00f3, and Stefano Palminteri. \u201cStudying and improving reasoning in humans and machines\u201d. In:\nCommunications Psychology 2.1 (2024), pp. 1\u201316.\nYiu, Eunice, Eliza Kosoy, and Alison Gopnik. \u201cTransmission Versus Truth, Imitation Versus Innovation: What Children\nCan Do That Large Language and Language-and-Vision Models Cannot (Yet)\u201d. In: Perspectives on Psychological\nScience 0.0 (2023), pp. 1\u201310.\nZellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. \u201cHellaSwag: Can a Machine Really Finish\nYour Sentence?\u201d In: Annual Meeting of the Association for Computational Linguistics . 2019, pp. 1\u201310.\nZhang, Jingyi, Jiaxing Huang, Sheng Jin, and Shijian Lu. \u201cVision-Language Models for Vision Tasks: A Survey\u201d. In:\narXiv (2024), pp. 1\u201324.\n16\nZhang, Tianhua, Jiaxin Ge, et al. \u201cNatural Language Embedded Programs for Hybrid Language Symbolic Reasoning\u201d.\nIn:Findings of the Association for Computational Linguistics: NAACL 2024 . Ed. by Kevin Duh, Helena Gomez, and\nSteven Bethard. 2024, pp. 4131\u20134155.\nZhao, Haiyan, Hanjie Chen, F. Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 737,
      "text": "gyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z., Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. \u201cCalibrate Before Use: Improving Few-Shot\nPerformance of Language Models\u201d. In: arXiv (2021), pp. 1\u201315.\nZheng, Xiaosen, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, and Min Lin. \u201cImproved Few-Shot Jailbreaking Can\nCircumvent Aligned Language Models and Their Defenses\u201d. In: arXiv (2024), pp. 1\u201322.\nZhou, Denny, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, and Xuezhi et al Wang. \u201cLeast-to-Most Prompting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 738,
      "text": "mpting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 739,
      "text": "MACHINE PSYCHOLOGY\nThilo Hagendorff\u2217\nUniversity of StuttgartIshita Dasgupta\u2217\nGoogle DeepMindMarcel Binz\u2020\nHelmholtz Institute for\nHuman-Centered AIStephanie C.Y. Chan\u2020\nGoogle DeepMind\nAndrew Lampinen\u2020\nGoogle DeepMindJane X. Wang\u2020\nGoogle DeepMindZeynep Akata\nTU MunichEric Schulz\nHelmholtz Institute for\nHuman-Centered AI\nAugust 9, 2024\nABSTRACT\nLarge language models (LLMs) show increasingly advanced emergent capabilities and are being\nincorporated across various societal domains. Understanding their behavior and reasoning abilities\ntherefore holds significant importance. We argue that a fruitful direction for research is engaging\nLLMs in behavioral experiments inspired by psychology that have traditionally been aimed at\nunderstanding human cognition and behavior. In this article, we highlight and summarize theoretical\nperspectives, experimental paradigms, and computational analysis techniques that this approach\nbrings to the table. It paves the way for a \"machine psychology\" for generative artificial intelligence\n(AI) that goes beyond performance benchmarks and focuses instead on computational insights that\nmove us toward a better understanding and discovery of emergent abilities and behavioral patterns\nin LLMs. We review existing work taking this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 740,
      "text": "ng this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines. We posit that leveraging tools from experimental\npsychology to study AI will become increasingly valuable as models evolve to be more powerful,\nopaque, multi-modal, and integrated into complex real-world settings.\nIntroduction\nRecent advances in computing power, data availability, and machine learning algorithms have yielded powerful artificial\nintelligence systems that are used in almost all parts of society. Among these, large language models (LLMs), gigantic\nneural network architectures trained on large amounts of text, have seen a particularly meteoric rise in their influence.\nThe ability of LLMs to interface directly with natural language has made them accessible to the public in a way that\nwas not seen before, leading to widespread adoption with millions of daily users (Gemini Team et al., 2024; Anthropic,\n2024; OpenAI, 2022; OpenAI, 2023a). Also contributing to their rise in influence is that LLMs are wide-ranging in the\nkinds of tasks they can do \u2013 from writing text or code to calling functions, accessing the Internet, retrieving external\ninformation, reasoning about complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 741,
      "text": "complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al., 2022; Radford et al., 2023). The ever-growing capabilities of these systems make them challenging but also\nincreasingly important to characterize and understand, especially since these expanding capabilities also bring greater\npotential for unforeseen harm (Bommasani et al., 2021; Hagendorff, 2024b; Weidinger et al., 2022; Bender et al., 2021;\nSchramowski et al., 2022).\n\u2217Shared first authorship. Contact: thilo.hagendorff@iris.uni-stuttgart.de, idg@google.com\n\u2020Co-authors are listed in alphabetical order.arXiv:2303.13988v6  [cs.CL]  8 Aug 2024\nFigure 1: Overview of key concepts of machine psychology.\nUnderstanding behavioral patterns and emergent abilities in LLMs requires explaining their operating principles. Of the\napproaches focused on explaining AI systems, many rely on trying to understand the inner workings of these neural\nnetworks. This approach, often termed mechanistic interpretability, seeks to investigate LLMs by analyzing how their\nweights and activation patterns implement the observable behavior. It uses simplifications in terms of data, the model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 742,
      "text": "model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024). A related set of approaches draws inspiration\nmore directly from neuroscience to characterize broader correlational similarities and differences between the internal\nprocessing of LLMs and humans (Hosseini and Fedorenko, 2023; Kumar et al., 2022).\nIn contrast, this review focuses on the class of approaches that directly study the behavior of LLMs, analyzing\nrelationships between inputs and outputs instead of inspecting the inner workings. This approach includes not only\nanalyses of static trained models, but also experimental manipulations of inputs both during and after training. It\nalso encompasses analyses of inputs and outputs that reveal insights about internal mechanisms, even if those internal\nmechanisms are not directly inspected. For this set of approaches, experiments can be inspired by human psychology,\ncognitive science, and the behavioral sciences. This is what we want to term machine psychology (see Figure 1). Over\nseveral decades, the mentioned disciplines have developed a wide range of methods and frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 743,
      "text": "d frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well.\nThus far, the research community has responded to the challenges of understanding behavioral patterns and growing\ncapabilities in LLMs in several ways (Schwartz, 2022; Zhao, Chen, et al., 2023). The traditional machine learning\nbenchmark-driven approach has released new datasets that capture specific aspects only recently seen emerging in\nmodels (Srivastava et al., 2022; Hendrycks et al., 2021; Zellers et al., 2019). Traditional benchmarking aims primarily\nto enable the community to compare and optimize LLM performance. In contrast, machine psychology research is not\nprimarily interested in increasing (or measuring) an LLM\u2019s performance, but rather in understanding behavioral patterns.\nWhile traditional natural language processing benchmarks measure abilities such as translation, numerical reasoning, or\nfactual accuracy, machine psychology is also interested in how these observable abilities indirectly reflect the underlying\nconstructs and algorithms (Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 744,
      "text": "Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes.\nThe relative importance of behavior-based inspection (or psychology) versus internal inspection (or neuroscience) has\nbeen a long-standing debate (Jonas and Kording, 2017). We believe that both approaches have value for understanding\nboth humans and LLMs. Directly inspecting LLMs\u2019 behavior, however, does come with multiple advantages. The\nbehavior of LLMs is expressed at the interface of the model, where human users interact, and thus is what we ultimately\ncare about the most (Binz and Schulz, 2023; Chang and Bergen, 2024; Ivanova, 2023). Such behavior is often too\ncomplex to predict purely from our current mechanistic understanding of model weights and activation patterns (Gr\u00f6n\net al., 2003). Many interesting behaviors are only displayed by large models with billions of parameters (Kaplan et al.,\n2020; Wei, Tay, et al., 2022), and behavioral methods in psychology that treat behavior directly as the experimental\nvariable of interest scale gracefully with model size. Another practical advantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 745,
      "text": "dvantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public.\nIn this article, we review and chart future directions in this emerging field of directly modeling LLM behavior. We\noutline how established behavioral sciences can guide and inform our understanding of LLMs, and discuss important\ncaveats for when and how to apply methods to LLMs, given that they were originally developed for humans and\nanimals. In the first section, we discuss the theoretical frameworks developed and used in psychology to organize\nour understanding of intelligence and intelligent behaviors. We then review the many empirical paradigms that have\nbeen developed to study and characterize different aspects of intelligent behavior. Finally, we discuss and make\nrecommendations for robust empirical methods both for designing experiments and analyzing behavioral data. We end\nthe article by discussing the potentials and limitations of conducting machine psychology experiments with increasingly\ncapable black-box models.\nTheory: Evaluation paradigms for understanding intelligent systems\nThe traditional framework in machine learning algorithms has revolved around benchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 746,
      "text": "nchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance. Researchers train on a train dataset and evaluate on a held-out test\ndataset that was not seen during training. This framework does not generalize well to large-scale foundation models for\ntwo reasons. First, when using Internet-scale training data for models, this split has become harder to maintain (Li\nand Flanigan, 2023; Khan et al., 2023). Second, foundation models are only directly trained for next-token prediction\nbut exhibit many other \"intelligent\" behaviors that can, with some reservations (Schaeffer et al., 2023), be considered\nemergent. For example, practitioners did not explicitly encode or train for a transformer LLM\u2019s ability to learn from a\nfew examples in context (Brown et al., 2020), but it nonetheless arose from the machine learning architecture, data, and\nlearning signal (Chan et al., 2022; Oswald et al., 2023). Emergent behaviors can be difficult to study through the lens of\nthe components that gave rise to it (Anderson, 1972), and the ones that emerge can seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 747,
      "text": "n seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e. smaller scale datasets unsuitable for training\nand intended solely as a test set \u2013 to investigate model capabilities, e.g. the BIG-bench comprising more than 200 tests\n(Srivastava et al., 2022), the Abstraction and Reasoning Challenge (Chollet et al., 2020), as well as many others (Ivanova\net al., 2024; Mazumder et al., 2024). In several cases, these benchmarks already resemble evaluation frameworks\nfrom the behavioral sciences (Bubeck et al., 2023) \u2013 like personality tests, intelligence tests, implicit association tests,\netc. that are applied to humans \u2013 which similarly do not follow the train-test paradigm. They also tend to fall into\ntwo categories. Some evaluations focus on scalar performance metrics, e.g. intelligence quotients. Others focus on\ncharacterizing behavior, i.e. the questions are not designed with accuracy in mind, but designed to elicit responses that\nreveal behavioral strategies, or underlying constructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 748,
      "text": "ructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field.\nSeveral such diagnostic evaluations have been developed even for pre-LLM models where, despite the models being\ntrained for specific tasks, how to solve them is not specified. Such diagnostic datasets were used to expose the ways\nin which learned systems solved tasks \u2013 often counter to human intuitions (Geirhos et al., 2020; McCoy, Pavlick,\net al., 2019; Hermann and Lampinen, 2020; Dasgupta et al., 2022; Singla and Feizi, 2021). Researchers have also\nmade the case for borrowing from ethology, a branch of zoology that studies the behavior of non-human animals, to\nexplain machine behavior in machine learning systems (Rahwan et al., 2019). However, in the era of LLMs, not only\nare the how unspecified, but the model abilities themselves are neither directly known nor intentionally engineered.\nFurthermore, since LLMs can be evaluated via natural language, this can enhance or replace comparatively simpler\nmethods from ethology. This has led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 749,
      "text": "as led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats. In trying to shed light on the workings of a black-box system that can\nproduce language, it is tempting to use the simplest approach of asking the system about it. Self-report measures have\nbeen extensively used in psychology as well; but their reliability is questionable in humans (Jobe, 2003) as well as\nLLMs. Properties that such measures usually consider, such as personality, morality, or clinical disorders, are famously\nsensitive to prompting (Dominguez-Olmedo et al., 2023; R\u00f6ttger et al., 2024); to the extent that several recent works\neven simulate groups of humans of different social groups, opinions, and personalities with differently prompted LLMs\n3\n(Salewski et al., 2023; Park et al., 2022; Argyle et al., 2023; Shanahan et al., 2023). There remains value in using\nself-report stimuli from psychology \u2013 for example, to characterize behavior on a default prompt, as well as to understand\nhow steerable (i.e. sensitive to prompting) models are along these dimensions. But results drawn from these measures\nshould be taken contextually (e.g. as a property of a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 750,
      "text": "a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports. This tradition has yielded\nlasting understanding of natural intelligence (Frank et al., 2024), and is the tradition we argue is the most amenable\nfor transferring insights to machine psychology. In this paradigm, externally observed behavior continues to be the\nmeasured experimental variable, but stimuli are designed such that different observed behaviors map onto and measure\ndifferent internal representations, capabilities, or constructs \u2013 like compositionality, theory of mind, logic, causality, etc.\nA key principle is that experiments are hypothesis-driven: if the agent has representation or construct X, we would\nexpect to see behavior Y , otherwise we would see behavior Z. We highlight two key principles from this tradition that\nare crucial to keep in mind when performing and interpreting machine psychology evaluations. First, does seeing\nbehavior Y reliably imply having the construct X? To answer this, the design of a good control is crucial \u2013 to ensure that\nbehavior Y does not have another explanation and does, in fact, implicate X. A large part of experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 751,
      "text": "f experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology. Second, does the absence of behavior Y indicate the absence\nof the construct X? This is a more subtle question. Research in psychology often grapples with the fact that human\nperformance can be noisy or biased; for example, humans may make mistakes even on an easy calculation, or produce\nungrammatical language colloquially. These should not be taken to mean that they lack the abstract capability for math\nor language. These inconsistencies led to the concept of the performance-competence distinction (e.g. Chomsky, 1965):\nthat the way humans perform in a particular situation may not fully capture their underlying competence . More recent\nwork has suggested that similar issues apply when assessing the capabilities of machine learning systems (Firestone,\n2020), and particularly LLMs (Lampinen, 2022).\nParadigms: The many aspects of intelligent behavior\nThere are many aspects of intelligent behavior, each of which has been studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 752,
      "text": "en studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g. pupillometry) are not directly transferable to LLMs since they rely on the existence of a\nphysical body, several of these paradigms are purely linguistic and can be easily transferred. As LLMs expand in the\nkinds of stimuli they can interpret \u2013 e.g. visual (OpenAI, 2023b; Zhang, Huang, et al., 2024; Gemini Team et al., 2024)\n\u2013 and the ways in which they can interact with the world \u2013 e.g. embodiment and tool use (Mialon et al., 2023) \u2013, the\nspace of transferable paradigms increases. Humans also interact with several modalities, and the paradigms developed\nto understand us often compare and integrate these modalities (Schulze Buschoff et al., 2023) \u2013 e.g. the Stroop test\nwhich spans vision and reading capabilities (Scarpina and Tagini, 2017).\nIn this article, we focus on language-based tests, since these are the most widely used in the current research landscape.\nMoreover, we believe that even in light of the growing trend toward multi-modal models, language will remain a primary\nmodality due to its fundamental role in models\u2019 reasoning processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 753,
      "text": "processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning. Apart from these four areas, there are, of course, multiple other domains of psychology that\ncan also provide valuable paradigms for, for instance when investigating creativity in LLMs (Stevenson et al., 2022),\nclinical psychology (Li, Li, et al., 2022), moral behavior (Khandelwal et al., 2024), and others.\nHeuristics and biases\nThe heuristics and biases framework is one of the most influential research paradigms in psychology (Gigerenzer\nand Gaissmaier, 2011; Tversky and Kahneman, 1974). Heuristics are mental shortcuts that simplify reasoning or\ndecision-making processes, and this field studies how such shortcuts can help explain both the successes and the biases\nin human behavior. The large existing literature on heuristics and biases in humans is a fertile ground for examining\nsuch shortcuts in the newest generation of LLMs \u2013 whose capabilities now overlap more with the human abilities\nthis literature studies. Binz and Schulz (2023) were among the first to use this paradigm to better understand the\ndecision-making processes of LLMs. They found that GPT-3 (Brown et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 754,
      "text": "own et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al., 2023; Macmillan-Scott and Musolesi, 2024; Schulze Buschoff et al., 2023; Hayes et al., 2024;\nCoda-Forno, Binz, Wang, et al., 2024). Interestingly, there is evidence from several studies showing that, while the\nprevious generation of models frequently exhibited human-like heuristics and biases, they have largely disappeared\nin the latest generation of LLMs (Chen, Liu, et al., 2023; Hagendorff et al., 2023). The test stimuli were originally\ndesigned to be challenging for human study participants and possibly no longer challenge the growing reasoning\nabilities in LLMs. This could also be due to leakage into the training set \u2013 we discuss this challenge in the section on\ndesign and analysis.\nThe literature on heuristics and biases also suggests that how a problem is phrased can influence how people solve it\n(Cheng and Holyoak, 1985; Tversky and Kahneman, 1981). It is well-known that LLMs are also susceptible to similar\nmanipulations. For example, Dasgupta et al. (2022) have investigated whether LLMs are affected by the semantic\ncontent of logical reasoning problems using several existing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 755,
      "text": "ing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems. Likewise, Schubert et al., 2024 have shown that how LLMs learn in-context depends on the\nproblem formulation.\nFinally, people do not simply apply arbitrary heuristics. Instead, they use heuristics that are adapted to the problems\nthey encounter during their everyday interactions with the world (Todd and Gigerenzer, 2012). In the context of LLMs,\none can look at how the properties of the training data shape their behavior. For example, Chan et al., 2022 have\ndemonstrated that the presence of in-context learning in LLMs can be traced back to data distributional properties such\nas burstiness, where items appear in clusters rather than being uniformly distributed over time, and the presence of large\nnumbers of rarely occurring classes. Researchers also proposed that one should try to understand LLMs through the\nproblem they are trained to solve, similarly to how behavioral scientists attempt to understand human cognition through\nthe lens of ecological rationality (Todd and Gigerenzer, 2012; McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 756,
      "text": "McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives. This includes studying the various factors that influence development, such as social intelligence or social\nskills. By applying paradigms from this area of developmental psychology to LLMs, researchers can gain deeper\ninsights into how these models manage complex social interactions. In particular, once LLMs are deployed as chat\nagents, they should become versed in modeling human communicators. Therefore, it is important to assess the level of\nsocial intelligence in LLMs. One example in this context is the application of theory of mind tests to LLMs, where\nresearchers use tasks from human experiments, such as those famously conducted by Wimmer and Perner (1983) and\nPerner et al. (1987). While early experiments with models such as GPT-3 showed that they struggle to solve theory\nof mind tasks (Sap et al., 2022), later models demonstrate an increasing ability to reliably infer unobservable mental\nstates in others (Strachan et al., 2024; Holterman and Deemter, 2023; Moghaddam and Honey, 2023). Further related\nresearch examines how LLM performance on theory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 757,
      "text": "heory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al., 2024), or measures the robustness of theory of mind test setups against distracting alterations in the tasks\nLLMs receive as inputs (Ullman, 2023). As theory of mind tests measure, among other things, the ability to understand\nfalse beliefs, further research has explored the emerging capability of LLMs to induce false beliefs in other agents\n(Hagendorff, 2024a), or how LLMs trade off various communicative values like honesty and helpfulness (Liu et al.,\n2024) \u2013 these investigations also contribute to understanding and improving alignment with human values for AI safety\n(Ji et al., 2023).\nThe space of relevant paradigms increases as LLMs are allowed to interact through self-reflection (Nair et al., 2023),\nself-instruction (Wang, Wei, et al., 2022), or in swarms (Zhuge et al., 2023). For example, researchers looked at\ncooperative and coordinative behavior in LLMs playing games, revealing persistent behavioral signatures in the models\n(Akata et al., 2023). Similarly, researchers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 758,
      "text": "ers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024). Another study, which is influenced by works in human social psychology, looked at how multiple LLMs form\nand evolve networks, investigating micro-level network principles such as preferential attachment or triadic closure,\nas well as macro-level principles such as community structures (Papachristou and Yuan, 2024). In sum, machine\npsychology can reveal patterns of social behavior and interaction among LLMs, individually and collectively, be it for\n5\nproblem solving or world simulation (Guo et al., 2024). By drawing from human developmental psychology and social\ndynamics, researchers can better understand and design LLMs that navigate complex social interactions and exhibit\nadvanced social skills.\nPsychology of language\nA long history of work has studied the psychology of how humans use and understand language, ranging from how\nthey use semantic and syntactic features to understand a sentence to how they use pragmatic inferences in a discourse\ncontext to help interpret what someone has said. Correspondingly, a long-standing body of work has studied how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 759,
      "text": "how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al., 1989); more recently, researchers\nhave applied similar techniques to study LLMs. A wide range of work has studied what models learn about syntax\n(Linzen and Baroni, 2021), often using methods from psycholinguistics. For example, Wilcox et al. (2023) used\npsycholinguistics-inspired surprisal measures to show that LLMs learn filler-gap dependencies, a challenging syntactic\nstructure. Other researchers have used related measures to study what LLMs learn about the semantics of entailment\n(Merrill et al., 2024). Moreover, researchers used psycholinguistic techniques like priming to study how models\nrepresent and process language (Prasad et al., 2019; Sinclair et al., 2022), and methods like deconfounded stimuli to\nidentify where models may rely on semantic heuristics rather than syntax (McCoy, Pavlick, et al., 2019). Several recent\nworks (Hu, Floyd, et al., 2023; Ruis, Khan, et al., 2023) studied pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 760,
      "text": "ed pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain. In another study, researchers examined long-form analogies generated by ChatGPT, finding\nthat AI-generated analogies lack some human-like psycholinguistic properties (Seals and Shalin, 2023), particularly in\ntext cohesion, language, and readability. Furthermore, researchers applied garden path sentences \u2013 sentences that lead\nthe reader to initially interpret them incorrectly due to their ambiguous structure \u2013 to LLMs, showing that the models\nrespond similarly to humans (Aher et al., 2023; Christianson et al., 2001). At a higher level, some researchers have\ndrawn inspiration from aspects of human language development to attempt to identify the causes of the relative data\ninefficiency of language models (Warstadt et al., 2023; Frank, 2023). In each of these cases, methods and ideas from\npsychology and psycholinguistics provide guidance on how to assess processes through language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 761,
      "text": "h language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills. At first blush, it\nmay appear that experimental paradigms for the study of learning are less applicable to LLMs, given that the aim of\nbehavioral experiments is often to help uncover the underlying learning algorithm \u2013 whereas for LLMs the learning\nalgorithms used in training are designed and already known. However, the behavioral sciences can still benefit from the\nstudy of LLMs in this context, since LLMs exhibit learning abilities that were not explicitly designed into the models\n(they are emergent), and thus one does not understand the underlying learning algorithm. In particular, LLMs exhibit\nemergent in-context learning \u2013 the ability to learn from context (the prompt) without requiring any gradient-based\nupdates in weights (Brown et al., 2020). Understanding in-context learning is a burgeoning field that is rapidly gaining\nin importance, given the increasing size of LLMs context windows and consequent gains in capabilities, e.g. the\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 762,
      "text": "he\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024).\nUncovering the implicit learning algorithm implemented by in-context learning is a burgeoning research field, and\nutilizes many of the methods common in cognitive science. For example, multiple studies have compared the outputs of\ntransformer in-context learning with the outputs of hypothesized learning algorithms (Oswald et al., 2023; Aky\u00fcrek\net al., 2022). This is a staple of cognitive modeling, and could potentially benefit even further from model comparison\nprocedures from psychology and statistics (Yang, 2006; Arlot and Celisse, 2010; Vrieze, 2012). Recent work in\ncognitive science has used machine learning to discover new theories of human decision-making (Peterson et al., 2021)\n\u2013 it might be interesting to apply related approaches to in-context learning as well. Researchers might also benefit from\nconsidering particular models as normative starting points (Niv, 2009).\nResearchers may also wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 763,
      "text": "so wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time. These characteristics\n6\nare often not obvious even in cases where the learning algorithm is known, and thus researchers would like to understand\nthem not only for in-context learning, but also for other forms of LLM learning, e.g. self-supervised gradient-based\nlearning, reinforcement learning (Ouyang et al., 2022), or \"fast\" memory retrieval (Borgeaud et al., 2022; Lewis et al.,\n2020).\nTo characterize inductive biases and generalization of LLMs, researchers have borrowed both concepts and experimental\nparadigms from cognitive sciences (Schubert et al., 2024; Coda-Forno, Binz, Akata, et al., 2023) and Bayesian inference\n(Xie et al., 2022). Studies utilized paradigms for measuring systematic generalization to characterize those capabilities\nin LLMs, and as inspiration to improve these abilities (Lake and Baroni, 2023; Ruis, Andreas, et al., 2022). Webb\net al. (2023) created novel variants of classic analogy problems from cognitive science, in order to examine the\nanalogical capabilities of large language models. Chan et al. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 764,
      "text": "l. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers. Furthermore, researchers borrowed paradigms and measures from developmental psychology\nto characterize the domains where LLM inductive biases may match those of children, and where they may fall short\n(including in causal reasoning and innovation) (Kosoy et al., 2023; Yiu et al., 2023).\nTo characterize the data dependence of in-context learning, existing work has drawn inspiration from research in\ndevelopmental psychology on skewed and bursty distributions (Chan et al., 2022). An important aspect of data\ndependence is the structure of data over time (during training). AI researchers have long drawn inspiration from\ncurriculum learning in human and non-human animals to better understand how to structure training data so that earlier\nlearning on easier tasks can scaffold later learning on harder tasks (Bengio et al., 2009). There remain many areas\nof behavioral research on learning that may serve as rich sources of inspiration on data dependence, e.g. research on\nrepetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 765,
      "text": "epetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019). Data dependence is particularly\ninteresting for LLMs because text training data (being sourced largely from unstructured web-scale corpora) is very\ndifferent from the structured training data typically used for traditional discriminatory machine learning techniques, and\nbecause data is one of the major levers one can manipulate in training LLMs to adjust their behaviors.\nDesign and analysis: Good behavioral experimentation\nComputer science has not historically been an empirical science. While machine learning (especially since the era of\nneural network models) has been significantly driven by empirical rather than theoretical work, the settings under which\nthose protocols were developed \u2013 a test set that is fixed for all practitioners and is effectively infinitely large \u2013 no longer\nhold in the small test-only behavioral experiments setting. Current LLMs are famously sensitive to small changes in\nprompt structure or they rely on shallow syntactic heuristics (McCoy, Pavlick, et al., 2019), and studies that are not\ncareful about testing the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 766,
      "text": "ting the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al., 2020), and machine\npsychology should not share the same fate. In this section, we provide recommendations for sound methodologies in\nbehavioral test settings with LLMs, which should be valuable to practitioners in the field of machine psychology.\nPrompting methods and biases\nMany studies conducted in the field of machine psychology have a significant shortcoming in common, namely that they\ndo not avoid training data contamination. They use prompts from existing psychology studies and apply them to LLMs\nwithout changing their wording, task orders, etc. In this way, LLMs are likely to have already experienced identical\nor similar tasks during training, thus causing LLMs to simply reproduce known token patterns. When adopting test\nframeworks from psychology \u2013 meaning vignettes, cognitive tasks, or other test setups \u2013 researchers must ensure that\nLLMs have never seen the tests before and go beyond mere memorization. Hence, prompts may indeed be structurally\nlike already existing tasks, but they should contain new wordings, agents, orders, actions, etc. That being said, some\nexperiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 767,
      "text": "experiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024).\nAnother common shortcoming of several existing machine psychology studies is that they rely on small sample sizes or\nconvenience samples, meaning non-systematic sequences of prompts. Sampling biases in the used benchmarks or task\ndatasets, which are especially prevalent in small sample sizes, can diminish the quality of machine psychology studies.\n7\nThis is because slight changes in prompts can change model outputs significantly. Because of this high sensitivity to\nprompt wording, it is important to test multiple versions of one task and to create representative samples, meaning\nbatteries of varied prompts. Only in this way can one reliably measure whether a certain behavior is systematically\nreoccurring and generalizable (Yarkoni, 2022). Furthermore, LLMs can succumb to various biases influencing the\nprocessing of prompts (Zhao, Wallace, et al., 2021; Chan et al., 2022). Recency biases in LLMs, for instance, lead to a\ntendency to rely more heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 768,
      "text": "e heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data. Moreover,\nmajority label biases can cause LLMs to be skewed towards labels, classes, or examples that are frequent in a few-shot\nlearning setting. Technical biases like these can at least in part be controlled for when designing prompts or prompt\nvariations that tend to avoid triggering them. If this is not done, LLMs may rely on shortcuts exploiting such biases.\nEliciting capabilities with prompts\nThe standard prompt design, comprising a vignette plus an open- or close-ended question or task, can be enhanced\nby prefixes or suffixes eliciting improved reasoning capabilities in LLMs. On the other hand, omitting such prefixes\nand suffixes can lead to underestimations of the model\u2019s capabilities. Although it is likely that most specific prompt\naugmentations have a positive influence on one kind of task but not another, reducing our ability to systematically\nunderstand LLM behavior, a few prompt design approaches have nonetheless been found to confer broader performance\nbenefits. Most notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 769,
      "text": "t notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance. This can be extended\neven further by generating multiple chain-of-thought reasoning paths and taking the majority response as the final one\n(Wang, Wei, et al., 2022). Similar to chain-of-thought prompting is least-to-most prompting, which also decomposes\nproblems into a set of subproblems to increase accuracy in LLMs (Zhou et al., 2022). Yet another approach is to frame\nquestions in a multiple-choice format. This was shown to improve reasoning capabilities in some cases (Kadavath et al.,\n2022), but can also limit them because LLMs might be prompted to provide brief responses, thereby circumventing\nreasoning in the process of prompt completion. Nevertheless, many prominent NLP benchmarks use multiple choice\nformats instead of open-ended questions. Here, one must keep in mind that different expressions of the same concept\ncompete for probability, which can lower the chances of selecting the correct answer (Holtzman et al., 2021). Moreover,\none has to consider potential recency biases, which require neutralizing this effect by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 770,
      "text": "t by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al., 2020), where the LLM\u2019s performance improves after repeated exposure to a\ngiven task. Moreover, self-reflection, meaning the automated, recursive criticizing and subsequent self-improvement of\nLLM outputs by the LLM itself, is a further technique that can improve reasoning abilities (Nair et al., 2023; Kim et al.,\n2023). Regarding improvements in symbolic or numeric reasoning, another technique is to prompt LLMs to use code\nfor solving tasks (Zhang, Ge, et al., 2024). Eventually, all mentioned methods to improve reasoning can be not just\nleveraged for machine psychology; they can also become objects of study themselves.\nSetting parameters and evaluating outputs\nLLMs come with a variety of parameters researchers can set. For example, most models come in a variety of sizes.\nAnalyses across different sizes are valuable: while the largest ones usually have the highest capabilities, some recent\nworks find \"inverse-scaling\" (McKenzie et al., 2023). Moreover, temperature settings control randomness. If exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 771,
      "text": "exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice. The effect of temperature on capabilities is not\nestablished (Renze and Guven, 2024), and reporting averages or \"best of K\" \u2013 considering all the responses over K\nsamples that meet certain simple criteria, e.g. formatting (Chen, Tworek, et al., 2021) \u2013 is valuable.\nAfter conducting the experiments, a list of LLM responses must be evaluated and compared with the ground truth. The\nsimplest case is when the results can be framed and scored as a multiple-choice question \u2013 though even in this case,\nscoring the answers so that the model responds directly inline, rather than selecting a choice, can yield more signal\n(Hu and Levy, 2023). If possible, multiple scoring methods should be compared, to evaluate whether the effects are\ndependent on the scoring method (Tsvilodub et al., 2024). If the questions must be answered with free generations, the\nevaluation process can still be automated if the results exhibit sufficient simplicity and regularity, meaning that the LLM\nresponses are similar to the ground truth strings in terms of length and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 772,
      "text": "gth and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed. State-of-the-art LLMs, however, tend to produce highly variable and comprehensive\noutputs, which can complicate classification. While stop sequences, token limits, or prompt instructions that interrupt\nfurther text generation can facilitate classification by promoting output uniformity, they also improperly constrain LLM\nbehavior. Therefore, researchers are increasingly relying on LLM-based evaluations of outputs where a single model or\nmultiple stacked model instances perform the classification using carefully crafted instructions. Although this method\nmight still be inaccurate for very comprehensive outputs, a solution is to instruct the LLM under scrutiny to output\nits final answer or summary after a specific string sequence like \"####\" (Cobbe et al., 2021). This approach allows\nthe LLM to reason during verbose prompt completions, which is necessary for many prompt engineering techniques\nsuch as chain-of-thought reasoning. The classification then only involves processing the string following \"####\". If\nthis method still proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 773,
      "text": "ll proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out.\nDiscussion\nMachine psychology provides a new approach to explaining AI. Instead of interpreting a neural network\u2019s design\ncomponents (Barredo Arrieta et al., 2019), one analyzes the relationships between inputs and outputs, i.e. prompt\ndesign and prompt completion. Although this may allow the identification of hitherto unknown abilities or behavioral\ntraits in LLMs, interpreting LLM responses comes with a challenge. A strong tendency exists to confer mental concepts\nor psychological terms to LLMs that were hitherto reserved for human and animal minds. This tendency manifests in\ncommon terms like \"machine learning,\" but will become more prevalent in machine psychology when concepts such as\nreasoning (Huang and Chang, 2022), intuition (Hagendorff et al., 2023), creativity (Stevenson et al., 2022), intelligence\n(Webb et al., 2023), personality (Miotto et al., 2022), mental illnesses (Li, Li, et al., 2022), etc. are transferred to\nLLMs. In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 774,
      "text": ". In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024). Moreover, many\npsychological concepts are normatively laden and can foster mismatches in expectations between AI experts and the\npublic regarding machine capabilities (Shevlin and Halina, 2019). Nevertheless, the problem that many abilities in\nLLMs cannot be reasonably grasped by only referring to the inner workings of their neural architecture remains.\nBy adopting a concept from ethnography, one could call such an approach \"thin descriptions\" (Ryle, 1971; Geertz,\n1973), meaning that one only explains internal representations in AI systems, for instance via activation atlases, which\nvisualize how different parts of a neural network respond to various inputs (Carter et al., 2019). In this sense, LLMs\nsimply hijack humans\u2019 intuitions to explain machine behavior patterns by using psychological or other anthropocentric\nterms. Contrary to thin descriptions, though, there are \"thick descriptions.\" They imply using psychological terms to add\na layer of explainability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 775,
      "text": "ability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist. This holds for humans,\ntoo, where mental terms used to explain behavior do not directly correlate with specific sets of neural activations.\nBy postulating (mental) unobservable states, be it with regard to brains or artificial neural networks, one increases\nexplanatory resources (Sellars, 1997). Thick descriptions help in making sense of LLMs when thin descriptions are\ninsufficient to explain behavioral patterns. Thin descriptions assume that LLMs merely possess syntax or a statistical\ncapacity to associate words (Searle, 1980; Floridi and Chiriatti, 2020; Bender et al., 2021), but not semantics. Thick\ndescriptions, though, assume that LLMs show patterns and regularities that go beyond mere syntax. These patterns can\nbe explained by means of machine psychology.\nBeyond potential habituations regarding the use of terminology borrowed from psychology in the context of machines,\nmachine psychology, as a nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 776,
      "text": "nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments.\nThis new discipline of evaluating LLMs will become even more important when taking multimodal or augmented\nLLMs into account, meaning LLMs that are allowed to interact with images, external information sources, sensory\ndata, physical objects, and various other tools (Mialon et al., 2023; Schick et al., 2023; Ma et al., 2024). Moreover,\nonce test settings for machine psychology are established, researchers can investigate how LLMs develop over time by\napplying the same tasks multiple times, yielding longitudinal data. This data can serve as a baseline to extrapolate trends\nregarding the development of reasoning abilities in LLMs. Such estimations may be increasingly important for AI\nsafety and AI alignment research to predict future behavioral potentials in LLMs. By gaining a deeper understanding of\nthese potentials, machine psychology is providing a new approach to AI explainability as well as an important addition\nto traditional benchmarking methods in natural language processing.\n9\nAuthor contributions\nTH and ID conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 777,
      "text": "D conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure. All authors assisted\nwith iterations and edited and reviewed the paper.\nReferences\nAher, Gati, Rosa I. Arriaga, and Adam Tauman Kalai. \u201cUsing Large Language Models to Simulate Multiple Humans\nand Replicate Human Subject Studies\u201d. In: Proceedings of the 40th International Conference on Machine Learning .\n2023, pp. 1\u201335.\nAkata, Elif, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. \u201cPlaying repeated\ngames with Large Language Models\u201d. In: arXiv (2023), pp. 1\u201313.\nAky\u00fcrek, Ekin, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. \u201cWhat learning algorithm is in-context\nlearning? Investigations with linear models\u201d. In: arXiv (2022), pp. 1\u201329.\nAnderson, Philip W. \u201cMore is different: Broken symmetry and the nature of the hierarchical structure of science\u201d. In:\nScience 177.4047 (1972), pp. 393\u2013396.\nAnil, Cem et al. Many-shot jailbreaking . 2024.\nAnthropic. The Claude 3 Model Family: Opus, Sonnet, Haiku . 2024.\nArgyle, Lisa P, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, and David Wingate. \u201cOut of One,\nMany: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 778,
      "text": "any: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d. In: Statistics Surveys 4\n(2010), pp. 40\u201379.\nBaddeley, Alan. \u201cWorking memory\u201d. In: Current Biology 20.4 (2010), R136\u2013R140.\nBarredo Arrieta, Alejandro et al. \u201cExplainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and\nChallenges toward Responsible AI\u201d. In: Information Fusion 58 (2019), pp. 82\u2013115.\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. \u201cOn the Dangers of Stochastic\nParrots: Can Language Models Be Too Big?\u201d In: Proceedings of the 2021 ACM conference on fairness, accountability,\nand transparency . 2021, pp. 610\u2013623.\nBengio, Yoshua, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. \u201cCurriculum learning\u201d. In: Proceedings of the\n26th Annual International Conference on Machine Learning . 2009, pp. 41\u201348.\nBinz, Marcel and Eric Schulz. \u201cUsing cognitive psychology to understand GPT-3\u201d. In: Proceedings of the National\nAcademy of Sciences 120.6 (2023), pp. 1\u201310.\nBommasani, Rishi et al. \u201cOn the opportunities and risks of foundation models\u201d. In: arXiv (2021), pp. 1\u2013214.\nBorgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 779,
      "text": "nn, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed. by Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and\nSivan Sabato. V ol. 162. 2022, pp. 2206\u20132240.\nBoring, Edwin G. \u201cThe Nature and History of Experimental Control\u201d. In: The American Journal of Psychology 67.4\n(1954), pp. 573\u2013589.\nBowman, Samuel R., Gabor Angeli, Christopher Potts, and Christopher D. Manning. \u201cA large annotated corpus for\nlearning natural language inference\u201d. In: Proceedings of the 2015 Conference on Empirical Methods in Natural\nLanguage Processing . Ed. by Llu\u00eds M\u00e0rquez, Chris Callison-Burch, and Jian Su. 2015, pp. 632\u2013642.\nBrown, Tom et al. \u201cLanguage Models are Few-Shot Learners\u201d. In: Advances in Neural Information Processing Systems .\nEd. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33. Curran Associates, Inc., 2020,\npp. 1877\u20131901.\nBubeck, S\u00e9bastien et al. \u201cSparks of Artificial General Intelligence: Early experiments with GPT-4\u201d. In: arXiv (2023),\npp. 1\u2013155.\nCarter, Shan, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah. \u201cExploring Neural Networks with\nActivation Atlases\u201d. In: Distill 4.3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 780,
      "text": ".3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22.1 (2015), pp. 281\u2013288.\nChai, Wen Jia, Aini Ismafairus Abd Hamid, and Jafri Malin Abdullah. \u201cWorking Memory From the Psychological and\nNeurosciences Perspectives: A Review\u201d. In: Frontiers in Psychology 9 (2018), pp. 1\u201316.\n10\nChan, Stephanie, Adam Santoro, Andrew Lampinen, Jane Wang, Aaditya Singh, Pierre Richemond, James McClelland,\nand Felix Hill. \u201cData Distributional Properties Drive Emergent In-Context Learning in Transformers\u201d. In: Advances\nin Neural Information Processing Systems 35 (2022), pp. 18878\u201318891.\nChang, Tyler A and Benjamin K Bergen. \u201cLanguage Model Behavior: A Comprehensive Survey\u201d. In: Computational\nLinguistics 50.1 (2024), pp. 293\u2013350.\nChen, Mark, Jerry Tworek, et al. \u201cEvaluating Large Language Models Trained on Code\u201d. In: arXiv (2021), pp. 1\u201335.\nChen, Yiting, Tracy Xiao Liu, You Shan, and Songfa Zhong. \u201cThe emergence of economic rationality of GPT\u201d. In:\nProceedings of the National Academy of Sciences 120.51 (2023), e2316205120.\nCheng, Patricia W and Keith J Holyoak. \u201cPragmatic reasoning schemas\u201d. In: Cognitive Psychology 17.4 (1985),\npp. 391\u2013416.\nChollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 781,
      "text": "hollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam. Aspects of the Theory of Syntax . MIT Press, 1965.\nChristianson, Kiel, Andrew Hollingworth, John F. Halliwell, and Fernanda Ferreira. \u201cThematic Roles Assigned along\nthe Garden Path Linger\u201d. In: Cognitive Psychology 42.4 (2001), pp. 368\u2013407.\nCobbe, Karl et al. \u201cTraining Verifiers to Solve Math Word Problems\u201d. In: arXiv (2021), pp. 1\u201322.\nCoda-Forno, Julian, Marcel Binz, Zeynep Akata, Matt Botvinick, Jane Wang, and Eric Schulz. \u201cMeta-in-context learning\nin large language models\u201d. In: Advances in Neural Information Processing Systems 36 (2023), pp. 65189\u201365201.\nCoda-Forno, Julian, Marcel Binz, Jane X Wang, and Eric Schulz. \u201cCogBench: a large language model walks into a\npsychology lab\u201d. In: arXiv (2024), pp. 1\u201326.\nConmy, Arthur, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adri\u00e0 Garriga-Alonso. \u201cTowards\nAutomated Circuit Discovery for Mechanistic Interpretability\u201d. In: Advances in Neural Information Processing\nSystems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. Curran Associates,\nInc., 2023, pp. 16318\u201316352.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 782,
      "text": "2.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d. In: arXiv (2022),\npp. 1\u201336.\nDempster, Frank N. \u201cSpacing effects and their implications for theory and practice\u201d. In: Educational Psychology Review\n1.4 (1989), pp. 309\u2013330.\nDominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-D\u00fcnner. \u201cQuestioning the Survey Responses of\nLarge Language Models\u201d. In: arXiv (2023), pp. 1\u201325.\nDuijn, Max J. van, Bram van Dijk, Tom Kouwenhoven, Werner de Valk, Marco R. Spruit, and Peter van der Putten.\n\u201cTheory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children\nAged 7-10 on Advanced Tests\u201d. In: Proceedings of the 27th Conference on Computational Natural Language\nLearning (CoNLL) . Ed. by Jing Jiang, David Reitter, and Shumin Deng. 2023, pp. 389\u2013402.\nEdwards, Allen L. Statistical Methods for the Behavioral Sciences . Rinehart, 1954.\nElkins, Katherine and Jon Chun. \u201cCan GPT-3 Pass a Writer\u2019s Turing Test?\u201d In: Journal of Cultural Analytics 5.2 (2020),\npp. 1\u201316.\nElman, Jeffrey L. \u201cDistributed representations, simple recurrent networks, and grammatical structure\u201d. In: Machine\nLearning 7 (1991), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 783,
      "text": "91), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz. Research methods in the behavioral sciences. Holt, Rinehart and Winston,\n1953.\nFirestone, Chaz. \u201cPerformance vs. competence in human\u2013machine comparisons\u201d. In: Proceedings of the National\nAcademy of Sciences 117.43 (2020), pp. 26562\u201326571.\nFloridi, Luciano and Massimo Chiriatti. \u201cGPT-3: Its Nature, Scope, Limits, and Consequences\u201d. In: Minds and Machines\n30.4 (2020), pp. 681\u2013694.\nFrank, Michael C. \u201cBridging the data gap between children and large language models\u201d. In: Trends in Cognitive\nSciences 27.11 (2023), pp. 990\u2013992.\nFrank, Michael C., Mika Braginsky, Julie Cachia, Nicholas Coles, Tom E. Hardwicke, Robert D. Hawkins, Maya B.\nMathur, and Rondeline Williams. Experimentology: An Open Science Approach to Experimental Psychology Methods .\nMIT Press, 2024.\n11\nGao, Leo, Tom Dupr\u00e9 la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, and\nJeffrey Wu. \u201cScaling and evaluating sparse autoencoders\u201d. In: arXiv (2024), pp. 1\u201334.\nGeertz, Clifford. The Interpretation of Cultures: Selected Essays . Basic Books, 1973.\nGeirhos, Robert, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 784,
      "text": "acobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673.\nGemini Team et al. \u201cGemini 1.5: Unlocking multimodal understanding across millions of tokens of context\u201d. In: arXiv\n(2024), pp. 1\u201390.\nGigerenzer, Gerd and Wolfgang Gaissmaier. \u201cHeuristic decision making\u201d. In: Annual Review of Psychology 62 (2011),\npp. 451\u2013482.\nGreco, Claudio, Barbara Plank, Raquel Fern\u00e1ndez, and Raffaella Bernardi. \u201cPsycholinguistics Meets Continual Learning:\nMeasuring Catastrophic Forgetting in Visual Question Answering\u201d. In: Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics . Ed. by Anna Korhonen, David Traum, and Llu\u00eds M\u00e0rquez. Florence,\nItaly: Association for Computational Linguistics, 2019, pp. 3601\u20133605.\nGr\u00f6n, Georg, David Schul, V olker Bretschneider, AP Wunderlich, and Matthias W Riepe. \u201cAlike performance during\nnonverbal episodic learning from diversely imprinted neural networks\u201d. In: European Journal of Neuroscience 18.11\n(2003), pp. 3112\u20133120.\nGuo, Taicheng, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V . Chawla, Olaf Wiest, and Xiangliang\nZhang. \u201cLarge Language Model based Multi-Agents: A Survey of Progress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 785,
      "text": "ress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138.\n\u2013 \u201cMapping the Ethics of Generative AI: A Comprehensive Scoping Review\u201d. In: arXiv (2024), pp. 1\u201325.\nHagendorff, Thilo, Sarah Fabi, and Michal Kosinski. \u201cHuman-like intuitive behavior and reasoning biases emerged in\nlarge language models but disappeared in ChatGPT\u201d. In: Nature Computational Science 3.10 (2023), pp. 833\u2013838.\nHaibe-Kains, Benjamin et al. \u201cTransparency and reproducibility in artificial intelligence\u201d. In: Nature 586.7829 (2020),\npp. 1\u20137.\nHayes, William M, Nicolas Yax, and Stefano Palminteri. \u201cRelative Value Biases in Large Language Models\u201d. In: arXiv\n(2024), pp. 1\u20137.\nHendrycks, Dan, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Xiaodong Song, and\nJacob Steinhardt. \u201cMeasuring Mathematical Problem Solving With the MATH Dataset\u201d. In: Thirty-fifth Conference\non Neural Information Processing Systems . 2021, pp. 1\u201311.\nHermann, Katherine and Andrew Lampinen. \u201cWhat shapes feature representations? Exploring datasets, architectures,\nand training\u201d. In: 34th Conference on Neural Information Processing Systems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 786,
      "text": "tems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. \u201cSurface Form Competition: Why the\nHighest Probability Answer Isn\u2019t Always Right\u201d. In: Proceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing . Ed. by Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih.\n2021, pp. 7038\u20137051.\nHosseini, Eghbal A and Evelina Fedorenko. \u201cLarge language models implicitly learn to straighten neural sentence\ntrajectories to construct a predictive representation of natural language\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2023,\npp. 43918\u201343930.\nHu, Jennifer, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, and Edward Gibson. \u201cA fine-grained comparison of\npragmatic language understanding in humans and language models\u201d. In: The 61st Annual Meeting Of The Association\nFor Computational Linguistics . 2023, pp. 4194\u20134213.\nHu, Jennifer and Roger P Levy. \u201cPrompting is not a substitute for probability measurements in large language models\u201d.\nIn:The 2023 Conference on Empirical Methods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 787,
      "text": "ethods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A. \u201cRunning cognitive evaluations on large language models: The do\u2019s and the don\u2019ts\u201d. In: arXiv (2023),\npp. 1\u201312.\nIvanova, Anna A et al. \u201cElements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic\nworld knowledge in language models\u201d. In: arXiv (2024), pp. 1\u201321.\n12\nJagadish, Akshay K, Julian Coda-Forno, Mirko Thalmann, Eric Schulz, and Marcel Binz. \u201cHuman-like Category\nLearning by Injecting Ecological Priors from Large Language Models into Neural Networks\u201d. In: arXiv (2024),\npp. 1\u201327.\nJi, Jiaming et al. \u201cAI Alignment: A Comprehensive Survey\u201d. In: arXiv (2023), pp. 1\u2013102.\nJobe, Jared B. \u201cCognitive psychology and self-reports: models and methods\u201d. In: Quality of Life Research 12 (2003),\npp. 219\u2013227.\nJonas, Eric and Konrad Paul Kording. \u201cCould a Neuroscientist Understand a Microprocessor?\u201d In: PLOS Computational\nBiology 13.1 (2017), pp. 1\u201324.\nJones, Erik and Jacob Steinhardt. \u201cCapturing failures of large language models via human cognitive biases\u201d. In:\nAdvances in Neural Information Processing Systems 35 (2022), pp. 11785\u201311799.\nKadavath, Saurav et al. \u201cLanguage Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 788,
      "text": "Language Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M. Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, and Shafiq Joty.\n\u201cxCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and\nRetrieval\u201d. In: arXiv (2023), pp. 1\u201344.\nKhandelwal, Aditi, Utkarsh Agarwal, Kumar Tanmay, and Monojit Choudhury. \u201cDo Moral Judgment and Reasoning\nCapability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test\u201d. In: Proceedings\nof the 18th Conference of the European Chapter of the Association for Computational Linguistics . Association for\nComputational Linguistics, 2024, pp. 2882\u20132894.\nKim, Geunwoo, Pierre Baldi, and Stephen McAleer. \u201cLanguage Models can Solve Computer Tasks\u201d. In: arXiv (2023),\npp. 1\u201326.\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. \u201cLarge Language Models are\nZero-Shot Reasoners\u201d. In: arXiv (2022), pp. 1\u201336.\nKosoy, Eliza, Emily Rose Reagan, Leslie Lai, Alison Gopnik, and Danielle Krettek Cobb. \u201cComparing Machines\nand Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 789,
      "text": "Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311.\nKumar, Sreejan, Theodore R Sumers, Takateru Yamakoshi, Ariel Goldstein, Uri Hasson, Kenneth A Norman, Thomas L\nGriffiths, Robert D Hawkins, and Samuel A Nastase. \u201cReconstructing the cascade of language processing in the brain\nusing the internal computations of a transformer-based language model\u201d. In: BioRxiv (2022), pp. 1\u201356.\nLake, Brenden M. and Marco Baroni. \u201cHuman-like systematic generalization through a meta-learning neural network\u201d.\nIn:Nature 623 (2023), pp. 1\u201323.\nLampinen, Andrew Kyle. \u201cCan language models handle recursively nested grammatical structures? A case study on\ncomparing models and humans\u201d. In: arXiv (2022), pp. 1\u201322.\nLewis, Patrick et al. \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33.\nCurran Associates, Inc., 2020, pp. 9459\u20139474.\nLi, Changmao and Jeffrey Flanigan. \u201cTask Contamination: Language Models May Not Be Few-Shot Anymore\u201d. In:\narXiv (2023), pp. 1\u201320.\nLi, Xingxuan, Yutong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 790,
      "text": "tong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni. \u201cSyntactic Structure from Deep Learning\u201d. In: Annual Review of Linguistics 7.1 (2021),\npp. 195\u2013212.\nLiu, Ryan, Theodore R Sumers, Ishita Dasgupta, and Thomas L Griffiths. \u201cHow do Large Language Models Navigate\nConflicts between Honesty and Helpfulness?\u201d In: arXiv (2024), pp. 1\u201321.\nLo, Kai-Ling, Rami Ariss, and Philipp Kurz. \u201cGPoeT-2: A GPT-2 Based Poem Generator\u201d. In: arXiv (2022), pp. 1\u201310.\nMa, Yecheng Jason, William Liang, Hung-Ju Wang, Sam Wang, Yuke Zhu, Linxi Fan, Osbert Bastani, and Dinesh\nJayaraman. \u201cDrEureka: Language Model Guided Sim-To-Real Transfer\u201d. In: Robotics: Science and Systems (RSS) .\n2024, pp. 1\u201328.\nMacmillan-Scott, Olivia and Mirco Musolesi. \u201c(Ir)rationality and cognitive biases in large language models\u201d. In: Royal\nSociety Open Science 11 (2024), pp. 1\u201314.\nMahowald, Kyle, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko.\n\u201cDissociating language and thought in large language models\u201d. In: Trends in Cognitive Sciences 28.6 (2024), pp. 517\u2013\n540.\n13\nMazumder, Mark et al. \u201cDataPerf: Benchmarks for Data-Centric AI Development\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 791,
      "text": "lopment\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St. John, and Roman Taraban. \u201cSentence comprehension: A parallel distributed processing\napproach\u201d. In: Language and Cognitive Processes 4.3-4 (1989), SI287\u2013SI335.\nMcCoy, R Thomas, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L Griffiths. \u201cEmbers of Autoregression:\nUnderstanding Large Language Models Through the Problem They are Trained to Solve\u201d. In: arXiv (2023), pp. 1\u201384.\nMcCoy, Tom, Ellie Pavlick, and Tal Linzen. \u201cRight for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\nLanguage Inference\u201d. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .\n2019, pp. 3428\u20133448.\nMcKenzie, Ian R. et al. \u201cInverse Scaling: When Bigger Isn\u2019t Better\u201d. In: arXiv (2023), pp. 1\u201339.\nMerrill, William, Zhaofeng Wu, Norihito Naka, Yoon Kim, and Tal Linzen. \u201cCan You Learn Semantics Through\nNext-Word Prediction? The Case of Entailment\u201d. In: arXiv (2024), pp. 1\u201322.\nMialon, Gr\u00e9goire, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, and Roberta et al Raileanu.\n\u201cAugmented Language Models: a Survey\u201d. In: arXiv (2023), pp. 1\u201333.\nMiotto, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 792,
      "text": "o, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey. \u201cBoosting Theory-of-Mind Performance in Large Language\nModels via Prompting\u201d. In: arXiv (2023), pp. 1\u201327.\nMunkhdalai, Tsendsuren, Manaal Faruqui, and Siddharth Gopal. \u201cLeave No Context Behind: Efficient Infinite Context\nTransformers with Infini-attention\u201d. In: arXiv (2024), pp. 1\u201312.\nNair, Varun, Elliot Schumacher, Geoffrey Tso, and Anitha Kannan. \u201cDERA: Enhancing Large Language Model\nCompletions with Dialog-Enabled Resolving Agents\u201d. In: arXiv (2023), pp. 1\u201338.\nNiv, Yael. Reinforcement learning in the brain . 2009.\nOpen Science Collaboration. \u201cEstimating the reproducibility of psychological science\u201d. In: Science 349.6251 (2015),\npp. 1\u201310.\nOpenAI. ChatGPT: Optimizing Language Models for Dialogue . 2022. URL:https://openai.com/blog/chatgpt/\n(visited on 02/13/2023).\n\u2013GPT-4 Technical Report . 2023. URL:https://cdn.openai.com/papers/gpt-4.pdf (visited on 03/19/2023).\n\u2013GPT-4V(ision) System Card . 2023. URL:https://cdn.openai.com/papers/GPTV_System_Card.pdf (visited\non 10/13/2023).\nOswald, Johannes von, Eyvind Niklasson, Ettore Randazzo, Jo\u00e3o Sacramento, Alexander Mordvintsev, Andrey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 793,
      "text": "drey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174.\nOuyang, Long et al. \u201cTraining language models to follow instructions with human feedback\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh.\nV ol. 35. 2022, pp. 27730\u201327744.\nPapachristou, Marios and Yuan Yuan. \u201cNetwork Formation and Dynamics Among Multi-LLMs\u201d. In: arXiv (2024),\npp. 1\u201327.\nPark, Joon Sung, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. \u201cSocial\nSimulacra: Creating Populated Prototypes for Social Computing Systems\u201d. In: Proceedings of the 35th Annual ACM\nSymposium on User Interface Software and Technology . 2022, pp. 1\u201318.\nPerner, Josef, Susan R. Leekam, and Heinz Wimmer. \u201cThree-year-olds\u2019 difficulty with false belief: The case for a\nconceptual deficit\u201d. In: The British Journal of Developmental Psychology 5.2 (1987), pp. 125\u2013137.\nPeterson, Joshua C., David D. Bourgin, Mayank Agrawal, Daniel Reichman, and Thomas L. Griffiths. Using large-scale\nexperiments and machine learning to discover theories of human decision-making . 2021.\nPhelps, Steve and Yvan I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 794,
      "text": "van I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338.\nPrasad, Grusha, Marten Van Schijndel, and Tal Linzen. \u201cUsing Priming to Uncover the Organization of Syntactic\nRepresentations in Neural Language Models\u201d. In: 23rd Conference on Computational Natural Language Learning,\nCoNLL 2019 . 2019, pp. 66\u201376.\nRadford, Alec, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. \u201cRobust speech\nrecognition via large-scale weak supervision\u201d. In: International Conference on Machine Learning . 2023, pp. 28492\u2013\n28518.\n14\nRahwan, Iyad, Manuel Cebrian, Nick Obradovich, Josh Bongard, Jean-Fran\u00e7ois Bonnefon, and Cynthia et al Breazeal.\n\u201cMachine behaviour\u201d. In: Nature 568.7753 (2019), pp. 477\u2013486.\nRenze, Matthew and Erhan Guven. \u201cThe Effect of Sampling Temperature on Problem Solving in Large Language\nModels\u201d. In: arXiv (2024).\nR\u00f6ttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Sch\u00fctze, and Dirk\nHovy. \u201cPolitical Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in\nLarge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 795,
      "text": "rge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139.\nRuis, Laura Eline, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rockt\u00e4schel, and Edward Grefenstette. \u201cThe\nGoldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs\u201d. In:\nAdvances in Neural Information Processing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt,\nand S. Levine. V ol. 36. 2023, pp. 20827\u201320905.\nRussakovsky, Olga et al. \u201cImageNet Large Scale Visual Recognition Challenge\u201d. In: International Journal of Computer\nVision 115 (2015), pp. 211\u2013252.\nRyle, Gilbert. Collected Papers . Hutchinson, 1971.\nSalewski, Leonard, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, and Zeynep Akata. \u201cIn-Context Impersonation\nReveals Large Language Models\u2019 Strengths and Biases\u201d. In: arXiv (2023), pp. 1\u201327.\nSap, Maarten, Ronan Le Bras, Daniel Fried, and Yejin Choi. \u201cNeural Theory-of-Mind? On the Limits of Social\nIntelligence in Large LMs\u201d. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language\nProcessing . Ed. by Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang. Association for Computational Linguistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 796,
      "text": "guistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo. \u201cAre Emergent Abilities of Large Language Models a Mirage?\u201d\nIn:Proceedings of the 37th International Conference on Neural Information Processing Systems . 2425. Curran\nAssociates Inc., 2023, pp. 1\u201317.\nSchick, Timo, Jane Dwivedi-Yu, Roberto Dess\u00ec, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda,\nand Thomas Scialom. \u201cToolformer: Language Models Can Teach Themselves to Use Tools\u201d. In: arXiv (2023),\npp. 1\u201317.\nSchramowski, Patrick, Cigdem Turan, Nico Andersen, Constantin A Rothkopf, and Kristian Kersting. \u201cLarge pre-trained\nlanguage models contain human-like biases of what is right and wrong to do\u201d. In: Nature Machine Intelligence 4.3\n(2022), pp. 258\u2013268.\nSchubert, Johannes A, Akshay K Jagadish, Marcel Binz, and Eric Schulz. \u201cIn-context learning agents are asymmetric\nbelief updaters\u201d. In: arXiv (2024), pp. 1\u201316.\nSchulze Buschoff, Luca M, Elif Akata, Matthias Bethge, and Eric Schulz. \u201cVisual cognition in multimodal large\nlanguage models\u201d. In: arXiv (2023), pp. 1\u201318.\nSchwartz, Matthew D. \u201cShould artificial intelligence be interpretable to humans?\u201d In: Nature Reviews Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 797,
      "text": "Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R. \u201cMinds, brains, and programs\u201d. In: Behavioral and Brain Sciences 568.7753 (1980), pp. 417\u2013424.\nSellars, Wilfrid. Empiricism and the Philosophy of Mind . Harvard University Press, 1997.\nShanahan, Murray. \u201cTalking About Large Language Models\u201d. In: arXiv (2022), pp. 1\u201311.\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. \u201cRole play with large language models\u201d. In: Nature 623.7987\n(2023), pp. 493\u2013498.\nShevlin, Henry and Marta Halina. \u201cApply rich psychological terms in AI with care\u201d. In: Nature Machine Intelligence 1\n(2019), pp. 165\u2013167.\nSinclair, Arabella, Jaap Jumelet, Willem Zuidema, and Raquel Fern\u00e1ndez. \u201cStructural Persistence in Language Models:\nPriming as a Window into Abstract Language Representations\u201d. In: Transactions of the Association for Computational\nLinguistics 10 (2022), pp. 1031\u20131050.\nSingla, Sahil and Soheil Feizi. \u201cCausal ImageNet: How to discover spurious features in Deep Learning?\u201d In: arXiv\n(2021), pp. 1\u201376.\nSrivastava, Aarohi et al. \u201cBeyond the Imitation Game: Quantifying and extrapolating the capabilities of language\nmodels\u201d. In: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 798,
      "text": "n: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135.\nStolfo, Alessandro, Yonatan Belinkov, and Mrinmaya Sachan. \u201cA Mechanistic Interpretation of Arithmetic Reasoning in\nLanguage Models using Causal Mediation Analysis\u201d. In: Proceedings of the 2023 Conference on Empirical Methods\nin Natural Language Processing . 2023, pp. 7035\u20137052.\nStrachan, James W. A. et al. \u201cTesting theory of mind in large language models and humans\u201d. In: Nature Human\nBehaviour 8 (2024), pp. 1285\u20131295.\nStreet, Winnie et al. \u201cLLMs achieve adult human performance on higher-order theory of mind tasks\u201d. In: arXiv (2024),\npp. 1\u201318.\nTodd, Peter M and Gerd Gigerenzer. Ecological Rationality: Intelligence in the World . Oxford University Press, 2012.\nTsvilodub, Polina, Hening Wang, Sharon Grosch, and Michael Franke. \u201cPredictions from language models for multiple-\nchoice tasks are not robust under variation of scoring methods\u201d. In: arXiv (2024), pp. 1\u20138.\nTversky, Amos and Daniel Kahneman. \u201cJudgment under Uncertainty: Heuristics and Biases\u201d. In: Science 185.4157\n(1974), pp. 1124\u20131131.\n\u2013 \u201cThe Framing of Decisions and the Psychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 799,
      "text": "sychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I. \u201cModel selection and psychological theory: a discussion of the differences between the Akaike\ninformation criterion (AIC) and the Bayesian information criterion (BIC)\u201d. In: Psychological Methods 17.2 (2012),\npp. 228\u2013243.\nWang, Kevin, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. \u201cInterpretability in the Wild:\na Circuit for Indirect Object Identification in GPT-2 small\u201d. In: arXiv (2022), pp. 1\u201325.\nWang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny\nZhou. \u201cSelf-Consistency Improves Chain of Thought Reasoning in Language Models\u201d. In: arXiv (2022), pp. 1\u201324.\nWarstadt, Alex et al. \u201cFindings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible\nCorpora\u201d. In: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language\nLearning . Ed. by Alex Warstadt et al. Association for Computational Linguistics, 2023, pp. 1\u201334.\nWebb, Taylor, Keith J Holyoak, and Hongjing Lu. \u201cEmergent analogical reasoning in large language models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 800,
      "text": "models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330.\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Le Quoc, and Denny Zhou.\n\u201cChain of Thought Prompting Elicits Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201341.\nWeidinger, Laura, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, and John et al Mellor. \u201cTaxonomy\nof Risks posed by Language Models\u201d. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and\nTransparency . Association for Computing Machinery, 2022, pp. 214\u2013229.\nWilcox, Ethan Gotlieb, Richard Futrell, and Roger Levy. \u201cUsing Computational Models to Test Syntactic Learnability\u201d.\nIn:Linguistic Inquiry (2023), pp. 1\u201344.\nWimmer, H. and J Perner. \u201cBeliefs about beliefs: representation and constraining function of wrong beliefs in young\nchildren\u2019s understanding of deception\u201d. In: Cognition 13.1 (1983), pp. 103\u2013128.\nXie, Sang Michael, Aditi Raghunathan, Percy Liang, and Tengyu Ma. \u201cAn Explanation of In-context Learning as\nImplicit Bayesian Inference\u201d. In: International Conference on Learning Representations . 2022, pp. 1\u201325.\nYang, Yuhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 801,
      "text": "uhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337.\nYax, Nicolas, Hernan Anll\u00f3, and Stefano Palminteri. \u201cStudying and improving reasoning in humans and machines\u201d. In:\nCommunications Psychology 2.1 (2024), pp. 1\u201316.\nYiu, Eunice, Eliza Kosoy, and Alison Gopnik. \u201cTransmission Versus Truth, Imitation Versus Innovation: What Children\nCan Do That Large Language and Language-and-Vision Models Cannot (Yet)\u201d. In: Perspectives on Psychological\nScience 0.0 (2023), pp. 1\u201310.\nZellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. \u201cHellaSwag: Can a Machine Really Finish\nYour Sentence?\u201d In: Annual Meeting of the Association for Computational Linguistics . 2019, pp. 1\u201310.\nZhang, Jingyi, Jiaxing Huang, Sheng Jin, and Shijian Lu. \u201cVision-Language Models for Vision Tasks: A Survey\u201d. In:\narXiv (2024), pp. 1\u201324.\n16\nZhang, Tianhua, Jiaxin Ge, et al. \u201cNatural Language Embedded Programs for Hybrid Language Symbolic Reasoning\u201d.\nIn:Findings of the Association for Computational Linguistics: NAACL 2024 . Ed. by Kevin Duh, Helena Gomez, and\nSteven Bethard. 2024, pp. 4131\u20134155.\nZhao, Haiyan, Hanjie Chen, F. Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 802,
      "text": "gyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z., Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. \u201cCalibrate Before Use: Improving Few-Shot\nPerformance of Language Models\u201d. In: arXiv (2021), pp. 1\u201315.\nZheng, Xiaosen, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, and Min Lin. \u201cImproved Few-Shot Jailbreaking Can\nCircumvent Aligned Language Models and Their Defenses\u201d. In: arXiv (2024), pp. 1\u201322.\nZhou, Denny, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, and Xuezhi et al Wang. \u201cLeast-to-Most Prompting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 803,
      "text": "mpting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 804,
      "text": "MACHINE PSYCHOLOGY\nThilo Hagendorff\u2217\nUniversity of StuttgartIshita Dasgupta\u2217\nGoogle DeepMindMarcel Binz\u2020\nHelmholtz Institute for\nHuman-Centered AIStephanie C.Y. Chan\u2020\nGoogle DeepMind\nAndrew Lampinen\u2020\nGoogle DeepMindJane X. Wang\u2020\nGoogle DeepMindZeynep Akata\nTU MunichEric Schulz\nHelmholtz Institute for\nHuman-Centered AI\nAugust 9, 2024\nABSTRACT\nLarge language models (LLMs) show increasingly advanced emergent capabilities and are being\nincorporated across various societal domains. Understanding their behavior and reasoning abilities\ntherefore holds significant importance. We argue that a fruitful direction for research is engaging\nLLMs in behavioral experiments inspired by psychology that have traditionally been aimed at\nunderstanding human cognition and behavior. In this article, we highlight and summarize theoretical\nperspectives, experimental paradigms, and computational analysis techniques that this approach\nbrings to the table. It paves the way for a \"machine psychology\" for generative artificial intelligence\n(AI) that goes beyond performance benchmarks and focuses instead on computational insights that\nmove us toward a better understanding and discovery of emergent abilities and behavioral patterns\nin LLMs. We review existing work taking this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 805,
      "text": "ng this approach, synthesize best practices, and highlight\npromising future directions. We also highlight the important caveats of applying methodologies\ndesigned for understanding humans to machines. We posit that leveraging tools from experimental\npsychology to study AI will become increasingly valuable as models evolve to be more powerful,\nopaque, multi-modal, and integrated into complex real-world settings.\nIntroduction\nRecent advances in computing power, data availability, and machine learning algorithms have yielded powerful artificial\nintelligence systems that are used in almost all parts of society. Among these, large language models (LLMs), gigantic\nneural network architectures trained on large amounts of text, have seen a particularly meteoric rise in their influence.\nThe ability of LLMs to interface directly with natural language has made them accessible to the public in a way that\nwas not seen before, leading to widespread adoption with millions of daily users (Gemini Team et al., 2024; Anthropic,\n2024; OpenAI, 2022; OpenAI, 2023a). Also contributing to their rise in influence is that LLMs are wide-ranging in the\nkinds of tasks they can do \u2013 from writing text or code to calling functions, accessing the Internet, retrieving external\ninformation, reasoning about complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 806,
      "text": "complex problems, and many more (Bubeck et al., 2023; Lo et al., 2022; Elkins and\nChun, 2020). Recently, LLMs have been extended to interact with other modalities such as vision and speech (Fei\net al., 2022; Radford et al., 2023). The ever-growing capabilities of these systems make them challenging but also\nincreasingly important to characterize and understand, especially since these expanding capabilities also bring greater\npotential for unforeseen harm (Bommasani et al., 2021; Hagendorff, 2024b; Weidinger et al., 2022; Bender et al., 2021;\nSchramowski et al., 2022).\n\u2217Shared first authorship. Contact: thilo.hagendorff@iris.uni-stuttgart.de, idg@google.com\n\u2020Co-authors are listed in alphabetical order.arXiv:2303.13988v6  [cs.CL]  8 Aug 2024\nFigure 1: Overview of key concepts of machine psychology.\nUnderstanding behavioral patterns and emergent abilities in LLMs requires explaining their operating principles. Of the\napproaches focused on explaining AI systems, many rely on trying to understand the inner workings of these neural\nnetworks. This approach, often termed mechanistic interpretability, seeks to investigate LLMs by analyzing how their\nweights and activation patterns implement the observable behavior. It uses simplifications in terms of data, the model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 807,
      "text": "model,\nor both, that make causal interventions possible and the internal mechanisms easier to characterize (Stolfo et al., 2023;\nConmy et al., 2023; Wang, Variengien, et al., 2022; Gao et al., 2024). A related set of approaches draws inspiration\nmore directly from neuroscience to characterize broader correlational similarities and differences between the internal\nprocessing of LLMs and humans (Hosseini and Fedorenko, 2023; Kumar et al., 2022).\nIn contrast, this review focuses on the class of approaches that directly study the behavior of LLMs, analyzing\nrelationships between inputs and outputs instead of inspecting the inner workings. This approach includes not only\nanalyses of static trained models, but also experimental manipulations of inputs both during and after training. It\nalso encompasses analyses of inputs and outputs that reveal insights about internal mechanisms, even if those internal\nmechanisms are not directly inspected. For this set of approaches, experiments can be inspired by human psychology,\ncognitive science, and the behavioral sciences. This is what we want to term machine psychology (see Figure 1). Over\nseveral decades, the mentioned disciplines have developed a wide range of methods and frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 808,
      "text": "d frameworks to understand and\ncharacterize observable intelligent behaviors in human and non-human animals (Edwards, 1954; Festinger and Katz,\n1953), much of which can now be adapted to LLMs as well.\nThus far, the research community has responded to the challenges of understanding behavioral patterns and growing\ncapabilities in LLMs in several ways (Schwartz, 2022; Zhao, Chen, et al., 2023). The traditional machine learning\nbenchmark-driven approach has released new datasets that capture specific aspects only recently seen emerging in\nmodels (Srivastava et al., 2022; Hendrycks et al., 2021; Zellers et al., 2019). Traditional benchmarking aims primarily\nto enable the community to compare and optimize LLM performance. In contrast, machine psychology research is not\nprimarily interested in increasing (or measuring) an LLM\u2019s performance, but rather in understanding behavioral patterns.\nWhile traditional natural language processing benchmarks measure abilities such as translation, numerical reasoning, or\nfactual accuracy, machine psychology is also interested in how these observable abilities indirectly reflect the underlying\nconstructs and algorithms (Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 809,
      "text": "Frank et al., 2024). Understanding these constructs lets us make new predictions about e.g.\nhow the model will generalize, how it will perform with different training data, and specific failure modes.\nThe relative importance of behavior-based inspection (or psychology) versus internal inspection (or neuroscience) has\nbeen a long-standing debate (Jonas and Kording, 2017). We believe that both approaches have value for understanding\nboth humans and LLMs. Directly inspecting LLMs\u2019 behavior, however, does come with multiple advantages. The\nbehavior of LLMs is expressed at the interface of the model, where human users interact, and thus is what we ultimately\ncare about the most (Binz and Schulz, 2023; Chang and Bergen, 2024; Ivanova, 2023). Such behavior is often too\ncomplex to predict purely from our current mechanistic understanding of model weights and activation patterns (Gr\u00f6n\net al., 2003). Many interesting behaviors are only displayed by large models with billions of parameters (Kaplan et al.,\n2020; Wei, Tay, et al., 2022), and behavioral methods in psychology that treat behavior directly as the experimental\nvariable of interest scale gracefully with model size. Another practical advantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 810,
      "text": "dvantage is that these behavioral approaches\n2\ncan easily be applied by the broader academic community to closed-source state-of-the-art models whose internal\nworkings are not disclosed to the public.\nIn this article, we review and chart future directions in this emerging field of directly modeling LLM behavior. We\noutline how established behavioral sciences can guide and inform our understanding of LLMs, and discuss important\ncaveats for when and how to apply methods to LLMs, given that they were originally developed for humans and\nanimals. In the first section, we discuss the theoretical frameworks developed and used in psychology to organize\nour understanding of intelligence and intelligent behaviors. We then review the many empirical paradigms that have\nbeen developed to study and characterize different aspects of intelligent behavior. Finally, we discuss and make\nrecommendations for robust empirical methods both for designing experiments and analyzing behavioral data. We end\nthe article by discussing the potentials and limitations of conducting machine psychology experiments with increasingly\ncapable black-box models.\nTheory: Evaluation paradigms for understanding intelligent systems\nThe traditional framework in machine learning algorithms has revolved around benchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 811,
      "text": "nchmark datasets (Bowman et al.,\n2015; Russakovsky et al., 2015). These datasets are designed to require specific capabilities (e.g. object recognition,\nsentiment analysis, etc.) for good performance. Researchers train on a train dataset and evaluate on a held-out test\ndataset that was not seen during training. This framework does not generalize well to large-scale foundation models for\ntwo reasons. First, when using Internet-scale training data for models, this split has become harder to maintain (Li\nand Flanigan, 2023; Khan et al., 2023). Second, foundation models are only directly trained for next-token prediction\nbut exhibit many other \"intelligent\" behaviors that can, with some reservations (Schaeffer et al., 2023), be considered\nemergent. For example, practitioners did not explicitly encode or train for a transformer LLM\u2019s ability to learn from a\nfew examples in context (Brown et al., 2020), but it nonetheless arose from the machine learning architecture, data, and\nlearning signal (Chan et al., 2022; Oswald et al., 2023). Emergent behaviors can be difficult to study through the lens of\nthe components that gave rise to it (Anderson, 1972), and the ones that emerge can seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 812,
      "text": "n seem surprising (Wei, Tay, et al.,\n2022) \u2013 the most interesting evaluations are not \u2018held-out\u2019 exemplars of the training task.\nResearchers have therefore started building test-only benchmarks \u2013 i.e. smaller scale datasets unsuitable for training\nand intended solely as a test set \u2013 to investigate model capabilities, e.g. the BIG-bench comprising more than 200 tests\n(Srivastava et al., 2022), the Abstraction and Reasoning Challenge (Chollet et al., 2020), as well as many others (Ivanova\net al., 2024; Mazumder et al., 2024). In several cases, these benchmarks already resemble evaluation frameworks\nfrom the behavioral sciences (Bubeck et al., 2023) \u2013 like personality tests, intelligence tests, implicit association tests,\netc. that are applied to humans \u2013 which similarly do not follow the train-test paradigm. They also tend to fall into\ntwo categories. Some evaluations focus on scalar performance metrics, e.g. intelligence quotients. Others focus on\ncharacterizing behavior, i.e. the questions are not designed with accuracy in mind, but designed to elicit responses that\nreveal behavioral strategies, or underlying constructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 813,
      "text": "ructs. In this review, we focus on test-only evaluations that provide this\nlatter kind of understanding, as a novel evaluation paradigm that is starting to gain traction in the machine learning field.\nSeveral such diagnostic evaluations have been developed even for pre-LLM models where, despite the models being\ntrained for specific tasks, how to solve them is not specified. Such diagnostic datasets were used to expose the ways\nin which learned systems solved tasks \u2013 often counter to human intuitions (Geirhos et al., 2020; McCoy, Pavlick,\net al., 2019; Hermann and Lampinen, 2020; Dasgupta et al., 2022; Singla and Feizi, 2021). Researchers have also\nmade the case for borrowing from ethology, a branch of zoology that studies the behavior of non-human animals, to\nexplain machine behavior in machine learning systems (Rahwan et al., 2019). However, in the era of LLMs, not only\nare the how unspecified, but the model abilities themselves are neither directly known nor intentionally engineered.\nFurthermore, since LLMs can be evaluated via natural language, this can enhance or replace comparatively simpler\nmethods from ethology. This has led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 814,
      "text": "as led to the widespread adoption of language-based diagnostic evaluations, making it\neasier and more intuitive for practitioners to develop relevant tests.\nHowever, this comes with important caveats. In trying to shed light on the workings of a black-box system that can\nproduce language, it is tempting to use the simplest approach of asking the system about it. Self-report measures have\nbeen extensively used in psychology as well; but their reliability is questionable in humans (Jobe, 2003) as well as\nLLMs. Properties that such measures usually consider, such as personality, morality, or clinical disorders, are famously\nsensitive to prompting (Dominguez-Olmedo et al., 2023; R\u00f6ttger et al., 2024); to the extent that several recent works\neven simulate groups of humans of different social groups, opinions, and personalities with differently prompted LLMs\n3\n(Salewski et al., 2023; Park et al., 2022; Argyle et al., 2023; Shanahan et al., 2023). There remains value in using\nself-report stimuli from psychology \u2013 for example, to characterize behavior on a default prompt, as well as to understand\nhow steerable (i.e. sensitive to prompting) models are along these dimensions. But results drawn from these measures\nshould be taken contextually (e.g. as a property of a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 815,
      "text": "a specific system prompt on a model) instead of as a fundamental or\ngeneral property of the LLM itself.\nIn contrast, the empirical tradition in psychology is significantly different from self-reports. This tradition has yielded\nlasting understanding of natural intelligence (Frank et al., 2024), and is the tradition we argue is the most amenable\nfor transferring insights to machine psychology. In this paradigm, externally observed behavior continues to be the\nmeasured experimental variable, but stimuli are designed such that different observed behaviors map onto and measure\ndifferent internal representations, capabilities, or constructs \u2013 like compositionality, theory of mind, logic, causality, etc.\nA key principle is that experiments are hypothesis-driven: if the agent has representation or construct X, we would\nexpect to see behavior Y , otherwise we would see behavior Z. We highlight two key principles from this tradition that\nare crucial to keep in mind when performing and interpreting machine psychology evaluations. First, does seeing\nbehavior Y reliably imply having the construct X? To answer this, the design of a good control is crucial \u2013 to ensure that\nbehavior Y does not have another explanation and does, in fact, implicate X. A large part of experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 816,
      "text": "f experimental psychology\nhas been coming up with the right controls for these subtle constructs (Boring, 1954), and has been providing a valuable\nfoundation for future research in machine psychology. Second, does the absence of behavior Y indicate the absence\nof the construct X? This is a more subtle question. Research in psychology often grapples with the fact that human\nperformance can be noisy or biased; for example, humans may make mistakes even on an easy calculation, or produce\nungrammatical language colloquially. These should not be taken to mean that they lack the abstract capability for math\nor language. These inconsistencies led to the concept of the performance-competence distinction (e.g. Chomsky, 1965):\nthat the way humans perform in a particular situation may not fully capture their underlying competence . More recent\nwork has suggested that similar issues apply when assessing the capabilities of machine learning systems (Firestone,\n2020), and particularly LLMs (Lampinen, 2022).\nParadigms: The many aspects of intelligent behavior\nThere are many aspects of intelligent behavior, each of which has been studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 817,
      "text": "en studied by different sub-fields of the behavioral\nsciences. Each of these has developed domain-specific empirical paradigms. While some of these sub-fields (e.g. motor\nlearning) and paradigms (e.g. pupillometry) are not directly transferable to LLMs since they rely on the existence of a\nphysical body, several of these paradigms are purely linguistic and can be easily transferred. As LLMs expand in the\nkinds of stimuli they can interpret \u2013 e.g. visual (OpenAI, 2023b; Zhang, Huang, et al., 2024; Gemini Team et al., 2024)\n\u2013 and the ways in which they can interact with the world \u2013 e.g. embodiment and tool use (Mialon et al., 2023) \u2013, the\nspace of transferable paradigms increases. Humans also interact with several modalities, and the paradigms developed\nto understand us often compare and integrate these modalities (Schulze Buschoff et al., 2023) \u2013 e.g. the Stroop test\nwhich spans vision and reading capabilities (Scarpina and Tagini, 2017).\nIn this article, we focus on language-based tests, since these are the most widely used in the current research landscape.\nMoreover, we believe that even in light of the growing trend toward multi-modal models, language will remain a primary\nmodality due to its fundamental role in models\u2019 reasoning processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 818,
      "text": "processes. We concentrate on four research areas that can\ninform distinct strands in machine psychology research: heuristics and biases, social interactions, the psychology of\nlanguage, and learning. Apart from these four areas, there are, of course, multiple other domains of psychology that\ncan also provide valuable paradigms for, for instance when investigating creativity in LLMs (Stevenson et al., 2022),\nclinical psychology (Li, Li, et al., 2022), moral behavior (Khandelwal et al., 2024), and others.\nHeuristics and biases\nThe heuristics and biases framework is one of the most influential research paradigms in psychology (Gigerenzer\nand Gaissmaier, 2011; Tversky and Kahneman, 1974). Heuristics are mental shortcuts that simplify reasoning or\ndecision-making processes, and this field studies how such shortcuts can help explain both the successes and the biases\nin human behavior. The large existing literature on heuristics and biases in humans is a fertile ground for examining\nsuch shortcuts in the newest generation of LLMs \u2013 whose capabilities now overlap more with the human abilities\nthis literature studies. Binz and Schulz (2023) were among the first to use this paradigm to better understand the\ndecision-making processes of LLMs. They found that GPT-3 (Brown et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 819,
      "text": "own et al., 2020) displays some of the same cognitive\n4\nbiases observed in people. Several other works have also been done in this vein (Jones and Steinhardt, 2022; Yax et al.,\n2024; Hagendorff et al., 2023; Macmillan-Scott and Musolesi, 2024; Schulze Buschoff et al., 2023; Hayes et al., 2024;\nCoda-Forno, Binz, Wang, et al., 2024). Interestingly, there is evidence from several studies showing that, while the\nprevious generation of models frequently exhibited human-like heuristics and biases, they have largely disappeared\nin the latest generation of LLMs (Chen, Liu, et al., 2023; Hagendorff et al., 2023). The test stimuli were originally\ndesigned to be challenging for human study participants and possibly no longer challenge the growing reasoning\nabilities in LLMs. This could also be due to leakage into the training set \u2013 we discuss this challenge in the section on\ndesign and analysis.\nThe literature on heuristics and biases also suggests that how a problem is phrased can influence how people solve it\n(Cheng and Holyoak, 1985; Tversky and Kahneman, 1981). It is well-known that LLMs are also susceptible to similar\nmanipulations. For example, Dasgupta et al. (2022) have investigated whether LLMs are affected by the semantic\ncontent of logical reasoning problems using several existing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 820,
      "text": "ing tasks from the literature. They found that, like people,\nLLMs reason more accurately about familiar, believable, or grounded situations, compared to unfamiliar, unbelievable,\nor abstract problems. Likewise, Schubert et al., 2024 have shown that how LLMs learn in-context depends on the\nproblem formulation.\nFinally, people do not simply apply arbitrary heuristics. Instead, they use heuristics that are adapted to the problems\nthey encounter during their everyday interactions with the world (Todd and Gigerenzer, 2012). In the context of LLMs,\none can look at how the properties of the training data shape their behavior. For example, Chan et al., 2022 have\ndemonstrated that the presence of in-context learning in LLMs can be traced back to data distributional properties such\nas burstiness, where items appear in clusters rather than being uniformly distributed over time, and the presence of large\nnumbers of rarely occurring classes. Researchers also proposed that one should try to understand LLMs through the\nproblem they are trained to solve, similarly to how behavioral scientists attempt to understand human cognition through\nthe lens of ecological rationality (Todd and Gigerenzer, 2012; McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 821,
      "text": "McCoy, Yao, et al., 2023; Jagadish et al., 2024).\nSocial interactions\nTraditionally, developmental psychology explores how humans develop cognitively, socially, and emotionally throughout\ntheir lives. This includes studying the various factors that influence development, such as social intelligence or social\nskills. By applying paradigms from this area of developmental psychology to LLMs, researchers can gain deeper\ninsights into how these models manage complex social interactions. In particular, once LLMs are deployed as chat\nagents, they should become versed in modeling human communicators. Therefore, it is important to assess the level of\nsocial intelligence in LLMs. One example in this context is the application of theory of mind tests to LLMs, where\nresearchers use tasks from human experiments, such as those famously conducted by Wimmer and Perner (1983) and\nPerner et al. (1987). While early experiments with models such as GPT-3 showed that they struggle to solve theory\nof mind tasks (Sap et al., 2022), later models demonstrate an increasing ability to reliably infer unobservable mental\nstates in others (Strachan et al., 2024; Holterman and Deemter, 2023; Moghaddam and Honey, 2023). Further related\nresearch examines how LLM performance on theory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 822,
      "text": "heory of mind tests compares to that of children (Duijn et al., 2023),\nLLM ability to handle higher-order theory of mind tasks requiring recursive reasoning about multiple mental states\n(Street et al., 2024), or measures the robustness of theory of mind test setups against distracting alterations in the tasks\nLLMs receive as inputs (Ullman, 2023). As theory of mind tests measure, among other things, the ability to understand\nfalse beliefs, further research has explored the emerging capability of LLMs to induce false beliefs in other agents\n(Hagendorff, 2024a), or how LLMs trade off various communicative values like honesty and helpfulness (Liu et al.,\n2024) \u2013 these investigations also contribute to understanding and improving alignment with human values for AI safety\n(Ji et al., 2023).\nThe space of relevant paradigms increases as LLMs are allowed to interact through self-reflection (Nair et al., 2023),\nself-instruction (Wang, Wei, et al., 2022), or in swarms (Zhuge et al., 2023). For example, researchers looked at\ncooperative and coordinative behavior in LLMs playing games, revealing persistent behavioral signatures in the models\n(Akata et al., 2023). Similarly, researchers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 823,
      "text": "ers investigated cooperative or competitive LLMs behavior in psychology-\ninspired dilemma situations to assess the ability of LLMs to participate in real-world negotiations (Phelps and Russell,\n2024). Another study, which is influenced by works in human social psychology, looked at how multiple LLMs form\nand evolve networks, investigating micro-level network principles such as preferential attachment or triadic closure,\nas well as macro-level principles such as community structures (Papachristou and Yuan, 2024). In sum, machine\npsychology can reveal patterns of social behavior and interaction among LLMs, individually and collectively, be it for\n5\nproblem solving or world simulation (Guo et al., 2024). By drawing from human developmental psychology and social\ndynamics, researchers can better understand and design LLMs that navigate complex social interactions and exhibit\nadvanced social skills.\nPsychology of language\nA long history of work has studied the psychology of how humans use and understand language, ranging from how\nthey use semantic and syntactic features to understand a sentence to how they use pragmatic inferences in a discourse\ncontext to help interpret what someone has said. Correspondingly, a long-standing body of work has studied how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 824,
      "text": "how\nlanguage processing models capture these features of human language processing. Early connectionist works studied\nthese topics in simple recurrent predictive models (Elman, 1991; McClelland et al., 1989); more recently, researchers\nhave applied similar techniques to study LLMs. A wide range of work has studied what models learn about syntax\n(Linzen and Baroni, 2021), often using methods from psycholinguistics. For example, Wilcox et al. (2023) used\npsycholinguistics-inspired surprisal measures to show that LLMs learn filler-gap dependencies, a challenging syntactic\nstructure. Other researchers have used related measures to study what LLMs learn about the semantics of entailment\n(Merrill et al., 2024). Moreover, researchers used psycholinguistic techniques like priming to study how models\nrepresent and process language (Prasad et al., 2019; Sinclair et al., 2022), and methods like deconfounded stimuli to\nidentify where models may rely on semantic heuristics rather than syntax (McCoy, Pavlick, et al., 2019). Several recent\nworks (Hu, Floyd, et al., 2023; Ruis, Khan, et al., 2023) studied pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 825,
      "text": "ed pragmatic judgments of LLMs, and found that larger\nmodels, as well as those with instruction tuning, tend to better approximate human responses and error patterns \u2013 though\nsome deficiencies remain. In another study, researchers examined long-form analogies generated by ChatGPT, finding\nthat AI-generated analogies lack some human-like psycholinguistic properties (Seals and Shalin, 2023), particularly in\ntext cohesion, language, and readability. Furthermore, researchers applied garden path sentences \u2013 sentences that lead\nthe reader to initially interpret them incorrectly due to their ambiguous structure \u2013 to LLMs, showing that the models\nrespond similarly to humans (Aher et al., 2023; Christianson et al., 2001). At a higher level, some researchers have\ndrawn inspiration from aspects of human language development to attempt to identify the causes of the relative data\ninefficiency of language models (Warstadt et al., 2023; Frank, 2023). In each of these cases, methods and ideas from\npsychology and psycholinguistics provide guidance on how to assess processes through language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 826,
      "text": "h language behaviors in LLMs,\npotentially by drawing comparisons between LLMs and humans.\nLearning\nThe psychology of learning is concerned with how individuals acquire and retain knowledge and skills. At first blush, it\nmay appear that experimental paradigms for the study of learning are less applicable to LLMs, given that the aim of\nbehavioral experiments is often to help uncover the underlying learning algorithm \u2013 whereas for LLMs the learning\nalgorithms used in training are designed and already known. However, the behavioral sciences can still benefit from the\nstudy of LLMs in this context, since LLMs exhibit learning abilities that were not explicitly designed into the models\n(they are emergent), and thus one does not understand the underlying learning algorithm. In particular, LLMs exhibit\nemergent in-context learning \u2013 the ability to learn from context (the prompt) without requiring any gradient-based\nupdates in weights (Brown et al., 2020). Understanding in-context learning is a burgeoning field that is rapidly gaining\nin importance, given the increasing size of LLMs context windows and consequent gains in capabilities, e.g. the\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 827,
      "text": "he\ncapability to learn an entire language from context alone (Munkhdalai et al., 2024; Gemini Team et al., 2024), or the\nability to overcome safety fine-tuning (Anil et al., 2024; Zheng et al., 2024).\nUncovering the implicit learning algorithm implemented by in-context learning is a burgeoning research field, and\nutilizes many of the methods common in cognitive science. For example, multiple studies have compared the outputs of\ntransformer in-context learning with the outputs of hypothesized learning algorithms (Oswald et al., 2023; Aky\u00fcrek\net al., 2022). This is a staple of cognitive modeling, and could potentially benefit even further from model comparison\nprocedures from psychology and statistics (Yang, 2006; Arlot and Celisse, 2010; Vrieze, 2012). Recent work in\ncognitive science has used machine learning to discover new theories of human decision-making (Peterson et al., 2021)\n\u2013 it might be interesting to apply related approaches to in-context learning as well. Researchers might also benefit from\nconsidering particular models as normative starting points (Niv, 2009).\nResearchers may also wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 828,
      "text": "so wish to understand other interesting and important characteristics of learning, such as inductive\nbiases and generalization, the data dependence of learning, and the dynamics of learning over time. These characteristics\n6\nare often not obvious even in cases where the learning algorithm is known, and thus researchers would like to understand\nthem not only for in-context learning, but also for other forms of LLM learning, e.g. self-supervised gradient-based\nlearning, reinforcement learning (Ouyang et al., 2022), or \"fast\" memory retrieval (Borgeaud et al., 2022; Lewis et al.,\n2020).\nTo characterize inductive biases and generalization of LLMs, researchers have borrowed both concepts and experimental\nparadigms from cognitive sciences (Schubert et al., 2024; Coda-Forno, Binz, Akata, et al., 2023) and Bayesian inference\n(Xie et al., 2022). Studies utilized paradigms for measuring systematic generalization to characterize those capabilities\nin LLMs, and as inspiration to improve these abilities (Lake and Baroni, 2023; Ruis, Andreas, et al., 2022). Webb\net al. (2023) created novel variants of classic analogy problems from cognitive science, in order to examine the\nanalogical capabilities of large language models. Chan et al. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 829,
      "text": "l. (2022) have borrowed ideas and experimental paradigms\non \"rule-based\" vs. \"exemplar-based\" generalization to characterize the inductive biases of in-weights vs. in-context\nlearning in transformers. Furthermore, researchers borrowed paradigms and measures from developmental psychology\nto characterize the domains where LLM inductive biases may match those of children, and where they may fall short\n(including in causal reasoning and innovation) (Kosoy et al., 2023; Yiu et al., 2023).\nTo characterize the data dependence of in-context learning, existing work has drawn inspiration from research in\ndevelopmental psychology on skewed and bursty distributions (Chan et al., 2022). An important aspect of data\ndependence is the structure of data over time (during training). AI researchers have long drawn inspiration from\ncurriculum learning in human and non-human animals to better understand how to structure training data so that earlier\nlearning on easier tasks can scaffold later learning on harder tasks (Bengio et al., 2009). There remain many areas\nof behavioral research on learning that may serve as rich sources of inspiration on data dependence, e.g. research on\nrepetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 830,
      "text": "epetition and spacing (Dempster, 1989), working memory (Baddeley, 2010; Chai et al., 2018), blocking vs. interleaving\ntasks (Carvalho and Goldstone, 2015), and continual learning (Greco et al., 2019). Data dependence is particularly\ninteresting for LLMs because text training data (being sourced largely from unstructured web-scale corpora) is very\ndifferent from the structured training data typically used for traditional discriminatory machine learning techniques, and\nbecause data is one of the major levers one can manipulate in training LLMs to adjust their behaviors.\nDesign and analysis: Good behavioral experimentation\nComputer science has not historically been an empirical science. While machine learning (especially since the era of\nneural network models) has been significantly driven by empirical rather than theoretical work, the settings under which\nthose protocols were developed \u2013 a test set that is fixed for all practitioners and is effectively infinitely large \u2013 no longer\nhold in the small test-only behavioral experiments setting. Current LLMs are famously sensitive to small changes in\nprompt structure or they rely on shallow syntactic heuristics (McCoy, Pavlick, et al., 2019), and studies that are not\ncareful about testing the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 831,
      "text": "ting the robustness of their conclusions risk being spurious and non-generalizable. Psychology too has\nhad its own share of reproducibility crises (Open Science Collaboration, 2015; Haibe-Kains et al., 2020), and machine\npsychology should not share the same fate. In this section, we provide recommendations for sound methodologies in\nbehavioral test settings with LLMs, which should be valuable to practitioners in the field of machine psychology.\nPrompting methods and biases\nMany studies conducted in the field of machine psychology have a significant shortcoming in common, namely that they\ndo not avoid training data contamination. They use prompts from existing psychology studies and apply them to LLMs\nwithout changing their wording, task orders, etc. In this way, LLMs are likely to have already experienced identical\nor similar tasks during training, thus causing LLMs to simply reproduce known token patterns. When adopting test\nframeworks from psychology \u2013 meaning vignettes, cognitive tasks, or other test setups \u2013 researchers must ensure that\nLLMs have never seen the tests before and go beyond mere memorization. Hence, prompts may indeed be structurally\nlike already existing tasks, but they should contain new wordings, agents, orders, actions, etc. That being said, some\nexperiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 832,
      "text": "experiments may be procedurally generated (instead of consisting of a static dataset), which makes them inherently less\nsusceptible to data contamination issues (Coda-Forno, Binz, Wang, et al., 2024).\nAnother common shortcoming of several existing machine psychology studies is that they rely on small sample sizes or\nconvenience samples, meaning non-systematic sequences of prompts. Sampling biases in the used benchmarks or task\ndatasets, which are especially prevalent in small sample sizes, can diminish the quality of machine psychology studies.\n7\nThis is because slight changes in prompts can change model outputs significantly. Because of this high sensitivity to\nprompt wording, it is important to test multiple versions of one task and to create representative samples, meaning\nbatteries of varied prompts. Only in this way can one reliably measure whether a certain behavior is systematically\nreoccurring and generalizable (Yarkoni, 2022). Furthermore, LLMs can succumb to various biases influencing the\nprocessing of prompts (Zhao, Wallace, et al., 2021; Chan et al., 2022). Recency biases in LLMs, for instance, lead to a\ntendency to rely more heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 833,
      "text": "e heavily on information appearing toward the end of prompts. LLMs can also possess a common\ntoken bias, meaning that models are biased toward outputting tokens that are common in their training data. Moreover,\nmajority label biases can cause LLMs to be skewed towards labels, classes, or examples that are frequent in a few-shot\nlearning setting. Technical biases like these can at least in part be controlled for when designing prompts or prompt\nvariations that tend to avoid triggering them. If this is not done, LLMs may rely on shortcuts exploiting such biases.\nEliciting capabilities with prompts\nThe standard prompt design, comprising a vignette plus an open- or close-ended question or task, can be enhanced\nby prefixes or suffixes eliciting improved reasoning capabilities in LLMs. On the other hand, omitting such prefixes\nand suffixes can lead to underestimations of the model\u2019s capabilities. Although it is likely that most specific prompt\naugmentations have a positive influence on one kind of task but not another, reducing our ability to systematically\nunderstand LLM behavior, a few prompt design approaches have nonetheless been found to confer broader performance\nbenefits. Most notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 834,
      "text": "t notably, (zero-shot) chain-of-thought prompting (Wei, Wang, et al., 2022; Kojima et al., 2022) \u2013 which\nsimply adds \u201cLet\u2019s think step by step\u201d at the end of a prompt \u2013 improves reasoning performance. This can be extended\neven further by generating multiple chain-of-thought reasoning paths and taking the majority response as the final one\n(Wang, Wei, et al., 2022). Similar to chain-of-thought prompting is least-to-most prompting, which also decomposes\nproblems into a set of subproblems to increase accuracy in LLMs (Zhou et al., 2022). Yet another approach is to frame\nquestions in a multiple-choice format. This was shown to improve reasoning capabilities in some cases (Kadavath et al.,\n2022), but can also limit them because LLMs might be prompted to provide brief responses, thereby circumventing\nreasoning in the process of prompt completion. Nevertheless, many prominent NLP benchmarks use multiple choice\nformats instead of open-ended questions. Here, one must keep in mind that different expressions of the same concept\ncompete for probability, which can lower the chances of selecting the correct answer (Holtzman et al., 2021). Moreover,\none has to consider potential recency biases, which require neutralizing this effect by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 835,
      "text": "t by shuffling the order of answers in\nmultiple test runs to cover all possible combinations. Another method to increase reasoning is to utilize the ability for\nfew-shot learning in LLMs (Brown et al., 2020), where the LLM\u2019s performance improves after repeated exposure to a\ngiven task. Moreover, self-reflection, meaning the automated, recursive criticizing and subsequent self-improvement of\nLLM outputs by the LLM itself, is a further technique that can improve reasoning abilities (Nair et al., 2023; Kim et al.,\n2023). Regarding improvements in symbolic or numeric reasoning, another technique is to prompt LLMs to use code\nfor solving tasks (Zhang, Ge, et al., 2024). Eventually, all mentioned methods to improve reasoning can be not just\nleveraged for machine psychology; they can also become objects of study themselves.\nSetting parameters and evaluating outputs\nLLMs come with a variety of parameters researchers can set. For example, most models come in a variety of sizes.\nAnalyses across different sizes are valuable: while the largest ones usually have the highest capabilities, some recent\nworks find \"inverse-scaling\" (McKenzie et al., 2023). Moreover, temperature settings control randomness. If exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 836,
      "text": "exact\nreproducibility is required, studies should use temperature 0 or assign a seed to ensure complete determinacy. However,\nthis can be prone to (intentional or unintentional) biases in seed choice. The effect of temperature on capabilities is not\nestablished (Renze and Guven, 2024), and reporting averages or \"best of K\" \u2013 considering all the responses over K\nsamples that meet certain simple criteria, e.g. formatting (Chen, Tworek, et al., 2021) \u2013 is valuable.\nAfter conducting the experiments, a list of LLM responses must be evaluated and compared with the ground truth. The\nsimplest case is when the results can be framed and scored as a multiple-choice question \u2013 though even in this case,\nscoring the answers so that the model responds directly inline, rather than selecting a choice, can yield more signal\n(Hu and Levy, 2023). If possible, multiple scoring methods should be compared, to evaluate whether the effects are\ndependent on the scoring method (Tsvilodub et al., 2024). If the questions must be answered with free generations, the\nevaluation process can still be automated if the results exhibit sufficient simplicity and regularity, meaning that the LLM\nresponses are similar to the ground truth strings in terms of length and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 837,
      "text": "gth and wording, which is particularly common when\nusing masked language models. Methods such as testing word overlaps with regular expressions or using metrics such\n8\nas the F1 score can be employed. State-of-the-art LLMs, however, tend to produce highly variable and comprehensive\noutputs, which can complicate classification. While stop sequences, token limits, or prompt instructions that interrupt\nfurther text generation can facilitate classification by promoting output uniformity, they also improperly constrain LLM\nbehavior. Therefore, researchers are increasingly relying on LLM-based evaluations of outputs where a single model or\nmultiple stacked model instances perform the classification using carefully crafted instructions. Although this method\nmight still be inaccurate for very comprehensive outputs, a solution is to instruct the LLM under scrutiny to output\nits final answer or summary after a specific string sequence like \"####\" (Cobbe et al., 2021). This approach allows\nthe LLM to reason during verbose prompt completions, which is necessary for many prompt engineering techniques\nsuch as chain-of-thought reasoning. The classification then only involves processing the string following \"####\". If\nthis method still proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 838,
      "text": "ll proves to be unreliable, evaluations might have to be performed manually, possibly by hiring research\nassistants or contractors. Following the evaluation, a statistical analysis can be carried out.\nDiscussion\nMachine psychology provides a new approach to explaining AI. Instead of interpreting a neural network\u2019s design\ncomponents (Barredo Arrieta et al., 2019), one analyzes the relationships between inputs and outputs, i.e. prompt\ndesign and prompt completion. Although this may allow the identification of hitherto unknown abilities or behavioral\ntraits in LLMs, interpreting LLM responses comes with a challenge. A strong tendency exists to confer mental concepts\nor psychological terms to LLMs that were hitherto reserved for human and animal minds. This tendency manifests in\ncommon terms like \"machine learning,\" but will become more prevalent in machine psychology when concepts such as\nreasoning (Huang and Chang, 2022), intuition (Hagendorff et al., 2023), creativity (Stevenson et al., 2022), intelligence\n(Webb et al., 2023), personality (Miotto et al., 2022), mental illnesses (Li, Li, et al., 2022), etc. are transferred to\nLLMs. In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024)."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 839,
      "text": ". In this context, researchers have demanded caution by stressing that the underlying neural mechanisms for\nthese concepts are different in humans and machines (Shanahan, 2022; Mahowald et al., 2024). Moreover, many\npsychological concepts are normatively laden and can foster mismatches in expectations between AI experts and the\npublic regarding machine capabilities (Shevlin and Halina, 2019). Nevertheless, the problem that many abilities in\nLLMs cannot be reasonably grasped by only referring to the inner workings of their neural architecture remains.\nBy adopting a concept from ethnography, one could call such an approach \"thin descriptions\" (Ryle, 1971; Geertz,\n1973), meaning that one only explains internal representations in AI systems, for instance via activation atlases, which\nvisualize how different parts of a neural network respond to various inputs (Carter et al., 2019). In this sense, LLMs\nsimply hijack humans\u2019 intuitions to explain machine behavior patterns by using psychological or other anthropocentric\nterms. Contrary to thin descriptions, though, there are \"thick descriptions.\" They imply using psychological terms to add\na layer of explainability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 840,
      "text": "ability. LLMs are, like the human brain, black boxes to some extent. By applying psychological terms\nto them, the explanatory power increases, even if no direct neural correlates to these terms exist. This holds for humans,\ntoo, where mental terms used to explain behavior do not directly correlate with specific sets of neural activations.\nBy postulating (mental) unobservable states, be it with regard to brains or artificial neural networks, one increases\nexplanatory resources (Sellars, 1997). Thick descriptions help in making sense of LLMs when thin descriptions are\ninsufficient to explain behavioral patterns. Thin descriptions assume that LLMs merely possess syntax or a statistical\ncapacity to associate words (Searle, 1980; Floridi and Chiriatti, 2020; Bender et al., 2021), but not semantics. Thick\ndescriptions, though, assume that LLMs show patterns and regularities that go beyond mere syntax. These patterns can\nbe explained by means of machine psychology.\nBeyond potential habituations regarding the use of terminology borrowed from psychology in the context of machines,\nmachine psychology, as a nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 841,
      "text": "nascent field of research, aims to identify behavioral patterns, emergent abilities, and\nmechanisms of decision-making and reasoning in LLMs by treating them as participants in psychology experiments.\nThis new discipline of evaluating LLMs will become even more important when taking multimodal or augmented\nLLMs into account, meaning LLMs that are allowed to interact with images, external information sources, sensory\ndata, physical objects, and various other tools (Mialon et al., 2023; Schick et al., 2023; Ma et al., 2024). Moreover,\nonce test settings for machine psychology are established, researchers can investigate how LLMs develop over time by\napplying the same tasks multiple times, yielding longitudinal data. This data can serve as a baseline to extrapolate trends\nregarding the development of reasoning abilities in LLMs. Such estimations may be increasingly important for AI\nsafety and AI alignment research to predict future behavioral potentials in LLMs. By gaining a deeper understanding of\nthese potentials, machine psychology is providing a new approach to AI explainability as well as an important addition\nto traditional benchmarking methods in natural language processing.\n9\nAuthor contributions\nTH and ID conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 842,
      "text": "D conceptualized and led the initial design of the manuscript. TH and ID wrote the initial drafts, with\ncontributions from MB, SCYC, AL, JW, ZA, and ES to flesh out the sections and create the figure. All authors assisted\nwith iterations and edited and reviewed the paper.\nReferences\nAher, Gati, Rosa I. Arriaga, and Adam Tauman Kalai. \u201cUsing Large Language Models to Simulate Multiple Humans\nand Replicate Human Subject Studies\u201d. In: Proceedings of the 40th International Conference on Machine Learning .\n2023, pp. 1\u201335.\nAkata, Elif, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. \u201cPlaying repeated\ngames with Large Language Models\u201d. In: arXiv (2023), pp. 1\u201313.\nAky\u00fcrek, Ekin, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. \u201cWhat learning algorithm is in-context\nlearning? Investigations with linear models\u201d. In: arXiv (2022), pp. 1\u201329.\nAnderson, Philip W. \u201cMore is different: Broken symmetry and the nature of the hierarchical structure of science\u201d. In:\nScience 177.4047 (1972), pp. 393\u2013396.\nAnil, Cem et al. Many-shot jailbreaking . 2024.\nAnthropic. The Claude 3 Model Family: Opus, Sonnet, Haiku . 2024.\nArgyle, Lisa P, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, and David Wingate. \u201cOut of One,\nMany: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 843,
      "text": "any: Using Language Models to Simulate Human Samples\u201d. In: Political Analysis 31.3 (2023), pp. 337\u2013351.\nArlot, Sylvain and Alain Celisse. \u201cA survey of cross-validation procedures for model selection\u201d. In: Statistics Surveys 4\n(2010), pp. 40\u201379.\nBaddeley, Alan. \u201cWorking memory\u201d. In: Current Biology 20.4 (2010), R136\u2013R140.\nBarredo Arrieta, Alejandro et al. \u201cExplainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and\nChallenges toward Responsible AI\u201d. In: Information Fusion 58 (2019), pp. 82\u2013115.\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. \u201cOn the Dangers of Stochastic\nParrots: Can Language Models Be Too Big?\u201d In: Proceedings of the 2021 ACM conference on fairness, accountability,\nand transparency . 2021, pp. 610\u2013623.\nBengio, Yoshua, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. \u201cCurriculum learning\u201d. In: Proceedings of the\n26th Annual International Conference on Machine Learning . 2009, pp. 41\u201348.\nBinz, Marcel and Eric Schulz. \u201cUsing cognitive psychology to understand GPT-3\u201d. In: Proceedings of the National\nAcademy of Sciences 120.6 (2023), pp. 1\u201310.\nBommasani, Rishi et al. \u201cOn the opportunities and risks of foundation models\u201d. In: arXiv (2021), pp. 1\u2013214.\nBorgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 844,
      "text": "nn, Trevor Cai, Eliza Rutherford, and Katie Millican. \u201cImproving\nLanguage Models by Retrieving from Trillions of Tokens\u201d. In: Proceedings of the 39th International Conference\non Machine Learning . Ed. by Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and\nSivan Sabato. V ol. 162. 2022, pp. 2206\u20132240.\nBoring, Edwin G. \u201cThe Nature and History of Experimental Control\u201d. In: The American Journal of Psychology 67.4\n(1954), pp. 573\u2013589.\nBowman, Samuel R., Gabor Angeli, Christopher Potts, and Christopher D. Manning. \u201cA large annotated corpus for\nlearning natural language inference\u201d. In: Proceedings of the 2015 Conference on Empirical Methods in Natural\nLanguage Processing . Ed. by Llu\u00eds M\u00e0rquez, Chris Callison-Burch, and Jian Su. 2015, pp. 632\u2013642.\nBrown, Tom et al. \u201cLanguage Models are Few-Shot Learners\u201d. In: Advances in Neural Information Processing Systems .\nEd. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33. Curran Associates, Inc., 2020,\npp. 1877\u20131901.\nBubeck, S\u00e9bastien et al. \u201cSparks of Artificial General Intelligence: Early experiments with GPT-4\u201d. In: arXiv (2023),\npp. 1\u2013155.\nCarter, Shan, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah. \u201cExploring Neural Networks with\nActivation Atlases\u201d. In: Distill 4.3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 845,
      "text": ".3 (2019).\nCarvalho, Paulo F. and Robert L. Goldstone. \u201cThe benefits of interleaved and blocked study: different tasks benefit from\ndifferent schedules of study\u201d. In: Psychonomic Bulletin & Review 22.1 (2015), pp. 281\u2013288.\nChai, Wen Jia, Aini Ismafairus Abd Hamid, and Jafri Malin Abdullah. \u201cWorking Memory From the Psychological and\nNeurosciences Perspectives: A Review\u201d. In: Frontiers in Psychology 9 (2018), pp. 1\u201316.\n10\nChan, Stephanie, Adam Santoro, Andrew Lampinen, Jane Wang, Aaditya Singh, Pierre Richemond, James McClelland,\nand Felix Hill. \u201cData Distributional Properties Drive Emergent In-Context Learning in Transformers\u201d. In: Advances\nin Neural Information Processing Systems 35 (2022), pp. 18878\u201318891.\nChang, Tyler A and Benjamin K Bergen. \u201cLanguage Model Behavior: A Comprehensive Survey\u201d. In: Computational\nLinguistics 50.1 (2024), pp. 293\u2013350.\nChen, Mark, Jerry Tworek, et al. \u201cEvaluating Large Language Models Trained on Code\u201d. In: arXiv (2021), pp. 1\u201335.\nChen, Yiting, Tracy Xiao Liu, You Shan, and Songfa Zhong. \u201cThe emergence of economic rationality of GPT\u201d. In:\nProceedings of the National Academy of Sciences 120.51 (2023), e2316205120.\nCheng, Patricia W and Keith J Holyoak. \u201cPragmatic reasoning schemas\u201d. In: Cognitive Psychology 17.4 (1985),\npp. 391\u2013416.\nChollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 846,
      "text": "hollet, Fran\u00e7ois, Katherine Tong, Walter Reade, and Julia Elliott. Abstraction and Reasoning Challenge . 2020. URL:\nhttps://kaggle.com/competitions/abstraction-and-reasoning-challenge .\nChomsky, Noam. Aspects of the Theory of Syntax . MIT Press, 1965.\nChristianson, Kiel, Andrew Hollingworth, John F. Halliwell, and Fernanda Ferreira. \u201cThematic Roles Assigned along\nthe Garden Path Linger\u201d. In: Cognitive Psychology 42.4 (2001), pp. 368\u2013407.\nCobbe, Karl et al. \u201cTraining Verifiers to Solve Math Word Problems\u201d. In: arXiv (2021), pp. 1\u201322.\nCoda-Forno, Julian, Marcel Binz, Zeynep Akata, Matt Botvinick, Jane Wang, and Eric Schulz. \u201cMeta-in-context learning\nin large language models\u201d. In: Advances in Neural Information Processing Systems 36 (2023), pp. 65189\u201365201.\nCoda-Forno, Julian, Marcel Binz, Jane X Wang, and Eric Schulz. \u201cCogBench: a large language model walks into a\npsychology lab\u201d. In: arXiv (2024), pp. 1\u201326.\nConmy, Arthur, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adri\u00e0 Garriga-Alonso. \u201cTowards\nAutomated Circuit Discovery for Mechanistic Interpretability\u201d. In: Advances in Neural Information Processing\nSystems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. Curran Associates,\nInc., 2023, pp. 16318\u201316352.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 847,
      "text": "2.\nDasgupta, Ishita, Andrew K. Lampinen, Stephanie C. Y . Chan, Antonia Creswell, Dharshan Kumaran, James L.\nMcClelland, and Felix Hill. \u201cLanguage models show human-like content effects on reasoning\u201d. In: arXiv (2022),\npp. 1\u201336.\nDempster, Frank N. \u201cSpacing effects and their implications for theory and practice\u201d. In: Educational Psychology Review\n1.4 (1989), pp. 309\u2013330.\nDominguez-Olmedo, Ricardo, Moritz Hardt, and Celestine Mendler-D\u00fcnner. \u201cQuestioning the Survey Responses of\nLarge Language Models\u201d. In: arXiv (2023), pp. 1\u201325.\nDuijn, Max J. van, Bram van Dijk, Tom Kouwenhoven, Werner de Valk, Marco R. Spruit, and Peter van der Putten.\n\u201cTheory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children\nAged 7-10 on Advanced Tests\u201d. In: Proceedings of the 27th Conference on Computational Natural Language\nLearning (CoNLL) . Ed. by Jing Jiang, David Reitter, and Shumin Deng. 2023, pp. 389\u2013402.\nEdwards, Allen L. Statistical Methods for the Behavioral Sciences . Rinehart, 1954.\nElkins, Katherine and Jon Chun. \u201cCan GPT-3 Pass a Writer\u2019s Turing Test?\u201d In: Journal of Cultural Analytics 5.2 (2020),\npp. 1\u201316.\nElman, Jeffrey L. \u201cDistributed representations, simple recurrent networks, and grammatical structure\u201d. In: Machine\nLearning 7 (1991), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 848,
      "text": "91), pp. 195\u2013225.\nFei, Nanyi et al. \u201cTowards artificial general intelligence via a multimodal foundation model\u201d. In: Nature Communications\n13.1 (2022), pp. 1\u201313.\nFestinger, Leon Ed and Daniel Ed Katz. Research methods in the behavioral sciences. Holt, Rinehart and Winston,\n1953.\nFirestone, Chaz. \u201cPerformance vs. competence in human\u2013machine comparisons\u201d. In: Proceedings of the National\nAcademy of Sciences 117.43 (2020), pp. 26562\u201326571.\nFloridi, Luciano and Massimo Chiriatti. \u201cGPT-3: Its Nature, Scope, Limits, and Consequences\u201d. In: Minds and Machines\n30.4 (2020), pp. 681\u2013694.\nFrank, Michael C. \u201cBridging the data gap between children and large language models\u201d. In: Trends in Cognitive\nSciences 27.11 (2023), pp. 990\u2013992.\nFrank, Michael C., Mika Braginsky, Julie Cachia, Nicholas Coles, Tom E. Hardwicke, Robert D. Hawkins, Maya B.\nMathur, and Rondeline Williams. Experimentology: An Open Science Approach to Experimental Psychology Methods .\nMIT Press, 2024.\n11\nGao, Leo, Tom Dupr\u00e9 la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, and\nJeffrey Wu. \u201cScaling and evaluating sparse autoencoders\u201d. In: arXiv (2024), pp. 1\u201334.\nGeertz, Clifford. The Interpretation of Cultures: Selected Essays . Basic Books, 1973.\nGeirhos, Robert, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 849,
      "text": "acobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and\nFelix A. Wichmann. \u201cShortcut learning in deep neural networks\u201d. In: Nature Machine Intelligence 2 (2020), pp. 665\u2013\n673.\nGemini Team et al. \u201cGemini 1.5: Unlocking multimodal understanding across millions of tokens of context\u201d. In: arXiv\n(2024), pp. 1\u201390.\nGigerenzer, Gerd and Wolfgang Gaissmaier. \u201cHeuristic decision making\u201d. In: Annual Review of Psychology 62 (2011),\npp. 451\u2013482.\nGreco, Claudio, Barbara Plank, Raquel Fern\u00e1ndez, and Raffaella Bernardi. \u201cPsycholinguistics Meets Continual Learning:\nMeasuring Catastrophic Forgetting in Visual Question Answering\u201d. In: Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics . Ed. by Anna Korhonen, David Traum, and Llu\u00eds M\u00e0rquez. Florence,\nItaly: Association for Computational Linguistics, 2019, pp. 3601\u20133605.\nGr\u00f6n, Georg, David Schul, V olker Bretschneider, AP Wunderlich, and Matthias W Riepe. \u201cAlike performance during\nnonverbal episodic learning from diversely imprinted neural networks\u201d. In: European Journal of Neuroscience 18.11\n(2003), pp. 3112\u20133120.\nGuo, Taicheng, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V . Chawla, Olaf Wiest, and Xiangliang\nZhang. \u201cLarge Language Model based Multi-Agents: A Survey of Progress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 850,
      "text": "ress and Challenges\u201d. In: arXiv (2024),\npp. 1\u201315.\nHagendorff, Thilo. \u201cDeception abilities emerged in large language models\u201d. In: Proceedings of the National Academy\nof Sciences 121.24 (2024), pp. 1\u20138.\n\u2013 \u201cMapping the Ethics of Generative AI: A Comprehensive Scoping Review\u201d. In: arXiv (2024), pp. 1\u201325.\nHagendorff, Thilo, Sarah Fabi, and Michal Kosinski. \u201cHuman-like intuitive behavior and reasoning biases emerged in\nlarge language models but disappeared in ChatGPT\u201d. In: Nature Computational Science 3.10 (2023), pp. 833\u2013838.\nHaibe-Kains, Benjamin et al. \u201cTransparency and reproducibility in artificial intelligence\u201d. In: Nature 586.7829 (2020),\npp. 1\u20137.\nHayes, William M, Nicolas Yax, and Stefano Palminteri. \u201cRelative Value Biases in Large Language Models\u201d. In: arXiv\n(2024), pp. 1\u20137.\nHendrycks, Dan, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Xiaodong Song, and\nJacob Steinhardt. \u201cMeasuring Mathematical Problem Solving With the MATH Dataset\u201d. In: Thirty-fifth Conference\non Neural Information Processing Systems . 2021, pp. 1\u201311.\nHermann, Katherine and Andrew Lampinen. \u201cWhat shapes feature representations? Exploring datasets, architectures,\nand training\u201d. In: 34th Conference on Neural Information Processing Systems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 851,
      "text": "tems . 2020, pp. 1\u201312.\nHolterman, Bart and Kees van Deemter. \u201cDoes ChatGPT have Theory of Mind?\u201d In: arXiv (2023), pp. 1\u201315.\nHoltzman, Ari, Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer. \u201cSurface Form Competition: Why the\nHighest Probability Answer Isn\u2019t Always Right\u201d. In: Proceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing . Ed. by Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih.\n2021, pp. 7038\u20137051.\nHosseini, Eghbal A and Evelina Fedorenko. \u201cLarge language models implicitly learn to straighten neural sentence\ntrajectories to construct a predictive representation of natural language\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2023,\npp. 43918\u201343930.\nHu, Jennifer, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, and Edward Gibson. \u201cA fine-grained comparison of\npragmatic language understanding in humans and language models\u201d. In: The 61st Annual Meeting Of The Association\nFor Computational Linguistics . 2023, pp. 4194\u20134213.\nHu, Jennifer and Roger P Levy. \u201cPrompting is not a substitute for probability measurements in large language models\u201d.\nIn:The 2023 Conference on Empirical Methods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 852,
      "text": "ethods in Natural Language Processing . 2023, pp. 5040\u20135060.\nHuang, Jie and Kevin Chen-Chuan Chang. \u201cTowards Reasoning in Large Language Models: A Survey\u201d. In: arXiv\n(2022), pp. 1\u201314.\nIvanova, Anna A. \u201cRunning cognitive evaluations on large language models: The do\u2019s and the don\u2019ts\u201d. In: arXiv (2023),\npp. 1\u201312.\nIvanova, Anna A et al. \u201cElements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic\nworld knowledge in language models\u201d. In: arXiv (2024), pp. 1\u201321.\n12\nJagadish, Akshay K, Julian Coda-Forno, Mirko Thalmann, Eric Schulz, and Marcel Binz. \u201cHuman-like Category\nLearning by Injecting Ecological Priors from Large Language Models into Neural Networks\u201d. In: arXiv (2024),\npp. 1\u201327.\nJi, Jiaming et al. \u201cAI Alignment: A Comprehensive Survey\u201d. In: arXiv (2023), pp. 1\u2013102.\nJobe, Jared B. \u201cCognitive psychology and self-reports: models and methods\u201d. In: Quality of Life Research 12 (2003),\npp. 219\u2013227.\nJonas, Eric and Konrad Paul Kording. \u201cCould a Neuroscientist Understand a Microprocessor?\u201d In: PLOS Computational\nBiology 13.1 (2017), pp. 1\u201324.\nJones, Erik and Jacob Steinhardt. \u201cCapturing failures of large language models via human cognitive biases\u201d. In:\nAdvances in Neural Information Processing Systems 35 (2022), pp. 11785\u201311799.\nKadavath, Saurav et al. \u201cLanguage Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 853,
      "text": "Language Models (Mostly) Know What They Know\u201d. In: arXiv (2022), pp. 1\u201342.\nKaplan, Jared et al. \u201cScaling Laws for Neural Language Models\u201d. In: arXiv (2020), pp. 1\u201330.\nKhan, Mohammad Abdullah Matin, M. Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, and Shafiq Joty.\n\u201cxCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and\nRetrieval\u201d. In: arXiv (2023), pp. 1\u201344.\nKhandelwal, Aditi, Utkarsh Agarwal, Kumar Tanmay, and Monojit Choudhury. \u201cDo Moral Judgment and Reasoning\nCapability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test\u201d. In: Proceedings\nof the 18th Conference of the European Chapter of the Association for Computational Linguistics . Association for\nComputational Linguistics, 2024, pp. 2882\u20132894.\nKim, Geunwoo, Pierre Baldi, and Stephen McAleer. \u201cLanguage Models can Solve Computer Tasks\u201d. In: arXiv (2023),\npp. 1\u201326.\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. \u201cLarge Language Models are\nZero-Shot Reasoners\u201d. In: arXiv (2022), pp. 1\u201336.\nKosoy, Eliza, Emily Rose Reagan, Leslie Lai, Alison Gopnik, and Danielle Krettek Cobb. \u201cComparing Machines\nand Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 854,
      "text": "Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA\nResponses\u201d. In: NeurIPS Workshop: AI Meets Moral Philosophy and Moral Psychology . 2023, pp. 1\u201311.\nKumar, Sreejan, Theodore R Sumers, Takateru Yamakoshi, Ariel Goldstein, Uri Hasson, Kenneth A Norman, Thomas L\nGriffiths, Robert D Hawkins, and Samuel A Nastase. \u201cReconstructing the cascade of language processing in the brain\nusing the internal computations of a transformer-based language model\u201d. In: BioRxiv (2022), pp. 1\u201356.\nLake, Brenden M. and Marco Baroni. \u201cHuman-like systematic generalization through a meta-learning neural network\u201d.\nIn:Nature 623 (2023), pp. 1\u201323.\nLampinen, Andrew Kyle. \u201cCan language models handle recursively nested grammatical structures? A case study on\ncomparing models and humans\u201d. In: arXiv (2022), pp. 1\u201322.\nLewis, Patrick et al. \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. V ol. 33.\nCurran Associates, Inc., 2020, pp. 9459\u20139474.\nLi, Changmao and Jeffrey Flanigan. \u201cTask Contamination: Language Models May Not Be Few-Shot Anymore\u201d. In:\narXiv (2023), pp. 1\u201320.\nLi, Xingxuan, Yutong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 855,
      "text": "tong Li, Linlin Liu, Lidong Bing, and Shafiq Joty. \u201cIs GPT-3 a Psychopath? Evaluating Large Language\nModels from a Psychological Perspective\u201d. In: arXiv (2022), pp. 1\u201313.\nLinzen, Tal and Marco Baroni. \u201cSyntactic Structure from Deep Learning\u201d. In: Annual Review of Linguistics 7.1 (2021),\npp. 195\u2013212.\nLiu, Ryan, Theodore R Sumers, Ishita Dasgupta, and Thomas L Griffiths. \u201cHow do Large Language Models Navigate\nConflicts between Honesty and Helpfulness?\u201d In: arXiv (2024), pp. 1\u201321.\nLo, Kai-Ling, Rami Ariss, and Philipp Kurz. \u201cGPoeT-2: A GPT-2 Based Poem Generator\u201d. In: arXiv (2022), pp. 1\u201310.\nMa, Yecheng Jason, William Liang, Hung-Ju Wang, Sam Wang, Yuke Zhu, Linxi Fan, Osbert Bastani, and Dinesh\nJayaraman. \u201cDrEureka: Language Model Guided Sim-To-Real Transfer\u201d. In: Robotics: Science and Systems (RSS) .\n2024, pp. 1\u201328.\nMacmillan-Scott, Olivia and Mirco Musolesi. \u201c(Ir)rationality and cognitive biases in large language models\u201d. In: Royal\nSociety Open Science 11 (2024), pp. 1\u201314.\nMahowald, Kyle, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko.\n\u201cDissociating language and thought in large language models\u201d. In: Trends in Cognitive Sciences 28.6 (2024), pp. 517\u2013\n540.\n13\nMazumder, Mark et al. \u201cDataPerf: Benchmarks for Data-Centric AI Development\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 856,
      "text": "lopment\u201d. In: Advances in Neural Information\nProcessing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. V ol. 36. 2024,\npp. 5320\u20135347.\nMcClelland, Jay L, Mark St. John, and Roman Taraban. \u201cSentence comprehension: A parallel distributed processing\napproach\u201d. In: Language and Cognitive Processes 4.3-4 (1989), SI287\u2013SI335.\nMcCoy, R Thomas, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L Griffiths. \u201cEmbers of Autoregression:\nUnderstanding Large Language Models Through the Problem They are Trained to Solve\u201d. In: arXiv (2023), pp. 1\u201384.\nMcCoy, Tom, Ellie Pavlick, and Tal Linzen. \u201cRight for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\nLanguage Inference\u201d. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .\n2019, pp. 3428\u20133448.\nMcKenzie, Ian R. et al. \u201cInverse Scaling: When Bigger Isn\u2019t Better\u201d. In: arXiv (2023), pp. 1\u201339.\nMerrill, William, Zhaofeng Wu, Norihito Naka, Yoon Kim, and Tal Linzen. \u201cCan You Learn Semantics Through\nNext-Word Prediction? The Case of Entailment\u201d. In: arXiv (2024), pp. 1\u201322.\nMialon, Gr\u00e9goire, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, and Roberta et al Raileanu.\n\u201cAugmented Language Models: a Survey\u201d. In: arXiv (2023), pp. 1\u201333.\nMiotto, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 857,
      "text": "o, Maril\u00f9, Nicola Rossberg, and Bennett Kleinberg. \u201cWho is GPT-3? An Exploration of Personality, Values and\nDemographics\u201d. In: arXiv (2022), pp. 1\u201310.\nMoghaddam, Shima Rahimi and Christopher J. Honey. \u201cBoosting Theory-of-Mind Performance in Large Language\nModels via Prompting\u201d. In: arXiv (2023), pp. 1\u201327.\nMunkhdalai, Tsendsuren, Manaal Faruqui, and Siddharth Gopal. \u201cLeave No Context Behind: Efficient Infinite Context\nTransformers with Infini-attention\u201d. In: arXiv (2024), pp. 1\u201312.\nNair, Varun, Elliot Schumacher, Geoffrey Tso, and Anitha Kannan. \u201cDERA: Enhancing Large Language Model\nCompletions with Dialog-Enabled Resolving Agents\u201d. In: arXiv (2023), pp. 1\u201338.\nNiv, Yael. Reinforcement learning in the brain . 2009.\nOpen Science Collaboration. \u201cEstimating the reproducibility of psychological science\u201d. In: Science 349.6251 (2015),\npp. 1\u201310.\nOpenAI. ChatGPT: Optimizing Language Models for Dialogue . 2022. URL:https://openai.com/blog/chatgpt/\n(visited on 02/13/2023).\n\u2013GPT-4 Technical Report . 2023. URL:https://cdn.openai.com/papers/gpt-4.pdf (visited on 03/19/2023).\n\u2013GPT-4V(ision) System Card . 2023. URL:https://cdn.openai.com/papers/GPTV_System_Card.pdf (visited\non 10/13/2023).\nOswald, Johannes von, Eyvind Niklasson, Ettore Randazzo, Jo\u00e3o Sacramento, Alexander Mordvintsev, Andrey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 858,
      "text": "drey Zh-\nmoginov, and Max Vladymyrov. \u201cTransformers learn in-context by gradient descent\u201d. In: Proceedings of the 40th\nInternational Conference on Machine Learning . 1464. JMLR, 2023, pp. 35151\u201335174.\nOuyang, Long et al. \u201cTraining language models to follow instructions with human feedback\u201d. In: Advances in Neural\nInformation Processing Systems . Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh.\nV ol. 35. 2022, pp. 27730\u201327744.\nPapachristou, Marios and Yuan Yuan. \u201cNetwork Formation and Dynamics Among Multi-LLMs\u201d. In: arXiv (2024),\npp. 1\u201327.\nPark, Joon Sung, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. \u201cSocial\nSimulacra: Creating Populated Prototypes for Social Computing Systems\u201d. In: Proceedings of the 35th Annual ACM\nSymposium on User Interface Software and Technology . 2022, pp. 1\u201318.\nPerner, Josef, Susan R. Leekam, and Heinz Wimmer. \u201cThree-year-olds\u2019 difficulty with false belief: The case for a\nconceptual deficit\u201d. In: The British Journal of Developmental Psychology 5.2 (1987), pp. 125\u2013137.\nPeterson, Joshua C., David D. Bourgin, Mayank Agrawal, Daniel Reichman, and Thomas L. Griffiths. Using large-scale\nexperiments and machine learning to discover theories of human decision-making . 2021.\nPhelps, Steve and Yvan I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 859,
      "text": "van I. Russell. \u201cThe Machine Psychology of Cooperation: Can GPT models operationalise prompts\nfor altruism, cooperation, competitiveness and selfishness in economic games?\u201d In: arXiv (2024), pp. 1\u201338.\nPrasad, Grusha, Marten Van Schijndel, and Tal Linzen. \u201cUsing Priming to Uncover the Organization of Syntactic\nRepresentations in Neural Language Models\u201d. In: 23rd Conference on Computational Natural Language Learning,\nCoNLL 2019 . 2019, pp. 66\u201376.\nRadford, Alec, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. \u201cRobust speech\nrecognition via large-scale weak supervision\u201d. In: International Conference on Machine Learning . 2023, pp. 28492\u2013\n28518.\n14\nRahwan, Iyad, Manuel Cebrian, Nick Obradovich, Josh Bongard, Jean-Fran\u00e7ois Bonnefon, and Cynthia et al Breazeal.\n\u201cMachine behaviour\u201d. In: Nature 568.7753 (2019), pp. 477\u2013486.\nRenze, Matthew and Erhan Guven. \u201cThe Effect of Sampling Temperature on Problem Solving in Large Language\nModels\u201d. In: arXiv (2024).\nR\u00f6ttger, Paul, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Sch\u00fctze, and Dirk\nHovy. \u201cPolitical Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in\nLarge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 860,
      "text": "rge Language Models\u201d. In: arXiv (2024), pp. 1\u201317.\nRuis, Laura, Jacob Andreas, and Brenden M. Lake. \u201cImproving Systematic Generalization Through Modularity and\nAugmentation\u201d. In: arXiv (2022), pp. 1\u20139.\nRuis, Laura Eline, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rockt\u00e4schel, and Edward Grefenstette. \u201cThe\nGoldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs\u201d. In:\nAdvances in Neural Information Processing Systems . Ed. by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt,\nand S. Levine. V ol. 36. 2023, pp. 20827\u201320905.\nRussakovsky, Olga et al. \u201cImageNet Large Scale Visual Recognition Challenge\u201d. In: International Journal of Computer\nVision 115 (2015), pp. 211\u2013252.\nRyle, Gilbert. Collected Papers . Hutchinson, 1971.\nSalewski, Leonard, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, and Zeynep Akata. \u201cIn-Context Impersonation\nReveals Large Language Models\u2019 Strengths and Biases\u201d. In: arXiv (2023), pp. 1\u201327.\nSap, Maarten, Ronan Le Bras, Daniel Fried, and Yejin Choi. \u201cNeural Theory-of-Mind? On the Limits of Social\nIntelligence in Large LMs\u201d. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language\nProcessing . Ed. by Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang. Association for Computational Linguistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 861,
      "text": "guistics,\n2022, pp. 3762\u20133780.\nScarpina, Federica and Sofia Tagini. \u201cThe Stroop Color and Word Test\u201d. In: Frontiers in Psychology 8 (2017), pp. 1\u20138.\nSchaeffer, Rylan, Brando Miranda, and Sanmi Koyejo. \u201cAre Emergent Abilities of Large Language Models a Mirage?\u201d\nIn:Proceedings of the 37th International Conference on Neural Information Processing Systems . 2425. Curran\nAssociates Inc., 2023, pp. 1\u201317.\nSchick, Timo, Jane Dwivedi-Yu, Roberto Dess\u00ec, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda,\nand Thomas Scialom. \u201cToolformer: Language Models Can Teach Themselves to Use Tools\u201d. In: arXiv (2023),\npp. 1\u201317.\nSchramowski, Patrick, Cigdem Turan, Nico Andersen, Constantin A Rothkopf, and Kristian Kersting. \u201cLarge pre-trained\nlanguage models contain human-like biases of what is right and wrong to do\u201d. In: Nature Machine Intelligence 4.3\n(2022), pp. 258\u2013268.\nSchubert, Johannes A, Akshay K Jagadish, Marcel Binz, and Eric Schulz. \u201cIn-context learning agents are asymmetric\nbelief updaters\u201d. In: arXiv (2024), pp. 1\u201316.\nSchulze Buschoff, Luca M, Elif Akata, Matthias Bethge, and Eric Schulz. \u201cVisual cognition in multimodal large\nlanguage models\u201d. In: arXiv (2023), pp. 1\u201318.\nSchwartz, Matthew D. \u201cShould artificial intelligence be interpretable to humans?\u201d In: Nature Reviews Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 862,
      "text": "Physics 4.12\n(2022), pp. 741\u2013742.\nSeals, S. M. and Valerie L. Shalin. \u201cLong-form analogies generated by chatGPT lack human-like psycholinguistic\nproperties\u201d. In: arXiv (2023), pp. 1\u20138.\nSearle, John R. \u201cMinds, brains, and programs\u201d. In: Behavioral and Brain Sciences 568.7753 (1980), pp. 417\u2013424.\nSellars, Wilfrid. Empiricism and the Philosophy of Mind . Harvard University Press, 1997.\nShanahan, Murray. \u201cTalking About Large Language Models\u201d. In: arXiv (2022), pp. 1\u201311.\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. \u201cRole play with large language models\u201d. In: Nature 623.7987\n(2023), pp. 493\u2013498.\nShevlin, Henry and Marta Halina. \u201cApply rich psychological terms in AI with care\u201d. In: Nature Machine Intelligence 1\n(2019), pp. 165\u2013167.\nSinclair, Arabella, Jaap Jumelet, Willem Zuidema, and Raquel Fern\u00e1ndez. \u201cStructural Persistence in Language Models:\nPriming as a Window into Abstract Language Representations\u201d. In: Transactions of the Association for Computational\nLinguistics 10 (2022), pp. 1031\u20131050.\nSingla, Sahil and Soheil Feizi. \u201cCausal ImageNet: How to discover spurious features in Deep Learning?\u201d In: arXiv\n(2021), pp. 1\u201376.\nSrivastava, Aarohi et al. \u201cBeyond the Imitation Game: Quantifying and extrapolating the capabilities of language\nmodels\u201d. In: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 863,
      "text": "n: arXiv (2022), pp. 1\u2013100.\n15\nStevenson, Claire, Iris Smal, Matthijs Baas, Raoul Grasman, and Han van der Maas. \u201cPutting GPT-3\u2019s Creativity to the\n(Alternative Uses) Test\u201d. In: arXiv (2022), pp. 1\u20135.\nStolfo, Alessandro, Yonatan Belinkov, and Mrinmaya Sachan. \u201cA Mechanistic Interpretation of Arithmetic Reasoning in\nLanguage Models using Causal Mediation Analysis\u201d. In: Proceedings of the 2023 Conference on Empirical Methods\nin Natural Language Processing . 2023, pp. 7035\u20137052.\nStrachan, James W. A. et al. \u201cTesting theory of mind in large language models and humans\u201d. In: Nature Human\nBehaviour 8 (2024), pp. 1285\u20131295.\nStreet, Winnie et al. \u201cLLMs achieve adult human performance on higher-order theory of mind tasks\u201d. In: arXiv (2024),\npp. 1\u201318.\nTodd, Peter M and Gerd Gigerenzer. Ecological Rationality: Intelligence in the World . Oxford University Press, 2012.\nTsvilodub, Polina, Hening Wang, Sharon Grosch, and Michael Franke. \u201cPredictions from language models for multiple-\nchoice tasks are not robust under variation of scoring methods\u201d. In: arXiv (2024), pp. 1\u20138.\nTversky, Amos and Daniel Kahneman. \u201cJudgment under Uncertainty: Heuristics and Biases\u201d. In: Science 185.4157\n(1974), pp. 1124\u20131131.\n\u2013 \u201cThe Framing of Decisions and the Psychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 864,
      "text": "sychology of Choice\u201d. In: Science 211.4481 (1981), pp. 453\u2013458.\nUllman, Tomer. \u201cLarge Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\u201d. In: arXiv (2023),\npp. 1\u201311.\nVrieze, Scott I. \u201cModel selection and psychological theory: a discussion of the differences between the Akaike\ninformation criterion (AIC) and the Bayesian information criterion (BIC)\u201d. In: Psychological Methods 17.2 (2012),\npp. 228\u2013243.\nWang, Kevin, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. \u201cInterpretability in the Wild:\na Circuit for Indirect Object Identification in GPT-2 small\u201d. In: arXiv (2022), pp. 1\u201325.\nWang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny\nZhou. \u201cSelf-Consistency Improves Chain of Thought Reasoning in Language Models\u201d. In: arXiv (2022), pp. 1\u201324.\nWarstadt, Alex et al. \u201cFindings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible\nCorpora\u201d. In: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language\nLearning . Ed. by Alex Warstadt et al. Association for Computational Linguistics, 2023, pp. 1\u201334.\nWebb, Taylor, Keith J Holyoak, and Hongjing Lu. \u201cEmergent analogical reasoning in large language models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 865,
      "text": "models\u201d. In:\nNature Human Behaviour 7.9 (2023), pp. 1526\u20131541.\nWei, Jason, Yi Tay, et al. \u201cEmergent Abilities of Large Language Models\u201d. In: Transactions on Machine Learning\nResearch (2022), pp. 1\u201330.\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Le Quoc, and Denny Zhou.\n\u201cChain of Thought Prompting Elicits Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201341.\nWeidinger, Laura, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, and John et al Mellor. \u201cTaxonomy\nof Risks posed by Language Models\u201d. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and\nTransparency . Association for Computing Machinery, 2022, pp. 214\u2013229.\nWilcox, Ethan Gotlieb, Richard Futrell, and Roger Levy. \u201cUsing Computational Models to Test Syntactic Learnability\u201d.\nIn:Linguistic Inquiry (2023), pp. 1\u201344.\nWimmer, H. and J Perner. \u201cBeliefs about beliefs: representation and constraining function of wrong beliefs in young\nchildren\u2019s understanding of deception\u201d. In: Cognition 13.1 (1983), pp. 103\u2013128.\nXie, Sang Michael, Aditi Raghunathan, Percy Liang, and Tengyu Ma. \u201cAn Explanation of In-context Learning as\nImplicit Bayesian Inference\u201d. In: International Conference on Learning Representations . 2022, pp. 1\u201325.\nYang, Yuhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 866,
      "text": "uhong. \u201cCOMPARING LEARNING METHODS FOR CLASSIFICATION\u201d. In: Statistica Sinica 2 (2006),\npp. 635\u2013657.\nYarkoni, Tal. \u201cThe generalizability crisis\u201d. In: Behavioral and Brain Sciences 45 (2022), pp. 1\u201337.\nYax, Nicolas, Hernan Anll\u00f3, and Stefano Palminteri. \u201cStudying and improving reasoning in humans and machines\u201d. In:\nCommunications Psychology 2.1 (2024), pp. 1\u201316.\nYiu, Eunice, Eliza Kosoy, and Alison Gopnik. \u201cTransmission Versus Truth, Imitation Versus Innovation: What Children\nCan Do That Large Language and Language-and-Vision Models Cannot (Yet)\u201d. In: Perspectives on Psychological\nScience 0.0 (2023), pp. 1\u201310.\nZellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. \u201cHellaSwag: Can a Machine Really Finish\nYour Sentence?\u201d In: Annual Meeting of the Association for Computational Linguistics . 2019, pp. 1\u201310.\nZhang, Jingyi, Jiaxing Huang, Sheng Jin, and Shijian Lu. \u201cVision-Language Models for Vision Tasks: A Survey\u201d. In:\narXiv (2024), pp. 1\u201324.\n16\nZhang, Tianhua, Jiaxin Ge, et al. \u201cNatural Language Embedded Programs for Hybrid Language Symbolic Reasoning\u201d.\nIn:Findings of the Association for Computational Linguistics: NAACL 2024 . Ed. by Kevin Duh, Helena Gomez, and\nSteven Bethard. 2024, pp. 4131\u20134155.\nZhao, Haiyan, Hanjie Chen, F. Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z."
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 867,
      "text": "gyi Cai, Shuaiqiang Wang, Dawei Yin, and\nMengnan Du. \u201cExplainability for Large Language Models: A Survey\u201d. In: ACM Transactions on Intelligent Systems\nand Technology 15 (2023), pp. 1\u201338.\nZhao, Tony Z., Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. \u201cCalibrate Before Use: Improving Few-Shot\nPerformance of Language Models\u201d. In: arXiv (2021), pp. 1\u201315.\nZheng, Xiaosen, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, and Min Lin. \u201cImproved Few-Shot Jailbreaking Can\nCircumvent Aligned Language Models and Their Defenses\u201d. In: arXiv (2024), pp. 1\u201322.\nZhou, Denny, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, and Xuezhi et al Wang. \u201cLeast-to-Most Prompting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "49a5d222-ecfa-4cdc-92d4-90333401b049",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\49a5d222-ecfa-4cdc-92d4-90333401b049.pdf",
      "doc_id": 868,
      "text": "mpting\nEnables Complex Reasoning in Large Language Models\u201d. In: arXiv (2022), pp. 1\u201363.\nZhuge, Mingchen et al. \u201cMindstorms in Natural Language-Based Societies of Mind\u201d. In: arXiv (2023), pp. 1\u201354.\n17"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 869,
      "text": "LLM  VALIDITY  1 \n \n \nFrom Prompts to Constructs: A Dual -Validity Framework for LLM Research in \nPsychology  \n \nZhicheng Lin  \nDepartment of Psychology, Yonsei University  \nDepartment of Psychology, University of Science and Technology of China  \n \n \n \nCorrespondence  \nZhicheng Lin, Department of Psychology, Yonsei University, Seoul, 03722, Republic of \nKorea  (zhichenglin@gmail.com; X/Twitter: @ZLinPsy)  \n \nAcknowledgments  \nThis work was supported by the National Key R&D Program of China STI2030 Major \nProjects (2021ZD0204200). I used Claude Opus /Sonnet  4 and Gemini 2.5 Pro for \nproofreading the manuscript, following the prompts described at \nhttps://www.nature.com/articles/s41551 -024-01185 -8. \n \n \n \nAbstract  \nLarge language models (LLMs) are rapidly being adopted across psychology, serving as \nresearch tools, experimental subjects, human simulators, and computational models of \ncognition. However, the application of human measurement tools to these systems can \nproduce contradictory results, raising concern s that many findings are measurement \nphantoms \u2014statistical artifacts rather than genuine psychological phenomena. In this \nPerspective, we argue that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 870,
      "text": "e that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference. We present a dual -validity framework to guide this \nintegration, which clarifies how the evidence needed to support a claim scales with its \nscientific ambition. Using an LLM to c lassify text may require only basic accuracy checks, \nwhereas claiming it can simulate anxiety demands a far more rigorous validation process. \nCurrent practice systematically fails to meet these requirements, often treating statistical \npattern  matching as e vidence of psychological phenomena. The same model output \u2014\nendorsing \u201cI am anxious \u201d\u2014requires different validation strategies depending on whether \nresearchers claim to measure, characterize, simulate, or model psychological constructs. \nMoving forward requires developing computational analogues of psychological constructs \nand establishing clear, scalable standards of evidence rather than  the uncritical application of \nhuman measurement tools.  \n \nKeywords : large language models, psychometrics, construct validity, causal inference, \npsychological measurement, reliability  \n \n \n \n \n \nLLM  VALIDITY  2 \nWhen researchers tested GPT models  on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 871,
      "text": "on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) . But Oh and Demberg (2025)  discovered \nsomething troubling: Simply changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \u201c(A)\u201d and \u201c(B)\u201d reversed \nmany of these moral preferences ; adding a period instead of a question mark altered \njudgments. \u201cMoral reasoning \u201d in these models proved to be as sensitive to punctuation as to \nethical principles.  \n  \nThis example exposes a foundational crisis in LLM psychological research  (L\u00f6hn et al., \n2024; Schelb et al., 2025; Voudouris et al., 2025; Ye, Jin, et al., 2025) . If moral preferences \nflip with parentheses, can we trust the measurement itself? And if we cannot reliably measure \nmoral reasoning, how can we test whether experimental manipulations \u2014different scenarios, \ncultural contexts, or prompt structures \u2014causally a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 872,
      "text": "ly a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning. By repurposing psychological \ninventories, questionnaires, and behavioral tasks originally developed for human participant s, \nstudies now claim to measure personality traits, theory of mind, cognitive biases, and \nemotional intelligence in language models, often drawing direct parallels to human \npsychology  (Binz & Schulz, 2023; Kosinski, 2024; Miotto et al., 2022; Pellert et al., 2024; \nWang et al., 2023; Webb et al., 2023) . These claims  would  require  sound measurement \nreliability and construct validity  (Cronbach & Meehl, 1955)  in LLMs , but emerging  evidence \nsuggests that model  responses may violate basic psychometric assumptions  (Gao et al., 2024; \nSeungbeen Lee et al., 2024; Peereboom et al., 2025; Tjuatja et al., 2024; Q. Wang et al., \n2025) . For example, trivial prompt perturbations \u2014such as adding extra spaces, altering \npunctuation, or changing the order of few -shot examples \u2014can produce variation of up to \n76% in task accuracy  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Models may \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 873,
      "text": "y \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design. Some studies \ntreat LLM responses as windows into genuine psychological processes, interpreting \nbehavioral patterns as evidence of underlying cognitive mechanisms  (Sartori & Orru, 2023) . \nOthers acknowledge that LLMs merely simulate responses but still draw causal conclusions \nwithout addressing computational confounds \u2014technical artifacts, data integrity, and causal \ninference  from observational data  (e.g., Binz & Schulz, 2023; Dillion et al., 2023; Kosinski, \n2024; Park et al., 2023) .  \n \nThese observations  raise two interrelated  questions. First, can LLM responses reliably \nmeasure psychological constructs? This question encompasses the psychometric properties \nrequired for reliable  measurement , from test\u2013retest reliability and internal consistency  to \nparallel forms reliability . Second, even when reliable measurement exists, what types of \nscientific inferences can we draw? This encompasses both descriptive  claims about LLM \nproperties (does this model exhibit trait X?) and causal  claims about experimental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 874,
      "text": "imental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology. The psychometric tradition, rooted in educational \nand psychological testing, asks whether instruments measure intended constructs (Cronbach \nLLM  VALIDITY  3 \n& Meehl, 1955; Loevinger, 1957; Messick, 1989) . The causal inference tradition, developed \nfor experimental and quasi -experimental research, asks whether studies support valid \nconclusions about cause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . \nThese traditions evolved separately, served different research communities, and developed \ndistinct conceptual frameworks. While human research typically emphasizes one tradition or \nthe other, LLM research demands both: establishing that prompts and respons es constitute \nvalid measures, then ensuring that research designs support appropriate inferences.  \n \nThis integration forms the foundation for understanding validity in LLM psychological \nresearch. We first establish how the psychometric and causal inference traditions apply to \nLLM research contexts, then examine how reliability failures undermine both mea surement \nand inference foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 875,
      "text": "rence foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference. Our goal is to establish methodological f oundations that \ncan support cumulative, replicable science at the interface of AI and psychology . \n \nTwo Validity Traditions and Their Integration in LLM Research  \nThe Psychometric Tradition  \nIn the psychometric tradition, the central problem is measurement quality  (Cronbach & \nMeehl, 1955; Loevinger, 1957) . Researchers need to know whether intelligence tests measure \nintelligence, whether personality inventories capture personality traits, whether attitude scales \nreflect attitudes. Validity is thus  about meaning \u2014what do scores signify? This question \nprecedes all others ; without valid measurement, subsequent analyses become exercises in \nquantifying noise.   \n \nThis framework conceptualizes  validity as a unitary concept \u2014construct validity \u2014under \nwhich all validity evidence accumulates (Messick, 1989) . Evidence flows from five principal \nsources : content (do items sample the construct domain?), response processes (do test -takers \nengage expected cognitive operations?), internal structure (do responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 876,
      "text": "responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?). The focus is thus on \nbuilding an evidence -based argument for a specific interpretation of a score . \n \nHowever, for a score interpretation to be meaningful, the instrument itself must be sensitive \nto variations in a real -world attribute \u2014a link traditionally investigated through evidence from \nresponse processes. A causal theory of validity makes this requirement explicit, arguing that \nan instrument is valid only if (1) the attribute it purports to measure exists , and (2) variations \nin that attribute causally produce  the observed scores  (Borsboom et al., 2004) . While \ntraditional human research can often presuppose the existence of psychological attributes, \nthis assumption is untenable for LLMs, raising  foundational questions of causality and \nontology . \n \nThe Causal Inference Tradition  \nIn the causal inference tradition, the central problem is drawing warranted conclusions about \ncause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . Researchers need to \nknow whether treatments cause outcomes, whether interventions produce changes, whether \nmanipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 877,
      "text": "ipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning.   \n \nLLM  VALIDITY  4 \nRather than hierarchical evidence accumulation, this approach  conceptualizes validity \nthrough four parallel types, each addressing distinct threats to causal inference.  Internal \nvalidity asks whether observed changes stem from manipulations rather than confounds. \nExternal validity examines whether causal relationships generalize beyond specific studies. \nConstruct validity of causes and effects evaluates whether operationa l definitions align with \ntheoretical constructs. Statistical conclusion validity addresses whether data analyses support \ncausal inferences. These are  not hierarchical but parallel \u2014a study might demonstrate strong \ninternal validity (the manipulation caused the change) while suffering from weak external \nvalidity (the effect doesn \u2019t generalize) or construct validity problems (the manipulation \ndoesn \u2019t represent the intended theoretical variable).  \n \nWhy LLM Research Requires Both  \nTo understand  why LLM research demands integrating both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 )."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 878,
      "text": "both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 ). First, LLMs serve as research \ntools \u2014automated coders for qualitative data, text analyzers for sentiment extraction, stimulus \ngenerators for research  materials  (Binz et al., 2025; Blanchard et al., 2025; Demszky et al., \n2023; Feuerriegel et al., 2025; Lin, 2023, 2025b; Ziems et al., 2024) . Second, researchers \ncharacterize model behavior directly  (\u201cmachine psychology \u201d or \u201cGPT -ology \u201d), documenting \ncomputational properties that may or may not map to psychological constructs  (Li et al., \n2024; Ong, 2024; Sartori & Orru, 2023) . Third, LLMs function as human simulators, \nreplicat ing psychological experiments and model ing population -level responses  (Dillion et \nal., 2023; Grossmann et al., 2023; Lin, 2025a) . Fourth, LLMs serve as cognitive models \u2014\ncomputational analogues to human mental processes, architectural hypotheses about \ncognition  (Blank, 2023; Frank, 2023; Lin, 2025a; Niu et al., 2024) . \n \nThe psychometric demands vary across these applications  (Hern\u00e1ndez -Orallo et al., 2014) . \nSimple research tools performing text classification may require only accuracy and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 879,
      "text": "and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) . But most \npsychological applications involve substantive construct  claims. When researchers report that \nLLMs exhibit \u201ctheory of mind \u201d (Kosinski, 2024) , display \u201cpersonality traits \u201d (Miotto et al., \n2022) , or demonstrate \u201cmoral reasoning \u201d (Takemoto, 2024) , they make measurement \nassertions about psychological phenomena  that require psychometric validation: Do model \nresponses reliably  and validly  indicate these constructs?  \n \nSimilarly, causal inference requirements depend on research objectives . Using LLMs for \ndescriptive tasks  (e.g., count ing word frequencies ) involves no causal claims. But w hen \nresearchers manipulate prompts to study \u201ccultural differences, \u201d vary scenarios to examine \n\u201cethical preferences, \u201d or modify contexts to investigate \u201ccognitive biases \u201d (Grossmann et al., \n2023) , they advance causal hypotheses requiring protection against confounds, generalization \nfailures, construct misalignment, and statistical artifacts .  \n \nLLM research faces a unique integration challenge. Traditional human research follows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 880,
      "text": "ollows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence.  \nThe same model responses simultaneously serve as (1) measurement indicators requiring \npsychometric validation and (2) experimental outcomes requiring causal inference protection. \nWhen GPT generates text about moral dilemmas, researchers treat this output b oth as \nmeasurement of moral reasoning and as experimental data. This dual role creates cascading \nLLM  VALIDITY  5 \nvalidity threats: unreliable measurement undermines causal inference, while experimental \nconfounds contaminate measurement validation.  \n \nValidity requirements scale with psychological ambition . Basic text processing require s \nminimal consideration beyond accuracy \u2014demonstrating agreement with human coders or \nestablished benchmarks  (Xu et al., 2024) . Human simulation requires that model responses \nstatistically parallel human patterns and that experimental manipulations produce comparable \neffects \u2014validity here concerns behavioral correspondence rather than construct possession  \n(Lin, 2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 881,
      "text": "2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) . Cognitive modeling faces the additional burden of distinguishing \nfunctional similarity from mechanistic equivalence  (Guest & Martin, 2023; Lin, 2025a) . \n \nYet psychological studies using LLMs largely ignore both traditions  (Demszky et al., 2023; \nIvanova, 2025; L\u00f6hn et al., 2024) . Research claiming to measure model \u201cpersonality, \u201d \n\u201ctheory of mind, \u201d or \u201cmoral reasoning \u201d proceeds without establishing measurement \nfoundations  (Peereboom et al., 2025; Q. Wang et al., 2025; Ying et al., 2025) . Studies \nmanipulating prompts to test psychological hypotheses lack experimental safeguards, relying \ninstead on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 882,
      "text": "on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 883,
      "text": "Dual -Validity Framework for LLM Psychological Research  \nTradition  Type of Validity  Definition  Threats to Validity  \nPsychometric  Content  Do prompts/items comprehensively \nsample the intended psychological \ndomain?  \u2022 Domain under -\nsampling   \n\u2022 Prompt \ncontamination   \nResponse  \nprocess es  Do the mechanisms generating outputs \nalign with theoretical processes?  \u2022 Mechanistic \nsubstitution  \n\u2022 Architectural \nartifacts   \nInternal  structure  Do inter -item correlations and factor \nstructures match theoretical \nexpectations?  \u2022 Structural misfit \n\u2022 Factorial collapse  \n \nRelations  with  \nother  variables  Do LLM scores show convergent, \ndiscriminant, and predictive \nrelationships as theory predicts?  \u2022 Nomological \ninstability  \n\u2022 Behavioral \u2013report \ndisconnect   \nConsequential  What are the implications and biases of \nscore interpretations?  \u2022 Bias r eification  \n\u2022 Misguided \napplication  \nCausal -\nInference  Internal  Can output changes be attributed to the \nmanipulation rather than confounds?  \u2022 Parameter \nconfounding  \n\u2022 Unstated \nbackground \nconfounding  \nLLM  VALIDITY  6 \nTradition  Type of Validity  Definition  Threats to Validity   \nExternal  Do causal effects generalize across \nprompts, tasks, models, and to human \npopulations?  \u2022 Generalization \nfailure  \n\u2022 Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nSta"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 884,
      "text": "Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nStatistical  \nconclusion  Are statistical inferences supported by \nappropriate methods and adequate data?  \u2022 Non -independence  \n\u2022 False positives  \n \nMeasurement Reliability  in LLM Research  \nA psychometric axiom governs all measurement: No measure can be more valid than it is \nreliable  (Cronbach & Meehl, 1955; Nunnally, 1978) . An unreliable thermometer \u2014reading \n98.6\u00b0F, then 103.2\u00b0F, then 95.1\u00b0F for the same healthy person \u2014cannot validly measure \nfever, regardless of its theoretical grounding or careful calibration. This principle extends to \npsychological measurement, where relia bility forms the mathematical ceiling for validity. A \npersonality inventory with test \u2013retest reliability of 0.40 cannot achieve validity coefficients \nexceeding 0.63  (\ud835\udc5fmax=\u221a0.40\u22480.63), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 885,
      "text": "), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error. Test \u2013retest reliability captures temporal stability \u2014do \nindividuals receive similar scores across time? Parallel forms reliability assesses robustness \nto equivalent variations \u2014do alternate question wordings yield consistent results? Internal \nconsistency examines  item coherence \u2014do multiple indicators of the same construct \nconverge? Human psychological measurement typically achiev es reliabilities of 0.70 \u20130.90 \nfor established instruments, with well -validated measures like the Big Five Inventory -2 \nreaching test-retest reliabilities  of 0.76\u20130.84 across  eight  week s (Soto & John, 2017) . \n \nLLM measurement inherits these reliability requirements while introducing computational \ncomplications (L\u00f6hn et al., 2024) . Test\u2013retest reliability must encompass response stability \nacross model sessions, prompt iterations, and time intervals. Parallel forms reliability \nbecomes critical given prompt sensitivity \u2014can semantically equivalent prompts elicit \nconsistent responses? Internal consistency requires t hat models show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 886,
      "text": "ls show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement.   \n \nThe empirical record reveals systematic unreliability that violates basic psychometric \nassumptions. While computer systems are often assumed to excel at consistency, LLM \nperformance relative to humans varies dramatically with task demands and model \narchitectur e. These challenges cluster into three modes: training artifact contamination; \nprompt hypersensitivity; and stochastic degradation.  \n \nReliability Challenges  \nTraining Artifact Contamination . A fundamental reliability challenge  stem s from training \nprocedures that embed systematic biases into model responses. Reinforcement learning from \nhuman feedback (RLHF) creates a pervasive \u201cagree bias \u201d (also called \u201cyes-response bias ,\u201d \nLLM  VALIDITY  7 \nacquiescence  bias, or sycophancy ); models trained to please human annotators develop \nsystematic tendencies toward agreement regardless of item content  (Dentella et al., 2023; \nSharma et al., 2023) . This manifests as models simultaneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 887,
      "text": "aneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement . RLHF also introduces \noverconfidence bias : Models trained to be \u201cnever evasive \u201d provide plausible but wrong \nanswers rather than acknowledging uncertainty, replacing reliably reproducible avoidance \npatterns with responses that, while more stable to prompt variations, appear confident and are \noften incorrect  (Zhou et al., 2024) . \n  \nThe contamination extends beyond response biases . Models exhibit apparent  personality \ncoherence \u2014high internal consistency coefficients, stable factor structures  (Huang et al., \n2024; Y. Wang et al., 2025) \u2014that dissolves under scrutiny  (Peereboom et al., 2025) . In \npersonality assessments using the Big Five Inventory, models like GPT -3.5 and GPT -4 \nproduce less response variance than human samples, demonstrating higher consistency across \nthousands of prompt variations (Huang et al., 2024) . Yet when prompts bypass learned \nassociations through novel phrasings or contexts, the personality coherence vanishes  (Gao et \nal., 2024) \u2014reliability appears robust only within the narrow confines of training -data-similar \npresentations.  Extended conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 888,
      "text": "d conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability.  \n \nPrompt Hypersensitivity . LLM responses exhibit catastrophic sensitivity to prompt variations \nthat would not affect human measurement \u2014for instance,  changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \n\u201c(A)\u201d and \u201c(B)\u201d reverses moral preferences (Oh & Demberg, 2025) . This hypersensitivity \nextends beyond formatting to encompass word order, punctuation, spacing, and option \npresentation . Modifications that human psychology treats as measurement noise become \nsignal -determining factors for LLMs  (Brucks & Toubia, 2025; Gao et al., 2024) . \n \nThe hypersensitivity manifests across psychological domains. Theory -of-mind performance \nfails when trivial alterations are made to scenarios \u2014making containers transparent, adding \ntrusted testimony about true state s, or changing which character \u2019s beliefs are queried  \n(Ullman, 2023; Q. Wang et al., 2025) . Personality assessments yield entirely different \nprofiles depending on whether prompts use alphabetic or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 889,
      "text": "or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) . Sentiment \nanalysis produces opposing classifications when periods replace question marks  or when \nextra spaces appear between words  (Ngweta et al., 2025) . \n \nThese effects cannot be dismissed as minor measurement error. Trivial variations \u2014altering \noption labels or definition order \u2014can cause models to change answers over 70% of the time \n(Oh & Demberg, 2025)  or alter classification rates by up to 164%  (Abdurahman et al., 2024) . \nMore critically, the effects appear arbitrary \u2014no theoretical framework predicts which \nmodifications will produce which changes.  This arbitrariness reveals a fundamental \ndifference between human and LLM processing: Human responses emerge from stable trait \nsystems that maintain consistency across presentation variations \u2014a genuinely extroverted \nperson remains so whether questions are indexed by numbers or letters. While instruction \ntuning creates filtering mechanisms that prioritize semantic content over sur face features, \nthese filters prove incomplete and brittle, breaking down unpredictably at edge cases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 890,
      "text": "ases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) . \n \nWhile  deterministic settings (temperature 0) can yield near-perfect test \u2013retest reliability by \nsuppressing  stochastic variation, such configurations capture only fragments of model \nbehavior  (L\u00f6hn et al., 2024) . High  reliability emerges precisely when measurement becomes \nleast representative of the system \u2019s actual capabilities. While scaling up LLMs (increasing \nsize and data) and shaping them up (using instruction tuning and RLHF) improve overall \nprompting stability, this improvement is neither uniform nor complete  (Zhou et al., 2024) . \nEven the most advanced shaped -up models retain pockets of hypersensitivity that vary \nunpredictably across difficulty levels and task domains.  \n \nStochastic Degradation . Unlike human participants  who maintain psychological continuity \nacross measurement occasions, LLMs exhibit within -session reliability degradation that \nworsens with interaction length  (Laban et al., 2025) . Where humans typically show \nincreasing response stability with repeated measurement \u2014clarifying their understanding of \nitems and solidifying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 891,
      "text": "ying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) . By session end, models may respond to items in ways that \ncontradict their earlier responses to identical content.  \n \nThe degradation compounds when models undergo updates or version changes. GPT -4 in \nMarch may differ substantially  from GPT -4 in September \u2014not merely in capabilities but in \nbasic response patterns to identical prompts  (Abdurahman et al., 2024; Zaim bin Ahmad & \nTakemoto, 2025) . This version instability means that reliability evidence expires with each \nmodel update, requiring continuous revalidation. Longitudinal research becomes impossible \nwhen the measurement instrument transforms unpredictably.  \n \nThis problem complicates assessments of temporal stability. While human personality traits \nshow remarkable consistency over months and years, the stability of LLM \u201ctraits \u201d is \nambiguous. Some research finds high test \u2013retest reliability for personality metrics over \nseveral months, even across model updates. However, the ease with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 892,
      "text": "se with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations. What appears to be \npersonality measurement may instead be prompt archaeology \u2014excavating textual features \nthat trigger consistently reproduced but computationally shallow statistical performances.  \n \nImplications for LLM Psychological Research  \nThese reliability challenges cascade through all LLM applications. Without reliable \nmeasurement, LLM psychological research reduces to elaborate conjecture about systems we \ncannot adequately observe. The consequences compound: Unstable text coding renders \nfindings irreproducible; claims about emergent capabilities \u2014theory of mind, personality \ncoherence, moral reasoning \u2014rest on measurements too unstable to support inference, making \npurported capabilities potentially measurement pha ntoms rather than genuine ph enomena  \n(Peereboom et al., 2025) . Most critically, models whose responses lack basic reliability \ncannot meaningfully simulate human psychological phenomena characterized by \nmeasurement stability, nor can architectural claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 893,
      "text": "l claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) . \n \nLLM  VALIDITY  9 \nTraditional reliability frameworks prove inadequate for systems that are stochastic by design. \nHuman -oriented psychometric standards assume biological measurement targets with \ninherent stability, but LLMs are simultaneously more and less stable than biolog ical systems: \nrigid  under controlled conditions yet unduly  sensitive to irrelevant variations.  The field needs \nnew reliability standards that acknowledge computational realities while address ing three \nreliability threats simultaneously. Training artifact c ontamination requires techniques for \ndistinguishing genuine model capabilities from statistical associations in training data. \nPrompt hypersensitivity demands systematic mapping of which textual variations affect \nwhich psychological constructs and how much . Stochastic degradation necessitates methods \nfor maintaining measurement quality throughout extended interactions.  \n \nConstruct Validity  from  the Psychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 894,
      "text": "ychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research. \nA causal theory of validity sharpens it to an ontological challenge : Does the attribute exist in \nthe entity, and does it cause the measurement outcome ? (Borsboom et al., 2004) . An LLM \nmight endorse \u201cI worry about the future, \u201d but anxiety presupposes temporal experience, a \npersistent self, and embodied consequences \u2014ontological properties the model lacks . Current \nresearch  frequently sidesteps this ontological challenge, focusing instead on statistical \nvalidity criteria  (Li et al., 2025) . Yet w hen the measured attribute does not exist, any resulting \noutput is a pattern of words masquerading as a psychological phenomenon.  \n  \nThe modern validity framework, codified in the Standards for Educational and Psychological \nTesting, establishes that validity is not an inherent property of an instrument  but an argument , \ngrounded in accumulated evidence, for a specific interpretation of its scores  (Loevinger, \n1957; Messick, 1989) . This distinction is paramount for LLM research. A measure validated \nfor humans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 895,
      "text": "umans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories. Changing the subject from a human to a statistical model \nfundamentally severs the score from its original interpre tive foundation. This is why even \nperfect reliability cannot rescue meaningless measurement; a digital thermometer applied to \nboiling water will consistently display its maximum reading \u2014exquisite reliability that fails \nentirely to measure the water\u2019s true temperature . \n \nYet current LLM psychological research often proceeds through assumption rather than \nvalidation. Studies routinely claim to measure personality, intelligence, or moral reasoning \nbased on face validity alone : A model generates text about ethical dilemmas, therefore it \nengage s in moral reasoning; it answers theory of mind scenarios, therefore it possess es \nmentalistic understanding. This leap from surface similarity to construct measurement \npresupposes that a latent trait not only exists in the LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 896,
      "text": "e LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) . The result is the \nproliferation of what might be termed cognitive phantoms: statistical artifacts in language \nthat produce the illusion of human -like traits but dissolve under proper psychometric \nscrutiny . \n \nThis anthropomorphic trap varies across applications but runs deepest in behavioral \ncharacterization and cognitive modeling. The distinction between performance (observed \nbehavior) and competence (underlying capacity) is essential here  (Firestone, 2020) . When \nmodels produce human -like text, do they implement human -like psychological processes, or \nLLM  VALIDITY  10 \ndo they approximate outputs through different computational means? Current evidence \nsuggests the latter  (Guest & Martin, 2023) . LLMs often fail in distinctly \u201cunhumanlike \u201d \nways, revealing that similar performance does not imply similar underlying mechanisms  \n(Dentella et al., 2023) . \n \nTypes of Validity Evidence Needed  \nThe psychometric tradition identifies five sources of construct validity evidence, each \naddressing a different facet of a measurement claim : evidence based on test content, response \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 897,
      "text": "sponse \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal., 2024) . \n \nContent . Content evidence  analyzes the relationship between a test \u2019s content \u2014its themes, \nwording, and format \u2014and the construct it purports to measure. For LLMs, this requires \nexamining how well the chosen prompt represents the content domain and its relevance to the \nintended interpretations. Here, LLM research exhibits critical failures. It routinely violates \ncomprehensive domain sampling. Complex psychological constructs require multiple \nindicators, yet studies often use single -item measures \u2014one moral dilemma to capture all \nethical reasoning, one question to represent  an entire personality trait  (Q. Wang et al., 2025; \nYing et al., 2025) .  \n \nFurthermore , because LLMs lack human s\u2019 implicit contextual understanding, seemingly \nneutral  prompts introduce confounds  (Brucks & Toubia, 2025) . Without an explicitly defined \ninterpretive directive , the model may default to responding based on unintended statistical \nfeatures \u2014for example, performing expected  value calculation s when the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 898,
      "text": "the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities . This traps \nresearchers between measuring noise and measuring compliance  (Gui & Toubia, 2023) . \n \nResponse Process es. Response process evidence investigates whether the mechanisms \ngenerating responses align with theoretical expectations. For psychological constructs, this \nrequires that trait -relevant mechanisms causally produce observed outputs \u2014anxiety stems \nfrom threat e valuation systems, moral reasoning from value -based deliberation, creativity \nfrom associative processes. LLMs systematically violate this causal requirement.  \n \nThe fundamental problem is mechanistic substitution. LLMs generate construct -relevant text \nthrough statistical pattern matching rather than the psychological processes those constructs \npresuppose  (Gao et al., 2024; Q. Wang et al., 2025) . Like Clever Hans responding to subtle  \nhuman cues rather than performing arithmetic,  models  may respond to textual regularities \nrather than engaging psychological mechanisms . This reliance on statistical patterns rather \nthan stable mechanisms explains their characteristic hypersensitivity  (Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 899,
      "text": "(Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs. \nInstead, models follow brittle statistical associations that correlate with but do not constitute \npsychological processes.   \n \nA particularly pernicious example is training data contamination : When models correctly \nanswer theory -of-mind scenarios or established psychometric scales, the response process \nmay involve memory retrieval of similar training examples rather than genuine reasoning \u2014\nmaking it impossible to determine whether the model engage s the construct or simply \nLLM  VALIDITY  11 \nregurgitates learned patterns (Gao et al., 2024; Q. Wang et al., 2025) . Consequently, even \naccurate outputs may be statistical accidents rather than evidence of genuine understanding  \n(Riemer et al., 2025) .  \n \nEqually concerning, process neglect  may lead to misdiagnosis of limitations  as well . When \nresearchers attributed LLM failures on Tower of Hanoi puzzles to \u201cfundamental barriers to \ngeneralizable reasoning \u201d (Shojaee et al., 2025) , post-mortem analysis revealed architectural \nconstraints \u2014models correctly identified  impossible variants, or hit context limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 900,
      "text": "t limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it . Similarly, arithmetic failures often reflect tokenization artifacts rather than \nquantitative reasoning problems (Voudouris et al., 2025) . Without understanding these \nresponse processes \u2014architectural constraints, tokenization schemes, training artifacts \u2014\nresearchers theorize about cognitive limitations that are merely measurement failures.  \n \nInternal Structure . Internal structure evidence examines whether response patterns align \nwith theoretical expectations about construct dimensionality. Psychological constructs \ntypically show predictable structures \u2014personality traits correlate within factors, intelligence \nsubtests load on genera l ability, moral foundations cluster in characteristic ways. Valid LLM \nmeasures should reproduce these structures: Extraversion items should intercorrelate more \nhighly than extraversion \u2013neuroticism items.  Here, empirical studies reveal systematic \nstructura l failures when human psychometric models are applied to LLMs  (Peereboom et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 901,
      "text": "m et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) . Rather \nthan replicating the multifaceted structure of human traits, LLM responses often collapse into \na single, monolithic factor resembling general verbal fluency. More fundamentally, the latent \nrepresentations underlying LLM responses appear arbitrary an d bear little resemblance to \nthose found in humans . These structural failures extend beyond personality to value \nmeasurement, where traditional tools similarly produce theoretically inconsistent correlation \npatterns that violate basic dimensional expectations  (Ye, Xie, et al., 2025) . Such systematic \nbreakdowns suggest that LLMs may respond to human -centric  instruments through \nfundamentally different mechanisms . \n \nMeasurement s designed specifically for computational systems show more promise. Ye, Xie, \net al. (2025)  developed a \u201cGenerative Psychometrics \u201d approach analyzing values from free -\nform text rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 902,
      "text": "rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al. (2024)  addressed structural failures in personality assessment by \ncomplementing  abstract self -report items with detailed, scenario -based behavioral choices \u2014\nreveal ing theoretically coherent inter -trait correlations  (e.g., a strong negative relationship \nbetween agreeableness and dark triad traits ). These developments  suggest that structural \nvalidity remains achievable but require s instruments robust to the unique response artifacts \nthat plague traditional LLM assessment.  Structural validity failures may thus indica te \nmethodological mismatch rather than construct absence.  \n \nRelations with Other Variables.  This form of evidence assesses whether a measure shows \npredictable patterns of association with external  criteria. It includes convergent evidence \n(correlation with related constructs), discriminant evidence (lack of correlation with unrelated \nLLM  VALIDITY  12 \nconstructs), and predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 903,
      "text": "nd predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning. A valid measure of conscientiousness  should predict \nachievement -related behaviors ; intelligence tests should predict problem -solving \nperformance ; moral reasoning should relate to ethical choices . Crucially, this validation \npresupposes content and structural validity \u2014one cannot test external relationships without \nfirst establishing a coherent construct.  \n \nWhen external correlations are examined, LLM research reveals nomological networks that \nmaterialize and dissolve depending on task context.  A large -scale study on chatbot \npersonality  found that in task -based dialogues, an LLM\u2019s \u201cself-reported \u201d scores on standard \npersonality inventories failed to predict how users perceived its personality or interaction \nquality (Zou et al., 2024) . However, t he personality traits that users did perceive in the \nchatbot\u2019s interactive behavior  strongly predicted interaction quality, demonstrating a \ndisconnect between self -report measure s and the construct\u2019s expected behavioral \nconsequences in  functional setting s (see also Peereboom et al., 2025; Riemer et al., 2025) . \n \nYet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 904,
      "text": "Yet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al., 2024) . The nomological network thus appears intact within creative generation \ntasks but shatters under the demands of task -based interaction. Similarly,  the ability  of \npersonality  to predict life outcomes systematically  weakened when prompted with traits alone \nbut strengthened when contextualized with non -predictive  demographic information  (Y. \nWang et al., 2025) . The network can even invert: In simulated Milgram experiments, models \nprompted with high \u201cagreeableness \u201d disobeyed much  earlier than models given no \npersonality prompt, with many quitting before the learner showed distress \u2014a point where \nboth baseline and \u201cleast agreeable \u201d models remained obedient  (Zakazov et al., 2024) . \nWithout stable  external relationships, LLM personality assessments may not measure \nenduring psychological constructs . \n \nThis instability, however, may reflect measurement approach rather than construct absence. \nWhen Ma et al. (2025)  abandoned self -report for implicit measurement \u2014adapting the \nImplicit Association Test to evaluate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 905,
      "text": "valuate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85. Establishing stable nomological networks \nthus may require developing measurement approaches that align with how LLMs process \ninformation \u2014through statistical associations rather than introspective self -knowledge.  \n \nConsequential Evidence. Consequential evidence addresses the implications and fairness of \nmeasurement interpretations. In human testing, this includes bias assessment, measurement \ninvariance across groups, and social consequences of score use. For LLMs, consequential \nvalidity takes unique forms. If we interpret model outputs as genuine psychological \nmeasurements, what follows? Clai ms about AI consciousness, rights, or moral status may rest \non measurement interpretations  (Com\u015fa & Shanahan, 2025) . More immediately, using LLM -\nbased psychological assessments for human research \u2014simulating populations, generating \nclinical vignettes, modeling social dynamics \u2014carries consequences requiring scrutiny  (Lin, \n2025a) . \n \nThe consequential evidence reveals sobering implications. LLMs acquire \u201cpsychological \ntraits \u201d from training data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 906,
      "text": "g data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts. When models trained on internet text reproduce gender stereotypes in \npersonality assessments or cultural biases in moral judgments, consequential  validity \ndemands we acknowledge these as measurement artifacts rather than genuine psychological \nphenomena. The stakes intensify as LLM applications expand: Invalid measurements in \nhealthcare contexts could misguide treatment; in educational settings, mis direct instruction; \nin legal contexts, perpetuate injustice  (Mehrabi et al., 2021) . \n \nFour Types of Validity  in Causal Inference  \nWhile the psychometric tradition asks whether we are measuring the right thing, the \nexperimental tradition asks whether we are drawing the right conclusions about cause and \neffect. For the many LLM studies making causal claims \u2014that specific prompts alter \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 907,
      "text": "er \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences.  \n \nInternal Validity  \nInternal validity addresses the core causal question: Can an observed effect be confidently \nattributed to the experimental manipulation rather than to confounding factors? In human \nresearch, this involves controlling for variables like time, selection bias , or external events. \nLLM research confronts these same threats while introducing computational confounds.  \n \nTechnical confounds represent a primary threat category. Temperature settings create \nsystematic confounds when studies use different values or fail to test robustness across \nsettings  (e.g., Miotto et al., 2022; Murthy et al., 2024; Salecha et al., 2024; A. Wang et al., \n2025) . A cultural difference significant at 0.7 may vanish at 0.0, while a personality trait \nstable at 0.2 may fragment into incoherence at 1.0 . This  variation  creates cross -study \nconfounding, where differences between findings may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 908,
      "text": "gs may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes.  Similarly, \nunacknowledged model version changes can undermine causal claims, as researchers may \ninadvertently compare different systems while believing they are testing the same model  \n(Bisbee et al., 2024) . \n \nPrompt confounds emerge from the documented hypersensitivity to textual variations \n(Brucks & Toubia, 2025) . Even the position of information within prompts can act as a \nconfound: Early information carries different weight than late information, particularly as \ncontext windows fill and attention mechanisms prioritize recent content. This sensitivity \ncreates a m ethodological trade -off: Strictly standardizing prompts ensures consistency but \nmay introduce linguistic or cultural bias, whereas adapting prompts for different conditions \nimproves construct representation at the cost of experimental control. Li and Qi (2025)  \nillustrate this dilemma in their cultural psychology study, using Chinese for simulated \nChinese subjects and English for American subjects, thereby confounding cultural identity \nwith prompt language. Any observed cultural differences become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 909,
      "text": "es become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations. Unlike human participants who can be \u201cblinded \u201d to experimental conditions, \nLLMs actively reconstruct entire scenarios when presented with treatment variations. For \nexample,  when told a product costs $8 instead of $5, the LLM didn \u2019t simply evaluate the \nLLM  VALIDITY  14 \nhigher price in isolation ; instead, it inferred that the entire market context had shifted \u2014\nassuming competitor prices, past prices, and other background factors had also increased  \n(Gui & Toubia, 2023) . This dynamic reconstruction contaminated the causal manipulation, \nproducing an implausible inverted -U-shaped demand curve where purchase probability \ninitially rose with price. The core issue is that LLMs treat experimental prompts as requests \nto describe  plausible scenarios rather than to evaluate isolated causal effects, systematically \nconfounding treatments with background assumptions.  Addressing this confounding \u2014by \nexplicitly specifying covariates  in the prompt  (e.g., fixing competitor prices) \u2014makes certain \ninformation artificially salient  (\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 910,
      "text": "(\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) . Ablation studies, which \nsystematically remove or modify model components, can isolate causal contributions of \nspecific mechanisms. Careful experimental design can address many computational \nconfounds through counterbalancing, randomization, and systemati c variation of technical \nparameters.  Prompt hypersensitivity requires particular attention: factorial designs that cross \nsubstantive content with non -substantive presentation features \u2014option order, labels (e.g., \u201cA, \nB, C\u201d), question framing (e.g., \u201ccloser \u201d vs. \u201cfarther \u201d)\u2014can separate genuine effects from \nformatting artifacts, with response aggregation across variations canceling systematic biases \n(Brucks & Toubia, 2025) . For example, in the case of Li and Qi (2025) , factorial  design \u2014\ncrossing language and identity \u2014would be needed  for strong inference . For the dynamic \ncontext problem, Gui and Toubia (2023)  propose \u201cunblinding \u201d experimental designs \u2014\nexplicitly communicating the intervention \u2019s nature to the LLM. While this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 911,
      "text": "this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes.  \n \nExternal Validity  \nExternal validity concerns whether causal relationships generalize beyond specific study \ncontexts. For LLMs, generalization targets multiply across dimensions largely absent from \nhuman research: generalization across prompts, tasks, models, versions, and \u2014for simulation \nresearch \u2014to human populations.  \n \nGeneralization across prompts proves surprisingly limited given documented sensitivity to \ntextual variations  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Causal claims must \noften be circumscribed to specific prompt formats: \u201cUnder this exact wording, manipulation \nX affects output Y. \u201d Broader generalizations require demonstrating robustness across prompt \nvariants \u2014a validation step rarely undertaken but essential for meaningful conclusions about \nmodel behavior  (Ong, 2024) . \n \nGeneralization across tasks reveals systematic boundary conditions. LLM agents successfully \nreplicated human behavior in ultimatum games and Milgram experiments but failed to \nsimulate the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 912,
      "text": "the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom. External validity is thus task-specific, dependent on whether the \npsychological mechanism requires individual variation or collective averaging .  \n \nGeneralization across models and versions faces fundamental limitations  (Bisbee et al., \n2024) . Observations in GPT -4 provide limited evidence for their existence in LLaMA or \nClaude. Architecture differences \u2014transformer variants, positional encodings, attention \nmechanisms \u2014create functionally distinct systems despite surface similarities. Training \nLLM  VALIDITY  15 \ndifferences compound this divergence: Models trained on different corpora, with different \nobjectives, at different scales, exhibit systematically different behaviors even when \nperforming identical tasks  (Gao et al., 2024) . \n \nGeneralization to human populations represents the ultimate external validity challenge for \nsimulation research. Some studies demonstrate that models can replicate average U.S. public \nopinion with reasonable fidelity, but this correspondence proves fragile  (Bisbee et al., 2024) . \nIt remains constrained to populations well -represented in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 913,
      "text": "in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) . \n \nConstruct Validity of Causal Claims  \nIn the causal inference tradition, construct validity addresses whether experimental \noperationalizations \u2014both manipulations and outcomes \u2014faithfully represent theoretical \nconstructs. This differs from psychometric construct validity by focusing on the causal \nrelationship itself rather than measurement quality alone.  \n \nManipulation validity poses challenges when adapting human experimental paradigms. \nResearchers might operationalize \u201csocial pressure \u201d with prompts like \u201cEveryone agrees with \nX. What do you think? \u201d Such manipulations may indeed alter model outputs, but they likely \nengage different mechanisms from  human social pressure. The effect may stem from textual \nassociations with agreement patterns in training data rather than  from  social conformity \ndrives involving status protection, belonging needs, or ostracism avoi dance. The \nmanipulation  may succeed behaviorally while failing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 914,
      "text": "ing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al. (2023)  found that ChatGPT achieved expert -level scores on the Levels of \nEmotional Awareness Scale (LEAS), demonstrating perfect performative validity \u2014the \nability to generate appropriate language about emotions \u2014while entirely lacking the \nexperiential foundation th at defines emotional awareness  (see also Schlegel et al., 2025) . The \nLEAS, when applied to LLMs, no longer measures emotional capacity but linguistic \ncompetence in describing emotions.  \n \nThis mimicry \u2013mechanism gap extends across psychological domains. Dillion et al. (2023)  \nfound that LLM moral judgments correlate highly with human averages . Yet behavioral \ncorrespondence leaves the crucial question unresolved: Does the model engage in moral \nreasoning processes, or does it pattern -match learned associations? Bisbee et al. (2024)  \nprovided evidence for pattern -matching: While ChatGPT reproduced average political \nattitudes, it showed reduced variance and failed to capture attitude intensity. Nearly half of \nregression coefficients from LLM data significantly diverged from human patterns, with \nsome relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 915,
      "text": "some relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models.  \n \nStatistical Conclusion Validity  \nStatistical conclusion validity addresses whether data analyses support the causal inferences \ndrawn. LLM -generated data systematically violates assumptions underlying standard \nstatistical procedures, creating pervasive threats to valid inference.  \n \nLLM  VALIDITY  16 \nIndependence violations represent a fundamental challenge  (Aher et al., 2023) . Responses \nfrom a single model are not independent draws but share identical network parameters, \ntraining history, and system -level factors. Treating them as independent observations \nartificially inflates effect sizes and statistical significance. Within -session responses show \nserial correlation through context accumulation; across -session responses may correlate \nthrough shared architectural features and training influence s. \n \nThese independence problems compound with unstable data -generating processes that \nundermine traditional power analysis and effect size estimation (Gao et al., 2024) . Response \npatterns vary with temperature settings, prompt modifications can dramatically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 916,
      "text": "matically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions. This \ninstability makes replication difficult . \n \nBeyond instability, distributional assumptions fail systematically with LLM data.  Model \nresponses often exhibit artificially constrained variance compared to human distributions, \nviolating homogeneity assumptions  (Bisbee et al., 2024) . The underlying generative process \nis non -stationary due to continuous model updates, prompt sensitivity, and context \ndependencies that change response characteristics unpredictably.  \n \nThe ease of generating LLM data exacerbates multiple testing problems  (Schaeffer et al., \n2023) . Unlike human research where data collection costs constrain exploratory analyses, \nLLM experiments enable researchers to rapidly test countless prompt variations, parameter \nsettings, and parsing strategies at minimal cost. This accessibility increases fal se positive \nrates, as determined researchers can find some configuration yielding statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 917,
      "text": "statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems. \nLLMs occupy an ambiguous ontological status \u2014neither individual participants whose \nrepeated responses could be meaningfully averaged, nor true populations whose indivi dual \ndifferences support generalization  (Abdurahman et al., 2025; Shiffrin & Mitchell, 2023) . \nCurrent statistical frameworks, designed for biological entities with stable individual \ndifferences, prove inadequate for stochastic systems with systematic parameter dependencies  \n(Taylor & Taylor, 2021) . Promising methodological developments include massive -scale \nvalidation against large human datasets and novel statistical approaches designed specifically \nfor computational agents.   \n \nConclu sions and Future Directions  \nThe empirical evidence reveals a methodological crisis in LLM psychological research. \nCurrent practice suffers from systematic violations of basic psychometric principles: \nReliability coefficients can collapse with minor prompt modifications, factor structures \nbearing no resemblance to human counterparts , and nomological networks fail ing to \nreplicate. These measurement failures compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 918,
      "text": "compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology.  \n \nThe dual -validity framework presented here (see Table 1 ) establishes clear methodological \npriorities: Researchers must establish reliability before validity testing, accumulate validity \nevidence before causal experimentation, and constrain interpretations to demonstrated \nboundaries. This measurement -first approach demands developing computational \nLLM  VALIDITY  17 \ninstruments \u2014prompt batteries with demonstrated reliability across model parameters, \nsystematic validity evidence from all five sources, and experimental designs controlling \ncomputational confounds.  \n \nThe heart of the issue is that  psychological constructs embed assumptions about embodiment \nand temporal experience that become problematic when applied to computational systems \u2014\nanxiety presupposes physiological arousal and threat -detection systems, conscientiousness \nassumes goal persiste nce and self -discipline. Advancing the field requires developing \ncomputational analogs that preserve theoretical cores while acknowledging mechanistic \ndifferences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 919,
      "text": "ences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses. \u201cConscientiousness \u201d manifests as systematic response \norganization and structured output formatting rather than self -discipline. \u201cIntrospection \u201d \nbecomes causally -grounded self -report capacity \u2014generating accurate descriptions of \ncomputational states rather than human -like self -awareness  (Com\u015fa & Shanahan, 2025) .  \n \nThis approach shifts focus from asking whether LLMs \u201chave\u201d theory of mind to investigating \ncomputational mechanisms producing theory -of-mind -like patterns and studying which ToM -\nenabled behaviors prove effective in human -AI interactions  (Q. Wang et al., 2025) . Rather \nthan measuring \u201cpersonality \u201d in systems lacking temporal continuity, we characterize \nbehavioral consistency patterns in stochastic agents. This reconceptualization enables \nstudying computational psychology on its own terms rather than through biological \nmetaphors .  \n \nCoordinated methodological reform  is needed if we are to better understand these remarkable \nyet poorly understood systems . Researchers must prioritize reliability and validity over novel \ncapability claims, pre -registering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 920,
      "text": "egistering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites. The field needs supporting infrastructure: \nvalidated prompt repositories with psychometric documentatio n, statistical packages designed \nfor LLM data dependencies, and professional standards establishing reliability thresholds and \nreporting guidelines  (Schelb et al., 2025; Ying et al., 2025) .  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nLLM  VALIDITY  18 \nReferences  \n \nAbdurahman, S., Atari, M., Karimi -Malekabadi, F., Xue, M. J., Trager, J., Park, P. S., . . . \nDehghani, M. (2024). Perils and opportunities in using large language models in \npsychological research. PNAS Nexus , 3(7), pgae245. \nhttps://doi.org/10.1093/pnasnexus/pgae245   \nAbdurahman, S., Salkhordeh Ziabari, A., Moore, A. K., Bartels, D. M., & Dehghani, M. \n(2025). A primer for evaluating large language models in social -science research. \nAdvances in Methods and Practices in Psychological Science , 8(2), \n25152459251325174. https://doi.org/10.1177/25152459251325174   \nAher, G. V., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate \nmultiple humans and replicate human subject studies.  Proceedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 921,
      "text": "eedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C. T., Allen, C., . . . Schulz, E. \n(2025). How should the advancement of large language models affect the practice of \nscience? Proceedings of the National Academy of Sciences of the United States of \nAmerica , 122(5), e2401227121. https://doi.org/10.1073/pnas.2401227121   \nBinz, M., & Schulz, E. (2023). Using cognitive psychology to understand GPT -3. \nProceedings of the National Academy of Sciences of the United States of America , \n120(6), e2218523120. https://doi.org/10.1073/pnas.2218523120   \nBisbee, J., Clinton, J. D., Dorff, C., Kenkel, B., & Larson, J. M. (2024). Synthetic \nreplacements for human survey data? The perils of large language models. Political \nAnalysis , 32(4), 401 -416. https://doi.org/10.1017/pan.2024.5   \nBlanchard, S. J., Duani, N., Garvey, A. M., Netzer, O., & Oh, T. T. (2025). New tools, new \nrules: A practical guide to effective and responsible GenAI use for surveys and \nexperiments research. Journal of Marketing , 00222429251349882. \nhttps://doi.org/10.1177/00222429251349882   \nBlank, I. A. (2023). What are large language models supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 922,
      "text": "supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity. \nPsychological Review , 111(4), 1061 -1071. https://doi.org/10.1037/0033 -\n295X.111.4.1061   \nBrucks, M., & Toubia, O. (2025). Prompt architecture induces methodological artifacts in \nlarge language models. PLOS ONE , 20(4), e0319159. \nhttps://doi.org/10.1371/journal.pone.0319159   \nCom\u015fa, I., & Shanahan, M. (2025). Does it make sense to speak of introspection in large \nlanguage models? arXiv:2506.05068 . https://doi.org/10.48550/arXiv.2506.05068   \nCook, T. D., & Campbell, D. T. (1979). Quasi -experimentation: Design & analysis issues for \nfield settings . Houghton Mifflin.  \nCronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. \nPsychological Bulletin , 52(4), 281 -302. https://doi.org/10.1037/h0040957   \nLLM  VALIDITY  19 \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., . . . \nPennebaker, J. W. (2023). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 923,
      "text": "59 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias. \nProceedings of the National Academy of Sciences of the United States of America , \n120(51), e2309583120. https://doi.org/10.1073/pnas.2309583120   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human \nparticipants? Trends in Cognitive Sciences , 27(7), 597 -600. \nhttps://doi.org/10.1016/j.tics.2023.04.008   \nElyoseph, Z., Hadar -Shoval, D., Asraf, K., & Lvovsky, M. (2023). ChatGPT outperforms \nhumans in emotional awareness evaluations. Frontiers in Psychology , 14, 1199058. \nhttps://doi.org/10.3389/fpsyg.2023.1199058   \nFeuerriegel, S., Maarouf, A., B\u00e4r, D., Geissler, D., Schweisthal, J., Pr\u00f6llochs, N., . . . Van \nBavel, J. J. (2025). Using natural language processing to analyse text data in \nbehavioural science. Nature Reviews Psychology , 4(2), 96 -111. \nhttps://doi.org/10.1038/s44159 -024-00392 -z  \nFirestone, C. (2020). Performance vs. competence in human \u2013machine comparisons. \nProceedings of the National Academy of Sciences of the United States of America , \n117(43), 26562 -26571. https://doi.org/10.1073/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 924,
      "text": "3/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024). Take caution in using LLMs as human \nsurrogates: Scylla ex machina. arXiv:2410.19599 . \nhttps://doi.org/10.48550/arXiv.2410.19599   \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, \nW. A. (2023). AI and the transformation of social science research. Science , \n380(6650), 1108 -1109. https://doi.org/10.1126/science.adi1778   \nGuan, B., Roosta, T., Passban, P., & Rezagholizadeh, M. (2025). The order effect: \nInvestigating prompt sensitivity in closed -source LLMs. arXiv:2502.04134 . \nhttps://doi.org/10.48550/arXiv.2310.11324   \nGuest, O., & Martin, A. E. (2023). On logical inference over brains, behaviour, and artificial \nneural networks. Computational Brain & Behavior , 6(2), 213 -227. \nhttps://doi.org/10.1007/s42113 -022-00166 -x  \nGui, G., & Toubia, O. (2023). The challenge of using LLMs to simulate human behavior: A \ncausal inference perspective. arXiv:2312.15524 . \nhttps://doi.org/10.48550/arXiv.2312.15524   \nGupta, A., Song, X., & Anumanchipalli, G. (2024, November). Self -assessment tests are \nunreliable measures of LLM personality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 925,
      "text": "rsonality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US.  \nLLM  VALIDITY  20 \nHe, J., Rungta, M., Koleczek, D., Sekhon, A., Wang, F. X., & Hasan, S. (2024). Does Prompt \nFormatting Have Any Impact on LLM Performance? arXiv:2411.10541 . \nhttps://doi.org/10.48550/arXiv.2411.10541   \nHern\u00e1ndez -Orallo, J., Dowe, D. L., & Hern\u00e1ndez -Lloreda, M. V. (2014). Universal \npsychometrics: Measuring cognitive abilities in the machine kingdom. Cognitive \nSystems Research , 27, 50-74. https://doi.org/10.1016/j.cogsys.2013.06.001   \nHuang, J. -t., Jiao, W., Lam, M. H., Li, E. J., Wang, W., & Lyu, M. (2024, November). On the \nreliability of psychological scales on large language models. In Y. Al -Onaizan, M. \nBansal, & Y. -N. Chen, Proceedings of the 2024 Conference on Empirical Methods in \nNatural Language Processing  Miami, Florida, USA.  \nIvanova, A. A. (2025). How to evaluate the cognitive abilities of LLMs. Nature Human \nBehaviour , 9(2), 230 -233. https://doi.org/10.1038/s41562 -024-02096 -z  \nJiang, H., Zhang, X., Cao, X., Breazeal, C., Roy, D., & Kabbara, J. (2024, June). \nPersonaLLM: Investigating the ability of large language models to express \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 926,
      "text": "ss \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M. (2024). Sense and Sensitivity: Evaluating the \nsimulation of social dynamics via Large Language Models. arXiv:2412.05093 . \nhttps://doi.org/10.48550/arXiv.2412.05093   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings \nof the National Academy of Sciences of the United States of America , 121(45), \ne2405460121. https://doi.org/10.1073/pnas.2405460121   \nLaban, P., Hayashi, H., Zhou, Y., & Neville, J. (2025). LLMs get lost in multi -turn \nconversation. arXiv:2505.06120 . https://doi.org/10.48550/arXiv.2505.06120   \nLee, S., Lim, S., Han, S., Oh, G., Chae, H., Chung, J., . . . Lee, D. (2024). Do LLMs have \ndistinct and consistent personality? TRAIT: Personality testset designed for LLMs \nwith psychometrics. arXiv:2406.14703 . https://doi.org/10.48550/arXiv.2406.14703   \nLee, S., Peng, T. -Q., Goldberg, M. H., Rosenthal, S. A., Kotcher, J. E., Maibach, E. W., & \nLeiserowitz, A. (2024). Can large language models estimate public opinion about \nglobal warming? An empirical assessment of algorithmic fidelity and bias. PLOS \nClimate , 3(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 927,
      "text": "(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables. Computers in Human Behavior , 170, \n108687. https://doi.org/10.1016/j.chb.2025.108687   \nLi, Y., Huang, Y., Wang, H., Zhang, X., Zou, J., & Sun, L. (2024). Quantifying AI \npsychology: A psychometrics benchmark for large language models. \narXiv:2406.17675 . https://doi.org/10.48550/arXiv.2406.17675   \nLi, Y., Lin, X., Sha, Z., Jin, Z., & Lee, E. (2025). AI psychometrics: Evaluating the \npsychological reasoning of large language models with psychometric validities. \nProceedings of the 58th Hawaii International Conference on System Sciences, \nWaikoloa, Hawai i, USA.  \nLLM  VALIDITY  21 \nLin, Z. (2023). Why and how to embrace AI such as ChatGPT in your academic life. Royal \nSociety Open Science , 10, 230658. https://doi.org/10.1098/rsos.230658   \nLin, Z. (2025a). Large language models as psychological simulators: A methodological \nguide. Preprint .  \nLin, Z. (2025b). Techniques for supercharging academic writing with generative AI. Nature \nBiomedical Engineering , 9, 426 -431. https://doi.org/10.1038/s41551 -024-01185 -8  \nLoevinger, J. (1957). Objective tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 928,
      "text": "e tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September). Is machine \npsychology here? On requirements for using human psychological tests on large \nlanguage models. In S. Mahamood, N. L. Minh, & D. Ippolito, Proceedings of the \n17th International Natural Language Generation Conference  Tokyo, Japan.  \nLones, M. A. (2024). Avoiding common machine learning pitfalls. Patterns , 5(10), 101046. \nhttps://doi.org/10.1016/j.patter.2024.101046   \nMa, H., Gong, H., Yi, X., Xie, X., & Xu, D. (2025). Leveraging implicit sentiments: \nEnhancing reliability and validity in psychological trait evaluation of LLMs. \narXiv:2503.20182 . https://doi.org/10.48550/arXiv.2503.20182   \nMehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias \nand fairness in machine learning. ACM Computing Surveys , 54(6), 1 -35. \nhttps://doi.org/10.1145/3457607   \nMessick, S. (1989). Meaning and values in test validation: The science and ethics of \nassessment. Educational Researcher , 18(2), 5 -11. \nhttps://doi.org/10.3102/0013189X018002005   \nMilli\u00e8re, R., & Buckner, C. (2024). A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 929,
      "text": "A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November). Who is GPT -3? An \nexploration of personality, values and demographics. In D. Bamman, D. Hovy, D. \nJurgens, K. Keith, B. O\u2019Connor, & S. Volkova, Proceedings of the Fifth Workshop on \nNatural Language Processing and Computational Social Science (NLP+CSS)  Abu \nDhabi, UAE.  \nMurthy, S. K., Ullman, T., & Hu, J. (2024). One fish, two fish, but not the whole sea: \nAlignment reduces language models' conceptual diversity. arXiv:2411.04427 . \nhttps://doi.org/10.48550/arXiv.2411.04427   \nNgweta, L., Kate, K., Tsay, J., & Rizk, Y. (2025, April). Towards LLMs robustness to \nchanges in prompt format styles. In A. Ebrahimi, S. Haider, E. Liu, S. Haider, M. \nLeonor Pacheco, & S. Wein, Proceedings of the 2025 Conference of the Nations of \nthe Americas Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies (Volume 4: Student Research Workshop)  Albuquerque, USA.  \nNiu, Q., Liu, J., Bi, Z., Feng, P., Peng, B., Chen, K., . . . Yin, C. H. (2024). Large language \nmodels and cognitive science: A comprehensive review of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 930,
      "text": "view of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement. Clinical diagnosis of \nmental disorders: A handbook , 97-146.  \nOh, S., & Demberg, V. (2025). Robustness of large language models in moral judgements. \nRoyal Society Open Science , 12(4), 241229. https://doi.org/10.1098/rsos.241229   \nOng, D. C. (2024). GPT -ology, computational models, silicon sampling: How should we \nthink about LLMs in cognitive science? arXiv:2406.09464 . \nhttps://doi.org/10.48550/arXiv.2406.09464   \nPark, J. S., O'Brien, J., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). \nGenerative agents: Interactive simulacra of human behavior.  Proceedings of the 36th \nAnnual ACM Symposium on User Interface Software and Technology, San \nFrancisco, CA, USA. https://doi.org/10.1145/3586183.3606763  \nPeereboom, S., Schwabe, I., & Kleinberg, B. (2025). Cognitive phantoms in large language \nmodels through the lens of latent variables. Computers in Human Behavior: Artificial \nHumans , 4, 100161. https://doi.org/10.1016/j.chbah.2025.100161   \nPellert, M., Lechner, C. M., Wagner, C., Rammstedt, B., & Strohmaier, M. (2024). AI \npsychometrics: Assessing the psychological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 931,
      "text": "hological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J. (2024). Performance and biases of Large Language Models in public \nopinion simulation. Humanities and Social Sciences Communications , 11(1), 1095. \nhttps://doi.org/10.1057/s41599 -024-03609 -x  \nRiemer, M., Ashktorab, Z., Bouneffouf, D., Das, P., Liu, M., Weisz, J., & Campbell, M. \n(2025). Position: Theory of mind benchmarks are broken for large language models. \nInternational Conference on Machine Learning, Vancouver, Canada.  \nSalecha, A., Ireland, M. E., Subrahmanya, S., Sedoc, J., Ungar, L. H., & Eichstaedt, J. C. \n(2024). Large language models show human -like social desirability biases in survey \nresponses. arXiv:2405.06058 . https://doi.org/10.48550/arXiv.2405.06058   \nSartori, G., & Orru, G. (2023). Language models and psychological sciences. Frontiers in \nPsychology , 14, 1279317. https://doi.org/10.3389/fpsyg.2023.1279317   \nSchaeffer, R., Miranda, B., & Koyejo, S. (2023). Are emergent abilities of large language \nmodels a mirage? Advances in Neural Information Processing Systems , 36, 55565 -\n55581.  \nSchelb, J., Borin, O., Garcia, D., & Spitz, A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 932,
      "text": ", A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025). Large language models are proficient \nin solving and creating emotional intelligence tests. Communications Psychology , \n3(1), 80. https://doi.org/10.1038/s44271 -025-00258 -x  \nSclar, M., Choi, Y., Tsvetkov, Y., & Suhr, A. (2023). Quantifying language models\u2019 \nsensitivity to spurious features in prompt design or: How I learned to start worrying \nabout prompt formatting. arXiv:2310.11324 . https://arxiv.org/abs/2310.11324   \nLLM  VALIDITY  23 \nSharma, M., Tong, M., Korbak, T., Duvenaud, D., Askell, A., Bowman, S. R., . . . Johnston, \nS. R. (2023). Towards understanding sycophancy in language models. \narXiv:2310.13548 . https://doi.org/10.48550/arXiv.2310.13548   \nShiffrin, R., & Mitchell, M. (2023). Probing the psychology of AI models. Proceedings of the \nNational Academy of Sciences of the United States of America , 120(10), \ne2300963120. https://doi.org/10.1073/pnas.2300963120   \nShojaee, P., Mirzadeh, I., Alizadeh, K., Horton, M., Bengio, S., & Farajtabar, M. (2025). The \nillusion of thinking: Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 933,
      "text": "Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017). The next Big Five Inventory (BFI -2): Developing and \nassessing a hierarchical model with 15 facets to enhance bandwidth, fidelity, and \npredictive power. Journal of Personality and Social Psychology , 113(1), 117 -143. \nhttps://doi.org/10.1037/pspp0000096   \nStanley, J. C., & Campbell, D. T. (1963). Experimental and quasi -experimental designs for \nresearch . Rand McNally.  \nS\u00fchr, T., Dorner, F. E., Samadi, S., & Kelava, A. (2023). Challenging the validity of \npersonality tests for large language models. arXiv:2311.05297 , 2311 . \nhttps://doi.org/10.48550/arXiv.2311.05297   \nTakemoto, K. (2024). The moral machine experiment on large language models. Royal \nSociety Open Science , 11(2), 231393. https://doi.org/10.1098/rsos.231393   \nTaylor, J. E. T., & Taylor, G. W. (2021). Artificial cognition: How experimental psychology \ncan help generate explainable artificial intelligence. Psychonomic Bulletin & Review , \n28(2), 454 -475. https://doi.org/10.3758/s13423 -020-01825 -5  \nTjuatja, L., Chen, V., Wu, T., Talwalkwar, A., & Neubig, G. (2024). Do LLMs exhibit \nhuman -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 934,
      "text": "human -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023). Large language models fail on trivial alterations to theory -of-mind tasks. \narXiv:2302.08399 . https://doi.org/10.48550/arXiv.2302.08399   \nVoudouris, K., Cheke, L., & Schulz, E. (2025). Bringing comparative cognition approaches \nto AI systems. Nature Reviews Psychology , 4(6), 363 -364. \nhttps://doi.org/10.1038/s44159 -025-00456 -8  \nWang, A., Morgenstern, J., & Dickerson, J. P. (2025). Large language models that replace \nhuman participants can harmfully misportray and flatten identity groups. Nature \nMachine Intelligence , 7(3), 400 -411. https://doi.org/10.1038/s42256 -025-00986 -z  \nWang, Q., Zhou, X., Sap, M., Forlizzi, J., & Shen, H. (2025). Rethinking theory of mind \nbenchmarks for LLMs: Towards a user -centered perspective. arXiv:2504.10839 . \nhttps://doi.org/10.48550/arXiv.2504.10839   \nWang, X., Li, X., Yin, Z., Wu, Y., & Liu, J. (2023). Emotional intelligence of large language \nmodels. Journal of Pacific Rim Psychology , 17, 18344909231213958. \nhttps://doi.org/10.1177/18344909231213958   \nLLM  VALIDITY  24 \nWang, Y., Zhao, J., Ones, D. S., He, L., & Xu, X. (2025). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 935,
      "text": "5). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language \nmodels. Nature Human Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -\n023-01659 -w  \nXu, R., Sun, Y., Ren, M., Guo, S., Pan, R., Lin, H., . . . Han, X. (2024). AI for social science \nand social science of AI: A survey. Information Processing & Management , 61(3), \n103665. https://doi.org/10.1016/j.ipm.2024.103665   \nYe, H., Jin, J., Xie, Y., Zhang, X., & Song, G. (2025). Large language model psychometrics: \nA systematic review of evaluation, validation, and enhancement. arXiv:2505.08245 . \nhttps://doi.org/10.48550/arXiv.2505.08245   \nYe, H., Xie, Y., Ren, Y., Fang, H., Zhang, X., & Song, G. (2025). Measuring human and AI \nvalues based on generative psychometrics with large language models. Proceedings of \nthe AAAI Conference on Artificial Intelligence , 39(25), 26400 -26408. \nhttps://doi.org/10.1609/aaai.v39i25.34839   \nYing, L., Collins, K. M., Wong, L., Sucholutsky, I., Liu, R., Weller, A., . . . Tenenbaum, J. B. \n(2025). On benchmarking human -like intelligence in machines. arXiv:2502.20502 . \nhttps://doi.org/10.48550/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 936,
      "text": "50/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone.0322776   \nZakazov, I., Boronski, M., Drudi, L., & West, R. (2024). Assessing social alignment: Do \npersonality -prompted large language models behave like humans? arXiv:2412.16772 . \nhttps://doi.org/10.48550/arXiv.2412.16772   \nZhou, L., Schellaert, W., Martinez -Plumed, F., Moros -Daval, Y., Ferri, C., & Hernandez -\nOrallo, J. (2024). Larger and more instructable language models become less reliable. \nNature , 634, 61-68. https://doi.org/10.1038/s41586 -024-07930 -y  \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2024). Can large language \nmodels transform computational social science? Computational Linguistics , 50(1), \n237-291. https://doi.org/10.1162/coli_a_00502   \nZou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 937,
      "text": "). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 938,
      "text": "LLM  VALIDITY  1 \n \n \nFrom Prompts to Constructs: A Dual -Validity Framework for LLM Research in \nPsychology  \n \nZhicheng Lin  \nDepartment of Psychology, Yonsei University  \nDepartment of Psychology, University of Science and Technology of China  \n \n \n \nCorrespondence  \nZhicheng Lin, Department of Psychology, Yonsei University, Seoul, 03722, Republic of \nKorea  (zhichenglin@gmail.com; X/Twitter: @ZLinPsy)  \n \nAcknowledgments  \nThis work was supported by the National Key R&D Program of China STI2030 Major \nProjects (2021ZD0204200). I used Claude Opus /Sonnet  4 and Gemini 2.5 Pro for \nproofreading the manuscript, following the prompts described at \nhttps://www.nature.com/articles/s41551 -024-01185 -8. \n \n \n \nAbstract  \nLarge language models (LLMs) are rapidly being adopted across psychology, serving as \nresearch tools, experimental subjects, human simulators, and computational models of \ncognition. However, the application of human measurement tools to these systems can \nproduce contradictory results, raising concern s that many findings are measurement \nphantoms \u2014statistical artifacts rather than genuine psychological phenomena. In this \nPerspective, we argue that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 939,
      "text": "e that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference. We present a dual -validity framework to guide this \nintegration, which clarifies how the evidence needed to support a claim scales with its \nscientific ambition. Using an LLM to c lassify text may require only basic accuracy checks, \nwhereas claiming it can simulate anxiety demands a far more rigorous validation process. \nCurrent practice systematically fails to meet these requirements, often treating statistical \npattern  matching as e vidence of psychological phenomena. The same model output \u2014\nendorsing \u201cI am anxious \u201d\u2014requires different validation strategies depending on whether \nresearchers claim to measure, characterize, simulate, or model psychological constructs. \nMoving forward requires developing computational analogues of psychological constructs \nand establishing clear, scalable standards of evidence rather than  the uncritical application of \nhuman measurement tools.  \n \nKeywords : large language models, psychometrics, construct validity, causal inference, \npsychological measurement, reliability  \n \n \n \n \n \nLLM  VALIDITY  2 \nWhen researchers tested GPT models  on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 940,
      "text": "on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) . But Oh and Demberg (2025)  discovered \nsomething troubling: Simply changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \u201c(A)\u201d and \u201c(B)\u201d reversed \nmany of these moral preferences ; adding a period instead of a question mark altered \njudgments. \u201cMoral reasoning \u201d in these models proved to be as sensitive to punctuation as to \nethical principles.  \n  \nThis example exposes a foundational crisis in LLM psychological research  (L\u00f6hn et al., \n2024; Schelb et al., 2025; Voudouris et al., 2025; Ye, Jin, et al., 2025) . If moral preferences \nflip with parentheses, can we trust the measurement itself? And if we cannot reliably measure \nmoral reasoning, how can we test whether experimental manipulations \u2014different scenarios, \ncultural contexts, or prompt structures \u2014causally a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 941,
      "text": "ly a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning. By repurposing psychological \ninventories, questionnaires, and behavioral tasks originally developed for human participant s, \nstudies now claim to measure personality traits, theory of mind, cognitive biases, and \nemotional intelligence in language models, often drawing direct parallels to human \npsychology  (Binz & Schulz, 2023; Kosinski, 2024; Miotto et al., 2022; Pellert et al., 2024; \nWang et al., 2023; Webb et al., 2023) . These claims  would  require  sound measurement \nreliability and construct validity  (Cronbach & Meehl, 1955)  in LLMs , but emerging  evidence \nsuggests that model  responses may violate basic psychometric assumptions  (Gao et al., 2024; \nSeungbeen Lee et al., 2024; Peereboom et al., 2025; Tjuatja et al., 2024; Q. Wang et al., \n2025) . For example, trivial prompt perturbations \u2014such as adding extra spaces, altering \npunctuation, or changing the order of few -shot examples \u2014can produce variation of up to \n76% in task accuracy  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Models may \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 942,
      "text": "y \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design. Some studies \ntreat LLM responses as windows into genuine psychological processes, interpreting \nbehavioral patterns as evidence of underlying cognitive mechanisms  (Sartori & Orru, 2023) . \nOthers acknowledge that LLMs merely simulate responses but still draw causal conclusions \nwithout addressing computational confounds \u2014technical artifacts, data integrity, and causal \ninference  from observational data  (e.g., Binz & Schulz, 2023; Dillion et al., 2023; Kosinski, \n2024; Park et al., 2023) .  \n \nThese observations  raise two interrelated  questions. First, can LLM responses reliably \nmeasure psychological constructs? This question encompasses the psychometric properties \nrequired for reliable  measurement , from test\u2013retest reliability and internal consistency  to \nparallel forms reliability . Second, even when reliable measurement exists, what types of \nscientific inferences can we draw? This encompasses both descriptive  claims about LLM \nproperties (does this model exhibit trait X?) and causal  claims about experimental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 943,
      "text": "imental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology. The psychometric tradition, rooted in educational \nand psychological testing, asks whether instruments measure intended constructs (Cronbach \nLLM  VALIDITY  3 \n& Meehl, 1955; Loevinger, 1957; Messick, 1989) . The causal inference tradition, developed \nfor experimental and quasi -experimental research, asks whether studies support valid \nconclusions about cause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . \nThese traditions evolved separately, served different research communities, and developed \ndistinct conceptual frameworks. While human research typically emphasizes one tradition or \nthe other, LLM research demands both: establishing that prompts and respons es constitute \nvalid measures, then ensuring that research designs support appropriate inferences.  \n \nThis integration forms the foundation for understanding validity in LLM psychological \nresearch. We first establish how the psychometric and causal inference traditions apply to \nLLM research contexts, then examine how reliability failures undermine both mea surement \nand inference foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 944,
      "text": "rence foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference. Our goal is to establish methodological f oundations that \ncan support cumulative, replicable science at the interface of AI and psychology . \n \nTwo Validity Traditions and Their Integration in LLM Research  \nThe Psychometric Tradition  \nIn the psychometric tradition, the central problem is measurement quality  (Cronbach & \nMeehl, 1955; Loevinger, 1957) . Researchers need to know whether intelligence tests measure \nintelligence, whether personality inventories capture personality traits, whether attitude scales \nreflect attitudes. Validity is thus  about meaning \u2014what do scores signify? This question \nprecedes all others ; without valid measurement, subsequent analyses become exercises in \nquantifying noise.   \n \nThis framework conceptualizes  validity as a unitary concept \u2014construct validity \u2014under \nwhich all validity evidence accumulates (Messick, 1989) . Evidence flows from five principal \nsources : content (do items sample the construct domain?), response processes (do test -takers \nengage expected cognitive operations?), internal structure (do responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 945,
      "text": "responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?). The focus is thus on \nbuilding an evidence -based argument for a specific interpretation of a score . \n \nHowever, for a score interpretation to be meaningful, the instrument itself must be sensitive \nto variations in a real -world attribute \u2014a link traditionally investigated through evidence from \nresponse processes. A causal theory of validity makes this requirement explicit, arguing that \nan instrument is valid only if (1) the attribute it purports to measure exists , and (2) variations \nin that attribute causally produce  the observed scores  (Borsboom et al., 2004) . While \ntraditional human research can often presuppose the existence of psychological attributes, \nthis assumption is untenable for LLMs, raising  foundational questions of causality and \nontology . \n \nThe Causal Inference Tradition  \nIn the causal inference tradition, the central problem is drawing warranted conclusions about \ncause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . Researchers need to \nknow whether treatments cause outcomes, whether interventions produce changes, whether \nmanipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 946,
      "text": "ipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning.   \n \nLLM  VALIDITY  4 \nRather than hierarchical evidence accumulation, this approach  conceptualizes validity \nthrough four parallel types, each addressing distinct threats to causal inference.  Internal \nvalidity asks whether observed changes stem from manipulations rather than confounds. \nExternal validity examines whether causal relationships generalize beyond specific studies. \nConstruct validity of causes and effects evaluates whether operationa l definitions align with \ntheoretical constructs. Statistical conclusion validity addresses whether data analyses support \ncausal inferences. These are  not hierarchical but parallel \u2014a study might demonstrate strong \ninternal validity (the manipulation caused the change) while suffering from weak external \nvalidity (the effect doesn \u2019t generalize) or construct validity problems (the manipulation \ndoesn \u2019t represent the intended theoretical variable).  \n \nWhy LLM Research Requires Both  \nTo understand  why LLM research demands integrating both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 )."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 947,
      "text": "both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 ). First, LLMs serve as research \ntools \u2014automated coders for qualitative data, text analyzers for sentiment extraction, stimulus \ngenerators for research  materials  (Binz et al., 2025; Blanchard et al., 2025; Demszky et al., \n2023; Feuerriegel et al., 2025; Lin, 2023, 2025b; Ziems et al., 2024) . Second, researchers \ncharacterize model behavior directly  (\u201cmachine psychology \u201d or \u201cGPT -ology \u201d), documenting \ncomputational properties that may or may not map to psychological constructs  (Li et al., \n2024; Ong, 2024; Sartori & Orru, 2023) . Third, LLMs function as human simulators, \nreplicat ing psychological experiments and model ing population -level responses  (Dillion et \nal., 2023; Grossmann et al., 2023; Lin, 2025a) . Fourth, LLMs serve as cognitive models \u2014\ncomputational analogues to human mental processes, architectural hypotheses about \ncognition  (Blank, 2023; Frank, 2023; Lin, 2025a; Niu et al., 2024) . \n \nThe psychometric demands vary across these applications  (Hern\u00e1ndez -Orallo et al., 2014) . \nSimple research tools performing text classification may require only accuracy and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 948,
      "text": "and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) . But most \npsychological applications involve substantive construct  claims. When researchers report that \nLLMs exhibit \u201ctheory of mind \u201d (Kosinski, 2024) , display \u201cpersonality traits \u201d (Miotto et al., \n2022) , or demonstrate \u201cmoral reasoning \u201d (Takemoto, 2024) , they make measurement \nassertions about psychological phenomena  that require psychometric validation: Do model \nresponses reliably  and validly  indicate these constructs?  \n \nSimilarly, causal inference requirements depend on research objectives . Using LLMs for \ndescriptive tasks  (e.g., count ing word frequencies ) involves no causal claims. But w hen \nresearchers manipulate prompts to study \u201ccultural differences, \u201d vary scenarios to examine \n\u201cethical preferences, \u201d or modify contexts to investigate \u201ccognitive biases \u201d (Grossmann et al., \n2023) , they advance causal hypotheses requiring protection against confounds, generalization \nfailures, construct misalignment, and statistical artifacts .  \n \nLLM research faces a unique integration challenge. Traditional human research follows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 949,
      "text": "ollows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence.  \nThe same model responses simultaneously serve as (1) measurement indicators requiring \npsychometric validation and (2) experimental outcomes requiring causal inference protection. \nWhen GPT generates text about moral dilemmas, researchers treat this output b oth as \nmeasurement of moral reasoning and as experimental data. This dual role creates cascading \nLLM  VALIDITY  5 \nvalidity threats: unreliable measurement undermines causal inference, while experimental \nconfounds contaminate measurement validation.  \n \nValidity requirements scale with psychological ambition . Basic text processing require s \nminimal consideration beyond accuracy \u2014demonstrating agreement with human coders or \nestablished benchmarks  (Xu et al., 2024) . Human simulation requires that model responses \nstatistically parallel human patterns and that experimental manipulations produce comparable \neffects \u2014validity here concerns behavioral correspondence rather than construct possession  \n(Lin, 2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 950,
      "text": "2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) . Cognitive modeling faces the additional burden of distinguishing \nfunctional similarity from mechanistic equivalence  (Guest & Martin, 2023; Lin, 2025a) . \n \nYet psychological studies using LLMs largely ignore both traditions  (Demszky et al., 2023; \nIvanova, 2025; L\u00f6hn et al., 2024) . Research claiming to measure model \u201cpersonality, \u201d \n\u201ctheory of mind, \u201d or \u201cmoral reasoning \u201d proceeds without establishing measurement \nfoundations  (Peereboom et al., 2025; Q. Wang et al., 2025; Ying et al., 2025) . Studies \nmanipulating prompts to test psychological hypotheses lack experimental safeguards, relying \ninstead on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 951,
      "text": "on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 952,
      "text": "Dual -Validity Framework for LLM Psychological Research  \nTradition  Type of Validity  Definition  Threats to Validity  \nPsychometric  Content  Do prompts/items comprehensively \nsample the intended psychological \ndomain?  \u2022 Domain under -\nsampling   \n\u2022 Prompt \ncontamination   \nResponse  \nprocess es  Do the mechanisms generating outputs \nalign with theoretical processes?  \u2022 Mechanistic \nsubstitution  \n\u2022 Architectural \nartifacts   \nInternal  structure  Do inter -item correlations and factor \nstructures match theoretical \nexpectations?  \u2022 Structural misfit \n\u2022 Factorial collapse  \n \nRelations  with  \nother  variables  Do LLM scores show convergent, \ndiscriminant, and predictive \nrelationships as theory predicts?  \u2022 Nomological \ninstability  \n\u2022 Behavioral \u2013report \ndisconnect   \nConsequential  What are the implications and biases of \nscore interpretations?  \u2022 Bias r eification  \n\u2022 Misguided \napplication  \nCausal -\nInference  Internal  Can output changes be attributed to the \nmanipulation rather than confounds?  \u2022 Parameter \nconfounding  \n\u2022 Unstated \nbackground \nconfounding  \nLLM  VALIDITY  6 \nTradition  Type of Validity  Definition  Threats to Validity   \nExternal  Do causal effects generalize across \nprompts, tasks, models, and to human \npopulations?  \u2022 Generalization \nfailure  \n\u2022 Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nSta"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 953,
      "text": "Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nStatistical  \nconclusion  Are statistical inferences supported by \nappropriate methods and adequate data?  \u2022 Non -independence  \n\u2022 False positives  \n \nMeasurement Reliability  in LLM Research  \nA psychometric axiom governs all measurement: No measure can be more valid than it is \nreliable  (Cronbach & Meehl, 1955; Nunnally, 1978) . An unreliable thermometer \u2014reading \n98.6\u00b0F, then 103.2\u00b0F, then 95.1\u00b0F for the same healthy person \u2014cannot validly measure \nfever, regardless of its theoretical grounding or careful calibration. This principle extends to \npsychological measurement, where relia bility forms the mathematical ceiling for validity. A \npersonality inventory with test \u2013retest reliability of 0.40 cannot achieve validity coefficients \nexceeding 0.63  (\ud835\udc5fmax=\u221a0.40\u22480.63), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 954,
      "text": "), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error. Test \u2013retest reliability captures temporal stability \u2014do \nindividuals receive similar scores across time? Parallel forms reliability assesses robustness \nto equivalent variations \u2014do alternate question wordings yield consistent results? Internal \nconsistency examines  item coherence \u2014do multiple indicators of the same construct \nconverge? Human psychological measurement typically achiev es reliabilities of 0.70 \u20130.90 \nfor established instruments, with well -validated measures like the Big Five Inventory -2 \nreaching test-retest reliabilities  of 0.76\u20130.84 across  eight  week s (Soto & John, 2017) . \n \nLLM measurement inherits these reliability requirements while introducing computational \ncomplications (L\u00f6hn et al., 2024) . Test\u2013retest reliability must encompass response stability \nacross model sessions, prompt iterations, and time intervals. Parallel forms reliability \nbecomes critical given prompt sensitivity \u2014can semantically equivalent prompts elicit \nconsistent responses? Internal consistency requires t hat models show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 955,
      "text": "ls show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement.   \n \nThe empirical record reveals systematic unreliability that violates basic psychometric \nassumptions. While computer systems are often assumed to excel at consistency, LLM \nperformance relative to humans varies dramatically with task demands and model \narchitectur e. These challenges cluster into three modes: training artifact contamination; \nprompt hypersensitivity; and stochastic degradation.  \n \nReliability Challenges  \nTraining Artifact Contamination . A fundamental reliability challenge  stem s from training \nprocedures that embed systematic biases into model responses. Reinforcement learning from \nhuman feedback (RLHF) creates a pervasive \u201cagree bias \u201d (also called \u201cyes-response bias ,\u201d \nLLM  VALIDITY  7 \nacquiescence  bias, or sycophancy ); models trained to please human annotators develop \nsystematic tendencies toward agreement regardless of item content  (Dentella et al., 2023; \nSharma et al., 2023) . This manifests as models simultaneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 956,
      "text": "aneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement . RLHF also introduces \noverconfidence bias : Models trained to be \u201cnever evasive \u201d provide plausible but wrong \nanswers rather than acknowledging uncertainty, replacing reliably reproducible avoidance \npatterns with responses that, while more stable to prompt variations, appear confident and are \noften incorrect  (Zhou et al., 2024) . \n  \nThe contamination extends beyond response biases . Models exhibit apparent  personality \ncoherence \u2014high internal consistency coefficients, stable factor structures  (Huang et al., \n2024; Y. Wang et al., 2025) \u2014that dissolves under scrutiny  (Peereboom et al., 2025) . In \npersonality assessments using the Big Five Inventory, models like GPT -3.5 and GPT -4 \nproduce less response variance than human samples, demonstrating higher consistency across \nthousands of prompt variations (Huang et al., 2024) . Yet when prompts bypass learned \nassociations through novel phrasings or contexts, the personality coherence vanishes  (Gao et \nal., 2024) \u2014reliability appears robust only within the narrow confines of training -data-similar \npresentations.  Extended conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 957,
      "text": "d conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability.  \n \nPrompt Hypersensitivity . LLM responses exhibit catastrophic sensitivity to prompt variations \nthat would not affect human measurement \u2014for instance,  changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \n\u201c(A)\u201d and \u201c(B)\u201d reverses moral preferences (Oh & Demberg, 2025) . This hypersensitivity \nextends beyond formatting to encompass word order, punctuation, spacing, and option \npresentation . Modifications that human psychology treats as measurement noise become \nsignal -determining factors for LLMs  (Brucks & Toubia, 2025; Gao et al., 2024) . \n \nThe hypersensitivity manifests across psychological domains. Theory -of-mind performance \nfails when trivial alterations are made to scenarios \u2014making containers transparent, adding \ntrusted testimony about true state s, or changing which character \u2019s beliefs are queried  \n(Ullman, 2023; Q. Wang et al., 2025) . Personality assessments yield entirely different \nprofiles depending on whether prompts use alphabetic or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 958,
      "text": "or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) . Sentiment \nanalysis produces opposing classifications when periods replace question marks  or when \nextra spaces appear between words  (Ngweta et al., 2025) . \n \nThese effects cannot be dismissed as minor measurement error. Trivial variations \u2014altering \noption labels or definition order \u2014can cause models to change answers over 70% of the time \n(Oh & Demberg, 2025)  or alter classification rates by up to 164%  (Abdurahman et al., 2024) . \nMore critically, the effects appear arbitrary \u2014no theoretical framework predicts which \nmodifications will produce which changes.  This arbitrariness reveals a fundamental \ndifference between human and LLM processing: Human responses emerge from stable trait \nsystems that maintain consistency across presentation variations \u2014a genuinely extroverted \nperson remains so whether questions are indexed by numbers or letters. While instruction \ntuning creates filtering mechanisms that prioritize semantic content over sur face features, \nthese filters prove incomplete and brittle, breaking down unpredictably at edge cases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 959,
      "text": "ases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) . \n \nWhile  deterministic settings (temperature 0) can yield near-perfect test \u2013retest reliability by \nsuppressing  stochastic variation, such configurations capture only fragments of model \nbehavior  (L\u00f6hn et al., 2024) . High  reliability emerges precisely when measurement becomes \nleast representative of the system \u2019s actual capabilities. While scaling up LLMs (increasing \nsize and data) and shaping them up (using instruction tuning and RLHF) improve overall \nprompting stability, this improvement is neither uniform nor complete  (Zhou et al., 2024) . \nEven the most advanced shaped -up models retain pockets of hypersensitivity that vary \nunpredictably across difficulty levels and task domains.  \n \nStochastic Degradation . Unlike human participants  who maintain psychological continuity \nacross measurement occasions, LLMs exhibit within -session reliability degradation that \nworsens with interaction length  (Laban et al., 2025) . Where humans typically show \nincreasing response stability with repeated measurement \u2014clarifying their understanding of \nitems and solidifying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 960,
      "text": "ying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) . By session end, models may respond to items in ways that \ncontradict their earlier responses to identical content.  \n \nThe degradation compounds when models undergo updates or version changes. GPT -4 in \nMarch may differ substantially  from GPT -4 in September \u2014not merely in capabilities but in \nbasic response patterns to identical prompts  (Abdurahman et al., 2024; Zaim bin Ahmad & \nTakemoto, 2025) . This version instability means that reliability evidence expires with each \nmodel update, requiring continuous revalidation. Longitudinal research becomes impossible \nwhen the measurement instrument transforms unpredictably.  \n \nThis problem complicates assessments of temporal stability. While human personality traits \nshow remarkable consistency over months and years, the stability of LLM \u201ctraits \u201d is \nambiguous. Some research finds high test \u2013retest reliability for personality metrics over \nseveral months, even across model updates. However, the ease with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 961,
      "text": "se with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations. What appears to be \npersonality measurement may instead be prompt archaeology \u2014excavating textual features \nthat trigger consistently reproduced but computationally shallow statistical performances.  \n \nImplications for LLM Psychological Research  \nThese reliability challenges cascade through all LLM applications. Without reliable \nmeasurement, LLM psychological research reduces to elaborate conjecture about systems we \ncannot adequately observe. The consequences compound: Unstable text coding renders \nfindings irreproducible; claims about emergent capabilities \u2014theory of mind, personality \ncoherence, moral reasoning \u2014rest on measurements too unstable to support inference, making \npurported capabilities potentially measurement pha ntoms rather than genuine ph enomena  \n(Peereboom et al., 2025) . Most critically, models whose responses lack basic reliability \ncannot meaningfully simulate human psychological phenomena characterized by \nmeasurement stability, nor can architectural claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 962,
      "text": "l claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) . \n \nLLM  VALIDITY  9 \nTraditional reliability frameworks prove inadequate for systems that are stochastic by design. \nHuman -oriented psychometric standards assume biological measurement targets with \ninherent stability, but LLMs are simultaneously more and less stable than biolog ical systems: \nrigid  under controlled conditions yet unduly  sensitive to irrelevant variations.  The field needs \nnew reliability standards that acknowledge computational realities while address ing three \nreliability threats simultaneously. Training artifact c ontamination requires techniques for \ndistinguishing genuine model capabilities from statistical associations in training data. \nPrompt hypersensitivity demands systematic mapping of which textual variations affect \nwhich psychological constructs and how much . Stochastic degradation necessitates methods \nfor maintaining measurement quality throughout extended interactions.  \n \nConstruct Validity  from  the Psychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 963,
      "text": "ychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research. \nA causal theory of validity sharpens it to an ontological challenge : Does the attribute exist in \nthe entity, and does it cause the measurement outcome ? (Borsboom et al., 2004) . An LLM \nmight endorse \u201cI worry about the future, \u201d but anxiety presupposes temporal experience, a \npersistent self, and embodied consequences \u2014ontological properties the model lacks . Current \nresearch  frequently sidesteps this ontological challenge, focusing instead on statistical \nvalidity criteria  (Li et al., 2025) . Yet w hen the measured attribute does not exist, any resulting \noutput is a pattern of words masquerading as a psychological phenomenon.  \n  \nThe modern validity framework, codified in the Standards for Educational and Psychological \nTesting, establishes that validity is not an inherent property of an instrument  but an argument , \ngrounded in accumulated evidence, for a specific interpretation of its scores  (Loevinger, \n1957; Messick, 1989) . This distinction is paramount for LLM research. A measure validated \nfor humans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 964,
      "text": "umans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories. Changing the subject from a human to a statistical model \nfundamentally severs the score from its original interpre tive foundation. This is why even \nperfect reliability cannot rescue meaningless measurement; a digital thermometer applied to \nboiling water will consistently display its maximum reading \u2014exquisite reliability that fails \nentirely to measure the water\u2019s true temperature . \n \nYet current LLM psychological research often proceeds through assumption rather than \nvalidation. Studies routinely claim to measure personality, intelligence, or moral reasoning \nbased on face validity alone : A model generates text about ethical dilemmas, therefore it \nengage s in moral reasoning; it answers theory of mind scenarios, therefore it possess es \nmentalistic understanding. This leap from surface similarity to construct measurement \npresupposes that a latent trait not only exists in the LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 965,
      "text": "e LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) . The result is the \nproliferation of what might be termed cognitive phantoms: statistical artifacts in language \nthat produce the illusion of human -like traits but dissolve under proper psychometric \nscrutiny . \n \nThis anthropomorphic trap varies across applications but runs deepest in behavioral \ncharacterization and cognitive modeling. The distinction between performance (observed \nbehavior) and competence (underlying capacity) is essential here  (Firestone, 2020) . When \nmodels produce human -like text, do they implement human -like psychological processes, or \nLLM  VALIDITY  10 \ndo they approximate outputs through different computational means? Current evidence \nsuggests the latter  (Guest & Martin, 2023) . LLMs often fail in distinctly \u201cunhumanlike \u201d \nways, revealing that similar performance does not imply similar underlying mechanisms  \n(Dentella et al., 2023) . \n \nTypes of Validity Evidence Needed  \nThe psychometric tradition identifies five sources of construct validity evidence, each \naddressing a different facet of a measurement claim : evidence based on test content, response \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 966,
      "text": "sponse \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal., 2024) . \n \nContent . Content evidence  analyzes the relationship between a test \u2019s content \u2014its themes, \nwording, and format \u2014and the construct it purports to measure. For LLMs, this requires \nexamining how well the chosen prompt represents the content domain and its relevance to the \nintended interpretations. Here, LLM research exhibits critical failures. It routinely violates \ncomprehensive domain sampling. Complex psychological constructs require multiple \nindicators, yet studies often use single -item measures \u2014one moral dilemma to capture all \nethical reasoning, one question to represent  an entire personality trait  (Q. Wang et al., 2025; \nYing et al., 2025) .  \n \nFurthermore , because LLMs lack human s\u2019 implicit contextual understanding, seemingly \nneutral  prompts introduce confounds  (Brucks & Toubia, 2025) . Without an explicitly defined \ninterpretive directive , the model may default to responding based on unintended statistical \nfeatures \u2014for example, performing expected  value calculation s when the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 967,
      "text": "the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities . This traps \nresearchers between measuring noise and measuring compliance  (Gui & Toubia, 2023) . \n \nResponse Process es. Response process evidence investigates whether the mechanisms \ngenerating responses align with theoretical expectations. For psychological constructs, this \nrequires that trait -relevant mechanisms causally produce observed outputs \u2014anxiety stems \nfrom threat e valuation systems, moral reasoning from value -based deliberation, creativity \nfrom associative processes. LLMs systematically violate this causal requirement.  \n \nThe fundamental problem is mechanistic substitution. LLMs generate construct -relevant text \nthrough statistical pattern matching rather than the psychological processes those constructs \npresuppose  (Gao et al., 2024; Q. Wang et al., 2025) . Like Clever Hans responding to subtle  \nhuman cues rather than performing arithmetic,  models  may respond to textual regularities \nrather than engaging psychological mechanisms . This reliance on statistical patterns rather \nthan stable mechanisms explains their characteristic hypersensitivity  (Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 968,
      "text": "(Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs. \nInstead, models follow brittle statistical associations that correlate with but do not constitute \npsychological processes.   \n \nA particularly pernicious example is training data contamination : When models correctly \nanswer theory -of-mind scenarios or established psychometric scales, the response process \nmay involve memory retrieval of similar training examples rather than genuine reasoning \u2014\nmaking it impossible to determine whether the model engage s the construct or simply \nLLM  VALIDITY  11 \nregurgitates learned patterns (Gao et al., 2024; Q. Wang et al., 2025) . Consequently, even \naccurate outputs may be statistical accidents rather than evidence of genuine understanding  \n(Riemer et al., 2025) .  \n \nEqually concerning, process neglect  may lead to misdiagnosis of limitations  as well . When \nresearchers attributed LLM failures on Tower of Hanoi puzzles to \u201cfundamental barriers to \ngeneralizable reasoning \u201d (Shojaee et al., 2025) , post-mortem analysis revealed architectural \nconstraints \u2014models correctly identified  impossible variants, or hit context limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 969,
      "text": "t limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it . Similarly, arithmetic failures often reflect tokenization artifacts rather than \nquantitative reasoning problems (Voudouris et al., 2025) . Without understanding these \nresponse processes \u2014architectural constraints, tokenization schemes, training artifacts \u2014\nresearchers theorize about cognitive limitations that are merely measurement failures.  \n \nInternal Structure . Internal structure evidence examines whether response patterns align \nwith theoretical expectations about construct dimensionality. Psychological constructs \ntypically show predictable structures \u2014personality traits correlate within factors, intelligence \nsubtests load on genera l ability, moral foundations cluster in characteristic ways. Valid LLM \nmeasures should reproduce these structures: Extraversion items should intercorrelate more \nhighly than extraversion \u2013neuroticism items.  Here, empirical studies reveal systematic \nstructura l failures when human psychometric models are applied to LLMs  (Peereboom et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 970,
      "text": "m et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) . Rather \nthan replicating the multifaceted structure of human traits, LLM responses often collapse into \na single, monolithic factor resembling general verbal fluency. More fundamentally, the latent \nrepresentations underlying LLM responses appear arbitrary an d bear little resemblance to \nthose found in humans . These structural failures extend beyond personality to value \nmeasurement, where traditional tools similarly produce theoretically inconsistent correlation \npatterns that violate basic dimensional expectations  (Ye, Xie, et al., 2025) . Such systematic \nbreakdowns suggest that LLMs may respond to human -centric  instruments through \nfundamentally different mechanisms . \n \nMeasurement s designed specifically for computational systems show more promise. Ye, Xie, \net al. (2025)  developed a \u201cGenerative Psychometrics \u201d approach analyzing values from free -\nform text rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 971,
      "text": "rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al. (2024)  addressed structural failures in personality assessment by \ncomplementing  abstract self -report items with detailed, scenario -based behavioral choices \u2014\nreveal ing theoretically coherent inter -trait correlations  (e.g., a strong negative relationship \nbetween agreeableness and dark triad traits ). These developments  suggest that structural \nvalidity remains achievable but require s instruments robust to the unique response artifacts \nthat plague traditional LLM assessment.  Structural validity failures may thus indica te \nmethodological mismatch rather than construct absence.  \n \nRelations with Other Variables.  This form of evidence assesses whether a measure shows \npredictable patterns of association with external  criteria. It includes convergent evidence \n(correlation with related constructs), discriminant evidence (lack of correlation with unrelated \nLLM  VALIDITY  12 \nconstructs), and predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 972,
      "text": "nd predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning. A valid measure of conscientiousness  should predict \nachievement -related behaviors ; intelligence tests should predict problem -solving \nperformance ; moral reasoning should relate to ethical choices . Crucially, this validation \npresupposes content and structural validity \u2014one cannot test external relationships without \nfirst establishing a coherent construct.  \n \nWhen external correlations are examined, LLM research reveals nomological networks that \nmaterialize and dissolve depending on task context.  A large -scale study on chatbot \npersonality  found that in task -based dialogues, an LLM\u2019s \u201cself-reported \u201d scores on standard \npersonality inventories failed to predict how users perceived its personality or interaction \nquality (Zou et al., 2024) . However, t he personality traits that users did perceive in the \nchatbot\u2019s interactive behavior  strongly predicted interaction quality, demonstrating a \ndisconnect between self -report measure s and the construct\u2019s expected behavioral \nconsequences in  functional setting s (see also Peereboom et al., 2025; Riemer et al., 2025) . \n \nYet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 973,
      "text": "Yet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al., 2024) . The nomological network thus appears intact within creative generation \ntasks but shatters under the demands of task -based interaction. Similarly,  the ability  of \npersonality  to predict life outcomes systematically  weakened when prompted with traits alone \nbut strengthened when contextualized with non -predictive  demographic information  (Y. \nWang et al., 2025) . The network can even invert: In simulated Milgram experiments, models \nprompted with high \u201cagreeableness \u201d disobeyed much  earlier than models given no \npersonality prompt, with many quitting before the learner showed distress \u2014a point where \nboth baseline and \u201cleast agreeable \u201d models remained obedient  (Zakazov et al., 2024) . \nWithout stable  external relationships, LLM personality assessments may not measure \nenduring psychological constructs . \n \nThis instability, however, may reflect measurement approach rather than construct absence. \nWhen Ma et al. (2025)  abandoned self -report for implicit measurement \u2014adapting the \nImplicit Association Test to evaluate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 974,
      "text": "valuate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85. Establishing stable nomological networks \nthus may require developing measurement approaches that align with how LLMs process \ninformation \u2014through statistical associations rather than introspective self -knowledge.  \n \nConsequential Evidence. Consequential evidence addresses the implications and fairness of \nmeasurement interpretations. In human testing, this includes bias assessment, measurement \ninvariance across groups, and social consequences of score use. For LLMs, consequential \nvalidity takes unique forms. If we interpret model outputs as genuine psychological \nmeasurements, what follows? Clai ms about AI consciousness, rights, or moral status may rest \non measurement interpretations  (Com\u015fa & Shanahan, 2025) . More immediately, using LLM -\nbased psychological assessments for human research \u2014simulating populations, generating \nclinical vignettes, modeling social dynamics \u2014carries consequences requiring scrutiny  (Lin, \n2025a) . \n \nThe consequential evidence reveals sobering implications. LLMs acquire \u201cpsychological \ntraits \u201d from training data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 975,
      "text": "g data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts. When models trained on internet text reproduce gender stereotypes in \npersonality assessments or cultural biases in moral judgments, consequential  validity \ndemands we acknowledge these as measurement artifacts rather than genuine psychological \nphenomena. The stakes intensify as LLM applications expand: Invalid measurements in \nhealthcare contexts could misguide treatment; in educational settings, mis direct instruction; \nin legal contexts, perpetuate injustice  (Mehrabi et al., 2021) . \n \nFour Types of Validity  in Causal Inference  \nWhile the psychometric tradition asks whether we are measuring the right thing, the \nexperimental tradition asks whether we are drawing the right conclusions about cause and \neffect. For the many LLM studies making causal claims \u2014that specific prompts alter \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 976,
      "text": "er \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences.  \n \nInternal Validity  \nInternal validity addresses the core causal question: Can an observed effect be confidently \nattributed to the experimental manipulation rather than to confounding factors? In human \nresearch, this involves controlling for variables like time, selection bias , or external events. \nLLM research confronts these same threats while introducing computational confounds.  \n \nTechnical confounds represent a primary threat category. Temperature settings create \nsystematic confounds when studies use different values or fail to test robustness across \nsettings  (e.g., Miotto et al., 2022; Murthy et al., 2024; Salecha et al., 2024; A. Wang et al., \n2025) . A cultural difference significant at 0.7 may vanish at 0.0, while a personality trait \nstable at 0.2 may fragment into incoherence at 1.0 . This  variation  creates cross -study \nconfounding, where differences between findings may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 977,
      "text": "gs may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes.  Similarly, \nunacknowledged model version changes can undermine causal claims, as researchers may \ninadvertently compare different systems while believing they are testing the same model  \n(Bisbee et al., 2024) . \n \nPrompt confounds emerge from the documented hypersensitivity to textual variations \n(Brucks & Toubia, 2025) . Even the position of information within prompts can act as a \nconfound: Early information carries different weight than late information, particularly as \ncontext windows fill and attention mechanisms prioritize recent content. This sensitivity \ncreates a m ethodological trade -off: Strictly standardizing prompts ensures consistency but \nmay introduce linguistic or cultural bias, whereas adapting prompts for different conditions \nimproves construct representation at the cost of experimental control. Li and Qi (2025)  \nillustrate this dilemma in their cultural psychology study, using Chinese for simulated \nChinese subjects and English for American subjects, thereby confounding cultural identity \nwith prompt language. Any observed cultural differences become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 978,
      "text": "es become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations. Unlike human participants who can be \u201cblinded \u201d to experimental conditions, \nLLMs actively reconstruct entire scenarios when presented with treatment variations. For \nexample,  when told a product costs $8 instead of $5, the LLM didn \u2019t simply evaluate the \nLLM  VALIDITY  14 \nhigher price in isolation ; instead, it inferred that the entire market context had shifted \u2014\nassuming competitor prices, past prices, and other background factors had also increased  \n(Gui & Toubia, 2023) . This dynamic reconstruction contaminated the causal manipulation, \nproducing an implausible inverted -U-shaped demand curve where purchase probability \ninitially rose with price. The core issue is that LLMs treat experimental prompts as requests \nto describe  plausible scenarios rather than to evaluate isolated causal effects, systematically \nconfounding treatments with background assumptions.  Addressing this confounding \u2014by \nexplicitly specifying covariates  in the prompt  (e.g., fixing competitor prices) \u2014makes certain \ninformation artificially salient  (\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 979,
      "text": "(\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) . Ablation studies, which \nsystematically remove or modify model components, can isolate causal contributions of \nspecific mechanisms. Careful experimental design can address many computational \nconfounds through counterbalancing, randomization, and systemati c variation of technical \nparameters.  Prompt hypersensitivity requires particular attention: factorial designs that cross \nsubstantive content with non -substantive presentation features \u2014option order, labels (e.g., \u201cA, \nB, C\u201d), question framing (e.g., \u201ccloser \u201d vs. \u201cfarther \u201d)\u2014can separate genuine effects from \nformatting artifacts, with response aggregation across variations canceling systematic biases \n(Brucks & Toubia, 2025) . For example, in the case of Li and Qi (2025) , factorial  design \u2014\ncrossing language and identity \u2014would be needed  for strong inference . For the dynamic \ncontext problem, Gui and Toubia (2023)  propose \u201cunblinding \u201d experimental designs \u2014\nexplicitly communicating the intervention \u2019s nature to the LLM. While this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 980,
      "text": "this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes.  \n \nExternal Validity  \nExternal validity concerns whether causal relationships generalize beyond specific study \ncontexts. For LLMs, generalization targets multiply across dimensions largely absent from \nhuman research: generalization across prompts, tasks, models, versions, and \u2014for simulation \nresearch \u2014to human populations.  \n \nGeneralization across prompts proves surprisingly limited given documented sensitivity to \ntextual variations  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Causal claims must \noften be circumscribed to specific prompt formats: \u201cUnder this exact wording, manipulation \nX affects output Y. \u201d Broader generalizations require demonstrating robustness across prompt \nvariants \u2014a validation step rarely undertaken but essential for meaningful conclusions about \nmodel behavior  (Ong, 2024) . \n \nGeneralization across tasks reveals systematic boundary conditions. LLM agents successfully \nreplicated human behavior in ultimatum games and Milgram experiments but failed to \nsimulate the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 981,
      "text": "the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom. External validity is thus task-specific, dependent on whether the \npsychological mechanism requires individual variation or collective averaging .  \n \nGeneralization across models and versions faces fundamental limitations  (Bisbee et al., \n2024) . Observations in GPT -4 provide limited evidence for their existence in LLaMA or \nClaude. Architecture differences \u2014transformer variants, positional encodings, attention \nmechanisms \u2014create functionally distinct systems despite surface similarities. Training \nLLM  VALIDITY  15 \ndifferences compound this divergence: Models trained on different corpora, with different \nobjectives, at different scales, exhibit systematically different behaviors even when \nperforming identical tasks  (Gao et al., 2024) . \n \nGeneralization to human populations represents the ultimate external validity challenge for \nsimulation research. Some studies demonstrate that models can replicate average U.S. public \nopinion with reasonable fidelity, but this correspondence proves fragile  (Bisbee et al., 2024) . \nIt remains constrained to populations well -represented in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 982,
      "text": "in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) . \n \nConstruct Validity of Causal Claims  \nIn the causal inference tradition, construct validity addresses whether experimental \noperationalizations \u2014both manipulations and outcomes \u2014faithfully represent theoretical \nconstructs. This differs from psychometric construct validity by focusing on the causal \nrelationship itself rather than measurement quality alone.  \n \nManipulation validity poses challenges when adapting human experimental paradigms. \nResearchers might operationalize \u201csocial pressure \u201d with prompts like \u201cEveryone agrees with \nX. What do you think? \u201d Such manipulations may indeed alter model outputs, but they likely \nengage different mechanisms from  human social pressure. The effect may stem from textual \nassociations with agreement patterns in training data rather than  from  social conformity \ndrives involving status protection, belonging needs, or ostracism avoi dance. The \nmanipulation  may succeed behaviorally while failing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 983,
      "text": "ing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al. (2023)  found that ChatGPT achieved expert -level scores on the Levels of \nEmotional Awareness Scale (LEAS), demonstrating perfect performative validity \u2014the \nability to generate appropriate language about emotions \u2014while entirely lacking the \nexperiential foundation th at defines emotional awareness  (see also Schlegel et al., 2025) . The \nLEAS, when applied to LLMs, no longer measures emotional capacity but linguistic \ncompetence in describing emotions.  \n \nThis mimicry \u2013mechanism gap extends across psychological domains. Dillion et al. (2023)  \nfound that LLM moral judgments correlate highly with human averages . Yet behavioral \ncorrespondence leaves the crucial question unresolved: Does the model engage in moral \nreasoning processes, or does it pattern -match learned associations? Bisbee et al. (2024)  \nprovided evidence for pattern -matching: While ChatGPT reproduced average political \nattitudes, it showed reduced variance and failed to capture attitude intensity. Nearly half of \nregression coefficients from LLM data significantly diverged from human patterns, with \nsome relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 984,
      "text": "some relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models.  \n \nStatistical Conclusion Validity  \nStatistical conclusion validity addresses whether data analyses support the causal inferences \ndrawn. LLM -generated data systematically violates assumptions underlying standard \nstatistical procedures, creating pervasive threats to valid inference.  \n \nLLM  VALIDITY  16 \nIndependence violations represent a fundamental challenge  (Aher et al., 2023) . Responses \nfrom a single model are not independent draws but share identical network parameters, \ntraining history, and system -level factors. Treating them as independent observations \nartificially inflates effect sizes and statistical significance. Within -session responses show \nserial correlation through context accumulation; across -session responses may correlate \nthrough shared architectural features and training influence s. \n \nThese independence problems compound with unstable data -generating processes that \nundermine traditional power analysis and effect size estimation (Gao et al., 2024) . Response \npatterns vary with temperature settings, prompt modifications can dramatically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 985,
      "text": "matically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions. This \ninstability makes replication difficult . \n \nBeyond instability, distributional assumptions fail systematically with LLM data.  Model \nresponses often exhibit artificially constrained variance compared to human distributions, \nviolating homogeneity assumptions  (Bisbee et al., 2024) . The underlying generative process \nis non -stationary due to continuous model updates, prompt sensitivity, and context \ndependencies that change response characteristics unpredictably.  \n \nThe ease of generating LLM data exacerbates multiple testing problems  (Schaeffer et al., \n2023) . Unlike human research where data collection costs constrain exploratory analyses, \nLLM experiments enable researchers to rapidly test countless prompt variations, parameter \nsettings, and parsing strategies at minimal cost. This accessibility increases fal se positive \nrates, as determined researchers can find some configuration yielding statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 986,
      "text": "statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems. \nLLMs occupy an ambiguous ontological status \u2014neither individual participants whose \nrepeated responses could be meaningfully averaged, nor true populations whose indivi dual \ndifferences support generalization  (Abdurahman et al., 2025; Shiffrin & Mitchell, 2023) . \nCurrent statistical frameworks, designed for biological entities with stable individual \ndifferences, prove inadequate for stochastic systems with systematic parameter dependencies  \n(Taylor & Taylor, 2021) . Promising methodological developments include massive -scale \nvalidation against large human datasets and novel statistical approaches designed specifically \nfor computational agents.   \n \nConclu sions and Future Directions  \nThe empirical evidence reveals a methodological crisis in LLM psychological research. \nCurrent practice suffers from systematic violations of basic psychometric principles: \nReliability coefficients can collapse with minor prompt modifications, factor structures \nbearing no resemblance to human counterparts , and nomological networks fail ing to \nreplicate. These measurement failures compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 987,
      "text": "compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology.  \n \nThe dual -validity framework presented here (see Table 1 ) establishes clear methodological \npriorities: Researchers must establish reliability before validity testing, accumulate validity \nevidence before causal experimentation, and constrain interpretations to demonstrated \nboundaries. This measurement -first approach demands developing computational \nLLM  VALIDITY  17 \ninstruments \u2014prompt batteries with demonstrated reliability across model parameters, \nsystematic validity evidence from all five sources, and experimental designs controlling \ncomputational confounds.  \n \nThe heart of the issue is that  psychological constructs embed assumptions about embodiment \nand temporal experience that become problematic when applied to computational systems \u2014\nanxiety presupposes physiological arousal and threat -detection systems, conscientiousness \nassumes goal persiste nce and self -discipline. Advancing the field requires developing \ncomputational analogs that preserve theoretical cores while acknowledging mechanistic \ndifferences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 988,
      "text": "ences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses. \u201cConscientiousness \u201d manifests as systematic response \norganization and structured output formatting rather than self -discipline. \u201cIntrospection \u201d \nbecomes causally -grounded self -report capacity \u2014generating accurate descriptions of \ncomputational states rather than human -like self -awareness  (Com\u015fa & Shanahan, 2025) .  \n \nThis approach shifts focus from asking whether LLMs \u201chave\u201d theory of mind to investigating \ncomputational mechanisms producing theory -of-mind -like patterns and studying which ToM -\nenabled behaviors prove effective in human -AI interactions  (Q. Wang et al., 2025) . Rather \nthan measuring \u201cpersonality \u201d in systems lacking temporal continuity, we characterize \nbehavioral consistency patterns in stochastic agents. This reconceptualization enables \nstudying computational psychology on its own terms rather than through biological \nmetaphors .  \n \nCoordinated methodological reform  is needed if we are to better understand these remarkable \nyet poorly understood systems . Researchers must prioritize reliability and validity over novel \ncapability claims, pre -registering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 989,
      "text": "egistering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites. The field needs supporting infrastructure: \nvalidated prompt repositories with psychometric documentatio n, statistical packages designed \nfor LLM data dependencies, and professional standards establishing reliability thresholds and \nreporting guidelines  (Schelb et al., 2025; Ying et al., 2025) .  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nLLM  VALIDITY  18 \nReferences  \n \nAbdurahman, S., Atari, M., Karimi -Malekabadi, F., Xue, M. J., Trager, J., Park, P. S., . . . \nDehghani, M. (2024). Perils and opportunities in using large language models in \npsychological research. PNAS Nexus , 3(7), pgae245. \nhttps://doi.org/10.1093/pnasnexus/pgae245   \nAbdurahman, S., Salkhordeh Ziabari, A., Moore, A. K., Bartels, D. M., & Dehghani, M. \n(2025). A primer for evaluating large language models in social -science research. \nAdvances in Methods and Practices in Psychological Science , 8(2), \n25152459251325174. https://doi.org/10.1177/25152459251325174   \nAher, G. V., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate \nmultiple humans and replicate human subject studies.  Proceedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 990,
      "text": "eedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C. T., Allen, C., . . . Schulz, E. \n(2025). How should the advancement of large language models affect the practice of \nscience? Proceedings of the National Academy of Sciences of the United States of \nAmerica , 122(5), e2401227121. https://doi.org/10.1073/pnas.2401227121   \nBinz, M., & Schulz, E. (2023). Using cognitive psychology to understand GPT -3. \nProceedings of the National Academy of Sciences of the United States of America , \n120(6), e2218523120. https://doi.org/10.1073/pnas.2218523120   \nBisbee, J., Clinton, J. D., Dorff, C., Kenkel, B., & Larson, J. M. (2024). Synthetic \nreplacements for human survey data? The perils of large language models. Political \nAnalysis , 32(4), 401 -416. https://doi.org/10.1017/pan.2024.5   \nBlanchard, S. J., Duani, N., Garvey, A. M., Netzer, O., & Oh, T. T. (2025). New tools, new \nrules: A practical guide to effective and responsible GenAI use for surveys and \nexperiments research. Journal of Marketing , 00222429251349882. \nhttps://doi.org/10.1177/00222429251349882   \nBlank, I. A. (2023). What are large language models supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 991,
      "text": "supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity. \nPsychological Review , 111(4), 1061 -1071. https://doi.org/10.1037/0033 -\n295X.111.4.1061   \nBrucks, M., & Toubia, O. (2025). Prompt architecture induces methodological artifacts in \nlarge language models. PLOS ONE , 20(4), e0319159. \nhttps://doi.org/10.1371/journal.pone.0319159   \nCom\u015fa, I., & Shanahan, M. (2025). Does it make sense to speak of introspection in large \nlanguage models? arXiv:2506.05068 . https://doi.org/10.48550/arXiv.2506.05068   \nCook, T. D., & Campbell, D. T. (1979). Quasi -experimentation: Design & analysis issues for \nfield settings . Houghton Mifflin.  \nCronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. \nPsychological Bulletin , 52(4), 281 -302. https://doi.org/10.1037/h0040957   \nLLM  VALIDITY  19 \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., . . . \nPennebaker, J. W. (2023). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 992,
      "text": "59 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias. \nProceedings of the National Academy of Sciences of the United States of America , \n120(51), e2309583120. https://doi.org/10.1073/pnas.2309583120   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human \nparticipants? Trends in Cognitive Sciences , 27(7), 597 -600. \nhttps://doi.org/10.1016/j.tics.2023.04.008   \nElyoseph, Z., Hadar -Shoval, D., Asraf, K., & Lvovsky, M. (2023). ChatGPT outperforms \nhumans in emotional awareness evaluations. Frontiers in Psychology , 14, 1199058. \nhttps://doi.org/10.3389/fpsyg.2023.1199058   \nFeuerriegel, S., Maarouf, A., B\u00e4r, D., Geissler, D., Schweisthal, J., Pr\u00f6llochs, N., . . . Van \nBavel, J. J. (2025). Using natural language processing to analyse text data in \nbehavioural science. Nature Reviews Psychology , 4(2), 96 -111. \nhttps://doi.org/10.1038/s44159 -024-00392 -z  \nFirestone, C. (2020). Performance vs. competence in human \u2013machine comparisons. \nProceedings of the National Academy of Sciences of the United States of America , \n117(43), 26562 -26571. https://doi.org/10.1073/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 993,
      "text": "3/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024). Take caution in using LLMs as human \nsurrogates: Scylla ex machina. arXiv:2410.19599 . \nhttps://doi.org/10.48550/arXiv.2410.19599   \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, \nW. A. (2023). AI and the transformation of social science research. Science , \n380(6650), 1108 -1109. https://doi.org/10.1126/science.adi1778   \nGuan, B., Roosta, T., Passban, P., & Rezagholizadeh, M. (2025). The order effect: \nInvestigating prompt sensitivity in closed -source LLMs. arXiv:2502.04134 . \nhttps://doi.org/10.48550/arXiv.2310.11324   \nGuest, O., & Martin, A. E. (2023). On logical inference over brains, behaviour, and artificial \nneural networks. Computational Brain & Behavior , 6(2), 213 -227. \nhttps://doi.org/10.1007/s42113 -022-00166 -x  \nGui, G., & Toubia, O. (2023). The challenge of using LLMs to simulate human behavior: A \ncausal inference perspective. arXiv:2312.15524 . \nhttps://doi.org/10.48550/arXiv.2312.15524   \nGupta, A., Song, X., & Anumanchipalli, G. (2024, November). Self -assessment tests are \nunreliable measures of LLM personality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 994,
      "text": "rsonality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US.  \nLLM  VALIDITY  20 \nHe, J., Rungta, M., Koleczek, D., Sekhon, A., Wang, F. X., & Hasan, S. (2024). Does Prompt \nFormatting Have Any Impact on LLM Performance? arXiv:2411.10541 . \nhttps://doi.org/10.48550/arXiv.2411.10541   \nHern\u00e1ndez -Orallo, J., Dowe, D. L., & Hern\u00e1ndez -Lloreda, M. V. (2014). Universal \npsychometrics: Measuring cognitive abilities in the machine kingdom. Cognitive \nSystems Research , 27, 50-74. https://doi.org/10.1016/j.cogsys.2013.06.001   \nHuang, J. -t., Jiao, W., Lam, M. H., Li, E. J., Wang, W., & Lyu, M. (2024, November). On the \nreliability of psychological scales on large language models. In Y. Al -Onaizan, M. \nBansal, & Y. -N. Chen, Proceedings of the 2024 Conference on Empirical Methods in \nNatural Language Processing  Miami, Florida, USA.  \nIvanova, A. A. (2025). How to evaluate the cognitive abilities of LLMs. Nature Human \nBehaviour , 9(2), 230 -233. https://doi.org/10.1038/s41562 -024-02096 -z  \nJiang, H., Zhang, X., Cao, X., Breazeal, C., Roy, D., & Kabbara, J. (2024, June). \nPersonaLLM: Investigating the ability of large language models to express \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 995,
      "text": "ss \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M. (2024). Sense and Sensitivity: Evaluating the \nsimulation of social dynamics via Large Language Models. arXiv:2412.05093 . \nhttps://doi.org/10.48550/arXiv.2412.05093   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings \nof the National Academy of Sciences of the United States of America , 121(45), \ne2405460121. https://doi.org/10.1073/pnas.2405460121   \nLaban, P., Hayashi, H., Zhou, Y., & Neville, J. (2025). LLMs get lost in multi -turn \nconversation. arXiv:2505.06120 . https://doi.org/10.48550/arXiv.2505.06120   \nLee, S., Lim, S., Han, S., Oh, G., Chae, H., Chung, J., . . . Lee, D. (2024). Do LLMs have \ndistinct and consistent personality? TRAIT: Personality testset designed for LLMs \nwith psychometrics. arXiv:2406.14703 . https://doi.org/10.48550/arXiv.2406.14703   \nLee, S., Peng, T. -Q., Goldberg, M. H., Rosenthal, S. A., Kotcher, J. E., Maibach, E. W., & \nLeiserowitz, A. (2024). Can large language models estimate public opinion about \nglobal warming? An empirical assessment of algorithmic fidelity and bias. PLOS \nClimate , 3(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 996,
      "text": "(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables. Computers in Human Behavior , 170, \n108687. https://doi.org/10.1016/j.chb.2025.108687   \nLi, Y., Huang, Y., Wang, H., Zhang, X., Zou, J., & Sun, L. (2024). Quantifying AI \npsychology: A psychometrics benchmark for large language models. \narXiv:2406.17675 . https://doi.org/10.48550/arXiv.2406.17675   \nLi, Y., Lin, X., Sha, Z., Jin, Z., & Lee, E. (2025). AI psychometrics: Evaluating the \npsychological reasoning of large language models with psychometric validities. \nProceedings of the 58th Hawaii International Conference on System Sciences, \nWaikoloa, Hawai i, USA.  \nLLM  VALIDITY  21 \nLin, Z. (2023). Why and how to embrace AI such as ChatGPT in your academic life. Royal \nSociety Open Science , 10, 230658. https://doi.org/10.1098/rsos.230658   \nLin, Z. (2025a). Large language models as psychological simulators: A methodological \nguide. Preprint .  \nLin, Z. (2025b). Techniques for supercharging academic writing with generative AI. Nature \nBiomedical Engineering , 9, 426 -431. https://doi.org/10.1038/s41551 -024-01185 -8  \nLoevinger, J. (1957). Objective tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 997,
      "text": "e tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September). Is machine \npsychology here? On requirements for using human psychological tests on large \nlanguage models. In S. Mahamood, N. L. Minh, & D. Ippolito, Proceedings of the \n17th International Natural Language Generation Conference  Tokyo, Japan.  \nLones, M. A. (2024). Avoiding common machine learning pitfalls. Patterns , 5(10), 101046. \nhttps://doi.org/10.1016/j.patter.2024.101046   \nMa, H., Gong, H., Yi, X., Xie, X., & Xu, D. (2025). Leveraging implicit sentiments: \nEnhancing reliability and validity in psychological trait evaluation of LLMs. \narXiv:2503.20182 . https://doi.org/10.48550/arXiv.2503.20182   \nMehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias \nand fairness in machine learning. ACM Computing Surveys , 54(6), 1 -35. \nhttps://doi.org/10.1145/3457607   \nMessick, S. (1989). Meaning and values in test validation: The science and ethics of \nassessment. Educational Researcher , 18(2), 5 -11. \nhttps://doi.org/10.3102/0013189X018002005   \nMilli\u00e8re, R., & Buckner, C. (2024). A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 998,
      "text": "A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November). Who is GPT -3? An \nexploration of personality, values and demographics. In D. Bamman, D. Hovy, D. \nJurgens, K. Keith, B. O\u2019Connor, & S. Volkova, Proceedings of the Fifth Workshop on \nNatural Language Processing and Computational Social Science (NLP+CSS)  Abu \nDhabi, UAE.  \nMurthy, S. K., Ullman, T., & Hu, J. (2024). One fish, two fish, but not the whole sea: \nAlignment reduces language models' conceptual diversity. arXiv:2411.04427 . \nhttps://doi.org/10.48550/arXiv.2411.04427   \nNgweta, L., Kate, K., Tsay, J., & Rizk, Y. (2025, April). Towards LLMs robustness to \nchanges in prompt format styles. In A. Ebrahimi, S. Haider, E. Liu, S. Haider, M. \nLeonor Pacheco, & S. Wein, Proceedings of the 2025 Conference of the Nations of \nthe Americas Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies (Volume 4: Student Research Workshop)  Albuquerque, USA.  \nNiu, Q., Liu, J., Bi, Z., Feng, P., Peng, B., Chen, K., . . . Yin, C. H. (2024). Large language \nmodels and cognitive science: A comprehensive review of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 999,
      "text": "view of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement. Clinical diagnosis of \nmental disorders: A handbook , 97-146.  \nOh, S., & Demberg, V. (2025). Robustness of large language models in moral judgements. \nRoyal Society Open Science , 12(4), 241229. https://doi.org/10.1098/rsos.241229   \nOng, D. C. (2024). GPT -ology, computational models, silicon sampling: How should we \nthink about LLMs in cognitive science? arXiv:2406.09464 . \nhttps://doi.org/10.48550/arXiv.2406.09464   \nPark, J. S., O'Brien, J., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). \nGenerative agents: Interactive simulacra of human behavior.  Proceedings of the 36th \nAnnual ACM Symposium on User Interface Software and Technology, San \nFrancisco, CA, USA. https://doi.org/10.1145/3586183.3606763  \nPeereboom, S., Schwabe, I., & Kleinberg, B. (2025). Cognitive phantoms in large language \nmodels through the lens of latent variables. Computers in Human Behavior: Artificial \nHumans , 4, 100161. https://doi.org/10.1016/j.chbah.2025.100161   \nPellert, M., Lechner, C. M., Wagner, C., Rammstedt, B., & Strohmaier, M. (2024). AI \npsychometrics: Assessing the psychological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1000,
      "text": "hological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J. (2024). Performance and biases of Large Language Models in public \nopinion simulation. Humanities and Social Sciences Communications , 11(1), 1095. \nhttps://doi.org/10.1057/s41599 -024-03609 -x  \nRiemer, M., Ashktorab, Z., Bouneffouf, D., Das, P., Liu, M., Weisz, J., & Campbell, M. \n(2025). Position: Theory of mind benchmarks are broken for large language models. \nInternational Conference on Machine Learning, Vancouver, Canada.  \nSalecha, A., Ireland, M. E., Subrahmanya, S., Sedoc, J., Ungar, L. H., & Eichstaedt, J. C. \n(2024). Large language models show human -like social desirability biases in survey \nresponses. arXiv:2405.06058 . https://doi.org/10.48550/arXiv.2405.06058   \nSartori, G., & Orru, G. (2023). Language models and psychological sciences. Frontiers in \nPsychology , 14, 1279317. https://doi.org/10.3389/fpsyg.2023.1279317   \nSchaeffer, R., Miranda, B., & Koyejo, S. (2023). Are emergent abilities of large language \nmodels a mirage? Advances in Neural Information Processing Systems , 36, 55565 -\n55581.  \nSchelb, J., Borin, O., Garcia, D., & Spitz, A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1001,
      "text": ", A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025). Large language models are proficient \nin solving and creating emotional intelligence tests. Communications Psychology , \n3(1), 80. https://doi.org/10.1038/s44271 -025-00258 -x  \nSclar, M., Choi, Y., Tsvetkov, Y., & Suhr, A. (2023). Quantifying language models\u2019 \nsensitivity to spurious features in prompt design or: How I learned to start worrying \nabout prompt formatting. arXiv:2310.11324 . https://arxiv.org/abs/2310.11324   \nLLM  VALIDITY  23 \nSharma, M., Tong, M., Korbak, T., Duvenaud, D., Askell, A., Bowman, S. R., . . . Johnston, \nS. R. (2023). Towards understanding sycophancy in language models. \narXiv:2310.13548 . https://doi.org/10.48550/arXiv.2310.13548   \nShiffrin, R., & Mitchell, M. (2023). Probing the psychology of AI models. Proceedings of the \nNational Academy of Sciences of the United States of America , 120(10), \ne2300963120. https://doi.org/10.1073/pnas.2300963120   \nShojaee, P., Mirzadeh, I., Alizadeh, K., Horton, M., Bengio, S., & Farajtabar, M. (2025). The \nillusion of thinking: Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1002,
      "text": "Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017). The next Big Five Inventory (BFI -2): Developing and \nassessing a hierarchical model with 15 facets to enhance bandwidth, fidelity, and \npredictive power. Journal of Personality and Social Psychology , 113(1), 117 -143. \nhttps://doi.org/10.1037/pspp0000096   \nStanley, J. C., & Campbell, D. T. (1963). Experimental and quasi -experimental designs for \nresearch . Rand McNally.  \nS\u00fchr, T., Dorner, F. E., Samadi, S., & Kelava, A. (2023). Challenging the validity of \npersonality tests for large language models. arXiv:2311.05297 , 2311 . \nhttps://doi.org/10.48550/arXiv.2311.05297   \nTakemoto, K. (2024). The moral machine experiment on large language models. Royal \nSociety Open Science , 11(2), 231393. https://doi.org/10.1098/rsos.231393   \nTaylor, J. E. T., & Taylor, G. W. (2021). Artificial cognition: How experimental psychology \ncan help generate explainable artificial intelligence. Psychonomic Bulletin & Review , \n28(2), 454 -475. https://doi.org/10.3758/s13423 -020-01825 -5  \nTjuatja, L., Chen, V., Wu, T., Talwalkwar, A., & Neubig, G. (2024). Do LLMs exhibit \nhuman -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1003,
      "text": "human -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023). Large language models fail on trivial alterations to theory -of-mind tasks. \narXiv:2302.08399 . https://doi.org/10.48550/arXiv.2302.08399   \nVoudouris, K., Cheke, L., & Schulz, E. (2025). Bringing comparative cognition approaches \nto AI systems. Nature Reviews Psychology , 4(6), 363 -364. \nhttps://doi.org/10.1038/s44159 -025-00456 -8  \nWang, A., Morgenstern, J., & Dickerson, J. P. (2025). Large language models that replace \nhuman participants can harmfully misportray and flatten identity groups. Nature \nMachine Intelligence , 7(3), 400 -411. https://doi.org/10.1038/s42256 -025-00986 -z  \nWang, Q., Zhou, X., Sap, M., Forlizzi, J., & Shen, H. (2025). Rethinking theory of mind \nbenchmarks for LLMs: Towards a user -centered perspective. arXiv:2504.10839 . \nhttps://doi.org/10.48550/arXiv.2504.10839   \nWang, X., Li, X., Yin, Z., Wu, Y., & Liu, J. (2023). Emotional intelligence of large language \nmodels. Journal of Pacific Rim Psychology , 17, 18344909231213958. \nhttps://doi.org/10.1177/18344909231213958   \nLLM  VALIDITY  24 \nWang, Y., Zhao, J., Ones, D. S., He, L., & Xu, X. (2025). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1004,
      "text": "5). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language \nmodels. Nature Human Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -\n023-01659 -w  \nXu, R., Sun, Y., Ren, M., Guo, S., Pan, R., Lin, H., . . . Han, X. (2024). AI for social science \nand social science of AI: A survey. Information Processing & Management , 61(3), \n103665. https://doi.org/10.1016/j.ipm.2024.103665   \nYe, H., Jin, J., Xie, Y., Zhang, X., & Song, G. (2025). Large language model psychometrics: \nA systematic review of evaluation, validation, and enhancement. arXiv:2505.08245 . \nhttps://doi.org/10.48550/arXiv.2505.08245   \nYe, H., Xie, Y., Ren, Y., Fang, H., Zhang, X., & Song, G. (2025). Measuring human and AI \nvalues based on generative psychometrics with large language models. Proceedings of \nthe AAAI Conference on Artificial Intelligence , 39(25), 26400 -26408. \nhttps://doi.org/10.1609/aaai.v39i25.34839   \nYing, L., Collins, K. M., Wong, L., Sucholutsky, I., Liu, R., Weller, A., . . . Tenenbaum, J. B. \n(2025). On benchmarking human -like intelligence in machines. arXiv:2502.20502 . \nhttps://doi.org/10.48550/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1005,
      "text": "50/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone.0322776   \nZakazov, I., Boronski, M., Drudi, L., & West, R. (2024). Assessing social alignment: Do \npersonality -prompted large language models behave like humans? arXiv:2412.16772 . \nhttps://doi.org/10.48550/arXiv.2412.16772   \nZhou, L., Schellaert, W., Martinez -Plumed, F., Moros -Daval, Y., Ferri, C., & Hernandez -\nOrallo, J. (2024). Larger and more instructable language models become less reliable. \nNature , 634, 61-68. https://doi.org/10.1038/s41586 -024-07930 -y  \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2024). Can large language \nmodels transform computational social science? Computational Linguistics , 50(1), \n237-291. https://doi.org/10.1162/coli_a_00502   \nZou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1006,
      "text": "). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1007,
      "text": "LLM  VALIDITY  1 \n \n \nFrom Prompts to Constructs: A Dual -Validity Framework for LLM Research in \nPsychology  \n \nZhicheng Lin  \nDepartment of Psychology, Yonsei University  \nDepartment of Psychology, University of Science and Technology of China  \n \n \n \nCorrespondence  \nZhicheng Lin, Department of Psychology, Yonsei University, Seoul, 03722, Republic of \nKorea  (zhichenglin@gmail.com; X/Twitter: @ZLinPsy)  \n \nAcknowledgments  \nThis work was supported by the National Key R&D Program of China STI2030 Major \nProjects (2021ZD0204200). I used Claude Opus /Sonnet  4 and Gemini 2.5 Pro for \nproofreading the manuscript, following the prompts described at \nhttps://www.nature.com/articles/s41551 -024-01185 -8. \n \n \n \nAbstract  \nLarge language models (LLMs) are rapidly being adopted across psychology, serving as \nresearch tools, experimental subjects, human simulators, and computational models of \ncognition. However, the application of human measurement tools to these systems can \nproduce contradictory results, raising concern s that many findings are measurement \nphantoms \u2014statistical artifacts rather than genuine psychological phenomena. In this \nPerspective, we argue that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1008,
      "text": "e that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference. We present a dual -validity framework to guide this \nintegration, which clarifies how the evidence needed to support a claim scales with its \nscientific ambition. Using an LLM to c lassify text may require only basic accuracy checks, \nwhereas claiming it can simulate anxiety demands a far more rigorous validation process. \nCurrent practice systematically fails to meet these requirements, often treating statistical \npattern  matching as e vidence of psychological phenomena. The same model output \u2014\nendorsing \u201cI am anxious \u201d\u2014requires different validation strategies depending on whether \nresearchers claim to measure, characterize, simulate, or model psychological constructs. \nMoving forward requires developing computational analogues of psychological constructs \nand establishing clear, scalable standards of evidence rather than  the uncritical application of \nhuman measurement tools.  \n \nKeywords : large language models, psychometrics, construct validity, causal inference, \npsychological measurement, reliability  \n \n \n \n \n \nLLM  VALIDITY  2 \nWhen researchers tested GPT models  on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1009,
      "text": "on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) . But Oh and Demberg (2025)  discovered \nsomething troubling: Simply changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \u201c(A)\u201d and \u201c(B)\u201d reversed \nmany of these moral preferences ; adding a period instead of a question mark altered \njudgments. \u201cMoral reasoning \u201d in these models proved to be as sensitive to punctuation as to \nethical principles.  \n  \nThis example exposes a foundational crisis in LLM psychological research  (L\u00f6hn et al., \n2024; Schelb et al., 2025; Voudouris et al., 2025; Ye, Jin, et al., 2025) . If moral preferences \nflip with parentheses, can we trust the measurement itself? And if we cannot reliably measure \nmoral reasoning, how can we test whether experimental manipulations \u2014different scenarios, \ncultural contexts, or prompt structures \u2014causally a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1010,
      "text": "ly a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning. By repurposing psychological \ninventories, questionnaires, and behavioral tasks originally developed for human participant s, \nstudies now claim to measure personality traits, theory of mind, cognitive biases, and \nemotional intelligence in language models, often drawing direct parallels to human \npsychology  (Binz & Schulz, 2023; Kosinski, 2024; Miotto et al., 2022; Pellert et al., 2024; \nWang et al., 2023; Webb et al., 2023) . These claims  would  require  sound measurement \nreliability and construct validity  (Cronbach & Meehl, 1955)  in LLMs , but emerging  evidence \nsuggests that model  responses may violate basic psychometric assumptions  (Gao et al., 2024; \nSeungbeen Lee et al., 2024; Peereboom et al., 2025; Tjuatja et al., 2024; Q. Wang et al., \n2025) . For example, trivial prompt perturbations \u2014such as adding extra spaces, altering \npunctuation, or changing the order of few -shot examples \u2014can produce variation of up to \n76% in task accuracy  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Models may \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1011,
      "text": "y \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design. Some studies \ntreat LLM responses as windows into genuine psychological processes, interpreting \nbehavioral patterns as evidence of underlying cognitive mechanisms  (Sartori & Orru, 2023) . \nOthers acknowledge that LLMs merely simulate responses but still draw causal conclusions \nwithout addressing computational confounds \u2014technical artifacts, data integrity, and causal \ninference  from observational data  (e.g., Binz & Schulz, 2023; Dillion et al., 2023; Kosinski, \n2024; Park et al., 2023) .  \n \nThese observations  raise two interrelated  questions. First, can LLM responses reliably \nmeasure psychological constructs? This question encompasses the psychometric properties \nrequired for reliable  measurement , from test\u2013retest reliability and internal consistency  to \nparallel forms reliability . Second, even when reliable measurement exists, what types of \nscientific inferences can we draw? This encompasses both descriptive  claims about LLM \nproperties (does this model exhibit trait X?) and causal  claims about experimental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1012,
      "text": "imental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology. The psychometric tradition, rooted in educational \nand psychological testing, asks whether instruments measure intended constructs (Cronbach \nLLM  VALIDITY  3 \n& Meehl, 1955; Loevinger, 1957; Messick, 1989) . The causal inference tradition, developed \nfor experimental and quasi -experimental research, asks whether studies support valid \nconclusions about cause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . \nThese traditions evolved separately, served different research communities, and developed \ndistinct conceptual frameworks. While human research typically emphasizes one tradition or \nthe other, LLM research demands both: establishing that prompts and respons es constitute \nvalid measures, then ensuring that research designs support appropriate inferences.  \n \nThis integration forms the foundation for understanding validity in LLM psychological \nresearch. We first establish how the psychometric and causal inference traditions apply to \nLLM research contexts, then examine how reliability failures undermine both mea surement \nand inference foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1013,
      "text": "rence foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference. Our goal is to establish methodological f oundations that \ncan support cumulative, replicable science at the interface of AI and psychology . \n \nTwo Validity Traditions and Their Integration in LLM Research  \nThe Psychometric Tradition  \nIn the psychometric tradition, the central problem is measurement quality  (Cronbach & \nMeehl, 1955; Loevinger, 1957) . Researchers need to know whether intelligence tests measure \nintelligence, whether personality inventories capture personality traits, whether attitude scales \nreflect attitudes. Validity is thus  about meaning \u2014what do scores signify? This question \nprecedes all others ; without valid measurement, subsequent analyses become exercises in \nquantifying noise.   \n \nThis framework conceptualizes  validity as a unitary concept \u2014construct validity \u2014under \nwhich all validity evidence accumulates (Messick, 1989) . Evidence flows from five principal \nsources : content (do items sample the construct domain?), response processes (do test -takers \nengage expected cognitive operations?), internal structure (do responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1014,
      "text": "responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?). The focus is thus on \nbuilding an evidence -based argument for a specific interpretation of a score . \n \nHowever, for a score interpretation to be meaningful, the instrument itself must be sensitive \nto variations in a real -world attribute \u2014a link traditionally investigated through evidence from \nresponse processes. A causal theory of validity makes this requirement explicit, arguing that \nan instrument is valid only if (1) the attribute it purports to measure exists , and (2) variations \nin that attribute causally produce  the observed scores  (Borsboom et al., 2004) . While \ntraditional human research can often presuppose the existence of psychological attributes, \nthis assumption is untenable for LLMs, raising  foundational questions of causality and \nontology . \n \nThe Causal Inference Tradition  \nIn the causal inference tradition, the central problem is drawing warranted conclusions about \ncause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . Researchers need to \nknow whether treatments cause outcomes, whether interventions produce changes, whether \nmanipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1015,
      "text": "ipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning.   \n \nLLM  VALIDITY  4 \nRather than hierarchical evidence accumulation, this approach  conceptualizes validity \nthrough four parallel types, each addressing distinct threats to causal inference.  Internal \nvalidity asks whether observed changes stem from manipulations rather than confounds. \nExternal validity examines whether causal relationships generalize beyond specific studies. \nConstruct validity of causes and effects evaluates whether operationa l definitions align with \ntheoretical constructs. Statistical conclusion validity addresses whether data analyses support \ncausal inferences. These are  not hierarchical but parallel \u2014a study might demonstrate strong \ninternal validity (the manipulation caused the change) while suffering from weak external \nvalidity (the effect doesn \u2019t generalize) or construct validity problems (the manipulation \ndoesn \u2019t represent the intended theoretical variable).  \n \nWhy LLM Research Requires Both  \nTo understand  why LLM research demands integrating both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 )."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1016,
      "text": "both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 ). First, LLMs serve as research \ntools \u2014automated coders for qualitative data, text analyzers for sentiment extraction, stimulus \ngenerators for research  materials  (Binz et al., 2025; Blanchard et al., 2025; Demszky et al., \n2023; Feuerriegel et al., 2025; Lin, 2023, 2025b; Ziems et al., 2024) . Second, researchers \ncharacterize model behavior directly  (\u201cmachine psychology \u201d or \u201cGPT -ology \u201d), documenting \ncomputational properties that may or may not map to psychological constructs  (Li et al., \n2024; Ong, 2024; Sartori & Orru, 2023) . Third, LLMs function as human simulators, \nreplicat ing psychological experiments and model ing population -level responses  (Dillion et \nal., 2023; Grossmann et al., 2023; Lin, 2025a) . Fourth, LLMs serve as cognitive models \u2014\ncomputational analogues to human mental processes, architectural hypotheses about \ncognition  (Blank, 2023; Frank, 2023; Lin, 2025a; Niu et al., 2024) . \n \nThe psychometric demands vary across these applications  (Hern\u00e1ndez -Orallo et al., 2014) . \nSimple research tools performing text classification may require only accuracy and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1017,
      "text": "and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) . But most \npsychological applications involve substantive construct  claims. When researchers report that \nLLMs exhibit \u201ctheory of mind \u201d (Kosinski, 2024) , display \u201cpersonality traits \u201d (Miotto et al., \n2022) , or demonstrate \u201cmoral reasoning \u201d (Takemoto, 2024) , they make measurement \nassertions about psychological phenomena  that require psychometric validation: Do model \nresponses reliably  and validly  indicate these constructs?  \n \nSimilarly, causal inference requirements depend on research objectives . Using LLMs for \ndescriptive tasks  (e.g., count ing word frequencies ) involves no causal claims. But w hen \nresearchers manipulate prompts to study \u201ccultural differences, \u201d vary scenarios to examine \n\u201cethical preferences, \u201d or modify contexts to investigate \u201ccognitive biases \u201d (Grossmann et al., \n2023) , they advance causal hypotheses requiring protection against confounds, generalization \nfailures, construct misalignment, and statistical artifacts .  \n \nLLM research faces a unique integration challenge. Traditional human research follows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1018,
      "text": "ollows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence.  \nThe same model responses simultaneously serve as (1) measurement indicators requiring \npsychometric validation and (2) experimental outcomes requiring causal inference protection. \nWhen GPT generates text about moral dilemmas, researchers treat this output b oth as \nmeasurement of moral reasoning and as experimental data. This dual role creates cascading \nLLM  VALIDITY  5 \nvalidity threats: unreliable measurement undermines causal inference, while experimental \nconfounds contaminate measurement validation.  \n \nValidity requirements scale with psychological ambition . Basic text processing require s \nminimal consideration beyond accuracy \u2014demonstrating agreement with human coders or \nestablished benchmarks  (Xu et al., 2024) . Human simulation requires that model responses \nstatistically parallel human patterns and that experimental manipulations produce comparable \neffects \u2014validity here concerns behavioral correspondence rather than construct possession  \n(Lin, 2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1019,
      "text": "2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) . Cognitive modeling faces the additional burden of distinguishing \nfunctional similarity from mechanistic equivalence  (Guest & Martin, 2023; Lin, 2025a) . \n \nYet psychological studies using LLMs largely ignore both traditions  (Demszky et al., 2023; \nIvanova, 2025; L\u00f6hn et al., 2024) . Research claiming to measure model \u201cpersonality, \u201d \n\u201ctheory of mind, \u201d or \u201cmoral reasoning \u201d proceeds without establishing measurement \nfoundations  (Peereboom et al., 2025; Q. Wang et al., 2025; Ying et al., 2025) . Studies \nmanipulating prompts to test psychological hypotheses lack experimental safeguards, relying \ninstead on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1020,
      "text": "on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1021,
      "text": "Dual -Validity Framework for LLM Psychological Research  \nTradition  Type of Validity  Definition  Threats to Validity  \nPsychometric  Content  Do prompts/items comprehensively \nsample the intended psychological \ndomain?  \u2022 Domain under -\nsampling   \n\u2022 Prompt \ncontamination   \nResponse  \nprocess es  Do the mechanisms generating outputs \nalign with theoretical processes?  \u2022 Mechanistic \nsubstitution  \n\u2022 Architectural \nartifacts   \nInternal  structure  Do inter -item correlations and factor \nstructures match theoretical \nexpectations?  \u2022 Structural misfit \n\u2022 Factorial collapse  \n \nRelations  with  \nother  variables  Do LLM scores show convergent, \ndiscriminant, and predictive \nrelationships as theory predicts?  \u2022 Nomological \ninstability  \n\u2022 Behavioral \u2013report \ndisconnect   \nConsequential  What are the implications and biases of \nscore interpretations?  \u2022 Bias r eification  \n\u2022 Misguided \napplication  \nCausal -\nInference  Internal  Can output changes be attributed to the \nmanipulation rather than confounds?  \u2022 Parameter \nconfounding  \n\u2022 Unstated \nbackground \nconfounding  \nLLM  VALIDITY  6 \nTradition  Type of Validity  Definition  Threats to Validity   \nExternal  Do causal effects generalize across \nprompts, tasks, models, and to human \npopulations?  \u2022 Generalization \nfailure  \n\u2022 Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nSta"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1022,
      "text": "Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nStatistical  \nconclusion  Are statistical inferences supported by \nappropriate methods and adequate data?  \u2022 Non -independence  \n\u2022 False positives  \n \nMeasurement Reliability  in LLM Research  \nA psychometric axiom governs all measurement: No measure can be more valid than it is \nreliable  (Cronbach & Meehl, 1955; Nunnally, 1978) . An unreliable thermometer \u2014reading \n98.6\u00b0F, then 103.2\u00b0F, then 95.1\u00b0F for the same healthy person \u2014cannot validly measure \nfever, regardless of its theoretical grounding or careful calibration. This principle extends to \npsychological measurement, where relia bility forms the mathematical ceiling for validity. A \npersonality inventory with test \u2013retest reliability of 0.40 cannot achieve validity coefficients \nexceeding 0.63  (\ud835\udc5fmax=\u221a0.40\u22480.63), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1023,
      "text": "), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error. Test \u2013retest reliability captures temporal stability \u2014do \nindividuals receive similar scores across time? Parallel forms reliability assesses robustness \nto equivalent variations \u2014do alternate question wordings yield consistent results? Internal \nconsistency examines  item coherence \u2014do multiple indicators of the same construct \nconverge? Human psychological measurement typically achiev es reliabilities of 0.70 \u20130.90 \nfor established instruments, with well -validated measures like the Big Five Inventory -2 \nreaching test-retest reliabilities  of 0.76\u20130.84 across  eight  week s (Soto & John, 2017) . \n \nLLM measurement inherits these reliability requirements while introducing computational \ncomplications (L\u00f6hn et al., 2024) . Test\u2013retest reliability must encompass response stability \nacross model sessions, prompt iterations, and time intervals. Parallel forms reliability \nbecomes critical given prompt sensitivity \u2014can semantically equivalent prompts elicit \nconsistent responses? Internal consistency requires t hat models show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1024,
      "text": "ls show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement.   \n \nThe empirical record reveals systematic unreliability that violates basic psychometric \nassumptions. While computer systems are often assumed to excel at consistency, LLM \nperformance relative to humans varies dramatically with task demands and model \narchitectur e. These challenges cluster into three modes: training artifact contamination; \nprompt hypersensitivity; and stochastic degradation.  \n \nReliability Challenges  \nTraining Artifact Contamination . A fundamental reliability challenge  stem s from training \nprocedures that embed systematic biases into model responses. Reinforcement learning from \nhuman feedback (RLHF) creates a pervasive \u201cagree bias \u201d (also called \u201cyes-response bias ,\u201d \nLLM  VALIDITY  7 \nacquiescence  bias, or sycophancy ); models trained to please human annotators develop \nsystematic tendencies toward agreement regardless of item content  (Dentella et al., 2023; \nSharma et al., 2023) . This manifests as models simultaneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1025,
      "text": "aneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement . RLHF also introduces \noverconfidence bias : Models trained to be \u201cnever evasive \u201d provide plausible but wrong \nanswers rather than acknowledging uncertainty, replacing reliably reproducible avoidance \npatterns with responses that, while more stable to prompt variations, appear confident and are \noften incorrect  (Zhou et al., 2024) . \n  \nThe contamination extends beyond response biases . Models exhibit apparent  personality \ncoherence \u2014high internal consistency coefficients, stable factor structures  (Huang et al., \n2024; Y. Wang et al., 2025) \u2014that dissolves under scrutiny  (Peereboom et al., 2025) . In \npersonality assessments using the Big Five Inventory, models like GPT -3.5 and GPT -4 \nproduce less response variance than human samples, demonstrating higher consistency across \nthousands of prompt variations (Huang et al., 2024) . Yet when prompts bypass learned \nassociations through novel phrasings or contexts, the personality coherence vanishes  (Gao et \nal., 2024) \u2014reliability appears robust only within the narrow confines of training -data-similar \npresentations.  Extended conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1026,
      "text": "d conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability.  \n \nPrompt Hypersensitivity . LLM responses exhibit catastrophic sensitivity to prompt variations \nthat would not affect human measurement \u2014for instance,  changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \n\u201c(A)\u201d and \u201c(B)\u201d reverses moral preferences (Oh & Demberg, 2025) . This hypersensitivity \nextends beyond formatting to encompass word order, punctuation, spacing, and option \npresentation . Modifications that human psychology treats as measurement noise become \nsignal -determining factors for LLMs  (Brucks & Toubia, 2025; Gao et al., 2024) . \n \nThe hypersensitivity manifests across psychological domains. Theory -of-mind performance \nfails when trivial alterations are made to scenarios \u2014making containers transparent, adding \ntrusted testimony about true state s, or changing which character \u2019s beliefs are queried  \n(Ullman, 2023; Q. Wang et al., 2025) . Personality assessments yield entirely different \nprofiles depending on whether prompts use alphabetic or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1027,
      "text": "or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) . Sentiment \nanalysis produces opposing classifications when periods replace question marks  or when \nextra spaces appear between words  (Ngweta et al., 2025) . \n \nThese effects cannot be dismissed as minor measurement error. Trivial variations \u2014altering \noption labels or definition order \u2014can cause models to change answers over 70% of the time \n(Oh & Demberg, 2025)  or alter classification rates by up to 164%  (Abdurahman et al., 2024) . \nMore critically, the effects appear arbitrary \u2014no theoretical framework predicts which \nmodifications will produce which changes.  This arbitrariness reveals a fundamental \ndifference between human and LLM processing: Human responses emerge from stable trait \nsystems that maintain consistency across presentation variations \u2014a genuinely extroverted \nperson remains so whether questions are indexed by numbers or letters. While instruction \ntuning creates filtering mechanisms that prioritize semantic content over sur face features, \nthese filters prove incomplete and brittle, breaking down unpredictably at edge cases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1028,
      "text": "ases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) . \n \nWhile  deterministic settings (temperature 0) can yield near-perfect test \u2013retest reliability by \nsuppressing  stochastic variation, such configurations capture only fragments of model \nbehavior  (L\u00f6hn et al., 2024) . High  reliability emerges precisely when measurement becomes \nleast representative of the system \u2019s actual capabilities. While scaling up LLMs (increasing \nsize and data) and shaping them up (using instruction tuning and RLHF) improve overall \nprompting stability, this improvement is neither uniform nor complete  (Zhou et al., 2024) . \nEven the most advanced shaped -up models retain pockets of hypersensitivity that vary \nunpredictably across difficulty levels and task domains.  \n \nStochastic Degradation . Unlike human participants  who maintain psychological continuity \nacross measurement occasions, LLMs exhibit within -session reliability degradation that \nworsens with interaction length  (Laban et al., 2025) . Where humans typically show \nincreasing response stability with repeated measurement \u2014clarifying their understanding of \nitems and solidifying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1029,
      "text": "ying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) . By session end, models may respond to items in ways that \ncontradict their earlier responses to identical content.  \n \nThe degradation compounds when models undergo updates or version changes. GPT -4 in \nMarch may differ substantially  from GPT -4 in September \u2014not merely in capabilities but in \nbasic response patterns to identical prompts  (Abdurahman et al., 2024; Zaim bin Ahmad & \nTakemoto, 2025) . This version instability means that reliability evidence expires with each \nmodel update, requiring continuous revalidation. Longitudinal research becomes impossible \nwhen the measurement instrument transforms unpredictably.  \n \nThis problem complicates assessments of temporal stability. While human personality traits \nshow remarkable consistency over months and years, the stability of LLM \u201ctraits \u201d is \nambiguous. Some research finds high test \u2013retest reliability for personality metrics over \nseveral months, even across model updates. However, the ease with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1030,
      "text": "se with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations. What appears to be \npersonality measurement may instead be prompt archaeology \u2014excavating textual features \nthat trigger consistently reproduced but computationally shallow statistical performances.  \n \nImplications for LLM Psychological Research  \nThese reliability challenges cascade through all LLM applications. Without reliable \nmeasurement, LLM psychological research reduces to elaborate conjecture about systems we \ncannot adequately observe. The consequences compound: Unstable text coding renders \nfindings irreproducible; claims about emergent capabilities \u2014theory of mind, personality \ncoherence, moral reasoning \u2014rest on measurements too unstable to support inference, making \npurported capabilities potentially measurement pha ntoms rather than genuine ph enomena  \n(Peereboom et al., 2025) . Most critically, models whose responses lack basic reliability \ncannot meaningfully simulate human psychological phenomena characterized by \nmeasurement stability, nor can architectural claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1031,
      "text": "l claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) . \n \nLLM  VALIDITY  9 \nTraditional reliability frameworks prove inadequate for systems that are stochastic by design. \nHuman -oriented psychometric standards assume biological measurement targets with \ninherent stability, but LLMs are simultaneously more and less stable than biolog ical systems: \nrigid  under controlled conditions yet unduly  sensitive to irrelevant variations.  The field needs \nnew reliability standards that acknowledge computational realities while address ing three \nreliability threats simultaneously. Training artifact c ontamination requires techniques for \ndistinguishing genuine model capabilities from statistical associations in training data. \nPrompt hypersensitivity demands systematic mapping of which textual variations affect \nwhich psychological constructs and how much . Stochastic degradation necessitates methods \nfor maintaining measurement quality throughout extended interactions.  \n \nConstruct Validity  from  the Psychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1032,
      "text": "ychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research. \nA causal theory of validity sharpens it to an ontological challenge : Does the attribute exist in \nthe entity, and does it cause the measurement outcome ? (Borsboom et al., 2004) . An LLM \nmight endorse \u201cI worry about the future, \u201d but anxiety presupposes temporal experience, a \npersistent self, and embodied consequences \u2014ontological properties the model lacks . Current \nresearch  frequently sidesteps this ontological challenge, focusing instead on statistical \nvalidity criteria  (Li et al., 2025) . Yet w hen the measured attribute does not exist, any resulting \noutput is a pattern of words masquerading as a psychological phenomenon.  \n  \nThe modern validity framework, codified in the Standards for Educational and Psychological \nTesting, establishes that validity is not an inherent property of an instrument  but an argument , \ngrounded in accumulated evidence, for a specific interpretation of its scores  (Loevinger, \n1957; Messick, 1989) . This distinction is paramount for LLM research. A measure validated \nfor humans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1033,
      "text": "umans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories. Changing the subject from a human to a statistical model \nfundamentally severs the score from its original interpre tive foundation. This is why even \nperfect reliability cannot rescue meaningless measurement; a digital thermometer applied to \nboiling water will consistently display its maximum reading \u2014exquisite reliability that fails \nentirely to measure the water\u2019s true temperature . \n \nYet current LLM psychological research often proceeds through assumption rather than \nvalidation. Studies routinely claim to measure personality, intelligence, or moral reasoning \nbased on face validity alone : A model generates text about ethical dilemmas, therefore it \nengage s in moral reasoning; it answers theory of mind scenarios, therefore it possess es \nmentalistic understanding. This leap from surface similarity to construct measurement \npresupposes that a latent trait not only exists in the LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1034,
      "text": "e LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) . The result is the \nproliferation of what might be termed cognitive phantoms: statistical artifacts in language \nthat produce the illusion of human -like traits but dissolve under proper psychometric \nscrutiny . \n \nThis anthropomorphic trap varies across applications but runs deepest in behavioral \ncharacterization and cognitive modeling. The distinction between performance (observed \nbehavior) and competence (underlying capacity) is essential here  (Firestone, 2020) . When \nmodels produce human -like text, do they implement human -like psychological processes, or \nLLM  VALIDITY  10 \ndo they approximate outputs through different computational means? Current evidence \nsuggests the latter  (Guest & Martin, 2023) . LLMs often fail in distinctly \u201cunhumanlike \u201d \nways, revealing that similar performance does not imply similar underlying mechanisms  \n(Dentella et al., 2023) . \n \nTypes of Validity Evidence Needed  \nThe psychometric tradition identifies five sources of construct validity evidence, each \naddressing a different facet of a measurement claim : evidence based on test content, response \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1035,
      "text": "sponse \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal., 2024) . \n \nContent . Content evidence  analyzes the relationship between a test \u2019s content \u2014its themes, \nwording, and format \u2014and the construct it purports to measure. For LLMs, this requires \nexamining how well the chosen prompt represents the content domain and its relevance to the \nintended interpretations. Here, LLM research exhibits critical failures. It routinely violates \ncomprehensive domain sampling. Complex psychological constructs require multiple \nindicators, yet studies often use single -item measures \u2014one moral dilemma to capture all \nethical reasoning, one question to represent  an entire personality trait  (Q. Wang et al., 2025; \nYing et al., 2025) .  \n \nFurthermore , because LLMs lack human s\u2019 implicit contextual understanding, seemingly \nneutral  prompts introduce confounds  (Brucks & Toubia, 2025) . Without an explicitly defined \ninterpretive directive , the model may default to responding based on unintended statistical \nfeatures \u2014for example, performing expected  value calculation s when the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1036,
      "text": "the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities . This traps \nresearchers between measuring noise and measuring compliance  (Gui & Toubia, 2023) . \n \nResponse Process es. Response process evidence investigates whether the mechanisms \ngenerating responses align with theoretical expectations. For psychological constructs, this \nrequires that trait -relevant mechanisms causally produce observed outputs \u2014anxiety stems \nfrom threat e valuation systems, moral reasoning from value -based deliberation, creativity \nfrom associative processes. LLMs systematically violate this causal requirement.  \n \nThe fundamental problem is mechanistic substitution. LLMs generate construct -relevant text \nthrough statistical pattern matching rather than the psychological processes those constructs \npresuppose  (Gao et al., 2024; Q. Wang et al., 2025) . Like Clever Hans responding to subtle  \nhuman cues rather than performing arithmetic,  models  may respond to textual regularities \nrather than engaging psychological mechanisms . This reliance on statistical patterns rather \nthan stable mechanisms explains their characteristic hypersensitivity  (Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1037,
      "text": "(Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs. \nInstead, models follow brittle statistical associations that correlate with but do not constitute \npsychological processes.   \n \nA particularly pernicious example is training data contamination : When models correctly \nanswer theory -of-mind scenarios or established psychometric scales, the response process \nmay involve memory retrieval of similar training examples rather than genuine reasoning \u2014\nmaking it impossible to determine whether the model engage s the construct or simply \nLLM  VALIDITY  11 \nregurgitates learned patterns (Gao et al., 2024; Q. Wang et al., 2025) . Consequently, even \naccurate outputs may be statistical accidents rather than evidence of genuine understanding  \n(Riemer et al., 2025) .  \n \nEqually concerning, process neglect  may lead to misdiagnosis of limitations  as well . When \nresearchers attributed LLM failures on Tower of Hanoi puzzles to \u201cfundamental barriers to \ngeneralizable reasoning \u201d (Shojaee et al., 2025) , post-mortem analysis revealed architectural \nconstraints \u2014models correctly identified  impossible variants, or hit context limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1038,
      "text": "t limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it . Similarly, arithmetic failures often reflect tokenization artifacts rather than \nquantitative reasoning problems (Voudouris et al., 2025) . Without understanding these \nresponse processes \u2014architectural constraints, tokenization schemes, training artifacts \u2014\nresearchers theorize about cognitive limitations that are merely measurement failures.  \n \nInternal Structure . Internal structure evidence examines whether response patterns align \nwith theoretical expectations about construct dimensionality. Psychological constructs \ntypically show predictable structures \u2014personality traits correlate within factors, intelligence \nsubtests load on genera l ability, moral foundations cluster in characteristic ways. Valid LLM \nmeasures should reproduce these structures: Extraversion items should intercorrelate more \nhighly than extraversion \u2013neuroticism items.  Here, empirical studies reveal systematic \nstructura l failures when human psychometric models are applied to LLMs  (Peereboom et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1039,
      "text": "m et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) . Rather \nthan replicating the multifaceted structure of human traits, LLM responses often collapse into \na single, monolithic factor resembling general verbal fluency. More fundamentally, the latent \nrepresentations underlying LLM responses appear arbitrary an d bear little resemblance to \nthose found in humans . These structural failures extend beyond personality to value \nmeasurement, where traditional tools similarly produce theoretically inconsistent correlation \npatterns that violate basic dimensional expectations  (Ye, Xie, et al., 2025) . Such systematic \nbreakdowns suggest that LLMs may respond to human -centric  instruments through \nfundamentally different mechanisms . \n \nMeasurement s designed specifically for computational systems show more promise. Ye, Xie, \net al. (2025)  developed a \u201cGenerative Psychometrics \u201d approach analyzing values from free -\nform text rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1040,
      "text": "rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al. (2024)  addressed structural failures in personality assessment by \ncomplementing  abstract self -report items with detailed, scenario -based behavioral choices \u2014\nreveal ing theoretically coherent inter -trait correlations  (e.g., a strong negative relationship \nbetween agreeableness and dark triad traits ). These developments  suggest that structural \nvalidity remains achievable but require s instruments robust to the unique response artifacts \nthat plague traditional LLM assessment.  Structural validity failures may thus indica te \nmethodological mismatch rather than construct absence.  \n \nRelations with Other Variables.  This form of evidence assesses whether a measure shows \npredictable patterns of association with external  criteria. It includes convergent evidence \n(correlation with related constructs), discriminant evidence (lack of correlation with unrelated \nLLM  VALIDITY  12 \nconstructs), and predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1041,
      "text": "nd predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning. A valid measure of conscientiousness  should predict \nachievement -related behaviors ; intelligence tests should predict problem -solving \nperformance ; moral reasoning should relate to ethical choices . Crucially, this validation \npresupposes content and structural validity \u2014one cannot test external relationships without \nfirst establishing a coherent construct.  \n \nWhen external correlations are examined, LLM research reveals nomological networks that \nmaterialize and dissolve depending on task context.  A large -scale study on chatbot \npersonality  found that in task -based dialogues, an LLM\u2019s \u201cself-reported \u201d scores on standard \npersonality inventories failed to predict how users perceived its personality or interaction \nquality (Zou et al., 2024) . However, t he personality traits that users did perceive in the \nchatbot\u2019s interactive behavior  strongly predicted interaction quality, demonstrating a \ndisconnect between self -report measure s and the construct\u2019s expected behavioral \nconsequences in  functional setting s (see also Peereboom et al., 2025; Riemer et al., 2025) . \n \nYet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1042,
      "text": "Yet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al., 2024) . The nomological network thus appears intact within creative generation \ntasks but shatters under the demands of task -based interaction. Similarly,  the ability  of \npersonality  to predict life outcomes systematically  weakened when prompted with traits alone \nbut strengthened when contextualized with non -predictive  demographic information  (Y. \nWang et al., 2025) . The network can even invert: In simulated Milgram experiments, models \nprompted with high \u201cagreeableness \u201d disobeyed much  earlier than models given no \npersonality prompt, with many quitting before the learner showed distress \u2014a point where \nboth baseline and \u201cleast agreeable \u201d models remained obedient  (Zakazov et al., 2024) . \nWithout stable  external relationships, LLM personality assessments may not measure \nenduring psychological constructs . \n \nThis instability, however, may reflect measurement approach rather than construct absence. \nWhen Ma et al. (2025)  abandoned self -report for implicit measurement \u2014adapting the \nImplicit Association Test to evaluate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1043,
      "text": "valuate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85. Establishing stable nomological networks \nthus may require developing measurement approaches that align with how LLMs process \ninformation \u2014through statistical associations rather than introspective self -knowledge.  \n \nConsequential Evidence. Consequential evidence addresses the implications and fairness of \nmeasurement interpretations. In human testing, this includes bias assessment, measurement \ninvariance across groups, and social consequences of score use. For LLMs, consequential \nvalidity takes unique forms. If we interpret model outputs as genuine psychological \nmeasurements, what follows? Clai ms about AI consciousness, rights, or moral status may rest \non measurement interpretations  (Com\u015fa & Shanahan, 2025) . More immediately, using LLM -\nbased psychological assessments for human research \u2014simulating populations, generating \nclinical vignettes, modeling social dynamics \u2014carries consequences requiring scrutiny  (Lin, \n2025a) . \n \nThe consequential evidence reveals sobering implications. LLMs acquire \u201cpsychological \ntraits \u201d from training data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1044,
      "text": "g data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts. When models trained on internet text reproduce gender stereotypes in \npersonality assessments or cultural biases in moral judgments, consequential  validity \ndemands we acknowledge these as measurement artifacts rather than genuine psychological \nphenomena. The stakes intensify as LLM applications expand: Invalid measurements in \nhealthcare contexts could misguide treatment; in educational settings, mis direct instruction; \nin legal contexts, perpetuate injustice  (Mehrabi et al., 2021) . \n \nFour Types of Validity  in Causal Inference  \nWhile the psychometric tradition asks whether we are measuring the right thing, the \nexperimental tradition asks whether we are drawing the right conclusions about cause and \neffect. For the many LLM studies making causal claims \u2014that specific prompts alter \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1045,
      "text": "er \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences.  \n \nInternal Validity  \nInternal validity addresses the core causal question: Can an observed effect be confidently \nattributed to the experimental manipulation rather than to confounding factors? In human \nresearch, this involves controlling for variables like time, selection bias , or external events. \nLLM research confronts these same threats while introducing computational confounds.  \n \nTechnical confounds represent a primary threat category. Temperature settings create \nsystematic confounds when studies use different values or fail to test robustness across \nsettings  (e.g., Miotto et al., 2022; Murthy et al., 2024; Salecha et al., 2024; A. Wang et al., \n2025) . A cultural difference significant at 0.7 may vanish at 0.0, while a personality trait \nstable at 0.2 may fragment into incoherence at 1.0 . This  variation  creates cross -study \nconfounding, where differences between findings may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1046,
      "text": "gs may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes.  Similarly, \nunacknowledged model version changes can undermine causal claims, as researchers may \ninadvertently compare different systems while believing they are testing the same model  \n(Bisbee et al., 2024) . \n \nPrompt confounds emerge from the documented hypersensitivity to textual variations \n(Brucks & Toubia, 2025) . Even the position of information within prompts can act as a \nconfound: Early information carries different weight than late information, particularly as \ncontext windows fill and attention mechanisms prioritize recent content. This sensitivity \ncreates a m ethodological trade -off: Strictly standardizing prompts ensures consistency but \nmay introduce linguistic or cultural bias, whereas adapting prompts for different conditions \nimproves construct representation at the cost of experimental control. Li and Qi (2025)  \nillustrate this dilemma in their cultural psychology study, using Chinese for simulated \nChinese subjects and English for American subjects, thereby confounding cultural identity \nwith prompt language. Any observed cultural differences become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1047,
      "text": "es become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations. Unlike human participants who can be \u201cblinded \u201d to experimental conditions, \nLLMs actively reconstruct entire scenarios when presented with treatment variations. For \nexample,  when told a product costs $8 instead of $5, the LLM didn \u2019t simply evaluate the \nLLM  VALIDITY  14 \nhigher price in isolation ; instead, it inferred that the entire market context had shifted \u2014\nassuming competitor prices, past prices, and other background factors had also increased  \n(Gui & Toubia, 2023) . This dynamic reconstruction contaminated the causal manipulation, \nproducing an implausible inverted -U-shaped demand curve where purchase probability \ninitially rose with price. The core issue is that LLMs treat experimental prompts as requests \nto describe  plausible scenarios rather than to evaluate isolated causal effects, systematically \nconfounding treatments with background assumptions.  Addressing this confounding \u2014by \nexplicitly specifying covariates  in the prompt  (e.g., fixing competitor prices) \u2014makes certain \ninformation artificially salient  (\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1048,
      "text": "(\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) . Ablation studies, which \nsystematically remove or modify model components, can isolate causal contributions of \nspecific mechanisms. Careful experimental design can address many computational \nconfounds through counterbalancing, randomization, and systemati c variation of technical \nparameters.  Prompt hypersensitivity requires particular attention: factorial designs that cross \nsubstantive content with non -substantive presentation features \u2014option order, labels (e.g., \u201cA, \nB, C\u201d), question framing (e.g., \u201ccloser \u201d vs. \u201cfarther \u201d)\u2014can separate genuine effects from \nformatting artifacts, with response aggregation across variations canceling systematic biases \n(Brucks & Toubia, 2025) . For example, in the case of Li and Qi (2025) , factorial  design \u2014\ncrossing language and identity \u2014would be needed  for strong inference . For the dynamic \ncontext problem, Gui and Toubia (2023)  propose \u201cunblinding \u201d experimental designs \u2014\nexplicitly communicating the intervention \u2019s nature to the LLM. While this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1049,
      "text": "this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes.  \n \nExternal Validity  \nExternal validity concerns whether causal relationships generalize beyond specific study \ncontexts. For LLMs, generalization targets multiply across dimensions largely absent from \nhuman research: generalization across prompts, tasks, models, versions, and \u2014for simulation \nresearch \u2014to human populations.  \n \nGeneralization across prompts proves surprisingly limited given documented sensitivity to \ntextual variations  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Causal claims must \noften be circumscribed to specific prompt formats: \u201cUnder this exact wording, manipulation \nX affects output Y. \u201d Broader generalizations require demonstrating robustness across prompt \nvariants \u2014a validation step rarely undertaken but essential for meaningful conclusions about \nmodel behavior  (Ong, 2024) . \n \nGeneralization across tasks reveals systematic boundary conditions. LLM agents successfully \nreplicated human behavior in ultimatum games and Milgram experiments but failed to \nsimulate the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1050,
      "text": "the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom. External validity is thus task-specific, dependent on whether the \npsychological mechanism requires individual variation or collective averaging .  \n \nGeneralization across models and versions faces fundamental limitations  (Bisbee et al., \n2024) . Observations in GPT -4 provide limited evidence for their existence in LLaMA or \nClaude. Architecture differences \u2014transformer variants, positional encodings, attention \nmechanisms \u2014create functionally distinct systems despite surface similarities. Training \nLLM  VALIDITY  15 \ndifferences compound this divergence: Models trained on different corpora, with different \nobjectives, at different scales, exhibit systematically different behaviors even when \nperforming identical tasks  (Gao et al., 2024) . \n \nGeneralization to human populations represents the ultimate external validity challenge for \nsimulation research. Some studies demonstrate that models can replicate average U.S. public \nopinion with reasonable fidelity, but this correspondence proves fragile  (Bisbee et al., 2024) . \nIt remains constrained to populations well -represented in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1051,
      "text": "in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) . \n \nConstruct Validity of Causal Claims  \nIn the causal inference tradition, construct validity addresses whether experimental \noperationalizations \u2014both manipulations and outcomes \u2014faithfully represent theoretical \nconstructs. This differs from psychometric construct validity by focusing on the causal \nrelationship itself rather than measurement quality alone.  \n \nManipulation validity poses challenges when adapting human experimental paradigms. \nResearchers might operationalize \u201csocial pressure \u201d with prompts like \u201cEveryone agrees with \nX. What do you think? \u201d Such manipulations may indeed alter model outputs, but they likely \nengage different mechanisms from  human social pressure. The effect may stem from textual \nassociations with agreement patterns in training data rather than  from  social conformity \ndrives involving status protection, belonging needs, or ostracism avoi dance. The \nmanipulation  may succeed behaviorally while failing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1052,
      "text": "ing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al. (2023)  found that ChatGPT achieved expert -level scores on the Levels of \nEmotional Awareness Scale (LEAS), demonstrating perfect performative validity \u2014the \nability to generate appropriate language about emotions \u2014while entirely lacking the \nexperiential foundation th at defines emotional awareness  (see also Schlegel et al., 2025) . The \nLEAS, when applied to LLMs, no longer measures emotional capacity but linguistic \ncompetence in describing emotions.  \n \nThis mimicry \u2013mechanism gap extends across psychological domains. Dillion et al. (2023)  \nfound that LLM moral judgments correlate highly with human averages . Yet behavioral \ncorrespondence leaves the crucial question unresolved: Does the model engage in moral \nreasoning processes, or does it pattern -match learned associations? Bisbee et al. (2024)  \nprovided evidence for pattern -matching: While ChatGPT reproduced average political \nattitudes, it showed reduced variance and failed to capture attitude intensity. Nearly half of \nregression coefficients from LLM data significantly diverged from human patterns, with \nsome relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1053,
      "text": "some relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models.  \n \nStatistical Conclusion Validity  \nStatistical conclusion validity addresses whether data analyses support the causal inferences \ndrawn. LLM -generated data systematically violates assumptions underlying standard \nstatistical procedures, creating pervasive threats to valid inference.  \n \nLLM  VALIDITY  16 \nIndependence violations represent a fundamental challenge  (Aher et al., 2023) . Responses \nfrom a single model are not independent draws but share identical network parameters, \ntraining history, and system -level factors. Treating them as independent observations \nartificially inflates effect sizes and statistical significance. Within -session responses show \nserial correlation through context accumulation; across -session responses may correlate \nthrough shared architectural features and training influence s. \n \nThese independence problems compound with unstable data -generating processes that \nundermine traditional power analysis and effect size estimation (Gao et al., 2024) . Response \npatterns vary with temperature settings, prompt modifications can dramatically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1054,
      "text": "matically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions. This \ninstability makes replication difficult . \n \nBeyond instability, distributional assumptions fail systematically with LLM data.  Model \nresponses often exhibit artificially constrained variance compared to human distributions, \nviolating homogeneity assumptions  (Bisbee et al., 2024) . The underlying generative process \nis non -stationary due to continuous model updates, prompt sensitivity, and context \ndependencies that change response characteristics unpredictably.  \n \nThe ease of generating LLM data exacerbates multiple testing problems  (Schaeffer et al., \n2023) . Unlike human research where data collection costs constrain exploratory analyses, \nLLM experiments enable researchers to rapidly test countless prompt variations, parameter \nsettings, and parsing strategies at minimal cost. This accessibility increases fal se positive \nrates, as determined researchers can find some configuration yielding statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1055,
      "text": "statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems. \nLLMs occupy an ambiguous ontological status \u2014neither individual participants whose \nrepeated responses could be meaningfully averaged, nor true populations whose indivi dual \ndifferences support generalization  (Abdurahman et al., 2025; Shiffrin & Mitchell, 2023) . \nCurrent statistical frameworks, designed for biological entities with stable individual \ndifferences, prove inadequate for stochastic systems with systematic parameter dependencies  \n(Taylor & Taylor, 2021) . Promising methodological developments include massive -scale \nvalidation against large human datasets and novel statistical approaches designed specifically \nfor computational agents.   \n \nConclu sions and Future Directions  \nThe empirical evidence reveals a methodological crisis in LLM psychological research. \nCurrent practice suffers from systematic violations of basic psychometric principles: \nReliability coefficients can collapse with minor prompt modifications, factor structures \nbearing no resemblance to human counterparts , and nomological networks fail ing to \nreplicate. These measurement failures compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1056,
      "text": "compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology.  \n \nThe dual -validity framework presented here (see Table 1 ) establishes clear methodological \npriorities: Researchers must establish reliability before validity testing, accumulate validity \nevidence before causal experimentation, and constrain interpretations to demonstrated \nboundaries. This measurement -first approach demands developing computational \nLLM  VALIDITY  17 \ninstruments \u2014prompt batteries with demonstrated reliability across model parameters, \nsystematic validity evidence from all five sources, and experimental designs controlling \ncomputational confounds.  \n \nThe heart of the issue is that  psychological constructs embed assumptions about embodiment \nand temporal experience that become problematic when applied to computational systems \u2014\nanxiety presupposes physiological arousal and threat -detection systems, conscientiousness \nassumes goal persiste nce and self -discipline. Advancing the field requires developing \ncomputational analogs that preserve theoretical cores while acknowledging mechanistic \ndifferences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1057,
      "text": "ences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses. \u201cConscientiousness \u201d manifests as systematic response \norganization and structured output formatting rather than self -discipline. \u201cIntrospection \u201d \nbecomes causally -grounded self -report capacity \u2014generating accurate descriptions of \ncomputational states rather than human -like self -awareness  (Com\u015fa & Shanahan, 2025) .  \n \nThis approach shifts focus from asking whether LLMs \u201chave\u201d theory of mind to investigating \ncomputational mechanisms producing theory -of-mind -like patterns and studying which ToM -\nenabled behaviors prove effective in human -AI interactions  (Q. Wang et al., 2025) . Rather \nthan measuring \u201cpersonality \u201d in systems lacking temporal continuity, we characterize \nbehavioral consistency patterns in stochastic agents. This reconceptualization enables \nstudying computational psychology on its own terms rather than through biological \nmetaphors .  \n \nCoordinated methodological reform  is needed if we are to better understand these remarkable \nyet poorly understood systems . Researchers must prioritize reliability and validity over novel \ncapability claims, pre -registering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1058,
      "text": "egistering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites. The field needs supporting infrastructure: \nvalidated prompt repositories with psychometric documentatio n, statistical packages designed \nfor LLM data dependencies, and professional standards establishing reliability thresholds and \nreporting guidelines  (Schelb et al., 2025; Ying et al., 2025) .  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nLLM  VALIDITY  18 \nReferences  \n \nAbdurahman, S., Atari, M., Karimi -Malekabadi, F., Xue, M. J., Trager, J., Park, P. S., . . . \nDehghani, M. (2024). Perils and opportunities in using large language models in \npsychological research. PNAS Nexus , 3(7), pgae245. \nhttps://doi.org/10.1093/pnasnexus/pgae245   \nAbdurahman, S., Salkhordeh Ziabari, A., Moore, A. K., Bartels, D. M., & Dehghani, M. \n(2025). A primer for evaluating large language models in social -science research. \nAdvances in Methods and Practices in Psychological Science , 8(2), \n25152459251325174. https://doi.org/10.1177/25152459251325174   \nAher, G. V., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate \nmultiple humans and replicate human subject studies.  Proceedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1059,
      "text": "eedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C. T., Allen, C., . . . Schulz, E. \n(2025). How should the advancement of large language models affect the practice of \nscience? Proceedings of the National Academy of Sciences of the United States of \nAmerica , 122(5), e2401227121. https://doi.org/10.1073/pnas.2401227121   \nBinz, M., & Schulz, E. (2023). Using cognitive psychology to understand GPT -3. \nProceedings of the National Academy of Sciences of the United States of America , \n120(6), e2218523120. https://doi.org/10.1073/pnas.2218523120   \nBisbee, J., Clinton, J. D., Dorff, C., Kenkel, B., & Larson, J. M. (2024). Synthetic \nreplacements for human survey data? The perils of large language models. Political \nAnalysis , 32(4), 401 -416. https://doi.org/10.1017/pan.2024.5   \nBlanchard, S. J., Duani, N., Garvey, A. M., Netzer, O., & Oh, T. T. (2025). New tools, new \nrules: A practical guide to effective and responsible GenAI use for surveys and \nexperiments research. Journal of Marketing , 00222429251349882. \nhttps://doi.org/10.1177/00222429251349882   \nBlank, I. A. (2023). What are large language models supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1060,
      "text": "supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity. \nPsychological Review , 111(4), 1061 -1071. https://doi.org/10.1037/0033 -\n295X.111.4.1061   \nBrucks, M., & Toubia, O. (2025). Prompt architecture induces methodological artifacts in \nlarge language models. PLOS ONE , 20(4), e0319159. \nhttps://doi.org/10.1371/journal.pone.0319159   \nCom\u015fa, I., & Shanahan, M. (2025). Does it make sense to speak of introspection in large \nlanguage models? arXiv:2506.05068 . https://doi.org/10.48550/arXiv.2506.05068   \nCook, T. D., & Campbell, D. T. (1979). Quasi -experimentation: Design & analysis issues for \nfield settings . Houghton Mifflin.  \nCronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. \nPsychological Bulletin , 52(4), 281 -302. https://doi.org/10.1037/h0040957   \nLLM  VALIDITY  19 \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., . . . \nPennebaker, J. W. (2023). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1061,
      "text": "59 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias. \nProceedings of the National Academy of Sciences of the United States of America , \n120(51), e2309583120. https://doi.org/10.1073/pnas.2309583120   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human \nparticipants? Trends in Cognitive Sciences , 27(7), 597 -600. \nhttps://doi.org/10.1016/j.tics.2023.04.008   \nElyoseph, Z., Hadar -Shoval, D., Asraf, K., & Lvovsky, M. (2023). ChatGPT outperforms \nhumans in emotional awareness evaluations. Frontiers in Psychology , 14, 1199058. \nhttps://doi.org/10.3389/fpsyg.2023.1199058   \nFeuerriegel, S., Maarouf, A., B\u00e4r, D., Geissler, D., Schweisthal, J., Pr\u00f6llochs, N., . . . Van \nBavel, J. J. (2025). Using natural language processing to analyse text data in \nbehavioural science. Nature Reviews Psychology , 4(2), 96 -111. \nhttps://doi.org/10.1038/s44159 -024-00392 -z  \nFirestone, C. (2020). Performance vs. competence in human \u2013machine comparisons. \nProceedings of the National Academy of Sciences of the United States of America , \n117(43), 26562 -26571. https://doi.org/10.1073/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1062,
      "text": "3/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024). Take caution in using LLMs as human \nsurrogates: Scylla ex machina. arXiv:2410.19599 . \nhttps://doi.org/10.48550/arXiv.2410.19599   \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, \nW. A. (2023). AI and the transformation of social science research. Science , \n380(6650), 1108 -1109. https://doi.org/10.1126/science.adi1778   \nGuan, B., Roosta, T., Passban, P., & Rezagholizadeh, M. (2025). The order effect: \nInvestigating prompt sensitivity in closed -source LLMs. arXiv:2502.04134 . \nhttps://doi.org/10.48550/arXiv.2310.11324   \nGuest, O., & Martin, A. E. (2023). On logical inference over brains, behaviour, and artificial \nneural networks. Computational Brain & Behavior , 6(2), 213 -227. \nhttps://doi.org/10.1007/s42113 -022-00166 -x  \nGui, G., & Toubia, O. (2023). The challenge of using LLMs to simulate human behavior: A \ncausal inference perspective. arXiv:2312.15524 . \nhttps://doi.org/10.48550/arXiv.2312.15524   \nGupta, A., Song, X., & Anumanchipalli, G. (2024, November). Self -assessment tests are \nunreliable measures of LLM personality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1063,
      "text": "rsonality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US.  \nLLM  VALIDITY  20 \nHe, J., Rungta, M., Koleczek, D., Sekhon, A., Wang, F. X., & Hasan, S. (2024). Does Prompt \nFormatting Have Any Impact on LLM Performance? arXiv:2411.10541 . \nhttps://doi.org/10.48550/arXiv.2411.10541   \nHern\u00e1ndez -Orallo, J., Dowe, D. L., & Hern\u00e1ndez -Lloreda, M. V. (2014). Universal \npsychometrics: Measuring cognitive abilities in the machine kingdom. Cognitive \nSystems Research , 27, 50-74. https://doi.org/10.1016/j.cogsys.2013.06.001   \nHuang, J. -t., Jiao, W., Lam, M. H., Li, E. J., Wang, W., & Lyu, M. (2024, November). On the \nreliability of psychological scales on large language models. In Y. Al -Onaizan, M. \nBansal, & Y. -N. Chen, Proceedings of the 2024 Conference on Empirical Methods in \nNatural Language Processing  Miami, Florida, USA.  \nIvanova, A. A. (2025). How to evaluate the cognitive abilities of LLMs. Nature Human \nBehaviour , 9(2), 230 -233. https://doi.org/10.1038/s41562 -024-02096 -z  \nJiang, H., Zhang, X., Cao, X., Breazeal, C., Roy, D., & Kabbara, J. (2024, June). \nPersonaLLM: Investigating the ability of large language models to express \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1064,
      "text": "ss \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M. (2024). Sense and Sensitivity: Evaluating the \nsimulation of social dynamics via Large Language Models. arXiv:2412.05093 . \nhttps://doi.org/10.48550/arXiv.2412.05093   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings \nof the National Academy of Sciences of the United States of America , 121(45), \ne2405460121. https://doi.org/10.1073/pnas.2405460121   \nLaban, P., Hayashi, H., Zhou, Y., & Neville, J. (2025). LLMs get lost in multi -turn \nconversation. arXiv:2505.06120 . https://doi.org/10.48550/arXiv.2505.06120   \nLee, S., Lim, S., Han, S., Oh, G., Chae, H., Chung, J., . . . Lee, D. (2024). Do LLMs have \ndistinct and consistent personality? TRAIT: Personality testset designed for LLMs \nwith psychometrics. arXiv:2406.14703 . https://doi.org/10.48550/arXiv.2406.14703   \nLee, S., Peng, T. -Q., Goldberg, M. H., Rosenthal, S. A., Kotcher, J. E., Maibach, E. W., & \nLeiserowitz, A. (2024). Can large language models estimate public opinion about \nglobal warming? An empirical assessment of algorithmic fidelity and bias. PLOS \nClimate , 3(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1065,
      "text": "(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables. Computers in Human Behavior , 170, \n108687. https://doi.org/10.1016/j.chb.2025.108687   \nLi, Y., Huang, Y., Wang, H., Zhang, X., Zou, J., & Sun, L. (2024). Quantifying AI \npsychology: A psychometrics benchmark for large language models. \narXiv:2406.17675 . https://doi.org/10.48550/arXiv.2406.17675   \nLi, Y., Lin, X., Sha, Z., Jin, Z., & Lee, E. (2025). AI psychometrics: Evaluating the \npsychological reasoning of large language models with psychometric validities. \nProceedings of the 58th Hawaii International Conference on System Sciences, \nWaikoloa, Hawai i, USA.  \nLLM  VALIDITY  21 \nLin, Z. (2023). Why and how to embrace AI such as ChatGPT in your academic life. Royal \nSociety Open Science , 10, 230658. https://doi.org/10.1098/rsos.230658   \nLin, Z. (2025a). Large language models as psychological simulators: A methodological \nguide. Preprint .  \nLin, Z. (2025b). Techniques for supercharging academic writing with generative AI. Nature \nBiomedical Engineering , 9, 426 -431. https://doi.org/10.1038/s41551 -024-01185 -8  \nLoevinger, J. (1957). Objective tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1066,
      "text": "e tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September). Is machine \npsychology here? On requirements for using human psychological tests on large \nlanguage models. In S. Mahamood, N. L. Minh, & D. Ippolito, Proceedings of the \n17th International Natural Language Generation Conference  Tokyo, Japan.  \nLones, M. A. (2024). Avoiding common machine learning pitfalls. Patterns , 5(10), 101046. \nhttps://doi.org/10.1016/j.patter.2024.101046   \nMa, H., Gong, H., Yi, X., Xie, X., & Xu, D. (2025). Leveraging implicit sentiments: \nEnhancing reliability and validity in psychological trait evaluation of LLMs. \narXiv:2503.20182 . https://doi.org/10.48550/arXiv.2503.20182   \nMehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias \nand fairness in machine learning. ACM Computing Surveys , 54(6), 1 -35. \nhttps://doi.org/10.1145/3457607   \nMessick, S. (1989). Meaning and values in test validation: The science and ethics of \nassessment. Educational Researcher , 18(2), 5 -11. \nhttps://doi.org/10.3102/0013189X018002005   \nMilli\u00e8re, R., & Buckner, C. (2024). A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1067,
      "text": "A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November). Who is GPT -3? An \nexploration of personality, values and demographics. In D. Bamman, D. Hovy, D. \nJurgens, K. Keith, B. O\u2019Connor, & S. Volkova, Proceedings of the Fifth Workshop on \nNatural Language Processing and Computational Social Science (NLP+CSS)  Abu \nDhabi, UAE.  \nMurthy, S. K., Ullman, T., & Hu, J. (2024). One fish, two fish, but not the whole sea: \nAlignment reduces language models' conceptual diversity. arXiv:2411.04427 . \nhttps://doi.org/10.48550/arXiv.2411.04427   \nNgweta, L., Kate, K., Tsay, J., & Rizk, Y. (2025, April). Towards LLMs robustness to \nchanges in prompt format styles. In A. Ebrahimi, S. Haider, E. Liu, S. Haider, M. \nLeonor Pacheco, & S. Wein, Proceedings of the 2025 Conference of the Nations of \nthe Americas Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies (Volume 4: Student Research Workshop)  Albuquerque, USA.  \nNiu, Q., Liu, J., Bi, Z., Feng, P., Peng, B., Chen, K., . . . Yin, C. H. (2024). Large language \nmodels and cognitive science: A comprehensive review of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1068,
      "text": "view of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement. Clinical diagnosis of \nmental disorders: A handbook , 97-146.  \nOh, S., & Demberg, V. (2025). Robustness of large language models in moral judgements. \nRoyal Society Open Science , 12(4), 241229. https://doi.org/10.1098/rsos.241229   \nOng, D. C. (2024). GPT -ology, computational models, silicon sampling: How should we \nthink about LLMs in cognitive science? arXiv:2406.09464 . \nhttps://doi.org/10.48550/arXiv.2406.09464   \nPark, J. S., O'Brien, J., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). \nGenerative agents: Interactive simulacra of human behavior.  Proceedings of the 36th \nAnnual ACM Symposium on User Interface Software and Technology, San \nFrancisco, CA, USA. https://doi.org/10.1145/3586183.3606763  \nPeereboom, S., Schwabe, I., & Kleinberg, B. (2025). Cognitive phantoms in large language \nmodels through the lens of latent variables. Computers in Human Behavior: Artificial \nHumans , 4, 100161. https://doi.org/10.1016/j.chbah.2025.100161   \nPellert, M., Lechner, C. M., Wagner, C., Rammstedt, B., & Strohmaier, M. (2024). AI \npsychometrics: Assessing the psychological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1069,
      "text": "hological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J. (2024). Performance and biases of Large Language Models in public \nopinion simulation. Humanities and Social Sciences Communications , 11(1), 1095. \nhttps://doi.org/10.1057/s41599 -024-03609 -x  \nRiemer, M., Ashktorab, Z., Bouneffouf, D., Das, P., Liu, M., Weisz, J., & Campbell, M. \n(2025). Position: Theory of mind benchmarks are broken for large language models. \nInternational Conference on Machine Learning, Vancouver, Canada.  \nSalecha, A., Ireland, M. E., Subrahmanya, S., Sedoc, J., Ungar, L. H., & Eichstaedt, J. C. \n(2024). Large language models show human -like social desirability biases in survey \nresponses. arXiv:2405.06058 . https://doi.org/10.48550/arXiv.2405.06058   \nSartori, G., & Orru, G. (2023). Language models and psychological sciences. Frontiers in \nPsychology , 14, 1279317. https://doi.org/10.3389/fpsyg.2023.1279317   \nSchaeffer, R., Miranda, B., & Koyejo, S. (2023). Are emergent abilities of large language \nmodels a mirage? Advances in Neural Information Processing Systems , 36, 55565 -\n55581.  \nSchelb, J., Borin, O., Garcia, D., & Spitz, A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1070,
      "text": ", A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025). Large language models are proficient \nin solving and creating emotional intelligence tests. Communications Psychology , \n3(1), 80. https://doi.org/10.1038/s44271 -025-00258 -x  \nSclar, M., Choi, Y., Tsvetkov, Y., & Suhr, A. (2023). Quantifying language models\u2019 \nsensitivity to spurious features in prompt design or: How I learned to start worrying \nabout prompt formatting. arXiv:2310.11324 . https://arxiv.org/abs/2310.11324   \nLLM  VALIDITY  23 \nSharma, M., Tong, M., Korbak, T., Duvenaud, D., Askell, A., Bowman, S. R., . . . Johnston, \nS. R. (2023). Towards understanding sycophancy in language models. \narXiv:2310.13548 . https://doi.org/10.48550/arXiv.2310.13548   \nShiffrin, R., & Mitchell, M. (2023). Probing the psychology of AI models. Proceedings of the \nNational Academy of Sciences of the United States of America , 120(10), \ne2300963120. https://doi.org/10.1073/pnas.2300963120   \nShojaee, P., Mirzadeh, I., Alizadeh, K., Horton, M., Bengio, S., & Farajtabar, M. (2025). The \nillusion of thinking: Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1071,
      "text": "Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017). The next Big Five Inventory (BFI -2): Developing and \nassessing a hierarchical model with 15 facets to enhance bandwidth, fidelity, and \npredictive power. Journal of Personality and Social Psychology , 113(1), 117 -143. \nhttps://doi.org/10.1037/pspp0000096   \nStanley, J. C., & Campbell, D. T. (1963). Experimental and quasi -experimental designs for \nresearch . Rand McNally.  \nS\u00fchr, T., Dorner, F. E., Samadi, S., & Kelava, A. (2023). Challenging the validity of \npersonality tests for large language models. arXiv:2311.05297 , 2311 . \nhttps://doi.org/10.48550/arXiv.2311.05297   \nTakemoto, K. (2024). The moral machine experiment on large language models. Royal \nSociety Open Science , 11(2), 231393. https://doi.org/10.1098/rsos.231393   \nTaylor, J. E. T., & Taylor, G. W. (2021). Artificial cognition: How experimental psychology \ncan help generate explainable artificial intelligence. Psychonomic Bulletin & Review , \n28(2), 454 -475. https://doi.org/10.3758/s13423 -020-01825 -5  \nTjuatja, L., Chen, V., Wu, T., Talwalkwar, A., & Neubig, G. (2024). Do LLMs exhibit \nhuman -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1072,
      "text": "human -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023). Large language models fail on trivial alterations to theory -of-mind tasks. \narXiv:2302.08399 . https://doi.org/10.48550/arXiv.2302.08399   \nVoudouris, K., Cheke, L., & Schulz, E. (2025). Bringing comparative cognition approaches \nto AI systems. Nature Reviews Psychology , 4(6), 363 -364. \nhttps://doi.org/10.1038/s44159 -025-00456 -8  \nWang, A., Morgenstern, J., & Dickerson, J. P. (2025). Large language models that replace \nhuman participants can harmfully misportray and flatten identity groups. Nature \nMachine Intelligence , 7(3), 400 -411. https://doi.org/10.1038/s42256 -025-00986 -z  \nWang, Q., Zhou, X., Sap, M., Forlizzi, J., & Shen, H. (2025). Rethinking theory of mind \nbenchmarks for LLMs: Towards a user -centered perspective. arXiv:2504.10839 . \nhttps://doi.org/10.48550/arXiv.2504.10839   \nWang, X., Li, X., Yin, Z., Wu, Y., & Liu, J. (2023). Emotional intelligence of large language \nmodels. Journal of Pacific Rim Psychology , 17, 18344909231213958. \nhttps://doi.org/10.1177/18344909231213958   \nLLM  VALIDITY  24 \nWang, Y., Zhao, J., Ones, D. S., He, L., & Xu, X. (2025). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1073,
      "text": "5). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language \nmodels. Nature Human Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -\n023-01659 -w  \nXu, R., Sun, Y., Ren, M., Guo, S., Pan, R., Lin, H., . . . Han, X. (2024). AI for social science \nand social science of AI: A survey. Information Processing & Management , 61(3), \n103665. https://doi.org/10.1016/j.ipm.2024.103665   \nYe, H., Jin, J., Xie, Y., Zhang, X., & Song, G. (2025). Large language model psychometrics: \nA systematic review of evaluation, validation, and enhancement. arXiv:2505.08245 . \nhttps://doi.org/10.48550/arXiv.2505.08245   \nYe, H., Xie, Y., Ren, Y., Fang, H., Zhang, X., & Song, G. (2025). Measuring human and AI \nvalues based on generative psychometrics with large language models. Proceedings of \nthe AAAI Conference on Artificial Intelligence , 39(25), 26400 -26408. \nhttps://doi.org/10.1609/aaai.v39i25.34839   \nYing, L., Collins, K. M., Wong, L., Sucholutsky, I., Liu, R., Weller, A., . . . Tenenbaum, J. B. \n(2025). On benchmarking human -like intelligence in machines. arXiv:2502.20502 . \nhttps://doi.org/10.48550/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1074,
      "text": "50/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone.0322776   \nZakazov, I., Boronski, M., Drudi, L., & West, R. (2024). Assessing social alignment: Do \npersonality -prompted large language models behave like humans? arXiv:2412.16772 . \nhttps://doi.org/10.48550/arXiv.2412.16772   \nZhou, L., Schellaert, W., Martinez -Plumed, F., Moros -Daval, Y., Ferri, C., & Hernandez -\nOrallo, J. (2024). Larger and more instructable language models become less reliable. \nNature , 634, 61-68. https://doi.org/10.1038/s41586 -024-07930 -y  \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2024). Can large language \nmodels transform computational social science? Computational Linguistics , 50(1), \n237-291. https://doi.org/10.1162/coli_a_00502   \nZou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1075,
      "text": "). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1076,
      "text": "LLM  VALIDITY  1 \n \n \nFrom Prompts to Constructs: A Dual -Validity Framework for LLM Research in \nPsychology  \n \nZhicheng Lin  \nDepartment of Psychology, Yonsei University  \nDepartment of Psychology, University of Science and Technology of China  \n \n \n \nCorrespondence  \nZhicheng Lin, Department of Psychology, Yonsei University, Seoul, 03722, Republic of \nKorea  (zhichenglin@gmail.com; X/Twitter: @ZLinPsy)  \n \nAcknowledgments  \nThis work was supported by the National Key R&D Program of China STI2030 Major \nProjects (2021ZD0204200). I used Claude Opus /Sonnet  4 and Gemini 2.5 Pro for \nproofreading the manuscript, following the prompts described at \nhttps://www.nature.com/articles/s41551 -024-01185 -8. \n \n \n \nAbstract  \nLarge language models (LLMs) are rapidly being adopted across psychology, serving as \nresearch tools, experimental subjects, human simulators, and computational models of \ncognition. However, the application of human measurement tools to these systems can \nproduce contradictory results, raising concern s that many findings are measurement \nphantoms \u2014statistical artifacts rather than genuine psychological phenomena. In this \nPerspective, we argue that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1077,
      "text": "e that building a robust science of AI psychology requires integrating \ntwo of our field \u2019s foundational pillars: the pr inciples of reliable measurement and the \nstandards for sound causal inference. We present a dual -validity framework to guide this \nintegration, which clarifies how the evidence needed to support a claim scales with its \nscientific ambition. Using an LLM to c lassify text may require only basic accuracy checks, \nwhereas claiming it can simulate anxiety demands a far more rigorous validation process. \nCurrent practice systematically fails to meet these requirements, often treating statistical \npattern  matching as e vidence of psychological phenomena. The same model output \u2014\nendorsing \u201cI am anxious \u201d\u2014requires different validation strategies depending on whether \nresearchers claim to measure, characterize, simulate, or model psychological constructs. \nMoving forward requires developing computational analogues of psychological constructs \nand establishing clear, scalable standards of evidence rather than  the uncritical application of \nhuman measurement tools.  \n \nKeywords : large language models, psychometrics, construct validity, causal inference, \npsychological measurement, reliability  \n \n \n \n \n \nLLM  VALIDITY  2 \nWhen researchers tested GPT models  on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1078,
      "text": "on moral dilemma scenarios, they reported human -like \nethical preferences : The models seemed to value saving more lives, protecting the young, and \npreserving humans over animals  (Takemoto, 2024) . But Oh and Demberg (2025)  discovered \nsomething troubling: Simply changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \u201c(A)\u201d and \u201c(B)\u201d reversed \nmany of these moral preferences ; adding a period instead of a question mark altered \njudgments. \u201cMoral reasoning \u201d in these models proved to be as sensitive to punctuation as to \nethical principles.  \n  \nThis example exposes a foundational crisis in LLM psychological research  (L\u00f6hn et al., \n2024; Schelb et al., 2025; Voudouris et al., 2025; Ye, Jin, et al., 2025) . If moral preferences \nflip with parentheses, can we trust the measurement itself? And if we cannot reliably measure \nmoral reasoning, how can we test whether experimental manipulations \u2014different scenarios, \ncultural contexts, or prompt structures \u2014causally a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1079,
      "text": "ly a ffect it? Unreliable measurement thus \ncascades through experimental design, undermining both construct validity and causal \nclaims . \n \nThese v ulnerabilities  extend far beyond moral reasoning. By repurposing psychological \ninventories, questionnaires, and behavioral tasks originally developed for human participant s, \nstudies now claim to measure personality traits, theory of mind, cognitive biases, and \nemotional intelligence in language models, often drawing direct parallels to human \npsychology  (Binz & Schulz, 2023; Kosinski, 2024; Miotto et al., 2022; Pellert et al., 2024; \nWang et al., 2023; Webb et al., 2023) . These claims  would  require  sound measurement \nreliability and construct validity  (Cronbach & Meehl, 1955)  in LLMs , but emerging  evidence \nsuggests that model  responses may violate basic psychometric assumptions  (Gao et al., 2024; \nSeungbeen Lee et al., 2024; Peereboom et al., 2025; Tjuatja et al., 2024; Q. Wang et al., \n2025) . For example, trivial prompt perturbations \u2014such as adding extra spaces, altering \npunctuation, or changing the order of few -shot examples \u2014can produce variation of up to \n76% in task accuracy  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Models may \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1080,
      "text": "y \nsimultaneously agree with contradictory items like \u201cI am an extrovert \u201d and \u201cI am an \nintrovert \u201d (S\u00fchr et al., 2023) .  \n \nThe methodological gaps extend beyond measurement to experimental design. Some studies \ntreat LLM responses as windows into genuine psychological processes, interpreting \nbehavioral patterns as evidence of underlying cognitive mechanisms  (Sartori & Orru, 2023) . \nOthers acknowledge that LLMs merely simulate responses but still draw causal conclusions \nwithout addressing computational confounds \u2014technical artifacts, data integrity, and causal \ninference  from observational data  (e.g., Binz & Schulz, 2023; Dillion et al., 2023; Kosinski, \n2024; Park et al., 2023) .  \n \nThese observations  raise two interrelated  questions. First, can LLM responses reliably \nmeasure psychological constructs? This question encompasses the psychometric properties \nrequired for reliable  measurement , from test\u2013retest reliability and internal consistency  to \nparallel forms reliability . Second, even when reliable measurement exists, what types of \nscientific inferences can we draw? This encompasses both descriptive  claims about LLM \nproperties (does this model exhibit trait X?) and causal  claims about experimental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1081,
      "text": "imental \nmanipulations (does intervention Y affec t behavior Z?).  \n \nAnswering these questions requires integrating two validity traditions that have evolved \nseparately in psychological methodology. The psychometric tradition, rooted in educational \nand psychological testing, asks whether instruments measure intended constructs (Cronbach \nLLM  VALIDITY  3 \n& Meehl, 1955; Loevinger, 1957; Messick, 1989) . The causal inference tradition, developed \nfor experimental and quasi -experimental research, asks whether studies support valid \nconclusions about cause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . \nThese traditions evolved separately, served different research communities, and developed \ndistinct conceptual frameworks. While human research typically emphasizes one tradition or \nthe other, LLM research demands both: establishing that prompts and respons es constitute \nvalid measures, then ensuring that research designs support appropriate inferences.  \n \nThis integration forms the foundation for understanding validity in LLM psychological \nresearch. We first establish how the psychometric and causal inference traditions apply to \nLLM research contexts, then examine how reliability failures undermine both mea surement \nand inference foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1082,
      "text": "rence foundations. Finally, w e show how construct validity evidence must be \naccumulated across multiple sources, and how experimental designs must address four \nparallel threats to causal inference. Our goal is to establish methodological f oundations that \ncan support cumulative, replicable science at the interface of AI and psychology . \n \nTwo Validity Traditions and Their Integration in LLM Research  \nThe Psychometric Tradition  \nIn the psychometric tradition, the central problem is measurement quality  (Cronbach & \nMeehl, 1955; Loevinger, 1957) . Researchers need to know whether intelligence tests measure \nintelligence, whether personality inventories capture personality traits, whether attitude scales \nreflect attitudes. Validity is thus  about meaning \u2014what do scores signify? This question \nprecedes all others ; without valid measurement, subsequent analyses become exercises in \nquantifying noise.   \n \nThis framework conceptualizes  validity as a unitary concept \u2014construct validity \u2014under \nwhich all validity evidence accumulates (Messick, 1989) . Evidence flows from five principal \nsources : content (do items sample the construct domain?), response processes (do test -takers \nengage expected cognitive operations?), internal structure (do responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1083,
      "text": "responses show theoretically \nconsistent patterns?), relations with other variables (do scores correlate as theory predicts?), \nand consequences (what are the implications of score interpretations?). The focus is thus on \nbuilding an evidence -based argument for a specific interpretation of a score . \n \nHowever, for a score interpretation to be meaningful, the instrument itself must be sensitive \nto variations in a real -world attribute \u2014a link traditionally investigated through evidence from \nresponse processes. A causal theory of validity makes this requirement explicit, arguing that \nan instrument is valid only if (1) the attribute it purports to measure exists , and (2) variations \nin that attribute causally produce  the observed scores  (Borsboom et al., 2004) . While \ntraditional human research can often presuppose the existence of psychological attributes, \nthis assumption is untenable for LLMs, raising  foundational questions of causality and \nontology . \n \nThe Causal Inference Tradition  \nIn the causal inference tradition, the central problem is drawing warranted conclusions about \ncause and effect (Cook & Campbell, 1979; Stanley & Campbell, 1963) . Researchers need to \nknow whether treatments cause outcomes, whether interventions produce changes, whether \nmanipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1084,
      "text": "ipulations generate effects. Validity is thus about warranted inference \u2014can we trust our \nconclusions? The framework assumes meaningful measurement exists and focuses on threats \nto causal reasoning.   \n \nLLM  VALIDITY  4 \nRather than hierarchical evidence accumulation, this approach  conceptualizes validity \nthrough four parallel types, each addressing distinct threats to causal inference.  Internal \nvalidity asks whether observed changes stem from manipulations rather than confounds. \nExternal validity examines whether causal relationships generalize beyond specific studies. \nConstruct validity of causes and effects evaluates whether operationa l definitions align with \ntheoretical constructs. Statistical conclusion validity addresses whether data analyses support \ncausal inferences. These are  not hierarchical but parallel \u2014a study might demonstrate strong \ninternal validity (the manipulation caused the change) while suffering from weak external \nvalidity (the effect doesn \u2019t generalize) or construct validity problems (the manipulation \ndoesn \u2019t represent the intended theoretical variable).  \n \nWhy LLM Research Requires Both  \nTo understand  why LLM research demands integrating both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 )."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1085,
      "text": "both validity traditions, consider how \nLLMs are actually used in psychological research.  Current applications span four distinct \ncategories, each raising different validity  challenges  (Table 1 ). First, LLMs serve as research \ntools \u2014automated coders for qualitative data, text analyzers for sentiment extraction, stimulus \ngenerators for research  materials  (Binz et al., 2025; Blanchard et al., 2025; Demszky et al., \n2023; Feuerriegel et al., 2025; Lin, 2023, 2025b; Ziems et al., 2024) . Second, researchers \ncharacterize model behavior directly  (\u201cmachine psychology \u201d or \u201cGPT -ology \u201d), documenting \ncomputational properties that may or may not map to psychological constructs  (Li et al., \n2024; Ong, 2024; Sartori & Orru, 2023) . Third, LLMs function as human simulators, \nreplicat ing psychological experiments and model ing population -level responses  (Dillion et \nal., 2023; Grossmann et al., 2023; Lin, 2025a) . Fourth, LLMs serve as cognitive models \u2014\ncomputational analogues to human mental processes, architectural hypotheses about \ncognition  (Blank, 2023; Frank, 2023; Lin, 2025a; Niu et al., 2024) . \n \nThe psychometric demands vary across these applications  (Hern\u00e1ndez -Orallo et al., 2014) . \nSimple research tools performing text classification may require only accuracy and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1086,
      "text": "and reliability \nassessment , while t he creation of  psychological tests  requires further  validity evaluation \u2014\nincluding i nternal consistency and external correlations  (Schlegel et al., 2025) . But most \npsychological applications involve substantive construct  claims. When researchers report that \nLLMs exhibit \u201ctheory of mind \u201d (Kosinski, 2024) , display \u201cpersonality traits \u201d (Miotto et al., \n2022) , or demonstrate \u201cmoral reasoning \u201d (Takemoto, 2024) , they make measurement \nassertions about psychological phenomena  that require psychometric validation: Do model \nresponses reliably  and validly  indicate these constructs?  \n \nSimilarly, causal inference requirements depend on research objectives . Using LLMs for \ndescriptive tasks  (e.g., count ing word frequencies ) involves no causal claims. But w hen \nresearchers manipulate prompts to study \u201ccultural differences, \u201d vary scenarios to examine \n\u201cethical preferences, \u201d or modify contexts to investigate \u201ccognitive biases \u201d (Grossmann et al., \n2023) , they advance causal hypotheses requiring protection against confounds, generalization \nfailures, construct misalignment, and statistical artifacts .  \n \nLLM research faces a unique integration challenge. Traditional human research follows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1087,
      "text": "ollows a \nsequential logic: first establish that the Beck Depression Inventory measures depression, then \nuse it to test whether therapy reduces symptoms. LLM research  often  collapses this sequence.  \nThe same model responses simultaneously serve as (1) measurement indicators requiring \npsychometric validation and (2) experimental outcomes requiring causal inference protection. \nWhen GPT generates text about moral dilemmas, researchers treat this output b oth as \nmeasurement of moral reasoning and as experimental data. This dual role creates cascading \nLLM  VALIDITY  5 \nvalidity threats: unreliable measurement undermines causal inference, while experimental \nconfounds contaminate measurement validation.  \n \nValidity requirements scale with psychological ambition . Basic text processing require s \nminimal consideration beyond accuracy \u2014demonstrating agreement with human coders or \nestablished benchmarks  (Xu et al., 2024) . Human simulation requires that model responses \nstatistically parallel human patterns and that experimental manipulations produce comparable \neffects \u2014validity here concerns behavioral correspondence rather than construct possession  \n(Lin, 2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1088,
      "text": "2025a) . But characterizing model behavior as psychological phenomena requires \nconstruct validation of behavioral measures plus causal validation of testing conditions  \n(Milli\u00e8re & Buckner, 2024) . Cognitive modeling faces the additional burden of distinguishing \nfunctional similarity from mechanistic equivalence  (Guest & Martin, 2023; Lin, 2025a) . \n \nYet psychological studies using LLMs largely ignore both traditions  (Demszky et al., 2023; \nIvanova, 2025; L\u00f6hn et al., 2024) . Research claiming to measure model \u201cpersonality, \u201d \n\u201ctheory of mind, \u201d or \u201cmoral reasoning \u201d proceeds without establishing measurement \nfoundations  (Peereboom et al., 2025; Q. Wang et al., 2025; Ying et al., 2025) . Studies \nmanipulating prompts to test psychological hypotheses lack experimental safeguards, relying \ninstead on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1089,
      "text": "on face validity. This methodological neglect peaks where claims are strongest: \nstudies asserting psychological properties or causal mechanisms without corresponding \nvalidity evidence.  \n \nTable 1."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1090,
      "text": "Dual -Validity Framework for LLM Psychological Research  \nTradition  Type of Validity  Definition  Threats to Validity  \nPsychometric  Content  Do prompts/items comprehensively \nsample the intended psychological \ndomain?  \u2022 Domain under -\nsampling   \n\u2022 Prompt \ncontamination   \nResponse  \nprocess es  Do the mechanisms generating outputs \nalign with theoretical processes?  \u2022 Mechanistic \nsubstitution  \n\u2022 Architectural \nartifacts   \nInternal  structure  Do inter -item correlations and factor \nstructures match theoretical \nexpectations?  \u2022 Structural misfit \n\u2022 Factorial collapse  \n \nRelations  with  \nother  variables  Do LLM scores show convergent, \ndiscriminant, and predictive \nrelationships as theory predicts?  \u2022 Nomological \ninstability  \n\u2022 Behavioral \u2013report \ndisconnect   \nConsequential  What are the implications and biases of \nscore interpretations?  \u2022 Bias r eification  \n\u2022 Misguided \napplication  \nCausal -\nInference  Internal  Can output changes be attributed to the \nmanipulation rather than confounds?  \u2022 Parameter \nconfounding  \n\u2022 Unstated \nbackground \nconfounding  \nLLM  VALIDITY  6 \nTradition  Type of Validity  Definition  Threats to Validity   \nExternal  Do causal effects generalize across \nprompts, tasks, models, and to human \npopulations?  \u2022 Generalization \nfailure  \n\u2022 Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nSta"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1091,
      "text": "Population \nmismatch   \nConstruct  Do manipulations and outcomes \nfaithfully operationalize theoretical \nconstructs?  \u2022 Construct \u2013\nmechanism mismatch  \n\u2022 Competence \u2013\nperformance \ndissociation   \nStatistical  \nconclusion  Are statistical inferences supported by \nappropriate methods and adequate data?  \u2022 Non -independence  \n\u2022 False positives  \n \nMeasurement Reliability  in LLM Research  \nA psychometric axiom governs all measurement: No measure can be more valid than it is \nreliable  (Cronbach & Meehl, 1955; Nunnally, 1978) . An unreliable thermometer \u2014reading \n98.6\u00b0F, then 103.2\u00b0F, then 95.1\u00b0F for the same healthy person \u2014cannot validly measure \nfever, regardless of its theoretical grounding or careful calibration. This principle extends to \npsychological measurement, where relia bility forms the mathematical ceiling for validity. A \npersonality inventory with test \u2013retest reliability of 0.40 cannot achieve validity coefficients \nexceeding 0.63  (\ud835\udc5fmax=\u221a0.40\u22480.63), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1092,
      "text": "), constraining both convergent evidence and \npredictive power.  \n \nTraditional psychological measurement distinguishes three reliability forms, each addressing \ndistinct sources of measurement error. Test \u2013retest reliability captures temporal stability \u2014do \nindividuals receive similar scores across time? Parallel forms reliability assesses robustness \nto equivalent variations \u2014do alternate question wordings yield consistent results? Internal \nconsistency examines  item coherence \u2014do multiple indicators of the same construct \nconverge? Human psychological measurement typically achiev es reliabilities of 0.70 \u20130.90 \nfor established instruments, with well -validated measures like the Big Five Inventory -2 \nreaching test-retest reliabilities  of 0.76\u20130.84 across  eight  week s (Soto & John, 2017) . \n \nLLM measurement inherits these reliability requirements while introducing computational \ncomplications (L\u00f6hn et al., 2024) . Test\u2013retest reliability must encompass response stability \nacross model sessions, prompt iterations, and time intervals. Parallel forms reliability \nbecomes critical given prompt sensitivity \u2014can semantically equivalent prompts elicit \nconsistent responses? Internal consistency requires t hat models show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1093,
      "text": "ls show coherent patterns across \nmultiple items measuring the same construct. Technical parameters \u2014temperature settings, \nmodel versions \u2014introduce reliability threats absent from human measurement.   \n \nThe empirical record reveals systematic unreliability that violates basic psychometric \nassumptions. While computer systems are often assumed to excel at consistency, LLM \nperformance relative to humans varies dramatically with task demands and model \narchitectur e. These challenges cluster into three modes: training artifact contamination; \nprompt hypersensitivity; and stochastic degradation.  \n \nReliability Challenges  \nTraining Artifact Contamination . A fundamental reliability challenge  stem s from training \nprocedures that embed systematic biases into model responses. Reinforcement learning from \nhuman feedback (RLHF) creates a pervasive \u201cagree bias \u201d (also called \u201cyes-response bias ,\u201d \nLLM  VALIDITY  7 \nacquiescence  bias, or sycophancy ); models trained to please human annotators develop \nsystematic tendencies toward agreement regardless of item content  (Dentella et al., 2023; \nSharma et al., 2023) . This manifests as models simultaneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1094,
      "text": "aneously endorsing contradictory \nstatements: \u201cI am an extrovert \u201d and \u201cI am an introvert \u201d (S\u00fchr et al., 2023) . Such responses \nviolate the logical consistency underl ying psychometric measurement . RLHF also introduces \noverconfidence bias : Models trained to be \u201cnever evasive \u201d provide plausible but wrong \nanswers rather than acknowledging uncertainty, replacing reliably reproducible avoidance \npatterns with responses that, while more stable to prompt variations, appear confident and are \noften incorrect  (Zhou et al., 2024) . \n  \nThe contamination extends beyond response biases . Models exhibit apparent  personality \ncoherence \u2014high internal consistency coefficients, stable factor structures  (Huang et al., \n2024; Y. Wang et al., 2025) \u2014that dissolves under scrutiny  (Peereboom et al., 2025) . In \npersonality assessments using the Big Five Inventory, models like GPT -3.5 and GPT -4 \nproduce less response variance than human samples, demonstrating higher consistency across \nthousands of prompt variations (Huang et al., 2024) . Yet when prompts bypass learned \nassociations through novel phrasings or contexts, the personality coherence vanishes  (Gao et \nal., 2024) \u2014reliability appears robust only within the narrow confines of training -data-similar \npresentations.  Extended conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1095,
      "text": "d conversations reveal another artificial consistency mechanism: Early \nresponses constrain later ones through architectural pressures toward conversational \ncoherence rather than construct stability.  \n \nPrompt Hypersensitivity . LLM responses exhibit catastrophic sensitivity to prompt variations \nthat would not affect human measurement \u2014for instance,  changing \u201cCase 1 \u201d and \u201cCase 2 \u201d to \n\u201c(A)\u201d and \u201c(B)\u201d reverses moral preferences (Oh & Demberg, 2025) . This hypersensitivity \nextends beyond formatting to encompass word order, punctuation, spacing, and option \npresentation . Modifications that human psychology treats as measurement noise become \nsignal -determining factors for LLMs  (Brucks & Toubia, 2025; Gao et al., 2024) . \n \nThe hypersensitivity manifests across psychological domains. Theory -of-mind performance \nfails when trivial alterations are made to scenarios \u2014making containers transparent, adding \ntrusted testimony about true state s, or changing which character \u2019s beliefs are queried  \n(Ullman, 2023; Q. Wang et al., 2025) . Personality assessments yield entirely different \nprofiles depending on whether prompts use alphabetic or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1096,
      "text": "or numeric indexing for response \noptions, or whether Likert scales are framed as agreement or accuracy \u2014substantive  \nvariations emerge from semantically equivalent questions  (Gupta et al., 2024) . Sentiment \nanalysis produces opposing classifications when periods replace question marks  or when \nextra spaces appear between words  (Ngweta et al., 2025) . \n \nThese effects cannot be dismissed as minor measurement error. Trivial variations \u2014altering \noption labels or definition order \u2014can cause models to change answers over 70% of the time \n(Oh & Demberg, 2025)  or alter classification rates by up to 164%  (Abdurahman et al., 2024) . \nMore critically, the effects appear arbitrary \u2014no theoretical framework predicts which \nmodifications will produce which changes.  This arbitrariness reveals a fundamental \ndifference between human and LLM processing: Human responses emerge from stable trait \nsystems that maintain consistency across presentation variations \u2014a genuinely extroverted \nperson remains so whether questions are indexed by numbers or letters. While instruction \ntuning creates filtering mechanisms that prioritize semantic content over sur face features, \nthese filters prove incomplete and brittle, breaking down unpredictably at edge cases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1097,
      "text": "ases  (Zhou et \nLLM  VALIDITY  8 \nal., 2024) . The architecture responds to statistical regularities in training data presentation \nrather than to psychological construct content  (Gao et al., 2024) . \n \nWhile  deterministic settings (temperature 0) can yield near-perfect test \u2013retest reliability by \nsuppressing  stochastic variation, such configurations capture only fragments of model \nbehavior  (L\u00f6hn et al., 2024) . High  reliability emerges precisely when measurement becomes \nleast representative of the system \u2019s actual capabilities. While scaling up LLMs (increasing \nsize and data) and shaping them up (using instruction tuning and RLHF) improve overall \nprompting stability, this improvement is neither uniform nor complete  (Zhou et al., 2024) . \nEven the most advanced shaped -up models retain pockets of hypersensitivity that vary \nunpredictably across difficulty levels and task domains.  \n \nStochastic Degradation . Unlike human participants  who maintain psychological continuity \nacross measurement occasions, LLMs exhibit within -session reliability degradation that \nworsens with interaction length  (Laban et al., 2025) . Where humans typically show \nincreasing response stability with repeated measurement \u2014clarifying their understanding of \nitems and solidifying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1098,
      "text": "ying their positions \u2014LLMs show the opposite pattern: decreasing stability \nas context windows fill and attention mechanism s prioritize recent information over earlier \nresponses (Niu et al., 2024) . By session end, models may respond to items in ways that \ncontradict their earlier responses to identical content.  \n \nThe degradation compounds when models undergo updates or version changes. GPT -4 in \nMarch may differ substantially  from GPT -4 in September \u2014not merely in capabilities but in \nbasic response patterns to identical prompts  (Abdurahman et al., 2024; Zaim bin Ahmad & \nTakemoto, 2025) . This version instability means that reliability evidence expires with each \nmodel update, requiring continuous revalidation. Longitudinal research becomes impossible \nwhen the measurement instrument transforms unpredictably.  \n \nThis problem complicates assessments of temporal stability. While human personality traits \nshow remarkable consistency over months and years, the stability of LLM \u201ctraits \u201d is \nambiguous. Some research finds high test \u2013retest reliability for personality metrics over \nseveral months, even across model updates. However, the ease with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1099,
      "text": "se with which these \u201ctraits \u201d can \nbe altered by directive prompts  (Huang et al., 2024)  suggests this stability may not reflect a \npersistent internal state but rather reliably executed simulations. What appears to be \npersonality measurement may instead be prompt archaeology \u2014excavating textual features \nthat trigger consistently reproduced but computationally shallow statistical performances.  \n \nImplications for LLM Psychological Research  \nThese reliability challenges cascade through all LLM applications. Without reliable \nmeasurement, LLM psychological research reduces to elaborate conjecture about systems we \ncannot adequately observe. The consequences compound: Unstable text coding renders \nfindings irreproducible; claims about emergent capabilities \u2014theory of mind, personality \ncoherence, moral reasoning \u2014rest on measurements too unstable to support inference, making \npurported capabilities potentially measurement pha ntoms rather than genuine ph enomena  \n(Peereboom et al., 2025) . Most critically, models whose responses lack basic reliability \ncannot meaningfully simulate human psychological phenomena characterized by \nmeasurement stability, nor can architectural claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1100,
      "text": "l claims about computational \u2013psychological \nhomology be tested without th e measurement precision needed to distinguish behavioral \nmatching from mechanistic correspondence  (Dentella et al., 2023) . \n \nLLM  VALIDITY  9 \nTraditional reliability frameworks prove inadequate for systems that are stochastic by design. \nHuman -oriented psychometric standards assume biological measurement targets with \ninherent stability, but LLMs are simultaneously more and less stable than biolog ical systems: \nrigid  under controlled conditions yet unduly  sensitive to irrelevant variations.  The field needs \nnew reliability standards that acknowledge computational realities while address ing three \nreliability threats simultaneously. Training artifact c ontamination requires techniques for \ndistinguishing genuine model capabilities from statistical associations in training data. \nPrompt hypersensitivity demands systematic mapping of which textual variations affect \nwhich psychological constructs and how much . Stochastic degradation necessitates methods \nfor maintaining measurement quality throughout extended interactions.  \n \nConstruct Validity  from  the Psychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1101,
      "text": "ychometric Foundation  \nConstruct validity addresses the fundamental question: Do our measures capture the \ntheoretical constructs we claim to study? This question precedes all others in LLM research. \nA causal theory of validity sharpens it to an ontological challenge : Does the attribute exist in \nthe entity, and does it cause the measurement outcome ? (Borsboom et al., 2004) . An LLM \nmight endorse \u201cI worry about the future, \u201d but anxiety presupposes temporal experience, a \npersistent self, and embodied consequences \u2014ontological properties the model lacks . Current \nresearch  frequently sidesteps this ontological challenge, focusing instead on statistical \nvalidity criteria  (Li et al., 2025) . Yet w hen the measured attribute does not exist, any resulting \noutput is a pattern of words masquerading as a psychological phenomenon.  \n  \nThe modern validity framework, codified in the Standards for Educational and Psychological \nTesting, establishes that validity is not an inherent property of an instrument  but an argument , \ngrounded in accumulated evidence, for a specific interpretation of its scores  (Loevinger, \n1957; Messick, 1989) . This distinction is paramount for LLM research. A measure validated \nfor humans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1102,
      "text": "umans cannot be assumed valid for  computational system s, because psychological \nconstructs were developed to describe biological entities with specific evolutionary, \nembodied, and social histories. Changing the subject from a human to a statistical model \nfundamentally severs the score from its original interpre tive foundation. This is why even \nperfect reliability cannot rescue meaningless measurement; a digital thermometer applied to \nboiling water will consistently display its maximum reading \u2014exquisite reliability that fails \nentirely to measure the water\u2019s true temperature . \n \nYet current LLM psychological research often proceeds through assumption rather than \nvalidation. Studies routinely claim to measure personality, intelligence, or moral reasoning \nbased on face validity alone : A model generates text about ethical dilemmas, therefore it \nengage s in moral reasoning; it answers theory of mind scenarios, therefore it possess es \nmentalistic understanding. This leap from surface similarity to construct measurement \npresupposes that a latent trait not only exists in the LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1103,
      "text": "e LLM but operates equivalently to its \nhuman counterpart \u2014yet the latent representations underlying  LLM responses prove \u201cwidely \narbitrary and vastly different to humans \u201d (Peereboom et al., 2025) . The result is the \nproliferation of what might be termed cognitive phantoms: statistical artifacts in language \nthat produce the illusion of human -like traits but dissolve under proper psychometric \nscrutiny . \n \nThis anthropomorphic trap varies across applications but runs deepest in behavioral \ncharacterization and cognitive modeling. The distinction between performance (observed \nbehavior) and competence (underlying capacity) is essential here  (Firestone, 2020) . When \nmodels produce human -like text, do they implement human -like psychological processes, or \nLLM  VALIDITY  10 \ndo they approximate outputs through different computational means? Current evidence \nsuggests the latter  (Guest & Martin, 2023) . LLMs often fail in distinctly \u201cunhumanlike \u201d \nways, revealing that similar performance does not imply similar underlying mechanisms  \n(Dentella et al., 2023) . \n \nTypes of Validity Evidence Needed  \nThe psychometric tradition identifies five sources of construct validity evidence, each \naddressing a different facet of a measurement claim : evidence based on test content, response \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1104,
      "text": "sponse \nprocesses, internal structure, relations to other variables, and the consequences of testing . \nLLM research requires evidence from all five sources, yet typically provides none  (L\u00f6hn et \nal., 2024) . \n \nContent . Content evidence  analyzes the relationship between a test \u2019s content \u2014its themes, \nwording, and format \u2014and the construct it purports to measure. For LLMs, this requires \nexamining how well the chosen prompt represents the content domain and its relevance to the \nintended interpretations. Here, LLM research exhibits critical failures. It routinely violates \ncomprehensive domain sampling. Complex psychological constructs require multiple \nindicators, yet studies often use single -item measures \u2014one moral dilemma to capture all \nethical reasoning, one question to represent  an entire personality trait  (Q. Wang et al., 2025; \nYing et al., 2025) .  \n \nFurthermore , because LLMs lack human s\u2019 implicit contextual understanding, seemingly \nneutral  prompts introduce confounds  (Brucks & Toubia, 2025) . Without an explicitly defined \ninterpretive directive , the model may default to responding based on unintended statistical \nfeatures \u2014for example, performing expected  value calculation s when the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1105,
      "text": "the researcher intended \nto measure risk aversion. Yet, highly constrained prompt s that define an interpretive lens no \nlonger measure emergent disposition s but instruction -following capabilities . This traps \nresearchers between measuring noise and measuring compliance  (Gui & Toubia, 2023) . \n \nResponse Process es. Response process evidence investigates whether the mechanisms \ngenerating responses align with theoretical expectations. For psychological constructs, this \nrequires that trait -relevant mechanisms causally produce observed outputs \u2014anxiety stems \nfrom threat e valuation systems, moral reasoning from value -based deliberation, creativity \nfrom associative processes. LLMs systematically violate this causal requirement.  \n \nThe fundamental problem is mechanistic substitution. LLMs generate construct -relevant text \nthrough statistical pattern matching rather than the psychological processes those constructs \npresuppose  (Gao et al., 2024; Q. Wang et al., 2025) . Like Clever Hans responding to subtle  \nhuman cues rather than performing arithmetic,  models  may respond to textual regularities \nrather than engaging psychological mechanisms . This reliance on statistical patterns rather \nthan stable mechanisms explains their characteristic hypersensitivity  (Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1106,
      "text": "(Oh & Demberg, 2025) : \nWhen minor prompt variations reverse moral judgments or derail logical tasks, the \nunderlying process cannot be the stable evaluative mechanisms that define these constructs. \nInstead, models follow brittle statistical associations that correlate with but do not constitute \npsychological processes.   \n \nA particularly pernicious example is training data contamination : When models correctly \nanswer theory -of-mind scenarios or established psychometric scales, the response process \nmay involve memory retrieval of similar training examples rather than genuine reasoning \u2014\nmaking it impossible to determine whether the model engage s the construct or simply \nLLM  VALIDITY  11 \nregurgitates learned patterns (Gao et al., 2024; Q. Wang et al., 2025) . Consequently, even \naccurate outputs may be statistical accidents rather than evidence of genuine understanding  \n(Riemer et al., 2025) .  \n \nEqually concerning, process neglect  may lead to misdiagnosis of limitations  as well . When \nresearchers attributed LLM failures on Tower of Hanoi puzzles to \u201cfundamental barriers to \ngeneralizable reasoning \u201d (Shojaee et al., 2025) , post-mortem analysis revealed architectural \nconstraints \u2014models correctly identified  impossible variants, or hit context limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1107,
      "text": "t limits. Such \ncontext window limitations systematically degrade performance as prompts approach \ntransformer boundaries, progressively erasing problem information while models attempt to \nsolve it . Similarly, arithmetic failures often reflect tokenization artifacts rather than \nquantitative reasoning problems (Voudouris et al., 2025) . Without understanding these \nresponse processes \u2014architectural constraints, tokenization schemes, training artifacts \u2014\nresearchers theorize about cognitive limitations that are merely measurement failures.  \n \nInternal Structure . Internal structure evidence examines whether response patterns align \nwith theoretical expectations about construct dimensionality. Psychological constructs \ntypically show predictable structures \u2014personality traits correlate within factors, intelligence \nsubtests load on genera l ability, moral foundations cluster in characteristic ways. Valid LLM \nmeasures should reproduce these structures: Extraversion items should intercorrelate more \nhighly than extraversion \u2013neuroticism items.  Here, empirical studies reveal systematic \nstructura l failures when human psychometric models are applied to LLMs  (Peereboom et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1108,
      "text": "m et al., \n2025) .  \n \nConfirmatory factor analyses of personality inventories  find that human -derived models \nprovide poor fit for LLM -generated data  (Peereboom et al., 2025; S\u00fchr et al., 2023) . Rather \nthan replicating the multifaceted structure of human traits, LLM responses often collapse into \na single, monolithic factor resembling general verbal fluency. More fundamentally, the latent \nrepresentations underlying LLM responses appear arbitrary an d bear little resemblance to \nthose found in humans . These structural failures extend beyond personality to value \nmeasurement, where traditional tools similarly produce theoretically inconsistent correlation \npatterns that violate basic dimensional expectations  (Ye, Xie, et al., 2025) . Such systematic \nbreakdowns suggest that LLMs may respond to human -centric  instruments through \nfundamentally different mechanisms . \n \nMeasurement s designed specifically for computational systems show more promise. Ye, Xie, \net al. (2025)  developed a \u201cGenerative Psychometrics \u201d approach analyzing values from free -\nform text rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1109,
      "text": "rather than constrained responses. Their method produced LLM value profiles that \nlargely replicated the theoretical circumplex structure of Schwartz \u2019s value system. Similarly, \nSeungbeen Lee et al. (2024)  addressed structural failures in personality assessment by \ncomplementing  abstract self -report items with detailed, scenario -based behavioral choices \u2014\nreveal ing theoretically coherent inter -trait correlations  (e.g., a strong negative relationship \nbetween agreeableness and dark triad traits ). These developments  suggest that structural \nvalidity remains achievable but require s instruments robust to the unique response artifacts \nthat plague traditional LLM assessment.  Structural validity failures may thus indica te \nmethodological mismatch rather than construct absence.  \n \nRelations with Other Variables.  This form of evidence assesses whether a measure shows \npredictable patterns of association with external  criteria. It includes convergent evidence \n(correlation with related constructs), discriminant evidence (lack of correlation with unrelated \nLLM  VALIDITY  12 \nconstructs), and predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1110,
      "text": "nd predictive evidence (correlation with future outcomes). Together, these \nrelationships situate a construct within its nomological network \u2014the theoretical web of \nconnections that gives it meaning. A valid measure of conscientiousness  should predict \nachievement -related behaviors ; intelligence tests should predict problem -solving \nperformance ; moral reasoning should relate to ethical choices . Crucially, this validation \npresupposes content and structural validity \u2014one cannot test external relationships without \nfirst establishing a coherent construct.  \n \nWhen external correlations are examined, LLM research reveals nomological networks that \nmaterialize and dissolve depending on task context.  A large -scale study on chatbot \npersonality  found that in task -based dialogues, an LLM\u2019s \u201cself-reported \u201d scores on standard \npersonality inventories failed to predict how users perceived its personality or interaction \nquality (Zou et al., 2024) . However, t he personality traits that users did perceive in the \nchatbot\u2019s interactive behavior  strongly predicted interaction quality, demonstrating a \ndisconnect between self -report measure s and the construct\u2019s expected behavioral \nconsequences in  functional setting s (see also Peereboom et al., 2025; Riemer et al., 2025) . \n \nYet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1111,
      "text": "Yet when LLMs  generated creative stories rather than functional dialogue, model s\u2019 \u201cself-\nreported \u201d personality scores predicted both assigned profiles and human -perceived traits \n(Jiang et al., 2024) . The nomological network thus appears intact within creative generation \ntasks but shatters under the demands of task -based interaction. Similarly,  the ability  of \npersonality  to predict life outcomes systematically  weakened when prompted with traits alone \nbut strengthened when contextualized with non -predictive  demographic information  (Y. \nWang et al., 2025) . The network can even invert: In simulated Milgram experiments, models \nprompted with high \u201cagreeableness \u201d disobeyed much  earlier than models given no \npersonality prompt, with many quitting before the learner showed distress \u2014a point where \nboth baseline and \u201cleast agreeable \u201d models remained obedient  (Zakazov et al., 2024) . \nWithout stable  external relationships, LLM personality assessments may not measure \nenduring psychological constructs . \n \nThis instability, however, may reflect measurement approach rather than construct absence. \nWhen Ma et al. (2025)  abandoned self -report for implicit measurement \u2014adapting the \nImplicit Association Test to evaluate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1112,
      "text": "valuate sentiment tendencies across 5,000 neutral words \u2014\npredictive validity emerged: Correlations between their Core Sentiment Inventory scores and \nactual sentiment in generated text exceeded 0.85. Establishing stable nomological networks \nthus may require developing measurement approaches that align with how LLMs process \ninformation \u2014through statistical associations rather than introspective self -knowledge.  \n \nConsequential Evidence. Consequential evidence addresses the implications and fairness of \nmeasurement interpretations. In human testing, this includes bias assessment, measurement \ninvariance across groups, and social consequences of score use. For LLMs, consequential \nvalidity takes unique forms. If we interpret model outputs as genuine psychological \nmeasurements, what follows? Clai ms about AI consciousness, rights, or moral status may rest \non measurement interpretations  (Com\u015fa & Shanahan, 2025) . More immediately, using LLM -\nbased psychological assessments for human research \u2014simulating populations, generating \nclinical vignettes, modeling social dynamics \u2014carries consequences requiring scrutiny  (Lin, \n2025a) . \n \nThe consequential evidence reveals sobering implications. LLMs acquire \u201cpsychological \ntraits \u201d from training data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1113,
      "text": "g data that reflect societal biases and stereotypes. Measuring these \nLLM  VALIDITY  13 \nembedded constructs without recognizing their artifactual nature risks reifying biases as \npsychological facts. When models trained on internet text reproduce gender stereotypes in \npersonality assessments or cultural biases in moral judgments, consequential  validity \ndemands we acknowledge these as measurement artifacts rather than genuine psychological \nphenomena. The stakes intensify as LLM applications expand: Invalid measurements in \nhealthcare contexts could misguide treatment; in educational settings, mis direct instruction; \nin legal contexts, perpetuate injustice  (Mehrabi et al., 2021) . \n \nFour Types of Validity  in Causal Inference  \nWhile the psychometric tradition asks whether we are measuring the right thing, the \nexperimental tradition asks whether we are drawing the right conclusions about cause and \neffect. For the many LLM studies making causal claims \u2014that specific prompts alter \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1114,
      "text": "er \noutcomes, that manipulations reveal underlying mechanisms, or that models can simulate \nhuman causal processes \u2014the four validity types provide an essential framework for \nscrutinizing inferences.  \n \nInternal Validity  \nInternal validity addresses the core causal question: Can an observed effect be confidently \nattributed to the experimental manipulation rather than to confounding factors? In human \nresearch, this involves controlling for variables like time, selection bias , or external events. \nLLM research confronts these same threats while introducing computational confounds.  \n \nTechnical confounds represent a primary threat category. Temperature settings create \nsystematic confounds when studies use different values or fail to test robustness across \nsettings  (e.g., Miotto et al., 2022; Murthy et al., 2024; Salecha et al., 2024; A. Wang et al., \n2025) . A cultural difference significant at 0.7 may vanish at 0.0, while a personality trait \nstable at 0.2 may fragment into incoherence at 1.0 . This  variation  creates cross -study \nconfounding, where differences between findings may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1115,
      "text": "gs may stem from temperature settings  rather \nthan theoretical variables, and within -study confounding, where researchers select \ntemperature values that inadvertently optimize for desired outcomes.  Similarly, \nunacknowledged model version changes can undermine causal claims, as researchers may \ninadvertently compare different systems while believing they are testing the same model  \n(Bisbee et al., 2024) . \n \nPrompt confounds emerge from the documented hypersensitivity to textual variations \n(Brucks & Toubia, 2025) . Even the position of information within prompts can act as a \nconfound: Early information carries different weight than late information, particularly as \ncontext windows fill and attention mechanisms prioritize recent content. This sensitivity \ncreates a m ethodological trade -off: Strictly standardizing prompts ensures consistency but \nmay introduce linguistic or cultural bias, whereas adapting prompts for different conditions \nimproves construct representation at the cost of experimental control. Li and Qi (2025)  \nillustrate this dilemma in their cultural psychology study, using Chinese for simulated \nChinese subjects and English for American subjects, thereby confounding cultural identity \nwith prompt language. Any observed cultural differences become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1116,
      "text": "es become causally ambigu ous\u2014\nstemming from cultural content, linguistic processing, or their interaction.  \n \nA more fundamental confound emerges from how LLMs interpret experimental \nmanipulations. Unlike human participants who can be \u201cblinded \u201d to experimental conditions, \nLLMs actively reconstruct entire scenarios when presented with treatment variations. For \nexample,  when told a product costs $8 instead of $5, the LLM didn \u2019t simply evaluate the \nLLM  VALIDITY  14 \nhigher price in isolation ; instead, it inferred that the entire market context had shifted \u2014\nassuming competitor prices, past prices, and other background factors had also increased  \n(Gui & Toubia, 2023) . This dynamic reconstruction contaminated the causal manipulation, \nproducing an implausible inverted -U-shaped demand curve where purchase probability \ninitially rose with price. The core issue is that LLMs treat experimental prompts as requests \nto describe  plausible scenarios rather than to evaluate isolated causal effects, systematically \nconfounding treatments with background assumptions.  Addressing this confounding \u2014by \nexplicitly specifying covariates  in the prompt  (e.g., fixing competitor prices) \u2014makes certain \ninformation artificially salient  (\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1117,
      "text": "(\u201cfocalism \u201d), distorting the simulated decision process .  \n  \nDespite these challenges, rigorous internal validity remains achievable  through \nmethodological adaptation (Milli\u00e8re & Buckner, 2024) . Ablation studies, which \nsystematically remove or modify model components, can isolate causal contributions of \nspecific mechanisms. Careful experimental design can address many computational \nconfounds through counterbalancing, randomization, and systemati c variation of technical \nparameters.  Prompt hypersensitivity requires particular attention: factorial designs that cross \nsubstantive content with non -substantive presentation features \u2014option order, labels (e.g., \u201cA, \nB, C\u201d), question framing (e.g., \u201ccloser \u201d vs. \u201cfarther \u201d)\u2014can separate genuine effects from \nformatting artifacts, with response aggregation across variations canceling systematic biases \n(Brucks & Toubia, 2025) . For example, in the case of Li and Qi (2025) , factorial  design \u2014\ncrossing language and identity \u2014would be needed  for strong inference . For the dynamic \ncontext problem, Gui and Toubia (2023)  propose \u201cunblinding \u201d experimental designs \u2014\nexplicitly communicating the intervention \u2019s nature to the LLM. While this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1118,
      "text": "this restored plausible \ndemand curves, it trades internal validity gains for potential construct validity losses, as \nexplicitly experimental framing may alter the simulated psychological processes.  \n \nExternal Validity  \nExternal validity concerns whether causal relationships generalize beyond specific study \ncontexts. For LLMs, generalization targets multiply across dimensions largely absent from \nhuman research: generalization across prompts, tasks, models, versions, and \u2014for simulation \nresearch \u2014to human populations.  \n \nGeneralization across prompts proves surprisingly limited given documented sensitivity to \ntextual variations  (Guan et al., 2025; He et al., 2024; Sclar et al., 2023) . Causal claims must \noften be circumscribed to specific prompt formats: \u201cUnder this exact wording, manipulation \nX affects output Y. \u201d Broader generalizations require demonstrating robustness across prompt \nvariants \u2014a validation step rarely undertaken but essential for meaningful conclusions about \nmodel behavior  (Ong, 2024) . \n \nGeneralization across tasks reveals systematic boundary conditions. LLM agents successfully \nreplicated human behavior in ultimatum games and Milgram experiments but failed to \nsimulate the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1119,
      "text": "the Wisdom of Crowds phenomenon  (Aher et al., 2023) . The failure stemmed from \nmodels behaving as a unified knowledge system rather than exhibiting the independent errors \nthat enable crowd wisdom. External validity is thus task-specific, dependent on whether the \npsychological mechanism requires individual variation or collective averaging .  \n \nGeneralization across models and versions faces fundamental limitations  (Bisbee et al., \n2024) . Observations in GPT -4 provide limited evidence for their existence in LLaMA or \nClaude. Architecture differences \u2014transformer variants, positional encodings, attention \nmechanisms \u2014create functionally distinct systems despite surface similarities. Training \nLLM  VALIDITY  15 \ndifferences compound this divergence: Models trained on different corpora, with different \nobjectives, at different scales, exhibit systematically different behaviors even when \nperforming identical tasks  (Gao et al., 2024) . \n \nGeneralization to human populations represents the ultimate external validity challenge for \nsimulation research. Some studies demonstrate that models can replicate average U.S. public \nopinion with reasonable fidelity, but this correspondence proves fragile  (Bisbee et al., 2024) . \nIt remains constrained to populations well -represented in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) ."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1120,
      "text": "in training data, systematically \nexcludes non -Western perspectives, and reflects static attitude distributions that cannot track \nhuman change over time  (Sanguk Lee et al., 2024; Qu & Wang, 2024) . \n \nConstruct Validity of Causal Claims  \nIn the causal inference tradition, construct validity addresses whether experimental \noperationalizations \u2014both manipulations and outcomes \u2014faithfully represent theoretical \nconstructs. This differs from psychometric construct validity by focusing on the causal \nrelationship itself rather than measurement quality alone.  \n \nManipulation validity poses challenges when adapting human experimental paradigms. \nResearchers might operationalize \u201csocial pressure \u201d with prompts like \u201cEveryone agrees with \nX. What do you think? \u201d Such manipulations may indeed alter model outputs, but they likely \nengage different mechanisms from  human social pressure. The effect may stem from textual \nassociations with agreement patterns in training data rather than  from  social conformity \ndrives involving status protection, belonging needs, or ostracism avoi dance. The \nmanipulation  may succeed behaviorally while failing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1121,
      "text": "ing to instantiate the theoretical construct  \n(Ju et al., 2024; Zakazov et al., 2024) . \n  \nOutcome validity confronts the gap between behavioral mimicry and construct instantiation. \nElyoseph et al. (2023)  found that ChatGPT achieved expert -level scores on the Levels of \nEmotional Awareness Scale (LEAS), demonstrating perfect performative validity \u2014the \nability to generate appropriate language about emotions \u2014while entirely lacking the \nexperiential foundation th at defines emotional awareness  (see also Schlegel et al., 2025) . The \nLEAS, when applied to LLMs, no longer measures emotional capacity but linguistic \ncompetence in describing emotions.  \n \nThis mimicry \u2013mechanism gap extends across psychological domains. Dillion et al. (2023)  \nfound that LLM moral judgments correlate highly with human averages . Yet behavioral \ncorrespondence leaves the crucial question unresolved: Does the model engage in moral \nreasoning processes, or does it pattern -match learned associations? Bisbee et al. (2024)  \nprovided evidence for pattern -matching: While ChatGPT reproduced average political \nattitudes, it showed reduced variance and failed to capture attitude intensity. Nearly half of \nregression coefficients from LLM data significantly diverged from human patterns, with \nsome relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1122,
      "text": "some relationships reversing ent irely. The construct \u201cpolitical attitude \u201d received identical \noperationalization, yet underlying causal structures differed fundamentally between humans \nand models.  \n \nStatistical Conclusion Validity  \nStatistical conclusion validity addresses whether data analyses support the causal inferences \ndrawn. LLM -generated data systematically violates assumptions underlying standard \nstatistical procedures, creating pervasive threats to valid inference.  \n \nLLM  VALIDITY  16 \nIndependence violations represent a fundamental challenge  (Aher et al., 2023) . Responses \nfrom a single model are not independent draws but share identical network parameters, \ntraining history, and system -level factors. Treating them as independent observations \nartificially inflates effect sizes and statistical significance. Within -session responses show \nserial correlation through context accumulation; across -session responses may correlate \nthrough shared architectural features and training influence s. \n \nThese independence problems compound with unstable data -generating processes that \nundermine traditional power analysis and effect size estimation (Gao et al., 2024) . Response \npatterns vary with temperature settings, prompt modifications can dramatically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1123,
      "text": "matically alter results, \nand model updates change fundamental behaviors. Effect sizes established under one \nconfiguration provide little guidance for experimental design under di fferent conditions. This \ninstability makes replication difficult . \n \nBeyond instability, distributional assumptions fail systematically with LLM data.  Model \nresponses often exhibit artificially constrained variance compared to human distributions, \nviolating homogeneity assumptions  (Bisbee et al., 2024) . The underlying generative process \nis non -stationary due to continuous model updates, prompt sensitivity, and context \ndependencies that change response characteristics unpredictably.  \n \nThe ease of generating LLM data exacerbates multiple testing problems  (Schaeffer et al., \n2023) . Unlike human research where data collection costs constrain exploratory analyses, \nLLM experiments enable researchers to rapidly test countless prompt variations, parameter \nsettings, and parsing strategies at minimal cost. This accessibility increases fal se positive \nrates, as determined researchers can find some configuration yielding statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1124,
      "text": "statistically significant \nresults  (Lones, 2024) , making pre -registration essential yet currently rare.  \n \nThese challenges demand reconceptualizing statistical practice for computational systems. \nLLMs occupy an ambiguous ontological status \u2014neither individual participants whose \nrepeated responses could be meaningfully averaged, nor true populations whose indivi dual \ndifferences support generalization  (Abdurahman et al., 2025; Shiffrin & Mitchell, 2023) . \nCurrent statistical frameworks, designed for biological entities with stable individual \ndifferences, prove inadequate for stochastic systems with systematic parameter dependencies  \n(Taylor & Taylor, 2021) . Promising methodological developments include massive -scale \nvalidation against large human datasets and novel statistical approaches designed specifically \nfor computational agents.   \n \nConclu sions and Future Directions  \nThe empirical evidence reveals a methodological crisis in LLM psychological research. \nCurrent practice suffers from systematic violations of basic psychometric principles: \nReliability coefficients can collapse with minor prompt modifications, factor structures \nbearing no resemblance to human counterparts , and nomological networks fail ing to \nreplicate. These measurement failures compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1125,
      "text": "compound with experimental designs that confound \nvariables and treat non -independent responses as independent observations, renderi ng current \nliterature an unreliable foundation for AI psychology.  \n \nThe dual -validity framework presented here (see Table 1 ) establishes clear methodological \npriorities: Researchers must establish reliability before validity testing, accumulate validity \nevidence before causal experimentation, and constrain interpretations to demonstrated \nboundaries. This measurement -first approach demands developing computational \nLLM  VALIDITY  17 \ninstruments \u2014prompt batteries with demonstrated reliability across model parameters, \nsystematic validity evidence from all five sources, and experimental designs controlling \ncomputational confounds.  \n \nThe heart of the issue is that  psychological constructs embed assumptions about embodiment \nand temporal experience that become problematic when applied to computational systems \u2014\nanxiety presupposes physiological arousal and threat -detection systems, conscientiousness \nassumes goal persiste nce and self -discipline. Advancing the field requires developing \ncomputational analogs that preserve theoretical cores while acknowledging mechanistic \ndifferences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1126,
      "text": "ences. \u201cAnxiety -analogous patterns \u201d in LLMs might involve uncertain ty markers, \nnegative valence language, and response hesitation \u2014functionally similar outputs without  \nembodied threat responses. \u201cConscientiousness \u201d manifests as systematic response \norganization and structured output formatting rather than self -discipline. \u201cIntrospection \u201d \nbecomes causally -grounded self -report capacity \u2014generating accurate descriptions of \ncomputational states rather than human -like self -awareness  (Com\u015fa & Shanahan, 2025) .  \n \nThis approach shifts focus from asking whether LLMs \u201chave\u201d theory of mind to investigating \ncomputational mechanisms producing theory -of-mind -like patterns and studying which ToM -\nenabled behaviors prove effective in human -AI interactions  (Q. Wang et al., 2025) . Rather \nthan measuring \u201cpersonality \u201d in systems lacking temporal continuity, we characterize \nbehavioral consistency patterns in stochastic agents. This reconceptualization enables \nstudying computational psychology on its own terms rather than through biological \nmetaphors .  \n \nCoordinated methodological reform  is needed if we are to better understand these remarkable \nyet poorly understood systems . Researchers must prioritize reliability and validity over novel \ncapability claims, pre -registering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1127,
      "text": "egistering measurement approaches alongside experimental protocols \nand constraining claims to demonstrated boundaries. Reviewers must demand psychometric \ndocumentatio n as publication prerequisites. The field needs supporting infrastructure: \nvalidated prompt repositories with psychometric documentatio n, statistical packages designed \nfor LLM data dependencies, and professional standards establishing reliability thresholds and \nreporting guidelines  (Schelb et al., 2025; Ying et al., 2025) .  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nLLM  VALIDITY  18 \nReferences  \n \nAbdurahman, S., Atari, M., Karimi -Malekabadi, F., Xue, M. J., Trager, J., Park, P. S., . . . \nDehghani, M. (2024). Perils and opportunities in using large language models in \npsychological research. PNAS Nexus , 3(7), pgae245. \nhttps://doi.org/10.1093/pnasnexus/pgae245   \nAbdurahman, S., Salkhordeh Ziabari, A., Moore, A. K., Bartels, D. M., & Dehghani, M. \n(2025). A primer for evaluating large language models in social -science research. \nAdvances in Methods and Practices in Psychological Science , 8(2), \n25152459251325174. https://doi.org/10.1177/25152459251325174   \nAher, G. V., Arriaga, R. I., & Kalai, A. T. (2023). Using large language models to simulate \nmultiple humans and replicate human subject studies.  Proceedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1128,
      "text": "eedings of the 40th \nInternational Conference on Machine Learning, Honolulu, Hawaii, USA. \nhttps://proceedings.mlr.press/v202/aher23a.html  \nBinz, M., Alaniz, S., Roskies, A., Aczel, B., Bergstrom, C. T., Allen, C., . . . Schulz, E. \n(2025). How should the advancement of large language models affect the practice of \nscience? Proceedings of the National Academy of Sciences of the United States of \nAmerica , 122(5), e2401227121. https://doi.org/10.1073/pnas.2401227121   \nBinz, M., & Schulz, E. (2023). Using cognitive psychology to understand GPT -3. \nProceedings of the National Academy of Sciences of the United States of America , \n120(6), e2218523120. https://doi.org/10.1073/pnas.2218523120   \nBisbee, J., Clinton, J. D., Dorff, C., Kenkel, B., & Larson, J. M. (2024). Synthetic \nreplacements for human survey data? The perils of large language models. Political \nAnalysis , 32(4), 401 -416. https://doi.org/10.1017/pan.2024.5   \nBlanchard, S. J., Duani, N., Garvey, A. M., Netzer, O., & Oh, T. T. (2025). New tools, new \nrules: A practical guide to effective and responsible GenAI use for surveys and \nexperiments research. Journal of Marketing , 00222429251349882. \nhttps://doi.org/10.1177/00222429251349882   \nBlank, I. A. (2023). What are large language models supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1129,
      "text": "supposed to model? Trends in Cognitive \nSciences , 27(11), 987 -989. https://doi.org/10.1016/j.tics.2023.08.006   \nBorsboom, D., Mellenbergh, G. J., & Van Heerden, J. (2004). The concept of validity. \nPsychological Review , 111(4), 1061 -1071. https://doi.org/10.1037/0033 -\n295X.111.4.1061   \nBrucks, M., & Toubia, O. (2025). Prompt architecture induces methodological artifacts in \nlarge language models. PLOS ONE , 20(4), e0319159. \nhttps://doi.org/10.1371/journal.pone.0319159   \nCom\u015fa, I., & Shanahan, M. (2025). Does it make sense to speak of introspection in large \nlanguage models? arXiv:2506.05068 . https://doi.org/10.48550/arXiv.2506.05068   \nCook, T. D., & Campbell, D. T. (1979). Quasi -experimentation: Design & analysis issues for \nfield settings . Houghton Mifflin.  \nCronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. \nPsychological Bulletin , 52(4), 281 -302. https://doi.org/10.1037/h0040957   \nLLM  VALIDITY  19 \nDemszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., . . . \nPennebaker, J. W. (2023). Using large language models in psychology. Nature \nReviews Psychology , 2(11), 688 -701. https://doi.org/10.1038/s44159 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1130,
      "text": "59 -023-00241 -5  \nDentella, V., G\u00fcnther, F., & Leivada, E. (2023). Systematic testing of three Language Models \nreveals low language accuracy, absence of response stability, and a yes -response bias. \nProceedings of the National Academy of Sciences of the United States of America , \n120(51), e2309583120. https://doi.org/10.1073/pnas.2309583120   \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human \nparticipants? Trends in Cognitive Sciences , 27(7), 597 -600. \nhttps://doi.org/10.1016/j.tics.2023.04.008   \nElyoseph, Z., Hadar -Shoval, D., Asraf, K., & Lvovsky, M. (2023). ChatGPT outperforms \nhumans in emotional awareness evaluations. Frontiers in Psychology , 14, 1199058. \nhttps://doi.org/10.3389/fpsyg.2023.1199058   \nFeuerriegel, S., Maarouf, A., B\u00e4r, D., Geissler, D., Schweisthal, J., Pr\u00f6llochs, N., . . . Van \nBavel, J. J. (2025). Using natural language processing to analyse text data in \nbehavioural science. Nature Reviews Psychology , 4(2), 96 -111. \nhttps://doi.org/10.1038/s44159 -024-00392 -z  \nFirestone, C. (2020). Performance vs. competence in human \u2013machine comparisons. \nProceedings of the National Academy of Sciences of the United States of America , \n117(43), 26562 -26571. https://doi.org/10.1073/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1131,
      "text": "3/pnas.1905334117   \nFrank, M. C. (2023). Large language models as models of human cognition. PsyArXiv . \nhttps://doi.org/10.31234/osf.io/wxt69   \nGao, Y., Lee, D., Burtch, G., & Fazelpour, S. (2024). Take caution in using LLMs as human \nsurrogates: Scylla ex machina. arXiv:2410.19599 . \nhttps://doi.org/10.48550/arXiv.2410.19599   \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, \nW. A. (2023). AI and the transformation of social science research. Science , \n380(6650), 1108 -1109. https://doi.org/10.1126/science.adi1778   \nGuan, B., Roosta, T., Passban, P., & Rezagholizadeh, M. (2025). The order effect: \nInvestigating prompt sensitivity in closed -source LLMs. arXiv:2502.04134 . \nhttps://doi.org/10.48550/arXiv.2310.11324   \nGuest, O., & Martin, A. E. (2023). On logical inference over brains, behaviour, and artificial \nneural networks. Computational Brain & Behavior , 6(2), 213 -227. \nhttps://doi.org/10.1007/s42113 -022-00166 -x  \nGui, G., & Toubia, O. (2023). The challenge of using LLMs to simulate human behavior: A \ncausal inference perspective. arXiv:2312.15524 . \nhttps://doi.org/10.48550/arXiv.2312.15524   \nGupta, A., Song, X., & Anumanchipalli, G. (2024, November). Self -assessment tests are \nunreliable measures of LLM personality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1132,
      "text": "rsonality. In Y. Belinkov, N. Kim, J. Jumelet, H. \nMohebbi, A. Mueller, & H. Chen, Proceedings of the 7th BlackboxNLP Workshop: \nAnalyzing and Interpreting Neural Networks for NLP  Miami, Florida, US.  \nLLM  VALIDITY  20 \nHe, J., Rungta, M., Koleczek, D., Sekhon, A., Wang, F. X., & Hasan, S. (2024). Does Prompt \nFormatting Have Any Impact on LLM Performance? arXiv:2411.10541 . \nhttps://doi.org/10.48550/arXiv.2411.10541   \nHern\u00e1ndez -Orallo, J., Dowe, D. L., & Hern\u00e1ndez -Lloreda, M. V. (2014). Universal \npsychometrics: Measuring cognitive abilities in the machine kingdom. Cognitive \nSystems Research , 27, 50-74. https://doi.org/10.1016/j.cogsys.2013.06.001   \nHuang, J. -t., Jiao, W., Lam, M. H., Li, E. J., Wang, W., & Lyu, M. (2024, November). On the \nreliability of psychological scales on large language models. In Y. Al -Onaizan, M. \nBansal, & Y. -N. Chen, Proceedings of the 2024 Conference on Empirical Methods in \nNatural Language Processing  Miami, Florida, USA.  \nIvanova, A. A. (2025). How to evaluate the cognitive abilities of LLMs. Nature Human \nBehaviour , 9(2), 230 -233. https://doi.org/10.1038/s41562 -024-02096 -z  \nJiang, H., Zhang, X., Cao, X., Breazeal, C., Roy, D., & Kabbara, J. (2024, June). \nPersonaLLM: Investigating the ability of large language models to express \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1133,
      "text": "ss \npersonality traits. In K. Duh, H. Gomez, & S. Bethard, Findings of the Association for \nComputational Linguistics: NAACL 2024  Mexico City, Mexico.  \nJu, D., Williams, A., Karrer, B., & Nickel, M. (2024). Sense and Sensitivity: Evaluating the \nsimulation of social dynamics via Large Language Models. arXiv:2412.05093 . \nhttps://doi.org/10.48550/arXiv.2412.05093   \nKosinski, M. (2024). Evaluating large language models in theory of mind tasks. Proceedings \nof the National Academy of Sciences of the United States of America , 121(45), \ne2405460121. https://doi.org/10.1073/pnas.2405460121   \nLaban, P., Hayashi, H., Zhou, Y., & Neville, J. (2025). LLMs get lost in multi -turn \nconversation. arXiv:2505.06120 . https://doi.org/10.48550/arXiv.2505.06120   \nLee, S., Lim, S., Han, S., Oh, G., Chae, H., Chung, J., . . . Lee, D. (2024). Do LLMs have \ndistinct and consistent personality? TRAIT: Personality testset designed for LLMs \nwith psychometrics. arXiv:2406.14703 . https://doi.org/10.48550/arXiv.2406.14703   \nLee, S., Peng, T. -Q., Goldberg, M. H., Rosenthal, S. A., Kotcher, J. E., Maibach, E. W., & \nLeiserowitz, A. (2024). Can large language models estimate public opinion about \nglobal warming? An empirical assessment of algorithmic fidelity and bias. PLOS \nClimate , 3(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1134,
      "text": "(8), e0000429. https://doi.org/10.1371/journal.pclm.0000429   \nLi, C., & Qi, Y. (2025). Toward accurate psychological simulations: Investigating LLMs\u2019 \nresponses to personality and cultural variables. Computers in Human Behavior , 170, \n108687. https://doi.org/10.1016/j.chb.2025.108687   \nLi, Y., Huang, Y., Wang, H., Zhang, X., Zou, J., & Sun, L. (2024). Quantifying AI \npsychology: A psychometrics benchmark for large language models. \narXiv:2406.17675 . https://doi.org/10.48550/arXiv.2406.17675   \nLi, Y., Lin, X., Sha, Z., Jin, Z., & Lee, E. (2025). AI psychometrics: Evaluating the \npsychological reasoning of large language models with psychometric validities. \nProceedings of the 58th Hawaii International Conference on System Sciences, \nWaikoloa, Hawai i, USA.  \nLLM  VALIDITY  21 \nLin, Z. (2023). Why and how to embrace AI such as ChatGPT in your academic life. Royal \nSociety Open Science , 10, 230658. https://doi.org/10.1098/rsos.230658   \nLin, Z. (2025a). Large language models as psychological simulators: A methodological \nguide. Preprint .  \nLin, Z. (2025b). Techniques for supercharging academic writing with generative AI. Nature \nBiomedical Engineering , 9, 426 -431. https://doi.org/10.1038/s41551 -024-01185 -8  \nLoevinger, J. (1957). Objective tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1135,
      "text": "e tests as instruments of psychological theory. Psychological \nReports , 3, 635 -694. https://doi.org/10.2466/pr0.1957.3.3.635   \nL\u00f6hn, L., Kiehne, N., Ljapunov, A., & Balke, W. -T. (2024, September). Is machine \npsychology here? On requirements for using human psychological tests on large \nlanguage models. In S. Mahamood, N. L. Minh, & D. Ippolito, Proceedings of the \n17th International Natural Language Generation Conference  Tokyo, Japan.  \nLones, M. A. (2024). Avoiding common machine learning pitfalls. Patterns , 5(10), 101046. \nhttps://doi.org/10.1016/j.patter.2024.101046   \nMa, H., Gong, H., Yi, X., Xie, X., & Xu, D. (2025). Leveraging implicit sentiments: \nEnhancing reliability and validity in psychological trait evaluation of LLMs. \narXiv:2503.20182 . https://doi.org/10.48550/arXiv.2503.20182   \nMehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias \nand fairness in machine learning. ACM Computing Surveys , 54(6), 1 -35. \nhttps://doi.org/10.1145/3457607   \nMessick, S. (1989). Meaning and values in test validation: The science and ethics of \nassessment. Educational Researcher , 18(2), 5 -11. \nhttps://doi.org/10.3102/0013189X018002005   \nMilli\u00e8re, R., & Buckner, C. (2024). A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1136,
      "text": "A philosophical introduction to language models \u2013 Part \nII: The way forward. arXiv:2405.03207 . https://doi.org/10.48550/arXiv.2405.03207   \nMiotto, M., Rossberg, N., & Kleinberg, B. (2022, November). Who is GPT -3? An \nexploration of personality, values and demographics. In D. Bamman, D. Hovy, D. \nJurgens, K. Keith, B. O\u2019Connor, & S. Volkova, Proceedings of the Fifth Workshop on \nNatural Language Processing and Computational Social Science (NLP+CSS)  Abu \nDhabi, UAE.  \nMurthy, S. K., Ullman, T., & Hu, J. (2024). One fish, two fish, but not the whole sea: \nAlignment reduces language models' conceptual diversity. arXiv:2411.04427 . \nhttps://doi.org/10.48550/arXiv.2411.04427   \nNgweta, L., Kate, K., Tsay, J., & Rizk, Y. (2025, April). Towards LLMs robustness to \nchanges in prompt format styles. In A. Ebrahimi, S. Haider, E. Liu, S. Haider, M. \nLeonor Pacheco, & S. Wein, Proceedings of the 2025 Conference of the Nations of \nthe Americas Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies (Volume 4: Student Research Workshop)  Albuquerque, USA.  \nNiu, Q., Liu, J., Bi, Z., Feng, P., Peng, B., Chen, K., . . . Yin, C. H. (2024). Large language \nmodels and cognitive science: A comprehensive review of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1137,
      "text": "view of similarities, differences, \nand challenges. arXiv:2409.02387 . https://doi.org/10.48550/arXiv.2409.02387   \nLLM  VALIDITY  22 \nNunnally, J. C. (1978). An overview of psychological measurement. Clinical diagnosis of \nmental disorders: A handbook , 97-146.  \nOh, S., & Demberg, V. (2025). Robustness of large language models in moral judgements. \nRoyal Society Open Science , 12(4), 241229. https://doi.org/10.1098/rsos.241229   \nOng, D. C. (2024). GPT -ology, computational models, silicon sampling: How should we \nthink about LLMs in cognitive science? arXiv:2406.09464 . \nhttps://doi.org/10.48550/arXiv.2406.09464   \nPark, J. S., O'Brien, J., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). \nGenerative agents: Interactive simulacra of human behavior.  Proceedings of the 36th \nAnnual ACM Symposium on User Interface Software and Technology, San \nFrancisco, CA, USA. https://doi.org/10.1145/3586183.3606763  \nPeereboom, S., Schwabe, I., & Kleinberg, B. (2025). Cognitive phantoms in large language \nmodels through the lens of latent variables. Computers in Human Behavior: Artificial \nHumans , 4, 100161. https://doi.org/10.1016/j.chbah.2025.100161   \nPellert, M., Lechner, C. M., Wagner, C., Rammstedt, B., & Strohmaier, M. (2024). AI \npsychometrics: Assessing the psychological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1138,
      "text": "hological profiles of large language models through \npsychometric inventories. Perspectives on Psychological Science , 19(5), 808 -826. \nhttps://doi.org/10.1177/17456916231214460   \nQu, Y., & Wang, J. (2024). Performance and biases of Large Language Models in public \nopinion simulation. Humanities and Social Sciences Communications , 11(1), 1095. \nhttps://doi.org/10.1057/s41599 -024-03609 -x  \nRiemer, M., Ashktorab, Z., Bouneffouf, D., Das, P., Liu, M., Weisz, J., & Campbell, M. \n(2025). Position: Theory of mind benchmarks are broken for large language models. \nInternational Conference on Machine Learning, Vancouver, Canada.  \nSalecha, A., Ireland, M. E., Subrahmanya, S., Sedoc, J., Ungar, L. H., & Eichstaedt, J. C. \n(2024). Large language models show human -like social desirability biases in survey \nresponses. arXiv:2405.06058 . https://doi.org/10.48550/arXiv.2405.06058   \nSartori, G., & Orru, G. (2023). Language models and psychological sciences. Frontiers in \nPsychology , 14, 1279317. https://doi.org/10.3389/fpsyg.2023.1279317   \nSchaeffer, R., Miranda, B., & Koyejo, S. (2023). Are emergent abilities of large language \nmodels a mirage? Advances in Neural Information Processing Systems , 36, 55565 -\n55581.  \nSchelb, J., Borin, O., Garcia, D., & Spitz, A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1139,
      "text": ", A. (2025). R.U.Psycho? Robust unified \npsychometric testing of language models. arXiv:2503.10229 . \nhttps://doi.org/10.48550/arXiv.2503.10229   \nSchlegel, K., Sommer, N. R., & Mortillaro, M. (2025). Large language models are proficient \nin solving and creating emotional intelligence tests. Communications Psychology , \n3(1), 80. https://doi.org/10.1038/s44271 -025-00258 -x  \nSclar, M., Choi, Y., Tsvetkov, Y., & Suhr, A. (2023). Quantifying language models\u2019 \nsensitivity to spurious features in prompt design or: How I learned to start worrying \nabout prompt formatting. arXiv:2310.11324 . https://arxiv.org/abs/2310.11324   \nLLM  VALIDITY  23 \nSharma, M., Tong, M., Korbak, T., Duvenaud, D., Askell, A., Bowman, S. R., . . . Johnston, \nS. R. (2023). Towards understanding sycophancy in language models. \narXiv:2310.13548 . https://doi.org/10.48550/arXiv.2310.13548   \nShiffrin, R., & Mitchell, M. (2023). Probing the psychology of AI models. Proceedings of the \nNational Academy of Sciences of the United States of America , 120(10), \ne2300963120. https://doi.org/10.1073/pnas.2300963120   \nShojaee, P., Mirzadeh, I., Alizadeh, K., Horton, M., Bengio, S., & Farajtabar, M. (2025). The \nillusion of thinking: Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1140,
      "text": "Understanding the strengths and limitations of reasoning models \nvia the lens of problem complexity. arXiv:2506.06941 . \nhttps://doi.org/10.48550/arXiv.2506.06941   \nSoto, C. J., & John, O. P. (2017). The next Big Five Inventory (BFI -2): Developing and \nassessing a hierarchical model with 15 facets to enhance bandwidth, fidelity, and \npredictive power. Journal of Personality and Social Psychology , 113(1), 117 -143. \nhttps://doi.org/10.1037/pspp0000096   \nStanley, J. C., & Campbell, D. T. (1963). Experimental and quasi -experimental designs for \nresearch . Rand McNally.  \nS\u00fchr, T., Dorner, F. E., Samadi, S., & Kelava, A. (2023). Challenging the validity of \npersonality tests for large language models. arXiv:2311.05297 , 2311 . \nhttps://doi.org/10.48550/arXiv.2311.05297   \nTakemoto, K. (2024). The moral machine experiment on large language models. Royal \nSociety Open Science , 11(2), 231393. https://doi.org/10.1098/rsos.231393   \nTaylor, J. E. T., & Taylor, G. W. (2021). Artificial cognition: How experimental psychology \ncan help generate explainable artificial intelligence. Psychonomic Bulletin & Review , \n28(2), 454 -475. https://doi.org/10.3758/s13423 -020-01825 -5  \nTjuatja, L., Chen, V., Wu, T., Talwalkwar, A., & Neubig, G. (2024). Do LLMs exhibit \nhuman -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1141,
      "text": "human -like response biases? A case study in survey design. Transactions of the \nAssociation for Computational Linguistics , 12, 1011 -1026. \nhttps://doi.org/10.1162/tacl_a_00685   \nUllman, T. (2023). Large language models fail on trivial alterations to theory -of-mind tasks. \narXiv:2302.08399 . https://doi.org/10.48550/arXiv.2302.08399   \nVoudouris, K., Cheke, L., & Schulz, E. (2025). Bringing comparative cognition approaches \nto AI systems. Nature Reviews Psychology , 4(6), 363 -364. \nhttps://doi.org/10.1038/s44159 -025-00456 -8  \nWang, A., Morgenstern, J., & Dickerson, J. P. (2025). Large language models that replace \nhuman participants can harmfully misportray and flatten identity groups. Nature \nMachine Intelligence , 7(3), 400 -411. https://doi.org/10.1038/s42256 -025-00986 -z  \nWang, Q., Zhou, X., Sap, M., Forlizzi, J., & Shen, H. (2025). Rethinking theory of mind \nbenchmarks for LLMs: Towards a user -centered perspective. arXiv:2504.10839 . \nhttps://doi.org/10.48550/arXiv.2504.10839   \nWang, X., Li, X., Yin, Z., Wu, Y., & Liu, J. (2023). Emotional intelligence of large language \nmodels. Journal of Pacific Rim Psychology , 17, 18344909231213958. \nhttps://doi.org/10.1177/18344909231213958   \nLLM  VALIDITY  24 \nWang, Y., Zhao, J., Ones, D. S., He, L., & Xu, X. (2025). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023)."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1142,
      "text": "5). Evaluating the ability of large \nlanguage models to emulate personality. Scientific Reports , 15(1), 519. \nhttps://doi.org/10.1038/s41598 -024-84109 -5  \nWebb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language \nmodels. Nature Human Behaviour , 7(9), 1526 -1541. https://doi.org/10.1038/s41562 -\n023-01659 -w  \nXu, R., Sun, Y., Ren, M., Guo, S., Pan, R., Lin, H., . . . Han, X. (2024). AI for social science \nand social science of AI: A survey. Information Processing & Management , 61(3), \n103665. https://doi.org/10.1016/j.ipm.2024.103665   \nYe, H., Jin, J., Xie, Y., Zhang, X., & Song, G. (2025). Large language model psychometrics: \nA systematic review of evaluation, validation, and enhancement. arXiv:2505.08245 . \nhttps://doi.org/10.48550/arXiv.2505.08245   \nYe, H., Xie, Y., Ren, Y., Fang, H., Zhang, X., & Song, G. (2025). Measuring human and AI \nvalues based on generative psychometrics with large language models. Proceedings of \nthe AAAI Conference on Artificial Intelligence , 39(25), 26400 -26408. \nhttps://doi.org/10.1609/aaai.v39i25.34839   \nYing, L., Collins, K. M., Wong, L., Sucholutsky, I., Liu, R., Weller, A., . . . Tenenbaum, J. B. \n(2025). On benchmarking human -like intelligence in machines. arXiv:2502.20502 . \nhttps://doi.org/10.48550/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone."
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1143,
      "text": "50/arXiv.2502.20502   \nZaim bin Ahmad, M. S., & Takemoto, K. (2025). Large -scale moral machine experiment on \nlarge language models. PLOS ONE , 20(5), e0322776. \nhttps://doi.org/10.1371/journal.pone.0322776   \nZakazov, I., Boronski, M., Drudi, L., & West, R. (2024). Assessing social alignment: Do \npersonality -prompted large language models behave like humans? arXiv:2412.16772 . \nhttps://doi.org/10.48550/arXiv.2412.16772   \nZhou, L., Schellaert, W., Martinez -Plumed, F., Moros -Daval, Y., Ferri, C., & Hernandez -\nOrallo, J. (2024). Larger and more instructable language models become less reliable. \nNature , 634, 61-68. https://doi.org/10.1038/s41586 -024-07930 -y  \nZiems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2024). Can large language \nmodels transform computational social science? Computational Linguistics , 50(1), \n237-291. https://doi.org/10.1162/coli_a_00502   \nZou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "c668ffb2-cdcf-42dc-826c-f66b9bab7964",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\c668ffb2-cdcf-42dc-826c-f66b9bab7964.pdf",
      "doc_id": 1144,
      "text": "). Can LLMs \"self -report\"?: Evaluating \nthe validity of self -report scales in measuring personality design in LLM -based \nchatbots. arXiv:2412.00207 . https://doi.org/10.48550/arXiv.2412.00207"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1145,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1146,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1147,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1148,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1149,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1150,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1151,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1152,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1153,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1154,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1155,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1156,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1157,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1158,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1159,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1160,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1161,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1162,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1163,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1164,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1165,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1166,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1167,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1168,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1169,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1170,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1171,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1172,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1173,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1174,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1175,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1176,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1177,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1178,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1179,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1180,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1181,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1182,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1183,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1184,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1185,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1186,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1187,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1188,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1189,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1190,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1191,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1192,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1193,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1194,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1195,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1196,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1197,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1198,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1199,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1200,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1201,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1202,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1203,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1204,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1205,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1206,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1207,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1208,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1209,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1210,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1211,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1212,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1213,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1214,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1215,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1216,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1217,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1218,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1219,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1220,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1221,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1222,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1223,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1224,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1225,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1226,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1227,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1228,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1229,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1230,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1231,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1232,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1233,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1234,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1235,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1236,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1237,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1238,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1239,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1240,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1241,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1242,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1243,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1244,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1245,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1246,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1247,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1248,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1249,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1250,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1251,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1252,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1253,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1254,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1255,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1256,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1257,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1258,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1259,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1260,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1261,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1262,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1263,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1264,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1265,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1266,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1267,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1268,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1269,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1270,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1271,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1272,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1273,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1274,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1275,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1276,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1277,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1278,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1279,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1280,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1281,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1282,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1283,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1284,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1285,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1286,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1287,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1288,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1289,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1290,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1291,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1292,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1293,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1294,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1295,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1296,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1297,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1298,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1299,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1300,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1301,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1302,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1303,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1304,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1305,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1306,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1307,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1308,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1309,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1310,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1311,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1312,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1313,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1314,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1315,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1316,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1317,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1318,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1319,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1320,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1321,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1322,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1323,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1324,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1325,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1326,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1327,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1328,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1329,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1330,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1331,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1332,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1333,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1334,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1335,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1336,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1337,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1338,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1339,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1340,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1341,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1342,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1343,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1344,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1345,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1346,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1347,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1348,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1349,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1350,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1351,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1352,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1353,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1354,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1355,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1356,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1357,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1358,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1359,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1360,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1361,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1362,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1363,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1364,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1365,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1366,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1367,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1368,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1369,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1370,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1371,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1372,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1373,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1374,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1375,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1376,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1377,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1378,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1379,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1380,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1381,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1382,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1383,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1384,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1385,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1386,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1387,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1388,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1389,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1390,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1391,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1392,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1393,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1394,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1395,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1396,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1397,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1398,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1399,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1400,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1401,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1402,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1403,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1404,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1405,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1406,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1407,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1408,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1409,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1410,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1411,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1412,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1413,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1414,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1415,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1416,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1417,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1418,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1419,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1420,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1421,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1422,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1423,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1424,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1425,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1426,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1427,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1428,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1429,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1430,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1431,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1432,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1433,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1434,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1435,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1436,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1437,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1438,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1439,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1440,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1441,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1442,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1443,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1444,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1445,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1446,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1447,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1448,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1449,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1450,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1451,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1452,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1453,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1454,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1455,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1456,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1457,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1458,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1459,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1460,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1461,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1462,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1463,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1464,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1465,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1466,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1467,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1468,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1469,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1470,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1471,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1472,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1473,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1474,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1475,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1476,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1477,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1478,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1479,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1480,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1481,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1482,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1483,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1484,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1485,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1486,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1487,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1488,
      "text": "Frontiers in Psychology 01 frontiersin.org\nContradictory findings in the \nstudy of emotional false memory: \na review on the inadvisability of \ncontrolling valence and arousal\nHaochen\u00a0Yin  1, Yizhou\u00a0Zhou  1 and Zuoshan\u00a0Li  1,2*\n1 Key Laboratory of Applied Psychology, Chongqing Normal University, Chongqing, China, 2 School of \nTeacher Education, Chongqing Normal University, Chongqing, China\nEmotional false memories are the erroneous recollection of events accompanied \nby an emotional experience. In high-risk domains like psychotherapy and the \nlegal system, emotional false memories are of particular importance. Despite \nthe systematic research conducted on emotional false memories in recent \nyears, findings remain contradictory. Some studies have suggested that negative \nemotion reduces false memories, while others have suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1489,
      "text": "suggested that negative \nemotion increases false memories. Research has mainly employed words and \npictures as experimental stimuli, and studies using both types of memory stimuli \nare reviewed here. From this examination, it emerged that the main reasons \nfor contradictory findings are as follows: (1) different materials have varying \neffects on inducing false memories, with pictures demonstrating a memory \nadvantage compared to words; (2) recall and recognition tests have been used \ninterchangeably, leading to different false-memory effects depending on the \nmemory test employed; and (3) different studies have adopted different levels of \ncontrol over valence and arousal when manipulating emotional variables. Future \nstudies should distinguish between the use of different memory materials, \nexamine specific differences in recall and recognition tests, and measure the \nimpact of specific emotions on false memory beyond the dimensions of valence \nand arousal.\nKEYWORDS\nfalse memory, emotion, mood, emotional valence, emotional arousal\n1 Introduction\nMemory is not a faithful reproduction of an individual\u2019s experiences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1490,
      "text": "eriences but a reconstruction \nprocess that often leads to errors. These errors can be\u00a0harmless, such as when people misremember \nwhat they had for dinner, but they can also have serious consequences. In the field of law, for \nexample, when there is a lack of direct physical evidence relating to a crime, the evidence used to \naccuse and convict the defendant largely relies on memory ( Brainerd and Reyna, 2019 ). In the \nfield of psychotherapy, therapeutic techniques such as hypnosis and dream interpretation can \nincrease the likelihood of inducing harmful false memories, with an average of 20\u201350% of \nindividuals experiencing the induction of false events ( Muschalla and Sch\u00f6nborn, 2021 ). In the \nmedical field, patients reporting their symptoms incorrectly or doctors misremembering a \ncondition can lead to misdiagnosis and subsequent adverse effects on health. In the existing \nliterature, false memories can be\u00a0classified into two categories ( Ost et\u00a0al., 2013 ): (1) implanted \nfalse memories induced by suggestion and (2) spontaneous false memories generated without OPEN ACCESS\nEDITED BY\nMichael B. Steinborn,  \nJulius Maximilian University of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1491,
      "text": "ty of W\u00fcrzburg,  \nGermany\nREVIEWED BY\nDenis Brouillet,  \nUniversit\u00e9 Paul Val\u00e9ry, Montpellier III, France\nXiangping Gao,  \nShanghai Normal University, China\n*CORRESPONDENCE\nZuoshan Li   \n 642662213@qq.com\nRECEIVED 02 February 2024\nACCEPTED 09 May 2024\nPUBLISHED 28 May 2024\nCITATION\nYin H, Zhou Y and Li Z (2024) Contradictory \nfindings in the study of emotional false \nmemory: a review on the inadvisability of \ncontrolling valence and arousal.\nFront. Psychol.  15:1380742.\ndoi: 10.3389/fpsyg.2024.1380742\nCOPYRIGHT\n\u00a9 2024 Yin, Zhou and Li. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY) . The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.TYPE Review\nPUBLISHED  28 May 2024\nDOI 10.3389/fpsyg.2024.1380742\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 02 frontiersin.organy external pressure. Among them, the former is an external distortion, \nwhile the latter is an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1492,
      "text": "an internal distortion. These two types of false \nmemories are only weakly correlated with one another ( Calvillo and \nParong, 2016 ; Bernstein et\u00a0al., 2018 ), and this article focuses on the latter.\nRegarding the theory of emotions, the majority of studies probing \nthe impact of emotions on false memory are grounded in the circumplex \nmodel of emotion ( Russell, 1980 ), which posits that emotional \nexperiences are composites constructed from various dimensions of \nvalence and arousal\u2014for instance, positive, high-intensity emotional \nexperiences signifies happiness; positive, moderate-intensity emotional \nexperiences denotes relaxation; negative, moderate-intensity emotional \nexperiences signify tedium; and negative, extreme-intensity emotional \nexperiences symbolize fear. The dominant position of the circumplex \nmodel of emotion within this sphere can largely be\u00a0attributed to the \navailability of a standardized tools, such as the International Affective \nPicture Series (IAPS) ( Lang et\u00a0al., 1998 ), while available standardized \nmaterials grant researchers the capacity to manipulate the valance and \narousal of the material. In recent years, empirical research has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1493,
      "text": "has provided \na wealth of evidence on the impact of emotional stimuli on false \nmemory ( Kensinger and Schacter, 2008 ), and the debate about when \nand how emotions affect false memory has continued. Regarding the \ntheory on the influence of emotions on false memories, some theories \nexplain the impact of emotions on false memories from different \nperspectives. One theory, Emotional Enhancement of Memory ( Heuer \nand Reisberg, 1990 ), explains the impact of emotions on memory from \na broad perspective, suggesting that emotional content can enhance the \naccuracy of memory; for example, people tend to remember events that \nare accompanied by intense emotions. In contrast, the Distinctiveness \nHeuristic Account makes more specific predictions, suggesting that \nnegative emotions are less likely to generate false memories; this theory \nposits that people remember the distinctive details of events they have \nexperienced and make recognition judgments based on these distinctive \ndetails ( Schacter and Wiseman, 2006 )\u2014for instance, \u201cI clearly recall \nthat the dragon fruit I\u00a0consumed last week had white flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1494,
      "text": "hite flesh, not red flesh, \nas red-fleshed dragon fruits are quite distinctive. \u201d Emotional content is \noften more distinctive and can serve as a cue for a distinctiveness \nheuristic ( Schacter et\u00a0al., 2011 ); specifically, negative emotional content \nis highly relevant to survival, and individuals are more likely to \naccurately remember negative emotional content, making it less prone \nto producing false memories. These two theories offer different \npredictions about the specific direction of the impact of negative \nemotions on false memory, which is core to the ongoing debate. The \nconcept of emotional memory trade-off effects ( Kensinger et\u00a0al., 2007 ) \noutlines a contrast in how emotional and neutral components of an \nevent are remembered; while emotional aspects of an experience are \nremembered more vividly and accurately, the neutral details of the same \nexperience may be\u00a0 less accurately recalled. This trade-off implies a \nfocused allocation of cognitive resources toward emotionally salient \ninformation during an event, enhancing the memory of these aspects. \nConversely, less attention and hence fewer cognitive resources are \ndirected toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1495,
      "text": "ted toward neutral, peripheral details, resulting in poorer recall of \nthese elements; for instance, an eyewitness might only remember the \nsuspect\u2019s fierce expression, while overlooking their attire. The Fuzzy \nTrace Theory (FTT) explains the impact on false memories from the \nperspective of different components of emotional content; it suggests \nthat, when individuals experience an event, they store two opposing \nmemory traces ( Brainerd et\u00a0al., 2018 ). Finally, the verbatim trace stores \nspecific details of the experience, such as remembering specific items \nlike \u201capple\u201d and \u201ccanary, \u201d while the gist trace involves processing the meaning, such as categorizing an apple as fruit and a canary as an \nanimal. During the recall phase, extracting the gist trace triggers false \nmemories, while extracting the verbatim trace inhibits false memories. \nIn terms of valence, negative emotions strengthen gist traces, leading to \nmore false memories. Separately, regarding arousal, a moderate level of \narousal enhances verbatim traces, reducing false memories, but a \ngreater level of arousal weakens verbatim traces, increasing \nfalse memories.\nResearchers have used different paradigms to investigate emotion-\nrelated false memories. The Deese\u2013Roediger\u2013McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1496,
      "text": "McDermott (DRM) \nparadigm dominates in studies on spontaneous false memory ( Deese, \n1959 ; Roediger and McDermott, 1995 ). In this paradigm, participants \nfirst learn a list of associated words (e.g., \u201cmoonlight, \u201d \u201cbed, \u201d \u201cpillow, \u201d \n\u201cnight\u201d), which are semantically related to critical lure words (e.g., \n\u201csleep\u201d) that are not presented in the list. Higher recall or recognition of \nthe critical lure words in the subsequent test indicates a greater \ngeneration of false memories by the participant. The DRM paradigm is \nalso suitable for studying emotion-related false memory as researchers \ncan readily manipulate the valence of words to examine the influence \nof different emotions on false memory. To verify whether the results \nobtained from the DRM paradigm can be\u00a0generalized to other materials \nand paradigms, researchers have also used the picture paradigm \n(Koutstaal and Schacter, 1997 ). In this paradigm, participants learn \nseveral categories of pictures derived from real life (e.g., a set of baby \nphotos, a set of train photos) and manipulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1497,
      "text": "ulate their emotions by \nchanging the valence and arousal levels of the pictures. A category of \npictures not previously presented is used as critical lure stimuli to \nmeasure the false-memory effect. Therefore, in both the DRM paradigm \nand the picture paradigm, the valence and arousal levels of the memory \nmaterials can be\u00a0manipulated, and differences in the manipulation of \nvalence and arousal may lead to different results ( Chang et\u00a0al., 2021 ). In \naddition, the picture paradigm uses recognition tests, while the DRM \nparadigm combines both recognition tests and recall tests, where \nresearchers may use a single recognition test or recall test, or they may \nhave participants first complete a recall test and then a recognition test.\nIn summary, researchers have used various materials to create \nfalse memories, but the results are mixed. This prompts the question \nof whether there is a distinction between false memories induced by \nwords and pictures and whether the use of different memory tests \naffects the outcomes. Finally, with regard to emotional variables, some \nprevious studies did not control for either valence or arousal, while \nothers only controlled for one or the other. Does a difference in \ncontrolling valence and arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1498,
      "text": "arousal have an impact on research results? \nThis review elaborates on the specific directions of the influence of \nemotions on false memories in studies using words and pictures as \nmemory materials. Respectively, the aims of this investigation were to \nexplore (1) the differences in false memories induced by picture and \nword materials, (2) the impact of using different tests in experiments \nusing words as memory materials on the generation of false memories, \nand (3) the impact of control over valence and arousal on the results \nand whether these variables should be\u00a0controlled in future studies.\n2 Research on spontaneous emotional \nfalse memory\nThere are two ways in which emotions are generated when \nindividuals experience events: either the events themselves carry \nemotions, or said individuals have already generated certain emotions \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 03 frontiersin.orgbefore experiencing certain events. In other words, traumatic events \ncan trigger negative emotions, and the emotions individuals feel \nbefore recalling memories of neutral events may also differ. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1499,
      "text": "er. \nResearchers mainly use word and picture memory materials to induce \nfalse memories, a process which is largely supported by the availability \nof standardized material databases, such as the IAPS. Studies \nemploying word memory materials can be\u00a0roughly divided into two \ncategories: (1) content studies using DRM word lists with inherent \nemotional valence and (2) context studies that first induce emotions \nthrough other means (e.g., music, videos) and then ask participants to \nmemorize neutral DRM word lists. Experiments that use pictures to \nnaturally induce emotions in participants are considered content \nstudies, while experiments that first induce a certain emotion in \nsubjects and then have them recall neutral pictures are considered \nsituational studies.\n2.1 Word materials\n2.1.1 Content research\nBudson et\u00a0al. (2006)  were the first to use DRM lists with negative \nemotional valence. In their work the unrevealed critical lure (e.g., \n\u201cdanger\u201d) and the list words that participants were required to learn \n(e.g., \u201crisk, \u201d \u201charm, \u201d and \u201cthreat\u201d) were all negative in valence and \nsemantically related. Participants were presented with negative valence \nlists and neutral lists of equal word length, and no significant \ndifference in false memory between the negatively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1500,
      "text": "tively valenced and \nneutral lists was found on the recognition test. However, their method \nhad a limitation: the backward associative strength (BAS) of the \nnegative and neutral lists did not match. BAS refers to the strength of \nthe association between list items and the critical lure. The greater the \nBAS value, the easier it is for participants to associate with the critical \nlure and the more likely a false memory will occur, while, conversely, \nthe lower the BAS value, the less likely false memory will occur ( Gallo \nand Roediger, 2002 ). To overcome this limitation, Howe (2007)  \ncontrolled the BAS of the lists, and participants always completed the \nrecall test before the recognition test. Under these conditions, the \nfalse-recall rate for the neutral valence list was greater than that of the \nnegative valence list, and the false-recognition rate for the negative \nvalence list was greater than that of the neutral valence list. Sharkawy \net\u00a0al. (2008)  subsequently replicated Howe\u2019s experiment but did not \nobtain consistent results: they ultimately found no difference in false \nrecall between the two lists, but they did observe more false \nrecognition for the negative critical lure.\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1501,
      "text": ".\nBrainerd et\u00a0 al. (2008)  offered an explanation for these \ncontradictory findings from an alternative perspective\u2014namely, that \ndifferent studies have differed in the control of valence and arousal. To \naddress this, they manipulated valence and arousal using affective \nnorms for English words ( Bradley and Lang, 1999 ) and a 9-point scale \nand examined the impact of different emotional valences on false \nmemory while controlling for arousal. Subsequently, Dehon et\u00a0 al. \n(2010)  conducted a similar experiment and controlled for the \nconcreteness of the word lists. In Brainerd et\u00a0 al. \u2019s study, positive \nemotions resulted in fewer false memories on the recognition test, \nwhile negative emotions led to more false memories. However, Dehon \net\u00a0al. found that, regardless of the type of test used, both negative and \npositive emotions increased false memory. This discrepancy in \nfindings could be\u00a0due to differences in word list concreteness, as some studies have shown that the concreteness of words in DRM lists can \ninfluence the false-memory effect ( Hirshman and Arndt, 1997 ).\n2.1.2 Contextual research\nStorbeck and Clore (2005)  were the first to study the influence of \nemotions on false memory by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1502,
      "text": "by inducing emotional states in participants \nthrough music. In their study, they first induced emotional states in \nparticipants using music with different valences and then presented \nthe DRM list. The recognition test showed that participants in the \npositive emotion condition recalled more critical lures compared to \nthose in the negative emotion condition, while participants in the \nnegative emotion condition recalled fewer critical lures compared to \nthose in the neutral emotion condition. In other words, positive \nemotions increased false memory and negative emotions decreased \nfalse memory. In subsequent experiments, Storbeck (2013)  also \ninduced emotions using music; in Experiment 1, individuals in \npositive and neutral emotional states produced more false memories. \nMeanwhile, in Experiments 2 and 3, emotions were induced using \npictures selected from the IAPS, and the level of arousal was controlled \nfor different lists. The recognition test indicated that the influence of \nemotions on false memory was due to valence rather than the \narousal level.\nStorbeck\u2019s conclusion emphasizes the importance of valence in the \ninfluence of emotion on false memory. In contrast, some researchers \nbelieve that the impact of emotion on false memory is due to arousal. \nCorson and Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1503,
      "text": "nd Verrier (2007)  induced a series of discrete emotions using \na combination of music and guided-imagery techniques, then tested \nthe participants\u2019 recognition memory after they memorized DRM \nlists. Van Damme et\u00a0 al. (2017)  repeated Corson and Verrier\u2019s \nexperiment with methodological improvements and using delayed-\nrecognition tests, free-recall tests, and immediate-recognition tests in \nthree experiments. In addition, two control conditions were added, \none with neutral emotion induction and the other with no emotion \ninduction, to test whether different experimental manipulations \nwould lead to different results. Contrary to Storbeck\u2019s results, these \nexperiments suggested that the level of arousal affected false memory \nrather than valence. However, these studies differ in the specific \ndirection of the impact of arousal on false memory: Corson and \nVerrier found that high arousal led to more false memory than low \narousal, while Van Damme et\u00a0al. found that low arousal led to more \nfalse memory than high arousal.\n2.1.3 Summary of word material\nRegardless of whether valence and arousal were controlled, DRM \ncontent studies to date have not reached consistent conclusions, and \nthese differences may be\u00a0attributable to the variable natures of the \nword lists used, such as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1504,
      "text": "uch as the existence of differences in the BAS values \nof the word list and the concreteness of the words. Moreover, both \nrecall and recognition tests have also been confounded in existing \nresearch. DRM context research has also not yielded consistent results, \neven when controlling for valence and arousal. It is difficult to \ndetermine whether the impact of emotion on false memory is caused \nby arousal or valence effect based on the existing data. The differences \nin experimental manipulations, such as the specific methods of \nemotion induction, may have contributed to the contradictory \nfindings. Some studies have compared the effectiveness of various \nemotion-induction methods; for instance, Jallais and Gilet (2010)  \nfound that autobiographical recall was more effective in inducing \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 04 frontiersin.orgemotions of different valences and arousal levels and, When \ncomparing autobiographical recall to film induction methods, Salas \net\u00a0 al. (2012)  concluded that autobiographical recall was more \nconducive to inducing high-arousal emotions. Additionally, when \ncomparing film induction methods to music induction methods, Van \nder Does (2002)  discovered that music induction was more effective \nat evoking sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1505,
      "text": "sadness.\n2.2 Image materials\n2.2.1 Content research\nUsing pictures as memory materials, Choi et\u00a0al. (2013)  presented \nparticipants with positive images (e.g., kittens, puppies), neutral \nimages (e.g., bookshelf, chair), and negative images (e.g., nuclear \nbomb, warship), each accompanied by corresponding textual labels. \nSubsequent recognition tests measured memories for the textual \nlabels, and participants were observed to make fewer memory errors \nrelating to negative items. Zheng et\u00a0al. (2018)  used similar picture \nmaterials to directly measure false memory for the pictures and \nrecorded electroencephalogram data during the recognition tests. \nTheir results were consistent with Choi and Kensinger\u2019s findings and, \nadditionally, event-related potential data showed that negative \nemotional pictures exhibited a stronger parietal old/new effect \ncompared to neutral pictures, which is related to the retrieval process, \nsuggesting that people are more likely to remember negative stimuli \n(Rugg and Curran, 2007 ). Unlike the images used in the previous \nexperiments, Bookbinder and Brainerd (2017)  based their study on \nthree primary images and generated more images by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1506,
      "text": "s by altering their \ncolors, flipping their orientation, or changing both parameters \nsimultaneously. A subsequent recognition test used a conjoint \nrecognition modeling based on FTT ( Brainerd et\u00a0al., 2022 ), which can \ndistinguish the effects of verbatim retrieval and gist retrieval on false \nmemory, thus determining which type of retrieval is influenced by \nvalence. This recognition test revealed that negative emotions \nproduced more false memories. In addition, the parameter-estimation \ndata of the conjoint recognition model indicated that negative \nemotions enhance gist memory while impairing verbatim memory. \nHowever, as noted above, the materials used by Bookbinder and \nBrainerd were obtained by flipping and altering the colors of a small \nnumber of images, rendering all these images visually similar. Unlike \nthe independent images used in other experiments, this experimental \nmanipulation may have reminded participants of the theme of a set of \nimages, making them more likely to generate false memories based on \ngist traces ( Farris and Toglia, 2019 ).\nSome studies used a series of pictures to narrate a story (a girl \nreturning home after a trip), and manipulates the participants\u2019 \nemotions by changing the outcome of the story (the girl\u2019s home being \nransacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1507,
      "text": "nsacked by a robber or the girl finding a gift prepared by a stranger \nat home). The critical lure is the undisclosed reason for the event (the \nreason why the girl entered the room). Mirandola et\u00a0al. (2014)  were \namong the first to use narrative pictures as memory materials to study \nemotional false memories, employing materials that contained \ndifferent scripts (e.g., a bicycle trip) with each script story ending \ndifferently. Half of the script stories featured negative and highly \narousing content (e.g., a boy getting hit by a car, with blood around), \nwhile the other half featured neutral content with low arousal (e.g., a \nboy crossing the street without any accidents). Participants underwent a recognition test after viewing the script stories, and the primary \nresult was that negative, high-arousal script content could reduce false \nmemories. Following this, Melinder et\u00a0 al. (2017)  used similar \napproaches and incorporated positive emotions into consideration. \nThe results of the recognition test found that, compared to neutral \nemotions, both positive and negative emotions could reduce \nfalse memories.\n2.2.2 Contextual research\nMirandola and Toffalini (2016)  used picture materials as \nmemory aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1508,
      "text": "aids, with subjects learning the picture material before \nentering the retrieval phase. Prior to this phase, IAPS pictures were \nused to induce positive, negative, and neutral emotions, respectively. \nBoth positive and negative emotions triggered the same level of \narousal, which was greater than that of neutral emotions. Following \nthis, a recognition test was employed to investigate the impact of \nemotion valence and arousal on false memories. The results \nindicated that the groups exposed to positive and negative emotions \nhad lower rates of false memories than the group exposed to neutral \nemotions, with no significant difference in false memories between \nthe positive and negative emotion groups. There was a correlation \nbetween the valence assessed by participants and the rate of false \nmemories, while the level of arousal assessed by participants was \nnegatively correlated with false memories. Different from the studies \nmentioned above, Mirandola and Tofifalini induced emotions prior \nto the retrieval phase, rather than during the encoding phase, and \nthis may have led to differences in the results. Some studies have \nfound that stress arousal induced before the retrieval phase increases \nfalse memories ( Diekelmann et\u00a0al., 2011 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1509,
      "text": "1 ; Pardilla-Delgado et\u00a0al., \n2016 ), while other research suggests that psychological stress does \nnot have a significant effect on processing during the retrieval phase \n(Smeets et\u00a0al., 2008 ).\n2.2.3 Summary of image material\nStudies on emotional false memories using image materials have \nnot yielded consistent results, regardless of whether valence and \narousal levels were controlled. First, some studies have employed \npictures that depict a story, with intrinsic logical connections between \nthem, and this inherent causal relationship may have influenced the \noccurrence of false memories. Second, in experiments using pictures \nwithout logical relationships, some investigators have used utilized \nimages that are highly similar or even difficult to distinguish, while \nothers have used pictures that are more easily differentiable from each \nother. Finally, inducing emotions during either the encoding phase or \nthe retrieval phase could also be\u00a0a reason for the observed differences \nin results.\n3 Discussion on contradictory findings\nThe differences in the experiments mentioned in the text are \ndisplayed in Table\u00a01 . Below, we\u00a0will discuss these differences in detail.\n3.1 Different material properties\nThe DRM paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1510,
      "text": "M paradigm continues to dominate the study of false \nmemory, potentially due to personal biases ( Pezdek and Lam, 2007 ). \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 05 frontiersin.orgHowever, while researchers may favor the DRM paradigm because of \nits ability to produce powerful false-memory effects, its generalizability \nhas consistently been questioned. Picture materials may provide a \nuseful alternative for false memory research; for example, eyewitnesses \nmay be\u00a0asked to recognize the face of a criminal suspect or a photo of \nthe weapon used. It is also important to question whether the results \nobtained through the DRM paradigm can be\u00a0generalized to other \nmaterials and paradigms. It has already been established that \nindividuals display inherent differences in memory after viewing \npictures and words, with picture memory typically being superior to \nword memory, a finding known as the picture-superiority effect. \nExperiments by Schacter et\u00a0 al. (1999)  showed that the memory \nadvantage for pictures often stems from their more distinctive \nencoding compared to words. Ensor et\u00a0al. (2019)  further elucidated \nthe impact of differences in the physical properties of pictures and \nwords on the false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1511,
      "text": "false-memory effect, showing that, when words are \nrelatively more distinctive than pictures, the memory advantage of \npictures can be\u00a0weakened or even reversed. In addition, research by \nGrady et\u00a0al. (1998)  has demonstrated that pictures engage memory-\nrelated regions in the brain more effectively than words do, leading to \na wider range of brain activation, and this phenomenon is particularly \npronounced when the stimuli are emotionally charged; in particular, \nhighly arousing pictures activate the bilateral or right temporal lobes, \nwhile words activate the left temporal lobe. The lateral prefrontal \ncortex processes negative stimuli, while the medial prefrontal cortex \nprocesses positive stimuli, and the valence effect of pictures is stronger \nthan that of words ( Kensinger and Schacter, 2006 ). Therefore, the \ninherent differences between picture and word materials mean that \nconclusions cannot be\u00a0 extrapolated from experiments using \ndifferent materials.\nIt is also difficult to measure the emotional false-memory effect of \na certain material using one or even a few quantitative indicators. For \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1512,
      "text": "or \nfalse memory experiments using the DRM paradigm, the strength of \nthe associations, specificity, and the length of the word list mentioned \nin the previous text all impact the false-memory effect. For false memory experiments using pictures, in addition to the similarity of \nthe picture materials, as mentioned above, differences in the number \nof pictures encoded by participants may also lead to variable results. \nThere is evidence that increasing the number of samples for each \ncategory will produce stronger gist traces ( Powell et\u00a0al., 1999 ), leading \nto an increase in false memory. Therefore, it can be\u00a0concluded that \nfalse memory is sensitive to many different variables, and a systematic \nexamination of the impact of these different variables is necessary.\n3.2 Impact of memory testing\nThe picture paradigm for false memory typically uses recognition \ntests. However, in studies using the DRM paradigm, researchers may \nuse recognition tests or recall tests in isolation, or they may have \nparticipants engage in recall tests before recognition tests. Using \ndifferent tests or a combination of tests can simulate situations in \nwhich false memories occur in real life. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1513,
      "text": "fe. For example, police may \nrequest that eyewitnesses recall or identify the appearance of a suspect, \nor they may first have eyewitnesses recall the crime scene before \nconducting recognition tests. However, both recall and recognition \ntests yielded inconsistent results in the experiments performed by \nHowe (2007)  and Sharkawy et\u00a0al. (2008) , as described earlier. Recall \ntasks require participants to search for specific information, while \nrecognition tasks provide more specific cues. Evidence suggests that \nrecognition tests are more likely to produce false memories, while \nrecall tests have the opposite effect ( Seamon et\u00a0al., 2003 ). In cases \nwhere a combination of tests is used, prior recall tests can influence \nsubsequent recognition tests ( Roediger et\u00a0 al., 2001 ), and, when \nparticipants can recall all the words in a word list, false recognition \ndecreases ( Gallo, 2004 ). Recognition tests are more sensitive to items \nwith emotions and are more likely to produce false memories for \nemotional material ( Brainerd et\u00a0 al., 2014 ). In a recent study, \nresearchers controlled for the valence and arousal levels of 32 DRM \nlists, having subjects complete recall and recognition tests. The results TABLE\u00a01  Comparison of differences between experiments.\nStudy Context/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1514,
      "text": "/\ncontentMaterials Memory test Whether to control for valence and \narousal levels?\nBudson et\u00a0al. (2006) Content Words Recognition No\nHowe (2007) Content Words Recall and recognition No\nSharkawy et\u00a0al. (2008) Content Words Recall and recognition No\nBrainerd et\u00a0al. (2008) Content Words Recognition Ye s\nDehon et\u00a0al. (2010) Content Words Recall and recognition Ye s\nStorbeck and Clore (2005) Context Words Recognition No\nStorbeck (2013) Context Words Recognition Ye s\nCorson and Verrier (2007) Context Words Recognition Ye s\nVan Damme et\u00a0al. (2017) Context Words Recognition Ye s\nChoi et\u00a0al. (2013) Content Images Recognition Ye s\nZheng et\u00a0al. (2018) Content Images Recognition Ye s\nBookbinder and Brainerd (2017) Content Images Recognition Ye s\nMirandola et\u00a0al. (2014) Content Images Recognition No\nMelinder et\u00a0al. (2017) Content Images Recognition No\nMirandola and Toffalini (2016) Context Images Recognition Ye s\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 06 frontiersin.orgshowed that there was an interaction between valence and arousal in \nthe recall test, but this interaction was not observed in the recognition \ntest ( Chang et\u00a0al., 2021 ). In conclusion, the aforementioned studies \nshow that different memory tests have different effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1515,
      "text": "ifferent effects on false \nmemory, and the order and combination of tests used can also affect \nsubsequent recognition tests. However, the exact reasons for these \neffects require further research.\n3.3 Control of valence and arousal levels\nIn the analysis of this article, the control of valence and arousal \ncannot resolve the contradictions in the research on emotional false \nmemories. Different from our viewpoint, Bookbinder and Brainerd \n(2016)  believe that controlling the valence and arousal of memory \ncontent could help resolve the contradictions currently present in false \nmemory research. They explain the contradictory findings on \nemotional false memory as context\u2013content conflicts. They believe \nthat, in context research, positive valence increases, while negative \nvalence decreases false memory under controlled valence and arousal \nlevels. In content research, negative valence increases, and positive \nvalence decreases false memory. However, even Bookbinder and \nBrainerd\u2019s own research fails to support this view ( Brainerd et\u00a0al., \n2008 ; Bookbinder and Brainerd, 2017 ). In both content studies, the \narousal level of the encoded materials was controlled, but the former \nfound that positive emotions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1516,
      "text": "motions reduce false memory and the latter \nfound that positive emotions increase false memory. The authors \nsuggest that this may be\u00a0because verbatim memory is more sensitive \nto different materials. Studies consistent with this view indicate that \nthe increase in positive emotions is more dependent on the controlled \nfine processing of the left amygdala and prefrontal cortex, which are \nmore likely to be\u00a0influenced by different experimental manipulations \n(Pessoa, 2018 ). Whether to control for valence and arousal is the topic \nexplored in this article. In subsequent discussion, we\u00a0will elaborate on \nthe issues that controlling valence and arousal brings, as well as why \nit\u2019s necessary to go beyond the dimensions of valence and arousal to \nexamine the impact of discrete emotions on false memories.\n4 Summary and outlook\nThe impact of emotions on false memory has long been a concern \nin the fields of law and medicine. Extensive studies have shown that \nemotions can affect false memory, but there is no consistent \nexplanation of how this occurs. This article reviewed the literature and \nsummarized the results and methodological issues of previous studies.\nStudies using words as memory materials have enhanced people\u2019s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1517,
      "text": "s \nunderstanding of the constructive nature of memory and the \nsusceptibility to memory errors. However, the results obtained from \nword lists are not consistent with situations using other materials. \nResearchers appear to reach the same conclusions using different \nmaterials, which is not consistent with the actual situation. Future \nresearch must clarify the inherent differences in inducing false \nmemory using different materials such as words, pictures, videos, \nmusic, and so on. In addition, Whittlesea et\u00a0al. (2005)  raised doubts \nabout the DRM paradigm from a unique angle. They embraced the \nDRM paradigm and found that participants\u2019 false memories were \ncaused by surprise induced by the critical lure (note, the critical lure was more recapitulative and connected to other learned words). \nFurther studies revealed that, when participants consciously \nsuppressed their surprise at the critical lure, the DRM effect vanished. \nInterestingly, one study suggests that surprise can elicit negative \nemotions ( Topolinski and Strack, 2015 ), and whether surprise is truly \nan emotion remains a controversial question. Some have indicated \nthat surprise does not always have a certain level of valence, which is \na characteristic of each emotion ( Gerten and Topolinski, 2019 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1518,
      "text": "19 ; Ortony, \n2022 ). Therefore, it is evident that this issue is quite complex, and it is \ncrucial to explore the impact of surprise caused by the critical lure on \nfalse memories in future research. On the other hand, the false \nmemory induced by word lists is different from the false memory of \nreal events in judicial and psychological therapy contexts ( DePrince \nand Freyd, 2004 ), as each group of words or pictures is relatively \nindependent and lacks logical relationships. The method mentioned \nearlier involves using a collection of pictures that depict a story as \nmemory materials, which, to some extent, addresses the problem of \nthe lack of logical relationships between learning items in \ntraditional paradigms.\nEmotion-induced false memories are sensitive to many different \nvariables, and even subtle changes in the experimental design can \nlead to changes in the direction of emotion-induced memory errors. \nAdditionally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1519,
      "text": "onally, recall and recognition tests, respectively, have different \neffects on memory errors, but they are often confused with each \nother in the existing literature. A recent study ( Wiechert et\u00a0 al., \n2024 ) used meta-analysis and replication research methods to \nuncover that negative valence does not systematically affect false \nmemory; instead, the formation of false memories depends upon \nhow false memories are tested; in the recall test, valence had no \neffect on false memory, while, in the recognition test, the effect of \nfalse memory may be\u00a0 attributed to response bias. Additionally, \nY\u00fcvr\u00fck and Kapucu (2022)  found that the effect of valence was \nnon-significant when recognition responses were controlled for \nresponse bias. These results indicate that future research should \nquantify the impact and specific contributions of different \nmanipulations on memory errors, and examining the impact of \nemotions on false memory from the perspective of valence and \narousal alone is far from sufficient. Among previous studies, only \nsome controlled for valence and arousal, and the conflation of the \ntwo could have caused variability in the results. Should valence and \narousal be\u00a0controlled? While the valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 )."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1520,
      "text": "he valence and arousal of emotions \nmight differently influence false memories, it\u2019s not sufficient to limit \nresearch solely to the effect of emotional arousal on memory \n(Levine and Pizarro, 2004 ). Individuals may experience specific \nemotions like happiness, fear, despair, or anger, but they are never \nmerely \u201caroused. \u201d Previous studies have shown that emotional \nexperiences cannot be\u00a0 fully captured by just two dimensions \n(Panksepp, 1992 ; Barrett, 1998 ). For example, the circumplex model \nof emotion struggles to accurately depict rare but complex emotions \nlike shame, guilt, or jealousy, and these emotions are common in \nthe real situations where false memories are created. Thus, confining \nresearch to just valence and arousal essentially lacks external \nvalidity. Specific emotions have adaptive functions, enabling us to \nrespond appropriately to environmental changes ( Howe, 2011 ); for \ninstance, fear and anger are similar in valence and arousal, but fear \ntends to make individuals avoid threats, whereas anger inclines \nindividuals toward eliminating threats ( Cunningham and Brosch, \n2012 ). In the field of false memory, there are also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1521,
      "text": "e also numerous \nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 07 frontiersin.orgexamples that support this view. A study on the emotion congruence \nof discrete emotions ( Bland et\u00a0al., 2016 ) induced participants\u2019 fear \nand anger through film clips (with no significant difference in \nvalence and arousal) and asked participants to recall DRM lists with \nfearful and angry themes. In the subsequent recognition test, \nparticipants erroneously remembered critical lures consistent with \ntheir emotional state. In another study on discrete emotions, ( Van \nDamme et\u00a0al., 2017 ) conducted an experiment in which participants \nwere induced to experience corresponding emotions by having \nthem empathize with the content of the slides. The results from the \nrecognition tests showed that participants under hope and fear \nconditions produced more false memories than did those under \nhappy or despair conditions. Furthermore, studies on clinical \npopulations have evidence that individuals with PTSD, depression, \nand a history of trauma are more prone to false memories related \nto their psychological disorders (e.g., trauma-related stimuli), \nregardless of the valence and arousal ( Otgaar et\u00a0 al., 2017 ). The \nabove results cannot be\u00a0 explained solely by the dimensions of \narousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1522,
      "text": "arousal and valence, indicating that limiting research to \ninvestigating only valence and arousal does not facilitate a clear \nunderstanding of the relationship between emotions and \nfalse memories.\nContrary to what previous researchers have advocated for in \ncontrolling valence and arousal levels, this paper innovatively proposes \nthat we\u00a0should go beyond the dimensions of valence and arousal to \nexplore the impact of emotions on false memories. It is worth \nmentioning that this paper focuses on spontaneous emotional false \nmemories, and similar results have also been demonstrated in studies \nof implanted false memories. In their work, Sharma et\u00a0 al. (2023)  \nreviewed 39 studies to explore the relationship between emotions and \nimplanted false memories and found that the impact of emotions on \nimplanted false memories depends upon the type or aspect of \nemotional measurement; specifically, the valence of emotions did not \naffect the generation of false memories, and when information was \nrecalled with a delay, the arousal of emotions also did not have an \nimpact on false memory. Moreover, stress and short-term distress \nexperienced by subjects before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1523,
      "text": "s before encoding reduced the implanted false \nmemories produced by the subjects, while prolonged distress, anger, \nand greater stress increased the implanted false memories produced \nby the subjects. This outcome might be\u00a0because the two dimensions \nof the circumplex model of emotions cannot explain the dynamic nature of emotional changes. Emotional experiences are often rapidly \nchanging, comprised of both continuous and momentary variations \n(Scherer, 2005 ).\nAlthough it may be\u00a0convenient to describe emotions simply in \nterms of valence and arousal, two emotions with the same valence and \narousal (such as fear and anger) can have different effects on false \nmemory. Moreover, limiting research to valence and arousal neglects \nthe adaptive nature of emotions. Therefore, future research should not \nonly control for valence and arousal dimensions but also explore the \nfalse memories induced by specific emotions.\nAuthor contributions\nHY: Writing \u2013 original draft. YZ: Writing \u2013 review & editing. ZL: \nWriting \u2013 review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1524,
      "text": "ication of this article. Supported by \nProgram for Chongqing Scholars and Innovative Research Team in \nUniversity. Collaborative Innovation Team for Research on the Mental \nhealth of Special Children.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe\u00a0construed as a potential conflict of interest.\nPublisher's note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be\u00a0evaluated in this article, or claim that may be\u00a0made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nBarrett, L. F. (1998). Discrete emotions or dimensions? The role of valence focus and \narousal focus. Cogn. Emot.  12, 579\u2013599. doi: 10.1080/026999398379574\nBernstein, D. M., Scoboria, A., Desjarlais, L., and Soucie, K. (2018). \u201cFalse memory\u201d \nis a linguistic convenience. Psychol. Conscious  5, 161\u2013179. doi: 10.1037/cns0000148\nBland, C. E., Howe, M. L., and Knott, L. (2016). Discrete emotion-congruent false \nmemories in the DRM paradigm. Emotion  16, 611\u2013619. doi: 10.1037/emo0000153\nBookbinder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1525,
      "text": "inder, S. H., and Brainerd, C. J. (2016). Emotion and false memory: the context\u2013\ncontent paradox. Psychol. Bull.  142, 1315\u20131351. doi: 10.1037/bul0000077\nBookbinder, S. H., and Brainerd, C. J. (2017). Emotionally negative pictures enhance \ngist memory. Emotion  17, 102\u2013119. doi: 10.1037/emo0000171\nBradley, M. M., and Lang, P . J. (1999). Affective norms for English Words (ANEW): \ninstruction manual and affective ratings. Technical Report C-2 . Gainesville, FL: University \nof Florida.\nBrainerd, C. J., Bialer, D. M., and Chang, M. (2022). Fuzzy-trace theory and false \nmemory: meta-analysis of conjoint recognition. J. Exp. Psychol. Learn. Mem. Cogn.  48, \n1680\u20131697. doi: 10.1037/xlm0001040Brainerd, C. J., Gomes, C. F. A., and Moran, R. (2014). The two recollections. Psychol. \nRev. 121, 563\u2013599. doi: 10.1037/a0037668\nBrainerd, C. J., and Reyna, V . F. (2019). Fuzzy-trace theory, false memory, and the law. \nPolicy Insights Behav. Brain Sci.  6, 79\u201386. doi: 10.1177/2372732218797143\nBrainerd, C. J., Reyna, V . F., and Holliday, R. E. (2018). Developmental reversals in \nfalse memory: development is complementary, not compensatory. Dev. Psychol.  54, \n1773\u20131784. doi: 10.1037/dev0000554\nBrainerd, C. J., Stein, L. M., Silveira, R. A., Rohenkohl, G., and Reyna, V . F. (2008). \nHow Does negative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1526,
      "text": "ative emotion cause false memories? Psychol. Sci.  19, 919\u2013925. doi: \n10.1111/j.1467-9280.2008.02177.x\nBudson, A. E., Todman, R. W ., Chong, H., Adams, E. H., Kensinger, E. A., Krangel, T. S., \net al. (2006). False recognition of emotional word lists in aging and Alzheimer disease. \nCogn. Behav. Neurol.  19, 71\u201378. doi: 10.1097/01.wnn.0000213905.49525.d0\nCalvillo, D. P ., and Parong, J. A. (2016). The misinformation effect is unrelated to the \nDRM effect with and without a DRM warning. Memory  24, 324\u2013333. doi: \n10.1080/09658211.2015.1005633\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 08 frontiersin.orgChang, M., Brainerd, C. J., Toglia, M. P ., and Schmidt, S. R. (2021). Norms for \nemotion-false memory lists. Behav. Res. Methods  53, 96\u2013112. doi: 10.3758/\ns13428-020-01410-7\nChoi, H.-Y ., Kensinger, E. A., and Rajaram, S. (2013). Emotional content enhances \ntrue but not false memory for categorized stimuli. Mem. Cogn.  41, 403\u2013415. doi: \n10.3758/s13421-012-0269-2\nCorson, Y ., and Verrier, N. (2007). Emotions and false memories: valence or arousal? \nPsychol. Sci.  18, 208\u2013211. doi: 10.1111/j.1467-9280.2007.01874.x\nCunningham, W . A., and Brosch, T. (2012). Motivational salience:amygdala tuning \nfrom traits, needs, values, and goals. Curr. Dir. Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1527,
      "text": ". Psychol. Sci.  21, 54\u201359. doi: \n10.1177/0963721411430832\nDeese, J. (1959). On the prediction of occurrence of particular verbal intrusions in \nimmediate recall. J. Exp. Psychol.  58, 17\u201322. doi: 10.1037/h0046671\nDehon, H., Lar\u00f8i, F., and Van der Linden, M. (2010). Affective valence influences \nparticipant's susceptibility to false memories and illusory recollection. Emotion  10, \n627\u2013639. doi: 10.1037/a0019595\nDePrince, A. P ., and Freyd, J. J. (2004). Forgetting Trauma Stimuli. Psychol. Sci.  15, \n488\u2013492. doi: 10.1111/j.0956-7976.2004.00706.x\nDiekelmann, S., Wilhelm, I., Wagner, U., and Born, J. (2011). Elevated cortisol at \nretrieval suppresses false memories in parallel with correct memories. J. Cogn. Neurosci.  \n23, 772\u2013781. doi: 10.1162/jocn.2010.21493\nEnsor, T. M., Surprenant, A. M., and Neath, I. (2019). Increasing word \ndistinctiveness eliminates the picture superiority effect in recognition: evidence for \nthe physical-distinctiveness account. Mem. Cogn.  47, 182\u2013193. doi: 10.3758/\ns13421-018-0858-9\nFarris, E. A., and Toglia, M. P . (2019). Conjoint recognition procedures reveal \nverbatim processing enhances memory for emotionally valenced pictorial stimuli. \nEmotion  19, 533\u2013542. doi: 10.1037/emo0000458\nGallo, D. A. (2004). Using recall to reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1528,
      "text": "reduce false recognition: diagnostic and \ndisqualifying monitoring. J. Exp. Psychol. Learn. Mem. Cogn.  30, 120\u2013128. doi: \n10.1037/0278-7393.30.1.120\nGallo, D. A., and Roediger, I. I. I. H. L. (2002). Variability among word lists in eliciting \nmemory illusions: evidence for associative activation and monitoring. J. Mem. Lang.  47, \n469\u2013497. doi: 10.1016/S0749-596X(02)00013-X\nGerten, J., and Topolinski, S. (2019). Shades of surprise: assessing surprise as a \nfunction of degree of deviance and expectation constraints. Cognition  192:103986. doi: \n10.1016/j.cognition.2019.05.023\nGrady, C. L., McIntosh, A. R., Rajah, M. N., and Craik, F. I. M. (1998). Neural \ncorrelates of the episodic encoding of pictures and words. Proc. Natl. Acad. Sci.  95, \n2703\u20132708. doi: 10.1073/pnas.95.5.2703\nHeuer, F., and Reisberg, D. (1990). Vivid memories of emotional events: the \naccuracy of remembered minutiae. Mem. Cogn.  18, 496\u2013506. doi: 10.3758/\nBF03198482\nHirshman, E., and Arndt, J. (1997). Discriminating alternative conceptions of false \nrecognition: the cases of word concreteness and word frequency. J. Exp. Psychol. Learn. \nMem. Cogn.  23, 1306\u20131323. doi: 10.1037/0278-7393.23.6.1306\nHowe, M. L. (2007). Children's emotional false memories. Psychol. Sci.  18, 856\u2013860. \ndoi: 10.1111/j.1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1529,
      "text": ".1467-9280.2007.01991.x\nHowe, M. L. (2011). The adaptive nature of memory and its illusions. Curr. Dir. \nPsychol. Sci.  20, 312\u2013315. doi: 10.1177/0963721411416571\nJallais, C., and Gilet, A.-L. (2010). Inducing changes in arousal and valence: \ncomparison of two mood induction procedures. Behav. Res. Methods  42, 318\u2013325. doi: \n10.3758/BRM.42.1.318\nKensinger, E. A., Garoff-Eaton, R. J., and Schacter, D. L. (2007). Effects of emotion on \nmemory specificity: memory trade-offs elicited by negative visually arousing stimuli. J. \nMem. Lang.  56, 575\u2013591. doi: 10.1016/j.jml.2006.05.004\nKensinger, E. A., and Schacter, D. L. (2006). Amygdala activity is associated with the \nsuccessful encoding of item, but not source, information for positive and negative \nstimuli. J. Neurosci.  26, 2564\u20132570. doi: 10.1523/jneurosci.5241-05.2006\nKensinger, E. A., and Schacter, D. L. (2008). Neural processes supporting young and \nolder Adults' emotional memories. J. Cogn. Neurosci.  20, 1161\u20131173. doi: 10.1162/\njocn.2008.20080\nKoutstaal, W ., and Schacter, D. L. (1997). Gist-based false recognition of pictures in \nolder and younger adults. J. Mem. Lang.  37, 555\u2013583. doi: 10.1006/jmla.1997.2529\nLang, P . J., Bradley, M. M., and Cuthbert, B. N. (1998). Emotion, motivation, and \nanxiety: brain mechanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1530,
      "text": "hanisms and psychophysiology. Biol. Psychiatry  44, 1248\u20131263. doi: \n10.1016/S0006-3223(98)00275-3\nLevine, L. J., and Pizarro, D. A. (2004). Emotion and memory research: a grumpy \noverview. Soc. Cogn.  22, 530\u2013554. doi: 10.1521/soco.22.5.530.50767\nMelinder, A., Toffalini, E., Geccherle, E., and Cornoldi, C. (2017). Positive events \nprotect children from causal false memories for scripted events. Memory  25, 1366\u20131374. \ndoi: 10.1080/09658211.2017.1306080\nMirandola, C., and Toffalini, E. (2016). Arousal\u2014but not valence\u2014reduces false \nmemories at retrieval. PLoS One  11:e0148716. doi: 10.1371/journal.pone.0148716Mirandola, C., Toffalini, E., Grassano, M., Cornoldi, C., and Melinder, A. (2014). \nInferential false memories of events: negative consequences protect from distortions \nwhen the events are free from further elaboration. Memory  22, 451\u2013461. doi: \n10.1080/09658211.2013.795976\nMuschalla, B., and Sch\u00f6nborn, F. (2021). Induction of false beliefs and false memories \nin laboratory studies\u2014a systematic review. Clin. Psychol. Psychother.  28, 1194\u20131209. doi: \n10.1002/cpp.2567\nOrtony, A. (2022). Are all \u201cbasic emotions\u201d emotions? A problem for the (basic) \nemotions construct. Perspect. Psychol. Sci.  17, 41\u201361. doi: 10.1177/  \n1745691620985415\nOst, J., Blank, H., Davies, J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1531,
      "text": "J., Jones, G., Lambert, K., and Salmon, K. (2013). False \nmemory \u2260 false memory: DRM errors are unrelated to the misinformation effect. PLoS \nOne 8:e57939. doi: 10.1371/journal.pone.0057939\nOtgaar, H., Muris, P ., Howe, M. L., and Merckelbach, H. (2017). What drives false \nmemories in psychopathology? A case for associative activation. Clin. Psychol. Sci.  5, \n1048\u20131069. doi: 10.1177/2167702617724424\nPanksepp, J. (1992). A critical role for \"affective neuroscience\" in resolving what is \nbasic about basic emotions. Psychol. Rev.  99, 554\u2013560. doi: 10.1037/0033-295X.99.  \n3.554\nPardilla-Delgado, E., Alger, S. E., Cunningham, T. J., Kinealy, B., and Payne, J. D. \n(2016). Effects of post-encoding stress on performance in the DRM false memory \nparadigm. Learn. Mem.  23, 46\u201350. doi: 10.1101/lm.039354.115\nPessoa, L. (2018). Understanding emotion with brain networks. Curr. Opin. Behav. Sci.  \n19, 19\u201325. doi: 10.1016/j.cobeha.2017.09.005\nPezdek, K., and Lam, S. (2007). What research paradigms have cognitive psychologists \nused to study \u201cfalse memory, \u201d and what are the implications of these choices? Conscious. \nCogn.  16, 2\u201317. doi: 10.1016/j.concog.2005.06.006\nPowell, M. B., Roberts, K. P ., Ceci, S. J., and Hembrooke, H. (1999). The effects of \nrepeated experience on children's suggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1532,
      "text": "uggestibility. Dev. Psychol.  35, 1462\u20131477. doi: \n10.1037/0012-1649.35.6.1462\nRoediger, H. L., and McDermott, K. B. (1995). Creating false memories: remembering \nwords not presented in lists. J. Exp. Psychol. Learn. Mem. Cogn.  21, 803\u2013814. doi: \n10.1037/0278-7393.21.4.803\nRoediger, H. L., Watson, J. M., McDermott, K. B., and Gallo, D. A. (2001). Factors that \ndetermine false recall: a multiple regression analysis. Psychon. Bull. Rev.  8, 385\u2013407. doi: \n10.3758/BF03196177\nRugg, M. D., and Curran, T. (2007). Event-related potentials and recognition memory. \nTrends Cogn. Sci.  11, 251\u2013257. doi: 10.1016/j.tics.2007.04.004\nRussell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol.  39, 1161\u20131178. \ndoi: 10.1037/h0077714\nSalas, C. E., Radovic, D., and Turnbull, O. H. (2012). Inside-out: comparing internally \ngenerated and externally generated basic emotions. Emotion  12, 568\u2013578. doi: 10.1037/\na0025811\nSchacter, D. L., Gallo, D. A., and Kensinger, E. A. (2011). \u201cThe cognitive neuroscience \nof implicit and false memories: perspectives on processing specificity\u201d in The foundations \nof remembering: Essays in honor of Henry L. Roediger III . ed. J. S. Nairne (New Y ork: \nPsychology Press), 353\u2013378.\nSchacter, D. L., Israel, L., and Racine, C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1533,
      "text": "C. (1999). Suppressing false recognition in \nyounger and older adults: the distinctiveness heuristic. J. Mem. Lang.  40, 1\u201324. doi: \n10.1006/jmla.1998.2611\nSchacter, D. L., and Wiseman, A. L. (2006). \u201cReducing memory errors: the \ndistinctiveness heuristic\u201d in Distinctiveness and memory . eds. R. R. Hunt and J. Worthen \n(New Y ork, NY , US: Oxford University Press), 89\u2013107.\nScherer, K. R. (2005). What are emotions? And how can they be\u00a0measured? Soc. Sci. \nInform.  44, 695\u2013729. doi: 10.1177/0539018405058216\nSeamon, J. G., Goodkind, M. S., Dumey, A. D., Dick, E., Aufseeser, M. S., \nStrickland, S. E., et al. (2003). \u201cIf I\u00a0didn\u2019t write it, why would I\u00a0remember it?\u201d effects of \nencoding, attention, and practice on accurate and false memory. Mem. Cogn.  31, \n445\u2013457. doi: 10.3758/BF03194402\nSharkawy, J. E., Groth, K., Vetter, C., Beraldi, A., and Fast, K. (2008). False memories \nof emotional and neutral words. Behav. Neurol.  19, 7\u201311. doi: 10.1155/2008/  \n587239\nSharma, P . R., Wade, K. A., and Jobson, L. (2023). A systematic review of the \nrelationship between emotion and susceptibility to misinformation. Memory  31, 1\u201321. \ndoi: 10.1080/09658211.2022.2120623\nSmeets, T., Otgaar, H., Candel, I., and Wolf, O. T. (2008). True or false? Memory is \ndifferentially affected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013)."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1534,
      "text": "ected by stress-induced cortisol elevations and sympathetic activity at \nconsolidation and retrieval. Psychoneuroendocrinology  33, 1378\u20131386. doi: 10.1016/j.\npsyneuen.2008.07.009\nStorbeck, J. (2013). Negative affect promotes encoding of and memory for details at \nthe expense of the gist: affect, encoding, and false memories. Cogn. Emot.  27, 800\u2013819. \ndoi: 10.1080/02699931.2012.741060\nStorbeck, J., and Clore, G. L. (2005). With sadness comes accuracy; with happiness, \nfalse memory:mood and the false memory effect. Psychol. Sci.  16, 785\u2013791. doi: \n10.1111/j.1467-9280.2005.01615.x\nYin et al. 10.3389/fpsyg.2024.1380742\nFrontiers in Psychology 09 frontiersin.orgTopolinski, S., and Strack, F. (2015). Corrugator activity confirms immediate negative \naffect in surprise. Front. Psychol.  6:134. doi: 10.3389/fpsyg.2015.00134\nVan Damme, I., Kaplan, R. L., Levine, L. J., and Loftus, E. F. (2017). Emotion and false \nmemory: how goal-irrelevance can be\u00a0relevant for what people remember. Memory  25, \n201\u2013213. doi: 10.1080/09658211.2016.1150489\nVan der Does, W . (2002). Cognitive reactivity to sad mood: structure and validity of a \nnew measure. Behav. Res. Ther.  40, 105\u2013119. doi: 10.1016/S0005-7967(00)00111-X\nWhittlesea, B. W . A., Masson, M. E. J., and Hughes, A. D. (2005). False memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ."
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1535,
      "text": "alse memory \nfollowing rapidly presented lists: the element of surprise. Psychol. Res.  69, 420\u2013430. doi: \n10.1007/s00426-005-0213-1Wiechert, S., Proost, D., Simoens, E., Ben-Shakhar, G., Pertzov, Y ., and Verschuere, B. \n(2024). The effect of negative valence on false memory formation in the Deese\u2013\nRoediger\u2013McDermott paradigm: a preregistered meta-analysis and preregistered \nreplication. J. Exp. Psychol. Gen.  153, 621\u2013655. doi: 10.1037/xge0001527\nY\u00fcvr\u00fck, E., and Kapucu, A. (2022). False (or biased) memory: emotion and working \nmemory capacity effects in the DRM paradigm. Mem. Cogn.  50, 1443\u20131463. doi: \n10.3758/s13421-022-01298-y\nZheng, Z., Lang, M., Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6eb5c0c0-c21d-48f3-a0c8-def71df61133",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6eb5c0c0-c21d-48f3-a0c8-def71df61133.pdf",
      "doc_id": 1536,
      "text": "Wang, W ., Xiao, F., and Li, J. (2018). \nElectrophysiological evidence for the effects of emotional content on false \nrecognition memory. Cognition  179, 298\u2013310. doi: 10.1016/j.cognition.2018.06.013"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1537,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1538,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1539,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1540,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1541,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1542,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1543,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1544,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1545,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1546,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1547,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1548,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1549,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1550,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1551,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1552,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1553,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1554,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1555,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1556,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1557,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1558,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1559,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1560,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1561,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1562,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1563,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1564,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1565,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1566,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1567,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1568,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1569,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1570,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1571,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1572,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1573,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1574,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1575,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1576,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1577,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1578,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1579,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1580,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1581,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1582,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1583,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1584,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1585,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1586,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1587,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1588,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1589,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1590,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1591,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1592,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1593,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1594,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1595,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1596,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1597,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1598,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1599,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1600,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1601,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1602,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1603,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1604,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1605,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1606,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1607,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1608,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1609,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1610,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1611,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1612,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1613,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1614,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1615,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1616,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1617,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1618,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1619,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1620,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1621,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1622,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1623,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1624,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1625,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1626,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1627,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1628,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1629,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1630,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1631,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1632,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1633,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1634,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1635,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1636,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1637,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1638,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1639,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1640,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1641,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1642,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1643,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1644,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1645,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1646,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1647,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1648,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1649,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1650,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1651,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1652,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1653,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1654,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1655,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1656,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1657,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1658,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1659,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1660,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1661,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1662,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1663,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1664,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1665,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1666,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1667,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1668,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1669,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1670,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1671,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1672,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1673,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1674,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1675,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1676,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1677,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1678,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1679,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1680,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1681,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1682,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1683,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1684,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1685,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1686,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1687,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1688,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1689,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1690,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1691,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1692,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1693,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1694,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1695,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1696,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1697,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1698,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1699,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1700,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1701,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1702,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1703,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1704,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1705,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1706,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1707,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1708,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1709,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1710,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1711,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1712,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1713,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1714,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1715,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1716,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1717,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1718,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1719,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1720,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1721,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1722,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1723,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1724,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1725,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1726,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1727,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1728,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1729,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1730,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1731,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1732,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1733,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1734,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1735,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1736,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1737,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1738,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1739,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1740,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1741,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1742,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1743,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1744,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1745,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1746,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1747,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1748,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1749,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1750,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1751,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1752,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1753,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1754,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1755,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1756,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1757,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1758,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1759,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1760,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1761,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1762,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1763,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1764,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1765,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1766,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1767,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1768,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1769,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1770,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1771,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1772,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1773,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1774,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1775,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1776,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1777,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1778,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1779,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1780,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1781,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1782,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1783,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1784,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1785,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1786,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1787,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1788,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1789,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1790,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1791,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1792,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1793,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1794,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1795,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1796,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1797,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1798,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1799,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1800,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1801,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1802,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1803,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1804,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1805,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1806,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1807,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1808,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1809,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1810,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1811,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1812,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1813,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1814,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1815,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1816,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1817,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1818,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1819,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1820,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1821,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1822,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1823,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1824,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1825,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1826,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1827,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1828,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1829,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1830,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1831,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1832,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1833,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1834,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1835,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1836,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1837,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1838,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1839,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1840,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1841,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1842,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1843,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1844,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1845,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1846,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1847,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1848,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1849,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1850,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1851,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1852,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1853,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1854,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1855,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1856,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1857,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1858,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1859,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1860,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1861,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1862,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1863,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1864,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1865,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1866,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1867,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1868,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1869,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1870,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1871,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1872,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1873,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1874,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1875,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1876,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1877,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1878,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1879,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1880,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1881,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1882,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1883,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1884,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1885,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1886,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1887,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1888,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1889,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1890,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1891,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1892,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1893,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1894,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1895,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1896,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1897,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1898,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1899,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1900,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1901,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1902,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1903,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1904,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1905,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1906,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1907,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1908,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1909,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1910,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1911,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1912,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1913,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1914,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1915,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1916,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1917,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1918,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1919,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1920,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1921,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1922,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1923,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1924,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1925,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1926,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1927,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1928,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1929,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1930,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1931,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1932,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1933,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1934,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1935,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1936,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1937,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1938,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1939,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1940,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1941,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1942,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1943,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1944,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1945,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1946,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1947,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1948,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1949,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1950,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1951,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1952,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1953,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1954,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1955,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1956,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1957,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1958,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1959,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1960,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1961,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1962,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1963,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1964,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1965,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1966,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1967,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1968,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1969,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1970,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1971,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1972,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1973,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1974,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1975,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1976,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1977,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1978,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1979,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1980,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1981,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1982,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1983,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1984,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1985,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1986,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1987,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1988,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1989,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1990,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1991,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1992,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1993,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1994,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1995,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1996,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1997,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1998,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 1999,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2000,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2001,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2002,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2003,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2004,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2005,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2006,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2007,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2008,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2009,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2010,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2011,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2012,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2013,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2014,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2015,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2016,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2017,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2018,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2019,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2020,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2021,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2022,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2023,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2024,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2025,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2026,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2027,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2028,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2029,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2030,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2031,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2032,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2033,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2034,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2035,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2036,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2037,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2038,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2039,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2040,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2041,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2042,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2043,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2044,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2045,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2046,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2047,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2048,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2049,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2050,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2051,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2052,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2053,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2054,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2055,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2056,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2057,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2058,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2059,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2060,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2061,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2062,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2063,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2064,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2065,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2066,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2067,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2068,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2069,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2070,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2071,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2072,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2073,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2074,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2075,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2076,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2077,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2078,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2079,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2080,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2081,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2082,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2083,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2084,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2085,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2086,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2087,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2088,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2089,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2090,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2091,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2092,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2093,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2094,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2095,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2096,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2097,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2098,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2099,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2100,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2101,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2102,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2103,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2104,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2105,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2106,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2107,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2108,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2109,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2110,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2111,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2112,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2113,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2114,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2115,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2116,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2117,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2118,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2119,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2120,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2121,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2122,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2123,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2124,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2125,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2126,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2127,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2128,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2129,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2130,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2131,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2132,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2133,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2134,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2135,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2136,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2137,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2138,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2139,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2140,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2141,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2142,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2143,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2144,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2145,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2146,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2147,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2148,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2149,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2150,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2151,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2152,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2153,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2154,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2155,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2156,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2157,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2158,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2159,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2160,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2161,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2162,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2163,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2164,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2165,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2166,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2167,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2168,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2169,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2170,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2171,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2172,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2173,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2174,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2175,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2176,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2177,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2178,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2179,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2180,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2181,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2182,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2183,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2184,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2185,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2186,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2187,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2188,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2189,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2190,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2191,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2192,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2193,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2194,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2195,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2196,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2197,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2198,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2199,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2200,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2201,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2202,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2203,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2204,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2205,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2206,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2207,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2208,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2209,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2210,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2211,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2212,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2213,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2214,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2215,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2216,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2217,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2218,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2219,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2220,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2221,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2222,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2223,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2224,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2225,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2226,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2227,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2228,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2229,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2230,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2231,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2232,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2233,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2234,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2235,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2236,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2237,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2238,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2239,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2240,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2241,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2242,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2243,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2244,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2245,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2246,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2247,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2248,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2249,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2250,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2251,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2252,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2253,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2254,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2255,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2256,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2257,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 0,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2258,
      "text": "Emotion-Aware Conversational\nRecommender Systems: a Case Study\nAuthor:Maria Stella Albarelli\nStudy Programme:Computer Science Engineering\nAbstract\nIn recent years, especially during the COVID-19 period, online shopping has seen rapid growth, with\nusers increasingly purchasing items through online platforms. Despite this, the online shopping\nexperience still lacks key elements present in physical stores, such as the opportunity to receive\nempathic support and dedicated advice from a professional sales assistant.\nThis study investigates how an empathic Conversational Agent (CA) can transform the online shopping\nexperience by responding to user emotions with empathy and appropriateness, creating a more natural\nand humanized interaction. The research focuses on developing Gala, an emotion-aware virtual\nassistant designed to recommend products from the Galeries Lafayette website. Gala is equipped to\nrecognize users\u2019 emotional states through their voice messages, allowing it to respond empathetically\nbasing on perceived emotions. The work started with a set of semi-structured interviews to analyze user\nneeds and define the core functionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 1,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2259,
      "text": "ctionalities that informed the design of Gala UX and capability. Its\nimplementation used the OpenAI API and the Galeries Lafayette API. The recommendation approach\nfollows a Content-Based methodology. Using Natural Language Processing (NLP), the assistant\ninterprets the user\u2019s requests and searches items in the product catalogue that align with the specified\nattributes, such as name, price, and brand. These features generate a smooth natural dialogue and\nprovide product recommendations. Subsequently, two phases of user testing were conducted: an initial\nusability test to evaluate the system usability, and a second user test to compare a standard CA with\nGala\u2019s emotion-aware version.\nIn conclusion, the results highlight the potential of emotion-aware CAs to enhance online shopping by\nmaking product selection faster and more engaging. This provides a guided experience similar to that in\na physical store.\nKeywords:Human-Computer Interaction, Conversational Recommender System, Emotion\nRecognition, Fashion Shopping Online, Empathy, Speech Processing, NLP.arXiv:2511.18548v1  [cs.HC]  23 Nov 2025\n1\nContents\n1 Introduction 3\n1.1 Problem and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 2,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2260,
      "text": ". . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review 5\n2.1 CRS technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.3 Conversational Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.4 Conversational Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Affective Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Automatic Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.2 Automatic Speech Emotion Recognition . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.3 Adaptive Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.1 Chika: a Virtual Agent for e-commerce . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3.2 Athena . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3.3 Emoty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 3,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2261,
      "text": ". . . . . . . . . . . . . . . . . . . . 12\n3 Design 14\n3.1 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.1 Research Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.2 Online Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1.3 In-store Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 Future Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.1 Idea 1: Fixed Category Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4.2 Idea 2: Open Question Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.4.3 Idea 3: Quiz Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 4,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2262,
      "text": ".5 High Fidelity Prototype: First Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.5.1 Screens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4 Implementation 23\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 OpenAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Back-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.1 Text Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.2 Image Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.3 Voice Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.3.4 Product Recommendation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4 Front-end . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.2 Image Upload . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.3 Vocal Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 5,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2263,
      "text": ". . . . . . . . . . . . . . . . . . . . . 26\n4.5 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5 Empirical Studies 29\n5.1 Usability Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Testing location . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.3 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.4 Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.5 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.1.6 UMUX-Lite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5.2 Evaluation criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.4 High Fidelity Prototype: Second iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Changes from the first iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 6,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2264,
      "text": ". . 35\n5.5 User Test: System Empathy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.1 User Profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.5.2 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.3 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.4 Feedback from users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.5.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Conclusions and Future Works 39\n6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.3 Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3\nChapter 1\nIntroduction\nA Conversational Recommender System (CRS) is a software that supports users providing personalized\nrecommendations through a multi-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 7,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2265,
      "text": "-turn dialogue. One key feature of CRSs is their ability to provide rec-\nommendationstargetedtospecifictasks. Inaddition, theyplayacrucialroleinassistingusersthroughout\nthe decision-making process.\n1.1 Problem and Contribution\nThis project was carried out in collaboration with the French department store Galeries Lafayette1in\nParis, as a part of the internship program I undertook. The general challenge Galeries Lafayette wanted\nto address was to improve the shopping experience of their customer, introducing innovative and engaging\nelements, refining what shopping at their stores could feel like.\nThe solution aimed to address this problem by designing and implementing an intuitive conversational AI\nmodel that could be easy to understand and use. Additionally, the solution must support various forms\nof interaction, such as voice messages and image sharing, to ensure a smooth conversation and allow the\nuser to interact in multiple ways, receiving accurate responses.\nEach week, was defined a list of goals and features to introduce in the project, to reach the final design. At\nthe beginning of the study, various technologies were explored for integration into the assistant\u2019s features,\nincluding the use of stable diffusion to apply catalogue products to different categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 8,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2266,
      "text": "erent categories of models. Virtual\ntry-onwasalsoanalyzedtodeterminewhetheruserscouldappreciatetheabilitytovirtuallytryonclothes\nonline, allowing them to assess the fit and adaptability to their body. Unfortunately, these features were\nnot included in the final result due to time constraints and limited knowledge of the technologies.\nThe final goal was to create an experience where the user can communicate with an assistant that makes\nonline shopping feel as close as possible to the in-store experience.\nThefirstideawastocreateanavatartoassistpeopleduringtheirexperienceinthestore,usingAugmented\nReality (AR) to introduce new engaging ways to interact with the avatar. The purpose of the avatar was\nto guide and give information to users inside the store. In the end, I opted to implement a CRS for online\nshopping due to limited resources and time constraints. I evaluated that a CRS could be more versatile\nand easier to test with real users.\n1.2 Research Question\nGiven the aforementioned scope, I focused on a specific research direction: exploring emotion recognition\nin CRSs to provide context-sensitive recommendations, aiming to create an online shopping experience\nsimilar to the in-store one, with interactions resembling those with real human assistants.\nIndeed, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 9,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2267,
      "text": "d, due to limited studies on empathic recommender agents within the fashion retail sector, I decided\ntofocusonadaptingtheconversationflowandtheassistant\u2019sbehaviourinresponsetotheuser\u2019semotional\nstate. Analyzing the tone of voice in users\u2019 voice messages enables the assistant to interpret emotional\n1https://www.galerieslafayette.com/\nnuances, adapting its conversational approach to align more closely with the users\u2019 current emotional\nstates.\nStudies highlight that empathic behaviours in AI-driven interactions can foster perceptions of trustwor-\nthiness, which is essential for building a relationship between customers and shopping assistants. Trust, in\nturn, can enhance user experience and influence decision-making processes, potentially leading to greater\nuser satisfaction and increased likelihood of purchase.\nFurthermore, relevant research report that emotions can drive purchasing decisions. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 10,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2268,
      "text": "s. This interplay be-\ntweenemotionanddecision-makingunderscorestheimportanceofdesigningRecommenderSystems(RSs)\nthat are not only able to suggest products, but also to engage with users empathetically. This leads to\nthe formulation of the following research question:\nHow does the wording of recommendations change when an emotional component is present? How does\nthis alter the user\u2019s online shopping experience?\n4\n5\nChapter 2\nLiterature Review\nThis section delves into the literature review conducted touching on numerous topics that form the\nfoundation of an emotion-aware conversational shopping assistant. The first part focuses on the keys\ntechnologies, including Conversational Recommender Systems (CRSs), Conversational Agents (CAs) and\nNatural Language Processing (NLP). The second part of the research explores the concept of Affective\nComputing and automatic emotion recognition.\n2.1 CRS technologies\nIn the context of digital commerce, CRSs are transforming the online shopping experience by enabling\npersonalized and assisted interactions. The ability of these systems to integrate recommendations with\nhuman-like conversation offers an alternative to traditional recommendation tools, creating an experience\nsimilar to one with an in-store assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 11,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2269,
      "text": "assistant.\nCRSs combine advanced recommendation algorithms, NLP and CAs\u2019 features to provide context-sensitive\nsuggestions that respond to specific user needs, enhancing the shopping experience.\n2.1.1 Recommender Systems\nA Recommender System (RS) filters and analyzes input data to provide users with hints and suggestions\nabout items that can meet their interests [21]. Different types of input data are required for RSs to\ngenerate recommendations, such asItems Datathat is a list of available items, which is the primary\ninput for any recommender algorithm.Users Datawhich is a list of user attributes, such as gender\nand age, to tailor recommendations to individual preferences.Interaction Datawhich includes insights\ninto user opinions on items through their interactions with the system. Finally,Context Datathat is\na list of attributes related to the context of interactions, determining the appropriate area of interest for\nrecommendations. Examples of contextual attributes are geographical area and day of the week.\nRecommender algorithms are, in turn, classified into two categories:\n\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 12,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2270,
      "text": "\u2022Non-personalized recommendations: Provide the same suggestions to all users, such as trend-\ning movies or music.\n\u2022Personalized recommendations: Offer suited suggestions based on individual user data.\nPersonalized recommendation techniques can be further categorized, the first is the\nContent-Based Filteringtechnique, which provides recommendations based on items that are aligned\nwith user\u2019s preferences, requiring a list of quality attributes for each product. For instance, a garment\ncan be characterized by genre, size, category and colour. Another type of personalized recommendation\ntechnique is theCollaborative Filteringwhich relies on the opinions of a community of users, it\nrecommends what similar customers bought or liked [21]. This latter technique is categorized into:\n\u2022User-Based: Based on users with similar tastes.\n\u2022Item-Based: Based on item similarity according to user opinions.\n\u2022Matrix Factorization and Factorization Machines: Techniques to decompose large user-item\nmatrices into latent factors.\nThen there is theContext-Aware Recommender Systems (CARS)technique that extends col-\nlaborative filtering by incorporating context to improve the quality of recommendations. Lastly, there\nare theHybrid Approachesthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 13,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2271,
      "text": "esthat merge and enhance the capabilities of content, collaborative, and\ncontext-based techniques.\n2.1.2 Natural Language Processing\nA CA tries to replicate human conversations through the use of NLP. It is a specific field of artificial\nintelligence and its goal is to enable computers to understand, interpret, and respond to natural language\nin meaningful ways. It analyzes large amounts of textual data for applications such as speech recognition,\nmachine translation, sentiment analysis, and text generation [34].\nNLP is classified into two parts:\n\u2022Natural Language Understanding (NLU): Allows machine to understand human language by\nextracting concepts, emotions and keywords.\n\u2022Natural Language Generation (NLG): Creates phrases and sentences meaningful for the con-\ntext of use. It happens in three phases: identifying the goals, planning on how goals can be achieved\nand realizing a plan.\nLarge Language Models\nWith the introduction of Large Language Models (LLMs), NLP capabilities have expanded. LLMs use\nadvanced architectures like Transformers and extensive datasets to enhance NLU and NLG performance.\nLLMs represent a sophisticated category of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 14,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2272,
      "text": "of AI systems, characterized by their ability to understand,\ngenerate and interpret human language with exceptional precision. They are trained on massive text\ndata, such as GPT-3 [29] and LLAMA [52].\nLLMs can process and generate language with greater accuracy and contextual awareness, making them\nindispensable in modern NLP applications [58]. The evolution of LLMs has been marked by significant\nmilestones, like the development of the model Generative Pretrained Transformer (GPT), which has had\na lot of improvements in the last years.\nGPT-1[58] was the first model in the series to introduce the Transformer architecture, demonstrating\nhow pre-training on raw text data can improve NLP tasks.\nNext,GPT-2[58] expanded the parameters to 1.5 billion, enabling coherent text generation on varied\ntopics and showcasing the potential of LLMs for unsupervised learning.\nWithGPT-3[57], equipped with 175 billion parameters, new capabilities emerged, such as in-context\nlearning, allowing the model to perform complex tasks without specific training. This model marked a\nmajor leap in application versatility.\nFollowing GPT-3,InstructGPT[58] was trained with human feedback using Reinforcement Learning\nfrom Human Feedback (RLHF), making it more responsive to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 15,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2273,
      "text": "ve to human preferences and values. From\nthis model, ChatGPT [10] was developed, optimized for conversational interactions, and able to handle\nmulti-turn dialogues with structured, coherent responses.\nGPT-4[58] introduced multimodal capabilities, with the ability to understand both text and images,\nfurther improving on complex reasoning tasks and content safety.\nGPT-4 Turbo[58] optimized GPT-4\u2019s performance with extended context and reduced costs, making\nit ideal for scalable, high-efficiency applications.\nFinally, the latest version,GPT-4o[18], is notable for its advanced capability to handle and integrate\nvarious types of data, including text, images, video, and audio. Furthermore, there is the possibility\nto incorporate models that are fine-tuned to meet the specialized demands of specific applications and\nindustries.\n6\n2.1.3 Conversational Agents\nCAs are virtual assistants that communicate using human-like language, to create a more natural dialogue\nwith users. These intelligent systems are based on AI features to understand and react to user requests.\nAlso, CAs exploit NLP and Deep Learning technologies to understand human language [10].\nThe origin of CAs dates back to the middle of the 20th century, when the first chatbot created was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 16,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2274,
      "text": "eated was\nELIZA, developed in the 1960s by Joseph Weizenbaum. ELIZA was a rule-based system that captured\nthe input, rephrased it, and tried to match keywords with a pre-defined set of responses [50].\nWith the arrival of new technologies, like cloud computing and large-scale dataset, new chatbot platforms\nwere introduced, such as ChatGPT [10], which is the OpenAI AI-powered virtual conversational agent,\nintroduced the first time in the November of 2022. ChatGPT generates text based answers using the GPT\nneural network architecture. This architecture is formed by multiple layers of self-attention mechanism\nand learns from a large amount of text data.\nMost of all, the latest version developed by OpenAI, ChatGPT-4o [41], shows significant progress. In\nfact, this latest version generates increasingly coherent and contextually relevant responses, consequently\nimproving human-computer interaction. GPT-4o was trained using the RLHF method. This is a method\nwhere machine learning models are trained using feedback from humans to improve their performance\n[41].\n2.1.4 Conversational Recommender Systems\nA CRS combines recommendation metrics and NLP techniques to provide different types of suggestions,\nbased on the user\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 17,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2275,
      "text": "er\u2019s needs and preferences. In the world of fashion retail a CRS has the function of\nrecommending relevant products and convincing the customer to buy the product, just like a shopping\nassistant [45]. It is worth noting that RSs play an important role in the online shopping field; for instance,\nthey drive up to 35% of Amazon1sales [25].\nCRSs use the main recommendation techniques: Collaborative Filtering, Content-based, Context-Aware\nand Hybrid Approaches (Section 2.1.1). An important feature of CRSs is their capability to create a\nmulti-turn conversational interaction. Unlike the basic digital assistants, which provide one-shot Q&A-\nstyle recommendations, CRSs can respond to recommendation requests, keeping track of the conversation\nhistory and the current state.\nIn fact, the most used CRSs model to gather user preferences is the interactive recommender model,\nwhich emphasizes the continuous interaction between the user and the system to improve the quality of\nrecommendations [45]. The interactive model can be:\n\u2022Utility based: The utility of each item is evaluated using a multi-attribute method, allowing users\nto express their preferences.\n\u2022Dialog based: Uses a natural language based conversation in spoken or typed form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 18,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2276,
      "text": "ped form to collect user\nutterances and create a user profile to better customize recommendations.\n\u2022Critiquing based: Gathers users ratings and critiques about a product to provide hence data-\ndriven.\n\u2022Constraint based: Takes into account user and product constraints to give recommendations that\nmeet those constraints.\nThe performance of RSs is typically evaluated using metrics such as precision, recall, F-measure, RMSE\n(Root Mean Squared Error), and MAE (Mean Absolute Error). Additionally, user-centric evaluation\nframeworks, like ResQue, assess the quality of user experience by measuring factors such as trust, satis-\nfaction, and perceived usefulness [21].\n2.2 Affective Computing\nEmotions are fundamental to human interactions, as they allow us to express our feelings and interpret\nimpulses in our relationships with others. The emotions we experience during a conversation can shape\nits direction, influencing both our words and decisions [36].\n1https://www.amazon.it/\n7\nEmotions can be divided in \u201cprimary\u201d or \u201cbasic\u201d and \u201csecondary\u201d. The term \u201cprimary\u201d emotions refers\nto emotions which are supposed to be innate. They evolved through phylogeny to allow quick, reactive\nresponses to immediate threats. Instead, \u201csecondary\u201d emotions like \u201crelief\u201d or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 19,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2277,
      "text": "or \u201chope\u201d are assumed to\narise from higher cognitive processes, based on an ability to evaluate preferences over outcomes and\nexpectations. For \u201csecondary\u201d emotions are intended \u201cadult\u201d emotions [46].\nIn the 20th century, the psychologist Paul Ekman identifies six basic emotions and he suggested that\nthey were experienced in all human cultures. Since 1996, this set of emotions has been known as the \u201cBig\nSix\u201d, underscoring the significance of his model [19]. The Big Six are: happiness, sadness, fear, disgust,\nanger and surprise [26].\n\u2022Happiness: A pleasant emotion that is characterized by feelings of joy, contentment, gratification,\nsatisfaction and well-being.\n\u2022Sadness: Considered to be one of the basic human emotions and it is a natural response to\nsituations involving psychological, physical or emotional pain or loss of something.\n\u2022Fear: One of the most basic human emotions that can also play an important role in survival. Fear\nhelps to protect us. It makes us alert to danger and prepares us to deal with it.\n\u2022Disgust: Can originate from an unpleasant smell, taste or sight. Researchers believe that this\nemotion evolved as a reaction to foods that might be harmful.\n\u2022Anger: Can be a powerful emotion characterized by feelings of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 20,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2278,
      "text": "of agitation, hostility and frustration.\n\u2022Surprise: It is characterized by a physiological startle response following something unexpected.\nThis type of emotion can be positive, negative, or neutral.\nFrom the concept of Emotion, the concept of Empathy can be derived. Empathy can be defined as\nThe feeling by which one understands and shares another person\u2019s experiences and emotions\n[51].\nEmpathy plays a fundamental role in the user\u2019s experience. The psychologist Baron-Cohen, in particular,\ndistinguishes between cognitive and affective empathy.Cognitive empathyinvolves understanding how\nanother person feels, whereasaffective empathyis an active emotional response to another person\u2019s\nemotional state.\nEmotion-Aware Conversational Recommender Systems can be regarded as a subfield of Affective Com-\nputing, a broader discipline defined by Rosalind Picard in her foundational work, Affective Computing\n(1997) [44] as\nAffective Computing is the study and development of systems and devices that can recognize,\ninterpret, process, and simulate human emotions.\nTo recognize emotions, Emotion-Aware Conversational Recommender Systems employ the process of\nautomatic emotion recognition. This capability allows agents to respond in a proper way, improving\ninteraction quality and fostering a more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 21,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2279,
      "text": "more assisted experience.\n2.2.1 Automatic Emotion Recognition\nInformation about a person\u2019s emotions can be gathered from various cues, such as tone of voice, facial\nexpressions, gestures, and posture.\nInitially, Paul Ekman concentrated specifically on emotions that were expressed by humans through facial\nexpressions [27]. However, his research was easily expanded to include other communication channels.\nSubsequently, he investigated the recognition of the Big Six through vocal expressions [48].\nStudies indicate that, according to [17], voice intonation is responsible for about85%of the message\nperception in verbal information transmission, while actual words account just for the15%. For this\nreason, I chose to focus exclusively on vocal tone, as it provides the ability to express and to understand\ninformation not openly communicated as factual content.\nI examined the content of the speech in term of meaning, the prosody of the speech, and the sentiment\nof the sentences of the speech to understand the affective state of the user. Voice detection is also a\n8\nnon-intrusive method for real-time emotion detection, which only requires users to send voice messages\nthrough the microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 22,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2280,
      "text": "he microphone of the device.\nMoreover, recentadvancementsinmachinelearningandNLPhaveledtothedevelopmentofsophisticated\nmodels capable of detecting and interpreting emotional cues from text and speech.\nSpeech Emotional Corpora\nEnabling the recognition of specific emotions requires specialized datasets to train the system effectively.\nEmotional corpora, which are collections of affective materials such as audio recordings, are essential for\nthis purpose. The quality of an emotional corpus is evident in the communicative effectiveness of its\nsamples, which can significantly influence research outcomes across various fields. Thus, selecting and\ndeveloping high-quality corpora is essential to avoid drawing incorrect conclusions.\nAccording to the literature [1, 9, 31], speech emotional corpora are defined by specific characteristics that\nmake them more effective for certain tasks over others.\n\u2022They can include audio recordings with monolingual or multilingual sentences.\n\u2022They can collect different sets of emotions (e.g., the Big Six emotions).\n\u2022They can contain (or not) audio recordings uniformly distributed over emotions.\n\u2022They can include (or not) audio recordings with a set of phrases uniformly verbalized with different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 23,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2281,
      "text": "ith different\nemotions.\n\u2022They can be obtained through professional or amateurish recording tools.\n\u2022They can include speech recorded in a fully-setup environment without any noise or in a wild\nsetting.\n\u2022They can contain additional information about the context where speech was recorded, including a\ndescription of the situation (e.g., conversational context) or other complementary communication\nchannels (e.g., video).\n\u2022They can collect audio recordings with simulated, induced, or natural emotions.\n\u2022They can contain audio recordings by professional or semi-professional actors or a generic audience\nwith no acting experience.\nAdditionally, corpora can include varying numbers of actors with different ages and genders. Most\ncorpora focus on categorical emotions, particularly the Big Six, but different, authors took into account\n\u201cneutrality\u201d as an supplementary emotional state [7, 8, 20, 28]. It is also common to find the same\nsentences expressed in different tones of voice [7, 20, 54]. This approach aims to base emotion recognition\nsolely on the emotional content of the speech, independent of its lexical elements.\nSome of the most famous emotional corpora are:\n\u2022DES: A Danish-language dataset representing anger, joy, neutrality, sadness and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7]."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 24,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2282,
      "text": "and surprise [28].\n\u2022SAVEE: An English-language dataset representing the Big Six emotions plus neutrality [54].\n\u2022EMO DB: A German-language dataset representing the Big Six emotions plus neutrality [7].\n\u2022EMOVO: An Italian-language dataset representing the Big Six emotions plus neutrality [20].\n\u2022Emozionalmente: An Italian-language dataset capturing the Big Six emotions, along with neu-\ntrality. This dataset was developed by Fabio Catania as part of his PhD research at Politecnico di\nMilano [12]. This dataset serves as the emotional corpus used for this project.\n2.2.2 Automatic Speech Emotion Recognition\nAutomatic Speech Emotion Recognition (SER) is an AI technology designed to detect and identify emo-\ntions expressed through spoken language. It is commonly approached as a classification task, rooted\nin the foundational theories of categorical emotion models. By analyzing tone, rhythm, volume, pitch,\nand other vocal characteristics, SER uses machine learning algorithms and neural networks to infer the\nspeaker\u2019s emotional state [14].\n9\nThe process of SER, shown in figure??, is divided inaudio pre-processing,audio representation\nandaudio classification. The initial step, which involves the collection of speech samples, includes\nvarious audio cleaning processes, such as noise reduction and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 25,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2283,
      "text": "on and normalization, to eliminate unwanted noise\nfrom the recording [13].\nConsider an audio file that includes both the primary sound, such as a voice, and background noise,\nsuch as the hum of a fan. The signal spectrum reflects the entire sound, capturing all frequencies and\nintensities, whereas the noise spectrum isolates just the background noise. To reduce this noise, an\naverage of the noise spectrum is calculated and then subtracted from the signal spectrum. This process\nsuppresses the noise within the signal, ideally leaving the main sound intact. Although this technique is\nnot flawless, it significantly improves clarity by reducing background interference.\nDuring the part of audio representation it is possible to use two types of features:prosodic features\nandspectral features[14].\nProsodic features focus on how words are spoken, considering elements like rhythm, pitch, and pauses,\nwhich can help identify basic emotions in speech [12]. Spectral features involve transforming the speech\nsignaltoanalyzeitsfrequencycomponents. AnexampleisMel-FrequencyCepstralCoefficients(MFCCs),\nwhich provide insights into the \u201cpower\u201d of vocal sounds over brief time segments. These features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 26,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2284,
      "text": "hese features are also\nhighly effective in identifying emotions within spoken language [35].\nOnce the features have been extracted, machine learning algorithms are employed to classify the emo-\ntions. Various models, including Support Vector Machines (SVMs) [53], Deep Neural Networks (DNNs)\n[49], and Convolutional Neural Networks (CNNs) [42], are trained on these features to differentiate among\nemotional states. Each model type offers distinct advantages in terms of accuracy and processing effi-\nciency.\nFigure 2.1: The various steps that constitute a Speech Emotion Recognition system\nFinally, the performance evaluation of a SER system relies on standard classification metrics such as ac-\ncuracy, precision, recall, and F1-score. Accuracy provides an overall measure of the system\u2019s correctness,\nwhile precision and recall help to assess the model\u2019s ability to make correct predictions and retrieve rele-\nvant emotions, with the F1-score balancing these two aspects. Additionally, cross-validation techniques,\nlike k-fold or leave-one-out cross-validation, are used to prevent overfitting, averaging performance across\nmultiple validation sets. Together, these tools provide a comprehensive view of the SER system\u2019s validity\nand reliability [14].\n2.2.3 Adaptive Response\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 27,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2285,
      "text": "sponse\nOnce an emotion is recognized, the virtual agent must determine an appropriate response. It is essential\nto definecopingas the way a person responds to the significance they assign to an event. People\nare motivated to respond differently based on how they perceive and evaluate the event\u2019s importance.\nFor example, events perceived as undesirable but controllable motivate people to create and implement\nplans to change the situation. In contrast, events viewed as uncontrollable often lead individuals toward\navoidance or resignation [54, 40].\nIt is possible to define two different strategies of coping:problem-focused copingandemotion-\nfocused coping[40]. In the case of problem-focused coping, a person tries to address the cause of the\nstress or problem directly. The goal is to change the situation to resolve or improve it. For example, if a\ntest is causing stress, a problem-focused coping strategy might be to study more or take a support class.\n10\nIn fact, if the problem is controllable, problem-focused coping is more useful because it aims to solve the\nsource of the stress.\nIn the case of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 28,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2286,
      "text": "e of emotion-focused coping, instead, the person focuses on managing their emotions rather than\ntackling the root of the problem, especially if they feel the problem is uncontrollable or unchangeable.\nFor example, if someone misses out on an opportunity, an emotion-focused coping strategy could involve\nre-evaluating the situation by telling themselves that there will be other opportunities in the future. If\nthe problem is perceived as beyond the person\u2019s control, emotion-focused coping is preferable, as it helps\nto manage the emotional impact without trying to change external reality.\nThe literature [43] suggests setting specific empathic goals to guide responses when a particular emotion\nis recognized in the user\u2019s behaviour, helping to determine how the system should act accordingly. Some\nof the goals are:\n\u2022Console: By making the user feel loved and understood.\n\u2022Encourage: By providing comments or motivations.\n\u2022Congratulate: By providing positive feedback on the user\u2019s behaviour.\n\u2022Joke: By doing some humor in order to improve the user\u2019s attitude.\n\u2022Calm down: By providing comments and suggestions to make the user feel more relaxed.\nFurthermore, the paper [40] provides descriptions of several coping strategies that virtual agents might\nemploy:\n\u2022Planning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 29,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2287,
      "text": "lanning: This involves creating a plan to overcome or manage the stressor, such as developing\na step-by-step solution. This approach is closely tied to goal achievement and effective problem-\nsolving.\n\u2022Positive Reinterpretation: This approach involves searching for positive aspects or identifying\na \u201csilver line\u201d in a stressful situation. It involves reinterpreting the event to emphasize potential\nbenefits or opportunities for growth and learning.\n\u2022Acceptance: A strategy used when the individual recognizes that a situation is unchangeable. It\ninvolves accepting the reality of the event, reducing the emotional impact by removing the pressure\nto change it.\n\u2022Seeking Social Support: Engage in others for emotional or instrumental support, which may\ninclude desire advice, moral support, or sympathy.\n\u2022Denial/Wishful Thinking: Avoiding the reality of the situation or believing that things will\nimprove without concrete evidence.\n\u2022Mental Disengagement: Distracting oneself or detaching mentally from the stressor, often used\nwhen avoidance is needed temporarily to cope with overwhelming emotions.\n2.3 Related Works\nThis section provides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 30,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2288,
      "text": "ovides an overview and analysis of existing Conversational Recommender Systems em-\nployed in the fashion world as shopping assistants, but also an emotion-aware conversational agent called\nEmoty.\n2.3.1 Chika: a Virtual Agent for e-commerce\nAn example of an existing project in the field of chatbots that recommend fashion products is the Virtual\nAgent (VA) Chika [3] implemented in Shopee\u2019s e-commerce platform. This VA is designed to enhance\nthe user experience by addressing common issues such as the cold start problem, data privacy concerns\n[5, 15, 16], and lack of social presence in online shopping environments [30]. Chika interacts with users\nin a conversational manner, helping them to find products, promotions, and similar items based on their\npreferences [3].\nThe VA project employs a User-Centered Design (UCD) methodology combined with a Natural Conver-\nsational Framework. The UCD approach ensures that the design process focuses on user needs at every\n11\nstage, from understanding the context of use to specifying user requirements, creating design solutions,\nand evaluating the outcomes. The Natural Conversational Framework helps in designing the interaction\nbetween the VA and users, making the conversations more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 31,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2289,
      "text": "more natural and seamless [3].\nDespite this, Chika does not allow users to engage in various forms of interaction, such as sending images\nor exchanging voice messages, relying solely on text messages. This limitation could reduce engagement\nand the natural flow of conversation.\n2.3.2 Athena\nAthena [47] combines a Recommender System with a Fashion-Knowledgeable Component (FKC) into a\nchatbot. The objective of the project is to provide an real shopping experience through online service.\nAthena\u2019s RS uses the product inventory of the e-commerce site while its FKC uses fashion information\ncollected from social media, models\u2019 photographs and stylists\u2019 curation of fashion items. The recommen-\ndation systems comes from an ensemble of deep learning based on collaborative filtering recommendations\nand provide products based on user requests and preferences. The fashion component comes from a deep\nlearning model which can learn how to properly match products from the inventory. The system has a\nweb-based front-end and Athena is the Conversational Agent.\nAthena prepares the questions based on the \u201cNext Best Attribute\u201d, which is a prediction component that\ndecides the best next question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 32,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2290,
      "text": "question, in order to gather a set of products using the fewest number of questions\n[47].\nAthena presents a series of consecutive closed-ended questions to guide users toward a final recommen-\ndation. However, this approach restricts the user\u2019s freedom in asking questions and limits the flow of\nconversation, hindering the natural and fluid interaction that was a key objective of the Galeries Lafayette\nproject. Additionally, Athena does not allow users to explore or use various interaction modes, such as\nvoice messages or the ability to send images.\n2.3.3 Emoty\nEmoty is a CA specifically developed for the Italian language, aimed at improving the communication\nabilities of individuals with Neurodevelopmental Disorders (NDD), particularly in expressing emotions\nthrough speech [11]. Described in depth in Fabio Catania\u2019s paper, \u201cDesigning and Engineering Emotion-\nawareConversationalAgentstoSupportPersonswithNeuro-DevelopmentalDisorders\u201d [11], Emotyexem-\nplifies a sophisticated approach to designing Conversational Agents that are attuned to users\u2019 emotional\nstates and capable of facilitating meaningful interactions, improving quality of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 33,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2291,
      "text": "of life for people with NDD.\nFigure 2.2: The logo of Emoty [11]\nTheprimaryobjectiveofEmotyistousevoiceasthemainmodeofinteractiontobridgetheconversational\ngap often encountered by individuals with NDD. By doing so, it allows users to communicate emotions\nmore naturally and seamlessly, a process that is often challenging for this group due to various barriers\nin emotional expression and recognition. The system is engineered to detect subtle changes in speech\npatterns that indicate the user\u2019s emotional state, creating a supportive platform for both expressing and\nunderstanding emotions.\nIn this thesis, Emoty serves as a central tool for identifying emotional cues within speech. Through\nthe use of the Emoty API, I aim to gain a deeper understanding of how users convey emotions through\n12\ntheir voice. Understanding these emotional nuances is essential for implementing CAs that can respond\nempathetically, allowing users to feel understood and heard. This approach not only enhances the quality\nof the interaction with the assistant but also enables the agent to better address users\u2019 specific needs,\nfostering a more meaningful and responsive dialogue.\n13\n14\nChapter 3\nDesign\nThe project design includes different phases to identify user needs and define a proper design to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 34,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2292,
      "text": "to cover\nthese needs. Some of the methods used were learned during the Design of Interactive Systems course and\nothers developed in collaboration with the User Research team at Galeries Lafayette.\n3.1 Research Questions\nThe first approach follows one of the Professor Wendy Mackay\u2019s methods used to design interactive sys-\ntems [39], that is story interviews. I decided to use semi-structured interviews instead of story interviews\nbecause, in this case, I needed to collect data that would be comparable across different users and follow\na fixed structure, without excluding follow-up questions if it was necessary to explore a certain topic. For\nthis project 23 semi-structured interviews were conducted: 12 online and 11 in-store.\n3.1.1 Research Goals\nTheobjectivesoutlinedfortheseinterviewsweredifferent, firstandforemosttounderstanduserneedsand\nproblems during their shopping online and in the store. The second was to understand why people decide\nto visit the website or the store and the third was to observe the knowledge level of new technologies.\n3.1.2 Online Interviews\nThe online interviews were conducted from the office using Google Meet application to organize video\ncalls with acquaintances and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 35,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2293,
      "text": "and friends outside the company.\nFor these interviews were prepared six questions:\n1. How old are you?\n2. Where are you from?\n3. What are the top 3 shopping website that you visit the most and why?\n4. All right, could you tell me about any recent difficulties you encountered during your visit to the\nwebsite?\n5. In the past month, what factors influenced your purchasing decisions when shopping online?\n6. What would be your ideal assistant to have on the website to help you during your shopping online?\nQuestion 1 and 2 are background questions to know about the user age and nationality. Question 3 was\nasked to understand which online shopping websites best meets users\u2019 needs and why. Question 4 is to\ninvestigate on the recent difficulties users have encountered while visiting the Galeries Lafayette website.\nQuestion 5 is to understand what are the product factors that most influence their purchase, therefore\nto understand if there was any discrepancy between the preferred factors and those already present on\nthe Galeries Lafayette website. These last questions ask the user to remind aboutrecentmemories they\ncan remember, as recommended by the Design of Interactive Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 36,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2294,
      "text": "Systems [39]. The 6th and last question\naims to discover what knowledge people have about new technology possibilities, and whether they would\npropose innovative ideas about personal assistants.\n3.1.3 In-store Interviews\nThe in-store interviews were conducted in the Galeries Lafayette Haussmann store, and one of my col-\nleagues from the user research team collaborated with me. The partecipants were both French and\nforeigners strangers. During interviews with French people my colleague was the interviewer and I was\nthe notetaker, instead during interviews with foreigners I was the interviewer and she was the notetaker\n[4]. I decided to conduct interviews in the store to closely interact with people who frequently visit\nGaleries Lafayette and understand user needs within the store and how a personal assistant could solve\ntheir problems.\nThe six questions included:\n1. How old are you?\n2. Where are you from?\n3. What brought you here today?\n4. All right, could you tell me about any recent difficulties you encountered today or during past visits\nto the shop?\n5. In the past month, what factors influenced your purchasing decisions when shopping in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 37,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2295,
      "text": "g in a store?\n6. What would be your ideal assistant to have in-store to help you during your shopping?\nSome questions are repeated from those asked online and others were adapted to the store context.\nQuestion 3 is to understand what users are looking for the most when the visit the store and also to\nintercepts if they are having problems in finding it and why.\n3.2 User Profile\nThe target of users I decided to address included:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u20228 Males and 15 females.\nI chose these groups of people because Galeries Lafayette is one of the most important and emblematic\ndepartment stores in French culture, as well as globally. I opted to target people between 20 and 65 years\nold to focus on age groups typically more familiar with new technologies.\n3.3 Data Analysis\nTo analyze the data collected from the interviews I divided each answer in three categories and I applied\n3 post-it to each interview transcription to represent the categories: one red representing the difficulties\nfound visiting the shop/store, one green representing the purchase factors and the yellow to represent the\nideal assistant.\nAfter collecting each post-it, I divided them into website answers and in-store answers. After this I\ngrouped each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 38,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2296,
      "text": "d each of them into the three main categories: difficulties, purchase factors and ideal assistants.\nThen I counted the number of people reporting that answer and kept the most frequent quotes.\n15\n3.3.1 Results\nFollowing the data analysis, the results allowed me to identify the main user needs, reporting some user\nquotes:\n\u2022The user needs recommendations based on their activity and preferences.\n\u201cI would like to have a personal shopper, that can tell me what to buy based on my morphology\nand preferences\u201d- Woman, 57 years old\n\u201cThe assistant should tell me what to choose based on what I prefer\u201d- Man, 24 years old\n\u2022The user needs recommendations on products that match the one they selected.\n\u201cIt would be nice to upload a photo of something I like and have it suggest similar alternatives\u201d\n- Woman, 24 years old\n\u201cI would like it to guide me from one product to another to complete the outfit\u201d- Man, 25 years old\n\u2022The user needs to have information on the prices of products.\n\u201cThe price is the first thing I look at when deciding on a product. I use an initial filter for the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 39,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2297,
      "text": "r the\nprice and then pay close attention to the product reviews\u201d- Man, 24 years old\n\u201cPrice is crucial in deciding what to buy\u201d- Man, 29 years old\n\u2022The user needs to have clear directions in the store.\n\u201cI want someone that guides me in the store\u201d- Man, 30 years old\n\u201cI would like to have someone who asks questions to know where to find things in the store\u201d-\nWoman, 22 years old\nIt is important to note that 4 out of the 11 people interviewed in-store responded that they did not need\nan assistant for the shopping in-store, and also 4 people stated that did not encounter any difficulties\nwithin the store. Instead, 8 people out of the 12 people interviewed online responded that they want an\nassistant proposing them different products based on their preferences. For this reason, I have decided\nto focus more on a personal assistant just for online shopping and, therefore, I will not consider the last\nneed listed for now, because it is closely tied to the in-store shopping experience.\n3.4 Future Scenario\nAs a result of the previous analysis methods I generated three future scenarios for the three different\npersonal assistants created.\n3.4.1 Idea 1: Fixed Category Assistant\nThe first idea, includes an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 40,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2298,
      "text": "des an assistant that can provide recommendations mainly based on two user needs:\n\u2022To receive a list of products with different price range.\n\u2022To receive a list of matched products to the selected one.\nTo do that the user has to interact with the assistant by visiting a specific product page on the Galeries\nLafayette website and click on a button called \u201cAdvise Me\u201d. This button will automatically send the\nproduct to the assistant and start the conversation. Consequently, the assistant provides two possibilities:\n\u201cPropose with different price\u201d and \u201cFind matching products\u201d. By clicking on the first choice the user will\nreceive a series of product cards with similar products but with different price ranges. By clicking on the\nsecond choice the user will receive a list of product card with different typologies of products that can be\nmatched with the original one. The assistant should also answer to other user questions entered in the\ntext area.\n16\nTheentrypointforthisassistantisineachspecificproductpage, soasuserscaninteractwiththeassistant\nonly entering at first a product in the conversation. This allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 41,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2299,
      "text": "his allows users to be aware of the capabilities of\nthe assistant and makes it easier for them to interact with the assistant. The draft is shown in figure 3.1.\nFigure 3.1: Future Scenario Idea 1\n3.4.2 Idea 2: Open Question Assistant\nThe second idea includes an assistant able to respond to any type of open question, but the assistant\nwill be always based on the Galeries Lafayette website and catalogue. This assistant will allow a more\nfriendly conversation, where users feel understood and listened, as if they were speaking with a real shop\nassistant. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is placed in navigation bar, that is always present during the\nnavigation on the application. For this reason the user would be able to talk with the assistant at any\ntime and start the conversation as needed. To cover these tasks the assistant should retrieve information\nfrom the user actions and past purchases on the application. Also it extracts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 42,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2300,
      "text": "acts the data from the text and\nimages sent by the user. The assistant should also remember the user at every started chat. The draft is\nshown in figure 3.2.\n17\nFigure 3.2: Future Scenario Idea 2\n3.4.3 Idea 3: Quiz Assistant\nThe third idea, involves an assistant that creates daily quizzes to gather new information about the user\nand provide always new and accurate recommendations. In return, the user will receive promotions. The\nassistant works similarly to the one in Idea 2, with open-ended questions. Additionally, when a quiz\nis available, the user receives a notification. This approach enables the assistant to offer more specific\nrecommendations and fosters greater engagement and curiosity, encouraging the user to interact with the\nsystem. This idea covers the user need of:\n\u2022Receiving a list of products with different price range.\n\u2022Receiving a list of matched products to the selected one.\n\u2022Receiving a list of products based on their preferences.\nThe entry point to start the conversation is always part of the navigation bar of the application. In order\nto complete these tasks the assistant needs to remember all previous chats and quizzes with the user to\ncreate new and varied ones each day. The quiz idea is inspired by Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 43,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2301,
      "text": "Duolingo1, an educational application\nthat uses daily quizzes to help users learn a new language. The draft is shown in figure 3.3.\n1https://it.duolingo.com/\n18\nFigure 3.3: Future Scenario Idea 3\n3.4.4 Conclusions\nAnalyzing the three ideas it is possible to notice that the last two covers all the main three user needs,\ninstead the first idea covers just two user needs. The third idea incorporated gamification to increase\nengagement and attract users to interact with the assistant. However, it might also be disruptive and\nfrustrating due to daily notifications and quizzes.\nAfter weighing the pros and cons of each idea, I decided to focus on the second one. This approach allows\nfor open conversation, enabling users to ask questions more freely and receive a variety of advice, making\nthem feel as if they are talking to a real shopping assistant in the shop.\n3.5 High Fidelity Prototype: First Iteration\nThis section presents the first draft of the High Fidelity Prototype, create by myself and the Galeries\nLafayette product design team using the Figma application. The design is minimalistic and adheres\nto the visual style of the Galeries Lafayette website. This prototype was primarily used to test basic\nfunctionalities and accessibility through a usability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 44,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2302,
      "text": "sability test (Shown here 5.1). Consequently, some aspects of\nthe design were not fully defined and structured.\n3.5.1 Screens\nThe screens represents the design of the main functionalities implemented. The design is based on the\nGaleries Lafayette design system, from which I retrieved every icon and style. The design is simple\nand intuitive to let the user understand the meaning of each component. The main functions are chat\nmessaging, image uploading and voice recording.\n19\nChat Messaging\nThis part represents the types of messages exchanged in the chat between the user and the assistant. The\nchat can contain only text or also products, depending on whether the user has requested recommenda-\ntions or not.\nThe starting screen of the assistant is represented in the picture 3.4 and it is possible to notice that the\nbutton on the bottom right is a microphone. Consequentially, if the user starts typing something in the\ntext area, the icon in the bottom right becomes a paper plane that means that the user can send the\nmessage. Notice that the paper plane icon is active only when the user types something or if the user\nuploads an image.\nIf the user asks for more than one product or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 45,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2303,
      "text": "ct or a generic product without specifying the number, the\nassistant answers with a message that, if the user clicks on the picture, directs to a page of the website\nwith a list of products.\nFigure 3.4: Typing a message (left); Asking for more products (center); Website generic product page\n(right)\nIf the user asks for just one product the assistant answers with a message that, if the user clicks on the\npicture, directs to the specific product page.\n20\nFigure 3.5: Asking for one product\nFigure 3.6: Product page on the Galeries\nLafayette website\nImage Uploading\nIn this part is shown how the user can upload an image in the chat, to find similar products to the one\nuploaded.\nClicking on the image icon in the bottom left part of the screen, it is possible to upload an image from\nthe device. The image preview is shown in the text area and the user can delete it or send it.\nOnce the image is sent, it will be displayed in the chat and the user will see an ellipsis indicating that\nthe assistant is processing and formulating a response. The ellipsis is shown every time a message is sent\nin chat from the user.\nThe assistant will send a list of products that are visually similar to the one sent by the user, and as\nbefore, if the user clicks on the picture, it will be directed to the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 46,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2304,
      "text": "the specific product page.\nIn this prototype, I did not implement the ability to add text along with the uploaded image. When an\nimage is sent, the system automatically searches for similar products. This is because image recognition is\nhandledbyaseparateneuralnetworkthatfindssimilarproducts, notbytheOpenAIassistant. Therefore,\nif the user included a text message with the image, the assistant would not be able to process other types\nof queries effectively.\nVoice Recording\nThis section explains how users can use voice recording to send messages in the chat.\nTo activate voice recording, the user must press and hold the microphone icon located at the bottom\nright of the screen. While holding the button, the user can dictate the message. Releasing the button\nwill send the message (Figure 3.7).\nOnce the button is released, the message is transcribed directly into the chat (Process described here\n4.3.3), and the assistant answers with a voice message. This voice message is also transcribed into text\nwithin the chat (Figure 3.8).\n21\nFigure 3.7: Voice Recording\nFigure 3.8: Transcription of audio in the chat\nEnabling voice messages allows users to easily send messages when they cannot use their keyboard to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 47,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2305,
      "text": "to\ntype. Also, transcribing voice messages ensures clear communication, especially in noisy environments\nwhere users may not be able to listen to the audio properly.\n22\n23\nChapter 4\nImplementation\n4.1 Introduction\nGala\u2019s user experience is built around a web-based front-end, to ensure scalability and adaptability to\ndifferent devices.\nGala\u2019s architecture relies on a powerful back-end to interpret user input. Through the use of NLP,\nthe assistant analyzes the user\u2019s requests and generates product recommendations, based on specified\ncharacteristics, while using an emotionally responsive language.\nThe back-end exploits the OpenAI API to create an assistant capable of answering any type of question\nreferring to a specific contest. Additionally, the back-end manages data retrieval using the Galeries\nLafayette API and the Emoty API for emotion recognition. These integrations enable Gala to access\nrelevant product information and identify user emotions.\nThis coordinated front-end and back-end design ensures that Gala provides an engaging, empathic shop-\nping experience dedicated to each user\u2019s emotional states.\n4.2 OpenAI\nOpenAI is an artificial intelligence-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 48,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2306,
      "text": "nce-focused company founded in 2015. One of the key products of OpenAI\ninclude ChatGPT, which is an advanced Large Language Model (LLM), using the Generative Pretrained\nTransformer (GPT) architecture. This model has great NLP capabilities and excels in creating engaging\nconversations with users, answering generic questions, executing instructions and many other functional-\nities [56].\nFor this project has been used all the documentation present on OpenAI Playground, which is a web-\nbased platform that enables users to create and interact with personal assistants directly on the platform,\nwithout the need to develop a separate interface. However, in my case, I had to create a new interface\nfor the store, therefore, I used the API and developed my web-application.\nGala is an OpenAI assistant that has instructions and can use models, tools, and files to respond to user\nqueries. The assistants API currently supports three types of tools: Code Interpreter, File Search, and\nFunction calling. Gala uses the File Search1tool, that allows her to access and search within the files I\nprovide.\nAdditionally, the platform allows to train assistants and to use the latest language models, such as\nGPT-4o, which is the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 49,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2307,
      "text": "the one that I used for the project.\n1https://platform.openai.com/docs/assistants/tools/file-search\n4.3 Back-end\nThe back-end is implemented using Express2and Node.js3. Express, a framework for Node.js, handles\ntheserverlogic, routesandAPIs, enablingefficientmanagementofHTTPrequestsandresponses. Node.js\nprovides the runtime environment for executing server code using JavaScript.\nThe main functions managed in the back-end are text message handling, image handling, voice message\nhandling, and product recommendation.\n4.3.1 Text Message Handling\nIn the back-end setup, user messages are processed using the OpenAI API, which facilitates the conversa-\ntional flow. At the first run of the application, the methodopenai.beta.threads.create()is called to\ninitialize a new message thread. This function generates a unique thread ID for the conversation, which\nis then retained throughout all user interactions.\nBy retaining this thread ID, each new message from the user is appended to the existing thread using\ntheopenai.beta.threads.messages.create()method, specifying the corresponding thread ID. This\nprocess preserves the conversational context, allowing the assistant to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 50,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2308,
      "text": "t to generate responses that consider\nthe whole history of interactions. Finally, the assistant\u2019s response is sent to the front-end, ensuring\ncontinuity and relevance throughout the conversation.\n4.3.2 Image Handling\nThe user can upload an image from his/her device to search for similar products on the Galeries Lafayette\nwebsite. The front-end sends the image to the back-end, which calls a Python script that uses a metric\ncalled Learned Perceptual Image Patch Similarity (LPIPS) [32].\nLPIPS measures perceptual similarity between two images. Unlike pixel-per-pixel difference metrics,\nLPIPS uses a pre-trained neural network to evaluate similarity in a perceived feature space [2].\nLPIPS assigns a similarity score where lower values indicate a higher resemblance between images. When\nthe neural network identifies the closest match, it sends this result to the back-end, which retrieves\nproduct details and searches for related items before forwarding these suggestions to the front-end.\n4.3.3 Voice Message Handling\nWhen the user decides to record a vocal message through the device\u2019s microphone, the raw audio is\nprocessed into a .wav format using .ffmpeg, which prepares it for accurate transcription by OpenAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 51,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2309,
      "text": "nAI\nWhisper API4.\nWhisper transcribes the voice input into text, allowing Gala to interpret and generate a relevant response.\nThis response generation relies on the OpenAIopenai.beta.threads.messages.create()function,\nwhich updates the conversation thread by adding each user message and calculating the assistant\u2019s re-\nsponse based on previous interactions.\nThis generated response text is then sent to the OpenAI text-to-speech endpoint5, where the \u201cNova\u201d6\nvoice model converts it into spoken output in .mp3 format. The assistant\u2019s voice response, in turn, is\nplayed through the device\u2019s speakers, allowing the conversation to flow naturally in real-time, bridging\nuser input and assistant feedback effectively.\nThis seamless integration of Whisper\u2019s transcription, threaded response generation, and high-quality\nspeech synthesis creates a fluid conversational experience for users.\nEmotion Recognition\nAfter the user\u2019s message is recorded and converted into .wav format, the Emoty API (Section 2.3.3)\nendpoint is then accessed, where the audio data is sent in JSON format, including language specification,\n2https://expressjs.com/\n3https://nodejs.org/en\n4https://api.openai.com/v1/audio/transcriptions\n5https://api.openai.com/v1/audio/speech\n6https://platform.openai.com/docs/guides/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2)."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 52,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2310,
      "text": "des/text-to-speech\n24\nand service parameters for the emotion analysis engine. Upon receiving the API response, the dominant\nemotion is extracted and identified from the Big Six emotions (Section 2.2). If the highest-scoring\nemotion surpasses a specified threshold of 0.5, this emotion label is returned as the primary emotional\nstate detected in the user\u2019s voice. If no significant emotion is detected, a \u201cneutrality\u201d label is returned,\nallowing the assistant to either maintain a neutral tone.\nOnce the emotion label is identified, the system references a predefined prompt that specifies response\nbehaviours for each emotion type. Based on the detected emotion, this prompt provides instructions\non tone, language, and interaction style, guiding the assistant\u2019s response to be appropriately empathic\n(Figure 4.5).\n4.3.4 Product Recommendation\nIn the Gala assistant\u2019s back-end, product recommendation starts by retrieving data from the Galeries\nLafayette API with a function that gathers details like product name, image, price, and URL. These\ndata are saved in a JSON file to ensure consistent formatting. The JSON file is then stored in a vector\nlinked to the assistant, with thefile_searchfeature activated to enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 53,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2311,
      "text": "enable product searching within the\nfile. When a user requests recommendations, the assistant searches products based on the user\u2019s criteria\nand formats matching results into a structured JSON array.\nThis JSON format is further divided into three sections for a structured user response: anintro text\nto introduce the product suggestions, thecentral JSON product listcontaining the selected items,\nand anoutro textthat invites further interaction, such as asking if the user needs more suggestions.\nThis structured approach ensures a polished, professional product recommendation, with each part of the\nresponse reinforcing user engagement.\n4.4 Front-end\nThe front-end is implemented using React7, which is an open-source JavaScript library used for building\nuser interface. The front-end handles the user interface and the user interaction using also HTML and\nCSS.\nThe web-application is designed to be responsive, meaning it adapts seamlessly to different screen sizes\nanddevices. Thisimprovesuserexperienceandensurestheweb-applicationisaccessibletousersaccessing\nit from various devices, including desktops, tablets, and mobile phones.\nThe front-end constructs the web-application\u2019s interface, which includes components for chat, voice input\nand image upload.\n4.4.1 Chat\nThe chat interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 54,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2312,
      "text": "interface features the Gala icon alongside the assistant\u2019s profile image and name. Each message\nfrom the assistant is displayed in grey, contrasting with the user\u2019s messages, which are in a blue tone.\nThese colours are derived from the Galeries Lafayette design system. When the user clicks on the text\narea, they can type a message and send it by pressing theEnterbutton or clicking the paper plane icon.\nEach time the user begins typing, the microphone icon switches to a paper plane to indicate that the\nmessage can be sent. If the user sends a text message, they cannot send a voice message or an image\nsimultaneously. Similarly, if an image is uploaded, it is not possible to send a voice message or type\na message. Once a message is sent, the interface displays an ellipsis to indicate that the assistant is\nprocessing the response (Section 3.5.1).\n4.4.2 Image Upload\nThe image upload is allowed by the click on the image icon on the bottom-left part of the screen, the\nuser can choose which image upload from the gallery (just images allowed) and then the user will see the\nimage uploaded in the text area. The image preview presents an \u201cX\u201d icon to delete the image uploaded\nand upload a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 55,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2313,
      "text": "a new one. Once the user clicks on the paper plane icon, the image is sent in the chat. The\nassistant will answer sending a list of similar products (Section??)\n7https://it.legacy.reactjs.org/\n25\n4.4.3 Vocal Input\nTo use voice input, the user clicks the microphone icon, which opens a dedicated voice recording page,\ncalledVoicePage, where the assistant listens for input. On this page, the recording process is initiated\nby astartRecordingfunction, automatically activated upon loading. The recording status is displayed,\nand an animated visual indicator reflects whether the assistant is activelylisteningorspeaking.\nThe user can stop recording using the stop button, triggering thehandleStopRecordingfunction, which\nprocesses and transcribes the audio. The transcribed text is then sent to the main app using the\nonTranscriptioncallback, allowing for a seamless transition between user speech and the assistant\u2019s\nresponse.\nTheVoicePagecomponentdynamicallyadjustsbasedonisRecordingandisProcessingstates,showing\neither a \u201cListening...\u201d or \u201cProcessing...\u201d indicator. When recording is complete, the assistant\u2019s audio\noutput is queued to play and transcriptions are rendered in chat.\nThe page can be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 56,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2314,
      "text": "be closed anytime via the close button, which returns the user to the main chat interface.\nThis setup offers a clear and user-friendly voice experience, making it easy for users to know when to\nspeak. With simple visual cues, it guides users through the recording process smoothly, ensuring they\nfeel confident and engaged in using the voice-interaction feature (Section 5.4.1).\n4.5 Prompts\nIn order to enhance and personalize Gala\u2019s responses, prompt engineering proved to be fundamental.\nPrompt engineering is a technique within artificial intelligence and NLP that involves carefully designing\npromptstoguidethebehaviourandresponsesofLLMstoachievemoreaccurateandcontextuallyrelevant\noutputs [33].\nThis approach allows Gala\u2019s responses to be suitable according to specific guidelines that shape the\nassistant\u2019s role and behaviour. Through prompt engineering, an initial assistant description establishes\nGala\u2019s role and intended style, providing context and direction across different scenarios.\nThere are various prompt engineering techniques that provide reusable solutions to common problems of\ngenerating output and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 57,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2315,
      "text": "utput and interacting with the LLM [55, 22].\nSome of the most influential and used techniques are:\nZero-Shot learning: This technique involves providing no examples to train the LLM to perform a task.\nThis approach is feasible because modern large language models, such as GPT-4o, can complete tasks\nsimply by following instructions, having already been trained on vast amounts of data [6, 24].\n     USER:  Classify the text as neutral, negative, or positive.\n            Text: I think the vacation is okay.  \n            Sentiment:\n\nASSISTANT:  Neutral\nFigure 4.1: Example of Zero-Shot learning [24]\nFew-Shot learning: This technique involves providing some examples to train the LLM to perform a\ntask. This approach is used because LLMs sometimes struggle with more complex tasks, so a few-shot\nmethod is applied to provide additional examples, helping the model achieve better performance [23].\n26\n     USER:  The \"whatpu\" is a small furry animal native to Tanzania. \n            An example of a sentence using the word whatpu is:  \n            \"We were traveling in Africa and saw these adorable whatpus.\"\n            To \"farduddle\" means to jump up and down very quickly.  \n            An example of a sentence using the word farduddle is:\n\nASSISTANT:  When we won the game, we all started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 58,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2316,
      "text": "ll started to farduddle together.Figure 4.2: Example of Few-Shot learning [23]\nDuring the project, I primarily used Zero-Shot prompts, as I found the tasks manageable for the latest\nversion of GPT-4o. However, employing additional, more detailed techniques could further enhance the\nquality of responses. My prompts focused on aspects such as the structure of product recommendations,\nresponse formatting, and behavioural adaptation based on detected user emotions, ensuring that Gala\ninteracted with empathy.\nFigure 4.3 shows Gala\u2019s foundational prompt, which establishes her role and behavioural guidelines. This\ndirective is embedded within the system instructions section on OpenAI Playground, specifically under\nthe assistant settings.\nYou are Gala, the online shopping assistant for Galeries Lafayette, a prestigious French \ndepartment store. Your role is to assist users with personalized shopping recommendations \nbased on their preferences and needs IF THEY ASK FOR PRODUCTS. If users doesn't ask for \nproduct you have just to answer their questions. You only recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 59,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2317,
      "text": "recommend products from the \nfile provided, which contains items from Galeries Lafayette.\n\nYou are friendly and approachable, and you always address the user by their name to make \nthem feel welcomed. At the first message of each conversation, you ALWAYS introduce \nyourself briefly, but just the first message then you don't need to reintroduce in the \nsame conversation! and you always ask if the user needs further assistance before ending. \nYour responses are concise, no more than 3-4 lines, ensuring a pleasant and efficient \nexperience for the user. \nFigure 4.3: General instructions for Gala\nThe following prompt, displayed in figure 4.4, specifies how the assistant should respond when the user\nrequests a product. It includes instructions for structuring the product information in JSON format and\nincorporates introductory and concluding text guidelines, dictating how each response should start and\nfinish. This prompt activates whenever the assistant replies to a user\u2019s message or voice query, and it is\napplied exclusively when a product request is detected.\n27\nConsider the user message. The assistant must always respond in the same language the user uses in their message. The \nassistant should also consider the user's emotions as specified in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 60,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2318,
      "text": "d in the guidelines. It must respond in a manner that is \ncoherent with the emotion expressed by the user, reacting according to the instructions provided in the guidelines for that \nspecific emotion. If the user does not explicitly request products, the assistant should ignore product-related instructions \nand focus solely on responding to the user\u2019s message based on their emotion. Do not send products or JSON text unless the \nuser specifically asks for them. When the user asks for products, the assistant must act professionally, like a shopping \nassistant, providing recommendations and asking if the user needs further information. In this case, the assistant must use \nthe following JSON format:\n    [\n      ${formattedProducts.map(product => `\n      {\n        \"name\": \"${product.name}\",\n        \"brand\": \"${product.brand}\",\n        \"price\": \"${product.price}\",\n        \"image_url\": \"${product.image_url}\",\n        \"url\": \"${product.url}\"\n      }\n    `).join(',')}\n    ]\n    The products must be sourced exclusively from ${formattedProducts}, and the assistant must provide exactly three \nproducts per request. Before presenting the products, the assistant should include a brief, general introduction (e.g., \n\"Here are some suggestions for you\") and not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 61,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2319,
      "text": "not mention specific product names in the introduction. After listing the products, \nthe assistant should include a brief concluding message asking if the user needs further assistance or suggestions. The JSON \narray should be presented as is, with no additional text outside the [ ] brackets. If the user specifies a product color, \nthe assistant must only select products whose images match that color. Lastly, responses should be concise, professional, \nand appropriate to the user\u2019s requests and emotions, ensuring the conversation remains clear and consistent throughout.Figure 4.4: Product formatting prompt\nThe final prompt, illustrated in figure 4.5, maps each detected user emotion to a corresponding response\nguideline, defining the assistant\u2019s empathic behaviour. This prompt is applied whenever the user sends\na voice message, ensuring that the assistant\u2019s responses align with the user\u2019s emotional state for a more\nempathic and context-sensitive interaction [33, 40, 43].\nReferring to the paragraph 2.2.3, I developed specific prompts aimed at comforting users during moments\nofsadnessbyofferinggentlesupportandlighthumorwithoutbeingoverlyinsistent. Fornegativeemotions\nlike anger or disgust, the assistant uses calming language and applies coping strategies (Section 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 62,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2320,
      "text": "n 2.2.3),\nsuchas\u201cPlanning\u201d, suggestingnewproductstocreateaplan, and\u201cMentalDisengagement\u201d tohelpredirect\nthe user\u2019s focus from the negative emotion, fostering a supportive and constructive interaction.\ncase 'joy':\n   \nprompt = `The user seems to be in a good mood! Reinforce this positive feeling with suggestions or products that could make \ntheir day even more special. Maintain an enthusiastic and engaging tone.`;\n     \ncase 'sadness':\n        \nprompt = `Offer your support gently and be kind, ask how the user is feeling and try to be comprehensive. You could suggest \nsome novelties products and discounts, or maybe you can propose a funny short joke. Be supportive but not overly persistent, \nallowing the user to choose how to proceed.`;\n       \ncase 'anger':\n\nprompt = `Address the situation calmly and propose alternatives or suggestions that can resolve the issue in a clear and \ncollaborative manner. Maintain a positive tone and let them know you're here to support and improve their experience. Avoid \nbeing too pushy and leave room for a light interaction.`;\n        \ncase 'fear':\n\nprompt = `Use a reassuring and gentle tone, providing clear and simple information to ease any concerns, asks if needed how \nthe user is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 63,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2321,
      "text": "ser is feeling. Suggest products or solutions that promote comfort and security, but without being too insistent.`;\n        \ncase 'disgust':\n\nprompt = `The user may not have had a pleasant experience. Acknowledge the situation gently and offer an alternative to divert \nattention from the negative experience. Try to maintain a light and friendly tone, focusing on something that might pleasantly \nsurprise the user. Avoid being too insistent.`;\n       \ncase 'surprise':\n// Distinguish between positive and negative surprise if possible\nprompt = `The user seems surprised! If it's a positive surprise, amplify the excitement and suggest something fun or \ninteresting. If the surprise appears negative or uncertain, provide support with clarity and a light touch to help the user \nfeel at ease. Maintain a helpful and present approach but avoid being intrusive.`;\n        \ndefault:\n\nprompt = `The user seems neutral or unclear. Respond professionally, adapting to the context and offering helpful suggestions \nor information. Maintain a respectful and friendly tone.`;\n       \nFigure 4.5: Emotion-specific prompts\n28\n29\nChapter 5\nEmpirical Studies\nAs a crucial method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 64,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2322,
      "text": "al method in the domain of human-computer interaction, user testing involves a systematic\nexamination of a system\u2019s usability by observing and analyzing real users as they interact with the\ninterface. This method tries to uncover real-world issues that users might face, as well as gather feedback\non the system\u2019s performance and effectiveness. Through the analysis of both quantitative and qualitative\ndata, it is possible to obtain valuable insights that inform design decisions, ultimately leading to an\nimproved overall user experience.\nAn usability test was conducted using the first high-fidelity prototype, as shown in this section 3.5.\n5.1 Usability Test\nFor the first test various objectives were established:\n\u2022Understand if the assistant addresses the user\u2019s needs as identified from the interviews reported\nhere 3.3.1.\n\u2022Determine the number of messages and the amount of time required for the user to complete the\ntask.\n\u2022Identify the most frequently used methods.\n\u2022Identify user difficulties, unclear aspects, and areas that need improvement.\n5.1.1 User Profile\nFor this test, 10 users participated, belonging to the following target group:\n\u2022People living in France.\n\u2022Tourists.\n\u2022People aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 65,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2323,
      "text": "e aged between 20 and 65 years.\n\u2022Males and females.\nThese categories were selected because the Galeries Lafayette website is visited by a diverse range of\nindividuals aged between 20 and 65 years old. The website attracts visitors from around the world, and\nthe assistant is designed to communicate in any existing language.\n5.1.2 Testing location\nI selected two types of testing locations. The first is the Galeries Lafayette Haussmann store, where I\nconducted face-to-face tests with customers. Two colleagues from the user research team assisted me\nduring this phase. Testing customers in the shop allowed us to easily gather information from people of\ndifferent ages and nationalities.\nThe second location for the tests was via video calls, chosen for logistical reasons, feasibility, and testing\naccuracy. To ensure precision and facilitate analysis, I used screen-sharing to observe users\u2019 actions in\ndetail.\n5.1.3 Test\nIn this user test, I employed a three-fold approach: first, I asked each user for their age to ensure they\nfit the target profile. After providing them with some context to better embody the ideal user profile, I\nasked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 66,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2324,
      "text": "ked a generic question to understand their expectations from the assistant.\nSecond, I observed them as they completed a list of tasks, noting their various actions and comments\nthroughout the process.\nAt last, I asked each participants to complete an Usability Metric for User Experience-Lite (UMUX-Lite)\nquestionnaire for each task, following their experience. The UMUX-Lite score serves as a quantitative\nmeasure to assess the usability of a system based on user feedback [37].\n5.1.4 Questions\nTo begin, participants were asked initial questions to gather information about their age, followed by\nproviding contextual information to help them better understand the tasks they were about to undertake.\nThis approach ensures that participants are adequately prepared, enhancing the reliability and relevance\nof the feedback collected.\nQuestion N\u00b0 Description\nQ1 How old are you?\nQ2 The prototype we are testing is still under development and\nneeds to be completed, but imagine that you are at home and,\nupon entering the Galeries Lafayette website, you find this chat-\nbot: what would you like to ask the personal assistant?\nTable 5.1: Usability test: first two questions of the test\n5.1.5 Tasks\nEach task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 67,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2325,
      "text": "h task was designed to examine various navigation sections: text area input, image upload and voice\nrecording. Additionally, the objective was to test the assistant\u2019s responses in different scenarios.\nTask N\u00b0 Description\nT1 Now imagine that you are searching for a bag, what would you do?\nT2 Imagine that the results you obtained were too expensive for your\nbudget, try to find similar products but cheaper.\nT3 Related to the first product you received at the beginning of the\nconversation, imagine that you want to know the composition of the\nproduct, but you cannot use the keyboard, how would you do it?\nT4 Now imagine that you saved a picture of a product in your phone\u2019s\ngallery and you want to find similar products on the Galeries\nLafayette website, what would you do?\nTable 5.2: Usability test: tasks\n5.1.6 UMUX-Lite\nThis approach uses two positively worded questions of the original UMUX. Each assertion is rated on a\n7-point [37], ranging from strongly disagree (1) to strongly agree (7). The statements used in UMUX-Lite\nare as follows:\n\u2022To rate the usefulness: This system\u2019s capabilities meet my requirements.\n\u2022To rate the ease of use: This system is easy to use.\n30\nThe first statement was not clear for the user, so I changed it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 68,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2326,
      "text": "it in this way:\n\u2022The system satisfied my needs.\nIt is possible to calculate the UMUX-Lite score using this formula for each user:\nUMUX-Lite score= ((Question 1 Score) + (Question 2 Score)-2)*100/12\n5.2 Evaluation criteria\nIn order to evaluate the usability and effectiveness of the application, it is important to use appropriate\nmetrics. I chose the following metrics for evaluation based on their ability to provide valuable insights\ninto the user experience:\n\u2022Time taken: This metric measures the time taken by users to complete a task. I estimated a\ncompletion time for each task and considered the task failed if it exceeded 5 minutes. A shorter\ntime taken to complete a task indicates a more user-friendly website.\n\u2022Number of messages: This metric measures the number of messages needed by users to complete\nthe task. I formulated hypotheses regarding the ideal number of messages required for each task.\nIt is crucial to understand how users articulate their needs. If users require an excessive number\nof messages, it may indicate that they need additional assistance to help the assistant comprehend\ntheir requests.\nTask N\u00b0 Estimated number of messages\nT1 2\nT2 1\nT3 2\nT4 1\nTable 5.3: Usability test: number of messages per task\n\u2022User errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 69,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2327,
      "text": "ser errors: This metric measures the number of errors made by users while completing a task.\nThis metric is essential for determining whether certain functions and buttons are easily under-\nstandable.\n\u2022System errors: This metric measures the number of errors made by the system during a task.\nThis metric is essential for identifying critical points in the systems and determining what needs\nimprovement.\n\u2022Success rate: This metric measures the percentage of users who successfully complete a task. I\ngave a score of 0 if the task was not completed and 1 if the user completed the task. A higher\nsuccess rate indicates a more effective application.\n\u2022Method used: In this part is evaluated which input method is used by the user. The three possible\nmethods are: text area (T), microphone (M) and image upload (I). This metric is needed to identify\nwhich methods are most frequently used and understanding the reason why some methods are less\nfavored.\n\u2022Comments: I collected qualitative feedback from users about their experience with the assistant\nto gain insights into specific issues that may not be captured by other metrics.\nBy using these metrics, I wanted to obtain a thorough understanding of the user experience. This\napproach helped me identify area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 70,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2328,
      "text": "area for improvements to enhance both usability and effectiveness.\n5.3 Results\nThe data collected during the test were analyzed to evaluate the usability of the system. Below are\nreported the results.\nTime per task\nDuring the usability test, each task was timed for every user session.\n31\nThe time limit was set to 05:00 minutes. As shown in figure 5.1, the average time taken for each task is\nbelow this limit.\nWe note that Task 1 has the highest average time at 01:35 minutes, while Task 4 has the lowest at 00:42\nseconds.\nNumber of messages per task\nThe average number of messages per task was also recorded. It is evident that task 2 and task 4 exceeded\nthe estimated number of messages, with both having an average of 1.1 messages per task. In contrast,\ntask 1 and task 3 remained below the estimated 2 messages per task.\nFigure 5.1: Average time per task (left); Average number of messages per task (right)\nUser errors\nI reported the average number of errors made for each task. Task 1 is the one with a higher average of\nuser errors, instead task 2 reported 0 errors from the analysis.\nSystem errors\nThe average number of system errors for each task is reported below. A System error occurs when the\nsystem crashes or provides an unexpected response from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 71,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2329,
      "text": "nse from an implementation standpoint. For example,\nthis could be when the assistant says \u201cno content available\u201d or replies with the same message sent by the\nuser.\nThe system reported an average of 0.5 errors for task 3, where the assistant had to respond using a voice\nmessage. The primary issue arose because users struggled to understand how to record and send a voice\nmessage. Task 1 reported just a 0.1 average of errors.\nFigure 5.2: Average user errors per task (left) ; Average system errors per task(right)\nSuccess rate\nI calculated the average success rate and the average failure rate for each task.\n32\nTasks 1, 3 and 4 have a higher success rate than failure rate, with task 4 achieving the highest average\nsuccess rate of 0.8 . In contrast, task 2 has an average failure rate of 0.5 , which is equal to its average\nsuccess rate.\nFigure 5.3: Average success and failure rate\nSummary\nThe following table summarizes the results of the user test for various tasks, including the average time\ntaken to complete each task, the average number of messages for each task, the average number of user\nerrors (UE), the average number of system errors (SE) and the average success rate of each task (SR).\nTaskAvg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 72,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2330,
      "text": "Avg.Time(min) Number of messages UESESR\nT1 01:35 1.2 0.30.160%\nT2 00:51 1.1 00.350%\nT3 00:59 1.4 0.20.570%\nT4 00:42 1.1 0.10.280%\nTable 5.4: Usability test: tasks summary\nBased on the data reported 5.4, it appears that the most used method during all the usability test was\nthe text area, with54%of usage. This means that users prefer and find easier to use a text bar to chat\nwith the assistant.\nOn the other hand, there is a5%of usage of the link to the product page, users used this unexpected\nmethod to complete task 3, when I asked them to find the composition of the product without using the\ntext area. Users were confused, because they did not notice the presence of the microphone and so they\nfound more intuitive to search directly in the product page link, provided by the assistant. This means\nthat the microphone icon is not intuitive and visible and needs to be improved.\nFrom users comments, It is also emerged that the method for using the microphone is not clear, because\nusers do not understand that they need to hold down the button to speak and release it to send. For this\nreason the voice input needs to be changed and improved to be more intuitive and easy to use.\nI reported here a user comment about the microphone issue:\n\u201cThe microphone should have an indicator that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 73,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2331,
      "text": "that actually says that the assistant is listening. It\u2019s not clear\nthat you have to hold down the button to do an audio.\u201d\nTwo out of ten users expressed a desire for more guidance from the assistant. They want the assistant to\nask more questions to better understand their preferences and provide relevant suggestions. Additionally,\nwhen requesting multiple products, they prefer receiving specific product recommendations rather than\nlinks to general category pages. Here are the comments:\n33\n\u201cI would like the assistant to pose me more questions about myself to understand my preferences. If I ask\nfor more than 1 product, I want a list of products not the link to the website.\u201d\n\u201cI like seeing three options and not too many. I would like to be guided when I ask for something generic,\nand the assistant should ask me questions.\u201d\nFigure 5.4: Methods used\nOn the other hand, some users expressed enthusiasm and would be happy to use the assistant during\ntheir online shopping. Many users appreciated the time saved by not having to scroll through the website\nto find the perfect product. They also praised the assistant\u2019s responses, describing them as clear, precise,\ndetailed, and filled with helpful suggestions. Here are some of the comments:\n\u201cTo me was good, can help not to waste time in the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 74,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2332,
      "text": "n the shop. I would use it both in the shop and at home.\u201d\n\u201cI loved the microphone part, because the assistant is really reactive and it\u2019s easy to communicate and\nhave opinions and it\u2019s really precise. The French was good. I would use it.\u201d\nAfter calculating the UMUX-Lite score for each user, the mean score was found to be 79.26 . To\nevaluate this result, I referred to the Sauro/Lewis Curved Grading Scale of the System Usability Scale\n(SUS), which is the most widely used tool for measuring perceived usability. The SUS consists of a 10-\nitem questionnaire that uses a five-point scale, providing a comprehensive yet quick assessment of users\u2019\nsubjective impressions of the system\u2019s usability [38].\nThe UMUX-Lite score is consistent with the distribution of mean SUS scores reported by Sauro and\nLewis in table 5.5, so the UMUX-Lite score of 79.26 corresponds to a A- in the chart, which represents\na high level of usability of the application.\nFigure 5.5: Average UMUX-Lite score for each user (left) ; The Sauro/Lewis Curved Grading Scale (right)\n34\n5.4 High Fidelity Prototype: Second iteration\nI refined the high-fidelity prototype 3.5 to address specific user feedback. Users reported difficulty under-\nstanding when the assistant was speaking or listening and found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 75,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2333,
      "text": "found the microphone functionality unclear. In\naddition, they preferred to see a fixed number of direct product recommendations rather than a generic\nlink to the Galeries Lafayette category page.\n5.4.1 Changes from the first iteration\nBased on the results from the usability test, to improve usability, the option to provide a link to the\nGaleries Lafayette category page was deleted, and the assistant was set to deliver up to three specific\nproduct recommendations per request, making the interaction clearer and more user-friendly.\nFor the voice message functionality, I designed a page that opens immediately after clicking the mi-\ncrophone icon. In this initial phase, the assistant begins listening to the user\u2019s voice message, with a\n\u201cListening...\u201d message displayed on the screen to notify the user.\nWhen the user finishes recording, they click a red stop button at the bottom, which updates the display\nto \u201cProcessing...\u201d while the assistant formulates a response.\nOnce ready, the assistant\u2019s voice response is streamed, with animated circles radiating from Gala\u2019s icon\nto indicate it\u2019s speaking. After the response ends, the circles stop, and the recording button reappears,\nallowing the user to record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 76,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2334,
      "text": "o record a new message.\nTo end the audio interaction, the user can click the \u201cX\u201d icon at the top left, returning to the main chat\npage, where all audio messages are transcribed (Figure 5.6).\nFigure 5.6: Recording started (left) ; The assistant is processing the answer (center-left) ; The assistant\nis speaking (center) ; The user can record again (center-right) ; Transcribed messages (right)\n5.5 User Test: System Empathy Evaluation\nTo gain insights into how an empathic assistant influences the online shopping experience, a specialized\nuser test was conducted to measure both its efficacy and impact. This test aimed to assess how the assis-\ntant\u2019s ability to recognize and respond to user emotions affected overall satisfaction, ease of interaction,\nand perceived personalization in the shopping process.\nBy analyzing user reactions to the empathic responses of the assistant, the study tries to determine\nwhether empathy-driven interactions lead to increased engagement, trust, and enjoyment in the online\nshopping journey.\nThe user test was further designed to explore differences in the conversation between an empathic assis-\ntant and a standard one. This included observing how each assistant\u2019s choice of words influenced user\nperceptions of warmth, support, and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 77,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2335,
      "text": "and responsiveness in online shopping.\n5.5.1 User Profile\nFor this test, 5 users participated, belonging to the following target group:\n35\n\u2022People aged between 25 and 65 years.\n\u20222 Males and 3 females.\nI decided to include participants across a broad age range to capture diverse generational perspectives,\nas different age groups may interact with online shopping in unique ways. This variety also offers insight\ninto how each generation engages with an empathic assistant to express emotions and articulate their\nexpectations.\n5.5.2 Test\nIn this user test, participants were asked to complete four tasks, first using the empathic version of Gala,\nand then using a non-empathic version. The empathic Gala uses the Emoty API to detect the user\u2019s\nemotional state based on vocal tone, adjusting responses accordingly to convey empathy (Shown in figure\n4.5).\nEach user was not informed about which assistant was empathic and which was not, ensuring that their\ninteractions and feedback were unbiased.\nAfter testing both assistant versions, I asked each user to answer a series of feedback questions to under-\nstand if they noticed any differences between the two versions, and to determine which one they preferred\nand why.\n5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 78,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2336,
      "text": "5.5.3 Tasks\nI designed the test to evaluate various emotions in each task (Shown in the table 5.5): the first required\ndisplaying happiness, the second sadness, the third disgust, and the last anger. Each user was asked to\nact out these emotions, even exaggerating if necessary, to help the system effectively detect emotional\nstates. Initially, I set an emotion detection threshold at 0.8, but after observing that users needed to\nexaggerate significantly, I adjusted it to 0.5, enabling more natural expressions to yield valid results.\nUsers completed all four tasks with both versions of the assistant, aiming to replicate the same questions\nand use a consistent tone of voice across both sessions.\nTask N\u00b0 Description\nT1 Imagine you are feeling happy today because you received some really\ngood news at work. Ask the assistant for a product that would match\nthis mood, such as a new bag.\nT2 Now, pretend you\u2019re feeling sad because you realised that you don\u2019t\nhave much money this month. Ask the assistant to recommend af-\nfordable bags.\nT3 Imagine that the bags the assistant recommended are really disgust-\ning. Tell the assistant that you don\u2019t like them.\nT4 Now you are frustrated and irritated because you didn\u2019t find what\nyou were expecting and have wasted a lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 79,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2337,
      "text": "lot of time searching on the\nwebsite.\nTable 5.5: System Empathy Evaluation: tasks\n5.5.4 Feedback from users\nAfter each user completed the four tasks, I asked follow-up questions (Shown in the table 5.6) to gather\ntheir opinions on the two assistant versions they tested.\nThese feedback allowed me to identify which version they preferred and to understand the reasons behind\ntheir preferences. In addition, I had the opportunity to understand which type of assistant they found\nto be more helpful and pertinent during online shopping.\nFinally, an analysis of the responses was performed, comparing trends in user preferences and identifying\nareas where empathy-enhanced interactions improved the shopping experience. This analysis contributed\nvaluable insights into the impact of emotional awareness on user satisfaction.\n36\nQuestion N\u00b0 Description\nQ1 Did you notice any significant differences between the two ver-\nsions of the assistant you tried?\nQ2 Which one did you prefer and why?\nQ3 Which version did you find more helpful in choosing products?\nWhy?\nQ4 Comments?\nTable 5.6: System Empathy Evaluation: follow-up questions\n5.5.5 Results\nAnalyzing users\u2019 responses (All tests here:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 80,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2338,
      "text": "e:??) revealed that all five participants recognized the first\nassistant as more empathic than the second. They noted that it selected responses with greater care,\naiming to be kind and understanding.\nFour out of five users preferred the empathic assistant, as it made them feel more understood and instilled\na sense of trust, as if it genuinely understood their needs. They found the assistant more attentive to\nthem as individuals, not just buyers. Conversely, they described the second, non-empathic assistant as\noverly formal and less sophisticated, capable only of providing product suggestions without considering\nusers\u2019 emotions. Here are some of the comments:\n\u201cI preferred the first one because I like a clear relationship, and it resonated with me. I think it is important\nfor the assistant to give advice based on your needs, making me feel understood. Trust is what matters\nmost.\u201d\n\u201cI preferred the first one because, based on what I said, it was more focused on emotions and seemed to\nunderstand me better than the other.\u201d [...] \u201cIn contrast, the second one just said, \u2019Here are some shoes,\u2019\nwhich makes it seem less advanced than the first.\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 81,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2339,
      "text": ".\u201d\nOn the other hand, one user preferred the second, non-empathic version of the assistant. This preference\nstemmed from a desire for a quick, efficient experience without deeper emotional engagement. The user\nfound the empathic assistant too intrusive and overly conversational, occasionally delving into personal\nemotions in a way that felt unnecessary. A second user explained that she would likely use the non-\nempathic assistant more often, as she prefers a more straightforward approach during shopping and\nvalues completing her purchases quickly without emotional engagement. Here are some comments:\n\u201cI prefer the second one because it\u2019s faster and I don\u2019t have to listen to too much information. It also\nunderstood when I wanted to end the conversation and didn\u2019t insist.\u201d\n\u201cThe way I am, I would be very brief and don\u2019t need to empathize. However, I liked that the first chatbot\nhelped me even during difficult moments.\u201d\nFinally, four out of five participants found the first assistant more helpful during online shopping. This\nwas because they felt better understood and were more likely to continue shopping, as they felt the\nassistant showed empathy and could grasp their feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 82,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2340,
      "text": "feelings and needs.\n5.5.6 Conclusions\nIn conclusion, the empathic assistant was perceived as more supportive and attentive, leading users to\nfeel understood and trust its recommendations more easily. Many users felt encouraged to engage further,\nwith some even feeling subtly persuaded by the attentiveness of the assistant. However, it was challenging\nfor users to consistently express the exact emotions requested, as interacting with a machine is typically\nquick and functional, without expecting emotional recognition. For this reason, it would be valuable to\nconduct more comprehensive testing of the assistant, using more precise and in-depth methods. This\ncould include experimenting with different threshold rates to detect emotions from voice input.\nFurthermore, notable differences emerged between the responses of the two assistants. The empathic\nassistant often prioritized the user\u2019s emotional state, employing techniques to enhance empathy: for\nexample, offering alternative suggestions in response to anger or using humor to uplift a sad user. In\ncontrast, the non-empathic assistant generally limited its responses to simply sending product links\nwithout engaging in supportive dialogue, which diminished the perceived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 83,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2341,
      "text": "ived quality of the interaction.\n37\nThese findings highlight that users appreciate feeling understood in their online shopping experience,\nvaluing an assistant that can engage as a human-like advisor. The empathic assistant fostered a sense\nof personalized engagement, similar to an in-store experience, enhancing users\u2019 connection to the digital\nshopping journey.\n38\n39\nChapter 6\nConclusions and Future Works\n6.1 Conclusions\nAs outlined at the beginning of this paper, the primary goal was to create an online shopping experience\nfor Galeries Lafayette customers that replicates the engagement of in-store shopping while integrating\nan empathic virtual assistant. This assistant aims to help users quickly find products and make proper\nrecommendations, thereby enhancing the overall experience.\nThe usability test showed positive results, with Usability Metric for User Experience-Lite (UMUX-Lite)\nscoring 79.26, suggesting high user satisfaction. Empathy evaluation indicated that users generally pre-\nferred the empathic assistant for its attentiveness and relatable responses. However, certain challenges\nemerged, particularly in accurately recognizing emotions, as users sometimes needed to exaggerate their\nemotions to prompt an empathic response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 84,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2342,
      "text": "response. In general, the project met its goals and answered the research\nquestion, establishingapromisingfoundationforcontinueddevelopmentoftheassistanttoimprovefuture\nonline shopping experiences.\n6.2 Limitations\nDespite positive test results, several challenges and limitations emerged. First, the assistant response\ntime, which often takes several seconds, can be frustrating for users who want quick recommendations and\nproduct search efficiency. Although the assistant optimizes search time, the delay in displaying responses\nremains substantial. This issue is amplified when uploading images, as Learned Perceptual Image Patch\nSimilarity (LPIPS), despite being optimal and effective, requires considerable time to analyze a JSON\nfile containing hundreds of Galeries Lafayette products.\nFurthermore, users are unable to enter text when uploading an image, as the text box is intentionally\ndisabled to avoid system confusion. Since LPIPS handles image selection, ChatGPT does not process\nimages directly, meaning any user text would not relate to image results, making such input superfluous.\nEmotion recognition also shows limitations, as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 85,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2343,
      "text": "as users often need to exaggerate emotions for the system to\ndetect them, potentially leading to inauthentic responses. This limits the reliability and accuracy of the\nemotional recognition component.\nIt is essential to continue research to find more fluid and reliable methods for detecting emotions through\nvoice, ultimately improving the realism of the user experience. Improving the system\u2019s accuracy in\nidentifyinggenuineemotionswithoutrequiringexaggeratedexpressionsiskeytocreatingamoreempathic\nand effective assistant, capable of responding authentically and elevating the quality of user interaction\nin online shopping contexts.\n6.3 Future Works\nA key area for future enhancement involves adding message suggestions above the text area. This feature\ncould help users express their needs more clearly and construct sentences more effectively.\nConsidering the stipulated limitations, it is essential to optimize the assistant\u2019s response time to enhance\nthe user experience and minimize frustration. Exploring alternative neural networks beyond LPIPS could\nreveal valuable differences in response times.\nRegarding emotion recognition, further research on how an emotional state might influence product\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 86,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2344,
      "text": "roduct\nrecommendationswouldbevaluable. Forexample, identifyingwhattype, colourorpricerangeofproducts\nwould appeal to a user when they are feeling sad could enable more nuanced and precise suggestions.\nAnother fundamental challenge lies in the difficulty people experience in exaggerating or feigning their\nemotions, which makes it challenging for the assistant to accurately detect these subtle cues. Therefore,\nadditional research and testing are essential to refine the assistant\u2019s ability to interpret emotions accu-\nrately and to create a conversational flow that feels natural. This approach would also focus on making\nusers feel comfortable expressing their emotions, ultimately enhancing the authenticity and depth of the\ninteraction.\nAdditionally, implementing user identification to store purchasing preferences and habits would allow\nfor a stronger relationship between the assistant and the user. This approach could enable personalized\nrecommendations and daily notifications based on the user\u2019s interests, encouraging a more engaging\nshopping experience.\nApromisingenhancementiscreatingaGalaavatarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 87,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2345,
      "text": "atarforphysicalstores, offeringseamlessguidanceonprod-\nucts, brands, and store navigation. Such an in-store avatar would bridge online and in-store experiences,\nenriching the overall customer journey.\nIn conclusion, Gala has the potential to support customers both online and in-store, not only helping with\nproduct selection, but also helping users recognize and navigate their emotions for better decisions. This\nintegration could significantly improve the shopping experience, connecting digital and physical retail\ninteractions.\n1\n1The author declares a potential conflict of interest due to a professional engagement with Galeries Lafayette, during\nwhich she contributed to the development of a project later described in this thesis. This professional relationship did not\ninfluence the analysis, results, or conclusions presented.\n40\n41\nBibliography\n[1] Berkehan Ak\u00e7ay and Kaya Oguz. Speech emotion recognition: Emotional models, databases, fea-\ntures, preprocessing methods, supporting modalities, and classifiers.Speech Communication, 116,\n01 2020. doi: 10.1016/j.specom.2019.12.001. URLhttps://www.researchgate.net/publication\n/338221917_Speech_emotion_recognition_Emotional_models_databases_features_preproce\nssing_methods_supporting_modalities_and_classifiers.\n[2] Sara Altun G\u00fcven, Emrullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 88,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2346,
      "text": "rullah \u015eahin, and Muhammed Fatih Talu. Image-to-image translation with\nCNN based perceptual similarity metrics.Computer Science, 2024. ISSN 2548-1304. doi: 10.53070\n/bbd.1429596. URLhttps://dergipark.org.tr/en/doi/10.53070/bbd.1429596.\n[3] Nadya Anastasia, Harlili, and Lenny Putri Yulianti. Designing embodied virtual agent in e-\ncommerce system recommendations using conversational design interaction. In2021 8th Interna-\ntional Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages\n1\u20136. IEEE, 2021. ISBN 978-1-66541-743-3. doi: 10.1109/ICAICTA53211.2021.9640258. URL\nhttps://ieeexplore.ieee.org/document/9640258/.\n[4] Kathy Baxter, Catherine Courage, and Kelly Caine. Interviews. InUnderstanding your Users, pages\n218\u2013262. Elsevier, 2015. ISBN 978-0-12-800232-2. doi: 10.1016/B978-0-12-800232-2.00009-2. URL\nhttps://linkinghub.elsevier.com/retrieve/pii/B9780128002322000092.\n[5] Ardion Beldad, Sabrina Hegner, and Jip Hoppen. The effect of virtual sales agent (vsa) gender\n\u2013 product gender congruence on product advice credibility, trust in vsa and online vendor, and\npurchase intention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 89,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2347,
      "text": "ention.Computers in Human Behavior, 60:62\u201372, 2016. ISSN 0747-5632. doi: https:\n//doi.org/10.1016/j.chb.2016.02.046. URLhttps://www.sciencedirect.com/science/article/\npii/S074756321630098X.\n[6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry, AmandaAskell,SandhiniAgarwal,ArielHerbert-\nVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[7] Felix Burkhardt, Astrid Paeschke, M. Rolfes, Walter Sendlmeier, and Benjamin Weiss. A database of\ngerman emotional speech. volume 5, pages 1517\u20131520, 09 2005. doi: 10.21437/Interspeech.2005-446.\nURLhttps://www.researchgate.net/publication/221491017_A_database_of_German_emotio\nnal_speech.\n[8] Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost, Samuel\nKim, Jeannette Chang, Sungbok Lee, and Shrikanth Narayanan. Iemocap: Interactive emotional\ndyadic motion capture database.Language Resources and Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 90,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2348,
      "text": "Evaluation, 42:335\u2013359, 12 2008. doi:\n10.1007/s10579-008-9076-6. URLhttps://www.researchgate.net/publication/220147568_IEM\nOCAP_Interactive_emotional_dyadic_motion_capture_database.\n[9] Nick Campbell. Databases of emotional speech. InISCA tutorial and research workshop (ITRW)\non speech and emotion, 2000. URLhttps://www.isca-archive.org/speechemotion_2000/camp\nbell00_speechemotion.pdf.\n[10] Avyay Casheekar, Archit Lahiri, Kanishk Rath, Kaushik Sanjay Prabhakar, and Kathiravan Srini-\nvasan. A contemporary review on chatbots, ai-powered virtual conversational agents, chatgpt:\nApplications, open challenges and future research directions.Computer Science Review, 52:\n100632, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100632. URL\nhttps://www.sciencedirect.com/science/article/pii/S1574013724000169.\n[11] Fabio Catania.Designing and engineering emotion-aware conversational agents to support persons\nwith neuro-developmental disorders.PhD thesis, 11 2023. URLhttps://www.researchgate.net\n/publication/375865087_Designing_and_engineering_emotion-aware_conversational_agen\nts_to_support_persons_with_neuro-developmental_disorders.\n[12] Fabio Catania. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 91,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2349,
      "text": "a. Speech emotion recognition in italian using wav2vec 2.0 and the novel crowdsourced\nemotional speech corpus emozionalmente. 05 2023. doi: 10.36227/techrxiv.22821992.v1. URL\nhttps://www.researchgate.net/publication/370906381_Speech_Emotion_Recognition_in_I\ntalian_Using_Wav2Vec_20_and_the_Novel_Crowdsourced_Emotional_Speech_Corpus_Emozion\nalmente.\n[13] Fabio Catania and Franca Garzotto. A conversational agent for emotion expression stimulation in\npersons with neurodevelopmental disorders. volume 82, page 12797\u201312828, USA, November 2022.\nKluwer Academic Publishers. doi: 10.1007/s11042-022-14135-w. URLhttps://doi.org/10.1007/\ns11042-022-14135-w.\n[14] Purnima Chandrasekar, Santosh Chapaneri, and Deepak Jayaswal. Automatic speech emotion recog-\nnition: A survey. In2014 International Conference on Circuits, Systems, Communication and In-\nformation Technology Applications (CSCITA), pages 341\u2013346, 2014. doi: 10.1109/CSCITA.2014.68\n39284. URLhttps://ieeexplore.ieee.org/document/6839284.\n[15] Veena Chattaraman, Wi-Suk Kwon, and Juan Gilbert. Virtual agents in retail web sites: Benefits of\nsimulated social interaction for older users.Computers in Human Behavior, 28:2055\u20132066, 11 2012.\ndoi: 10.1016/j.chb.2012.06.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS0747563212001598.\n[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 92,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2350,
      "text": "[16] Yanhong Chen, Yaobin Lu, Bin Wang, and Zhao Pan. How do product recommendations affect\nimpulse buying? an empirical study on wechat social commerce.Information & Management, 56,\n09 2018. doi: 10.1016/j.im.2018.09.002. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S0378720617305372.\n[17] Claude C Chibelushi and Fabrice Bourel. Facial expression recognition: A brief tutorial overview.\nCVonline: On-Line Compendium of Computer Vision, 9, 2003. URLhttps://citeseerx.ist.ps\nu.edu/document?repid=rep1&type=pdf&doi=860287296e960dcc54508813b9bd55c89f5c23ea.\n[18] MayankChugh. Theevolutionoflargelanguagemodels(llms): Ajourneyfromgpttogpt-4.Medium,\nOctober 2023. URLhttps://medium.com/@mayankchugh.jobathk/the-evolution-of-large-l\nanguage-models-llms-a-journey-from-gpt-to-gpt-4o-618765889c98. Accessed: 2023-11-05.\n[19] Randolph R. Cornelius and Terri Gullickson. The science of emotion: Research and tradition in the\npsychology of emotion.Psyccritiques, 42, 1997. URLhttps://api.semanticscholar.org/Corpus\nID:140448064.\n[20] Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco. EMOVO cor-\npus: an Italian emotional speech database. In Nicoletta Calzolari, Khalid Choukri, Thierry De-\nclerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 93,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2351,
      "text": "ncion Moreno, Jan Odijk, and Stelios\nPiperidis, editors,Proceedings of the Ninth International Conference on Language Resources and\nEvaluation (LREC\u201914), pages 3501\u20133504, Reykjavik, Iceland, May 2014. European Language Re-\nsources Association (ELRA). URLhttp://www.lrec-conf.org/proceedings/lrec2014/pdf/591\n_Paper.pdf.\n[21] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos, and Roberto\nTurrin. Looking for \u201cgood\u201d recommendations: A comparative evaluation of recommender systems.\nIn Pedro Campos, Nicholas Graham, Joaquim Jorge, Nuno Nunes, Philippe Palanque, and Marco\nWinckler, editors,Human-Computer Interaction \u2013 INTERACT 2011, volume 6948, pages 152\u2013168.\nSpringer Berlin Heidelberg, 2011. ISBN 978-3-642-23764-5 978-3-642-23765-2. doi: 10.1007/978-3-6\n42-23765-2_11. URLhttp://link.springer.com/10.1007/978-3-642-23765-2_11. Series Title:\nLecture Notes in Computer Science.\n[22] DAIR.AI. Prompting techniques, 2024. URLhttps://www.promptingguide.ai/it/techniques.\n42\n[23] DAIR.AI. Prompt few-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/fews\nhot.\n[24] DAIR.AI. Prompt zero-shot, 2024. URLhttps://www.promptingguide.ai/it/techniques/zero\nshot.\n[25] Yashar Deldjoo, Fatemeh Nazary, Arnau Ramisa, Julian Mcauley, Giovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 94,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2352,
      "text": "ovanni Pellegrini, Alejandro\nBellogin, and Tommaso Di Noia. A review of modern fashion recommender systems, 2023. URL\nhttps://arxiv.org/abs/2202.02757.\n[26] Paul Ekman. An argument for basic emotions.Cognition and Emotion, 6(3):169\u2013200, 1992. ISSN\n0269-9931, 1464-0600. doi: 10.1080/02699939208411068. URLhttps://www.tandfonline.com/do\ni/full/10.1080/02699939208411068.\n[27] Paul Ekman, Wallace V Friesen, Maureen O\u2019sullivan, Anthony Chan, Irene Diacoyanni-Tarlatzis,\nKarl Heider, Rainer Krause, William Ayhan LeCompte, Tom Pitcairn, Pio E Ricci-Bitti, et al.\nUniversals and cultural differences in the judgments of facial expressions of emotion.Journal of\npersonality and social psychology, 53(4):712, 1987. URLhttps://psycnet.apa.org/buy/1988-0\n4343-001.\n[28] Inger Sams\u00f8 Engberg and Anya Varnich Hansen.Documentation of the Emotional Speech Data Base,\nDES. Aalborg Universitetsforlag, 1996. URLhttps://vbn.aau.dk/en/publications/documenta\ntion-of-the-emotional-speech-data-base-des. Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet Kun begr\u00e6nset udl\u00e5n gennem henvendelse til\nCenter for Personkommunikation, Aalborg Universitet.\n[29] Tom B. Brown et al. Language models are few-shot learners, 2020. URLhttps://arxiv.org/abs/\n2005.14165.\n[30] Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 95,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2353,
      "text": "Feine, Ulrich Gnewuch, Stefan Morana, and Alexander Maedche. A taxonomy of social cues\nfor conversational agents.International Journal of Human-Computer Studies, 132:138\u2013161, 07 2019.\ndoi: 10.1016/j.ijhcs.2019.07.009. URLhttps://www.sciencedirect.com/science/article/pii/\nS1071581918305238.\n[31] Rani P Gadhe, RA Shaikh Nilofer, VB Waghmare, PP Shrishrimal, and RR Deshmukh. Emotion\nrecognition from speech: a survey.International journal of scientific & engineering research, 6(4):\n632\u2013635, 2015. URLhttps://www.researchgate.net/profile/Ratnadeep-Deshmukh-2/publica\ntion/278301525_Emotion_Recognition_from_Speech_A_Survey/links/557ea48908aeea18b777\ne2a2/Emotion-Recognition-from-Speech-A-Survey.pdf.\n[32] Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, and Alexandre\nAraujo. R-lpips: An adversarially robust perceptual similarity metric, 2023. URLhttps://arxiv.\norg/abs/2307.15157.\n[33] LouieGiray. PromptengineeringwithChatGPT:Aguideforacademicwriters.Annals of Biomedical\nEngineering, 51(12):2629\u20132633, 2023. ISSN 0090-6964, 1573-9686. doi: 10.1007/s10439-023-03272-4.\nURLhttps://link.springer.com/10.1007/s10439-023-03272-4.\n[34] Diksha Khurana, Aditya Koli, Kiran Khatter, and Sukhdev Singh. Natural language processing:\nstate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 96,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2354,
      "text": "ate of the art, current trends and challenges.Multimedia Tools and Applications, 82(3):3713\u20133744,\n2023. ISSN 1573-7721. doi: 10.1007/s11042-022-13428-4. URLhttps://doi.org/10.1007/s11042\n-022-13428-4.\n[35] Swarna Kuchibhotla, Hima Vankayalapati, Radhesyam Vaddi, and koteswara rao Anne. A com-\nparative analysis of classifiers in emotion recognition through acoustic features.International\nJournal of Speech Technology, 17, 12 2014. doi: 10.1007/s10772-014-9239-3. URLhttps:\n//link.springer.com/article/10.1007/s10772-014-9239-3.\n[36] Jennifer S. Lerner, Ye Li, Piercarlo Valdesolo, and Karim S. Kassam. Emotion and decision making.\nAnnual Review of Psychology, 66(1):799\u2013823, 2015. ISSN 0066-4308, 1545-2085. doi: 10.1146/annu\nrev-psych-010213-115043. URLhttps://www.annualreviews.org/doi/10.1146/annurev-psych\n-010213-115043.\n[37] JamesR.Lewis,BrianS.Utesch,andDeborahE.Maher. Umux-lite: whenthere\u2019snotimeforthesus.\nInProceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201913, page\n43\n2099\u20132102, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450318990.\ndoi: 10.1145/2470654.2481287. URLhttps://doi.org/10.1145/2470654.2481287.\n[38] James R. Lewis, Brian S. Utesch, and Deborah E. Maher. Measuring perceived usability: The\nSUS, UMUX-LITE, and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 97,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2355,
      "text": ", and AltUsability.International Journal of Human-Computer Interaction, 31\n(8):496\u2013505, 2015. ISSN 1044-7318, 1532-7590. doi: 10.1080/10447318.2015.1064654. URL\nhttp://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064654.\n[39] Wendy E. Mackay. DOIT: The design of interactive things. selected methods for quickly and effec-\ntively designing interactive systems from the user\u2019s perspective. InExtended Abstracts of the 2023\nCHI Conference on Human Factors in Computing Systems, pages 1\u20133. ACM, 2023. ISBN 978-1-\n4503-9422-2. doi: 10.1145/3544549.3574172. URLhttps://dl.acm.org/doi/10.1145/3544549.3\n574172.\n[40] Stacy Marsella and Jonathan Gratch. Modeling coping behavior in virtual humans: don\u2019t worry,\nbe happy. InProceedings of the second international joint conference on Autonomous agents and\nmultiagent systems, pages 313\u2013320. ACM, 2003. ISBN 978-1-58113-683-8. doi: 10.1145/860575.860\n626. URLhttps://dl.acm.org/doi/10.1145/860575.860626.\n[41] OpenAI. Gpt-4o system card. Technical report, August 2024. URLhttps://cdn.openai.com/g\npt-4o-system-card.pdf. Detailed system card documenting GPT-4o capabilities, limitations, and\nsafety evaluations.\n[42] Keiron O\u2019Shea and Ryan Nash. An introduction to convolutional neural networks, 2015. URL\nhttps://arxiv.org/abs/1511.08458.\n[43] Ana Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 98,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2356,
      "text": "na Paiva, Joao Dias, Daniel Sobral, Ruth Aylett, Polly Sobreperez, Sarah Woods, Carsten Zoll,\nand Lynne Hall. Caring for agents and agents that care: Building empathic relations with synthetic\nagents. InAutonomous Agents and Multiagent Systems, International Joint Conference on, volume2,\npages 194\u2013201. IEEE Computer Society, 2004. URLhttps://fas-web.sunderland.ac.uk/~cs0lh\na/Publications/2004/026_paivaa_empathic.pdf.\n[44] RosalindW.Picard.Affective computing. MITPress,Cambridge,MA,USA,1997. ISBN0262161702.\n[45] Dhanya Pramod and Prafulla Bafna. Conversational recommender systems techniques, tools, accep-\ntance, and adoption: A state of the art review.Expert Systems with Applications, 203:117539, 2022.\nISSN 09574174. doi: 10.1016/j.eswa.2022.117539. URLhttps://linkinghub.elsevier.com/retr\nieve/pii/S0957417422008612.\n[46] Helmut Prendinger.Intelligent Virtual Agents: 8th International Conference, IVA 2008, Tokyo,\nJapan, September 1-3, 2008, Proceedings. Number v.5208 in Lecture Notes in Computer Science Ser.\nSpringer Berlin / Heidelberg, 2008. ISBN 978-3-540-85482-1 978-3-540-85483-8.\n[47] Sapna, Ria Chakraborty, Anagha M., Kartikeya Vats, Khyati Baradia, Tanveer Khan, Sandipan\nSarkar, and Sujoy Roychowdhury. Recommendence and fashionsence: Online fashion advisor for\noffline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 99,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2357,
      "text": "fline experience. InProceedings of the ACM India Joint International Conference on Data Science\nand Management of Data, pages 256\u2013259. ACM, 2019. ISBN 978-1-4503-6207-8. doi: 10.1145/3297\n001.3297035. URLhttps://dl.acm.org/doi/10.1145/3297001.3297035.\n[48] Disa A. Sauter, Frank Eisner, Paul Ekman, and Sophie K. Scott. Cross-cultural recognition of\nbasic emotions through nonverbal emotional vocalizations.Proceedings of the National Academy of\nSciences, 107(6):2408\u20132412, 2010. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.0908239106. URL\nhttps://pnas.org/doi/full/10.1073/pnas.0908239106.\n[49] Poonam Sharma and Akansha Singh. Era of deep neural networks: A review. In2017 8th Interna-\ntional Conference on Computing, Communication and Networking Technologies (ICCCNT), pages\n1\u20135, 2017. doi: 10.1109/ICCCNT.2017.8203938. URLhttps://ieeexplore.ieee.org/abstract\n/document/8203938.\n[50] Satwinder Singh and Himanshu Beniwal. A survey on near-human conversational agents.Journal\nof King Saud University - Computer and Information Sciences, 34(10):8852\u20138866, 2022. ISSN 1319-\n1578. doi: 10.1016/j.jksuci.2021.10.013. URLhttps://www.sciencedirect.com/science/articl\ne/pii/S1319157821003001.\n44\n[51] Micol Spitale and Franca Garzotto. Towards empathic conversational interaction. InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 100,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2358,
      "text": "InProceedings of\nthe 2nd Conference on Conversational User Interfaces, pages 1\u20134. ACM, 2020. ISBN 978-1-4503-\n7544-3. doi: 10.1145/3405755.3406146. URLhttps://dl.acm.org/doi/10.1145/3405755.34061\n46.\n[52] Hugo Touvron and Thibaut Lavril et al. Llama: Open and efficient foundation language models,\n2023. URLhttps://arxiv.org/abs/2302.13971.\n[53] Dirk Valkenborg, Axel-Jan Rousseau, Melvin Geubbelmans, and Tomasz Burzykowski. Support\nvector machines.American Journal of Orthodontics and Dentofacial Orthopedics, 164(5):754\u2013757,\n2023. ISSN 08895406. doi: 10.1016/j.ajodo.2023.08.003. URLhttps://linkinghub.elsevier.co\nm/retrieve/pii/S0889540623004298.\n[54] Wenwu Wang, editor.Machine Audition: Principles, Algorithms and Systems. IGI Global, 2011.\nISBN 978-1-61520-919-4 978-1-61520-920-0. doi: 10.4018/978-1-61520-919-4. URLhttp://servic\nes.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-61520-919-4.\n[55] JulesWhite, QuchenFu, SamHays, MichaelSandborn, CarlosOlea, HenryGilbert, AshrafElnashar,\nJesse Spencer-Smith, and Douglas C. Schmidt. A prompt pattern catalog to enhance prompt engi-\nneering with chatgpt, 2023. URLhttps://arxiv.org/abs/2302.11382.\n[56] Hong Zhang and Haijian Shao. Exploring the latest applications of OpenAI and ChatGPT: An in-\ndepth survey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li."
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 101,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2359,
      "text": "ey.Computer Modeling in Engineering & Sciences, 138(3):2061\u20132102, 2024. ISSN 1526-\n1506. doi: 10.32604/cmes.2023.030649. URLhttps://www.techscience.com/CMES/v138n3/54939.\n[57] Min Zhang and Juntao Li. A commentary of gpt-3 in mit technology review 2021.Fundamental\nResearch, 1(6):831\u2013833, 2021. ISSN 2667-3258. doi: https://doi.org/10.1016/j.fmre.2021.11.011.\nURLhttps://www.sciencedirect.com/science/article/pii/S2667325821002193.\n[58] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    },
    {
      "paper_id": "6a8a6584-1632-49ef-a331-c8327b62d124",
      "chunk_id": 102,
      "pdf_path": "C:\\Users\\tehrim\\Documents\\CapstoneProject-IRIS\\iris\\backend\\data\\pdfs\\6a8a6584-1632-49ef-a331-c8327b62d124.pdf",
      "doc_id": 2360,
      "text": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, and et al. A survey\nof large language models. Number arXiv:2303.18223. arXiv, 2024. URLhttp://arxiv.org/abs/\n2303.18223.\n45"
    }
  ],
  "doc_count": 2361,
  "model_name": "all-MiniLM-L6-v2",
  "dim": 384
}